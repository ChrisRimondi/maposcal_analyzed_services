[
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"sync/atomic\"\n)\n\n// UsagePool is a thread-safe map that pools values\n// based on usage (reference counting). Values are\n// only inserted if they do not already exist. There\n// are two ways to add values to the pool:\n//\n//  1. LoadOrStore will increment usage and store the\n//     value immediately if it does not already exist.\n//  2. LoadOrNew will atomically check for existence\n//     and construct the value immediately if it does\n//     not already exist, or increment the usage\n//     otherwise, then store that value in the pool.\n//     When the constructed value is finally deleted\n//     from the pool (when its usage reaches 0), it\n//     will be cleaned up by calling Destruct().\n//\n// The use of LoadOrNew allows values to be created\n// and reused and finally cleaned up only once, even\n// though they may have many references throughout\n// their lifespan. This is helpful, for example, when\n// sharing thread-safe io.Writers that you only want\n// to open and close once.\n//\n// There is no way to overwrite existing keys in the\n// pool without first deleting it as many times as it\n// was stored. Deleting too many times will panic.\n//\n// The implementation does not use a sync.Pool because\n// UsagePool needs additional atomicity to run the\n// constructor functions when creating a new value when\n// LoadOrNew is used. (We could probably use sync.Pool\n// but we'd still have to layer our own additional locks\n// on top.)\n//\n// An empty UsagePool is NOT safe to use; always call\n// NewUsagePool() to make a new one.\ntype UsagePool struct {\n\tsync.RWMutex\n\tpool map[any]*usagePoolVal\n}\n\n// NewUsagePool returns a new usage pool that is ready to use.\nfunc NewUsagePool() *UsagePool {\n\treturn &UsagePool{\n\t\tpool: make(map[any]*usagePoolVal),\n\t}\n}\n\n// LoadOrNew loads the value associated with key from the pool if it\n// already exists. If the key doesn't exist, it will call construct\n// to create a new value and then stores that in the pool. An error\n// is only returned if the constructor returns an error. The loaded\n// or constructed value is returned. The loaded return value is true\n// if the value already existed and was loaded, or false if it was\n// newly constructed.\nfunc (up *UsagePool) LoadOrNew(key any, construct Constructor) (value any, loaded bool, err error) {\n\tvar upv *usagePoolVal\n\tup.Lock()\n\tupv, loaded = up.pool[key]\n\tif loaded {\n\t\tatomic.AddInt32(&upv.refs, 1)\n\t\tup.Unlock()\n\t\tupv.RLock()\n\t\tvalue = upv.value\n\t\terr = upv.err\n\t\tupv.RUnlock()\n\t} else {\n\t\tupv = &usagePoolVal{refs: 1}\n\t\tupv.Lock()\n\t\tup.pool[key] = upv\n\t\tup.Unlock()\n\t\tvalue, err = construct()\n\t\tif err == nil {\n\t\t\tupv.value = value\n\t\t} else {\n\t\t\tupv.err = err\n\t\t\tup.Lock()\n\t\t\t// this *should* be safe, I think, because we have a\n\t\t\t// write lock on upv, but we might also need to ensure\n\t\t\t// that upv.err is nil before doing this, since we\n\t\t\t// released the write lock on up during construct...\n\t\t\t// but then again it's also after midnight...\n\t\t\tdelete(up.pool, key)\n\t\t\tup.Unlock()\n\t\t}\n\t\tupv.Unlock()\n\t}\n\treturn\n}\n\n// LoadOrStore loads the value associated with key from the pool if it\n// already exists, or stores it if it does not exist. It returns the\n// value that was either loaded or stored, and true if the value already\n// existed and was loaded, false if the value didn't exist and was stored.\nfunc (up *UsagePool) LoadOrStore(key, val any) (value any, loaded bool) {\n\tvar upv *usagePoolVal\n\tup.Lock()\n\tupv, loaded = up.pool[key]\n\tif loaded {\n\t\tatomic.AddInt32(&upv.refs, 1)\n\t\tup.Unlock()\n\t\tupv.Lock()\n\t\tif upv.err == nil {\n\t\t\tvalue = upv.value\n\t\t} else {\n\t\t\tupv.value = val\n\t\t\tupv.err = nil\n\t\t}\n\t\tupv.Unlock()\n\t} else {\n\t\tupv = &usagePoolVal{refs: 1, value: val}\n\t\tup.pool[key] = upv\n\t\tup.Unlock()\n\t\tvalue = val\n\t}\n\treturn\n}\n\n// Range iterates the pool similarly to how sync.Map.Range() does:\n// it calls f for every key in the pool, and if f returns false,\n// iteration is stopped. Ranging does not affect usage counts.\n//\n// This method is somewhat naive and acquires a read lock on the\n// entire pool during iteration, so do your best to make f() really\n// fast, m'kay?\nfunc (up *UsagePool) Range(f func(key, value any) bool) {\n\tup.RLock()\n\tdefer up.RUnlock()\n\tfor key, upv := range up.pool {\n\t\tupv.RLock()\n\t\tif upv.err != nil {\n\t\t\tupv.RUnlock()\n\t\t\tcontinue\n\t\t}\n\t\tval := upv.value\n\t\tupv.RUnlock()\n\t\tif !f(key, val) {\n\t\t\tbreak\n\t\t}\n\t}\n}\n\n// Delete decrements the usage count for key and removes the\n// value from the underlying map if the usage is 0. It returns\n// true if the usage count reached 0 and the value was deleted.\n// It panics if the usage count drops below 0; always call\n// Delete precisely as many times as LoadOrStore.\nfunc (up *UsagePool) Delete(key any) (deleted bool, err error) {\n\tup.Lock()\n\tupv, ok := up.pool[key]\n\tif !ok {\n\t\tup.Unlock()\n\t\treturn false, nil\n\t}\n\trefs := atomic.AddInt32(&upv.refs, -1)\n\tif refs == 0 {\n\t\tdelete(up.pool, key)\n\t\tup.Unlock()\n\t\tupv.RLock()\n\t\tval := upv.value\n\t\tupv.RUnlock()\n\t\tif destructor, ok := val.(Destructor); ok {\n\t\t\terr = destructor.Destruct()\n\t\t}\n\t\tdeleted = true\n\t} else {\n\t\tup.Unlock()\n\t\tif refs < 0 {\n\t\t\tpanic(fmt.Sprintf(\"deleted more than stored: %#v (usage: %d)\",\n\t\t\t\tupv.value, upv.refs))\n\t\t}\n\t}\n\treturn\n}\n\n// References returns the number of references (count of usages) to a\n// key in the pool, and true if the key exists, or false otherwise.\nfunc (up *UsagePool) References(key any) (int, bool) {\n\tup.RLock()\n\tupv, loaded := up.pool[key]\n\tup.RUnlock()\n\tif loaded {\n\t\t// I wonder if it'd be safer to read this value during\n\t\t// our lock on the UsagePool... guess we'll see...\n\t\trefs := atomic.LoadInt32(&upv.refs)\n\t\treturn int(refs), true\n\t}\n\treturn 0, false\n}\n\n// Constructor is a function that returns a new value\n// that can destruct itself when it is no longer needed.\ntype Constructor func() (Destructor, error)\n\n// Destructor is a value that can clean itself up when\n// it is deallocated.\ntype Destructor interface {\n\tDestruct() error\n}\n\ntype usagePoolVal struct {\n\trefs  int32 // accessed atomically; must be 64-bit aligned for 32-bit systems\n\tvalue any\n\terr   error\n\tsync.RWMutex\n}\n",
    "source_file": "usagepool.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"net\"\n\t\"net/netip\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\n\t\"github.com/quic-go/quic-go\"\n\t\"github.com/quic-go/quic-go/http3\"\n\t\"github.com/quic-go/quic-go/qlog\"\n\t\"go.uber.org/zap\"\n\t\"golang.org/x/time/rate\"\n\n\t\"github.com/caddyserver/caddy/v2/internal\"\n)\n\n// NetworkAddress represents one or more network addresses.\n// It contains the individual components for a parsed network\n// address of the form accepted by ParseNetworkAddress().\ntype NetworkAddress struct {\n\t// Should be a network value accepted by Go's net package or\n\t// by a plugin providing a listener for that network type.\n\tNetwork string\n\n\t// The \"main\" part of the network address is the host, which\n\t// often takes the form of a hostname, DNS name, IP address,\n\t// or socket path.\n\tHost string\n\n\t// For addresses that contain a port, ranges are given by\n\t// [StartPort, EndPort]; i.e. for a single port, StartPort\n\t// and EndPort are the same. For no port, they are 0.\n\tStartPort uint\n\tEndPort   uint\n}\n\n// ListenAll calls Listen for all addresses represented by this struct, i.e. all ports in the range.\n// (If the address doesn't use ports or has 1 port only, then only 1 listener will be created.)\n// It returns an error if any listener failed to bind, and closes any listeners opened up to that point.\nfunc (na NetworkAddress) ListenAll(ctx context.Context, config net.ListenConfig) ([]any, error) {\n\tvar listeners []any\n\tvar err error\n\n\t// if one of the addresses has a failure, we need to close\n\t// any that did open a socket to avoid leaking resources\n\tdefer func() {\n\t\tif err == nil {\n\t\t\treturn\n\t\t}\n\t\tfor _, ln := range listeners {\n\t\t\tif cl, ok := ln.(io.Closer); ok {\n\t\t\t\tcl.Close()\n\t\t\t}\n\t\t}\n\t}()\n\n\t// an address can contain a port range, which represents multiple addresses;\n\t// some addresses don't use ports at all and have a port range size of 1;\n\t// whatever the case, iterate each address represented and bind a socket\n\tfor portOffset := uint(0); portOffset < na.PortRangeSize(); portOffset++ {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil, ctx.Err()\n\t\tdefault:\n\t\t}\n\n\t\t// create (or reuse) the listener ourselves\n\t\tvar ln any\n\t\tln, err = na.Listen(ctx, portOffset, config)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tlisteners = append(listeners, ln)\n\t}\n\n\treturn listeners, nil\n}\n\n// Listen is similar to net.Listen, with a few differences:\n//\n// Listen announces on the network address using the port calculated by adding\n// portOffset to the start port. (For network types that do not use ports, the\n// portOffset is ignored.)\n//\n// First Listen checks if a plugin can provide a listener from this address. Otherwise,\n// the provided ListenConfig is used to create the listener. Its Control function,\n// if set, may be wrapped by an internally-used Control function. The provided\n// context may be used to cancel long operations early. The context is not used\n// to close the listener after it has been created.\n//\n// Caddy's listeners can overlap each other: multiple listeners may be created on\n// the same socket at the same time. This is useful because during config changes,\n// the new config is started while the old config is still running. How this is\n// accomplished varies by platform and network type. For example, on Unix, SO_REUSEPORT\n// is set except on Unix sockets, for which the file descriptor is duplicated and\n// reused; on Windows, the close logic is virtualized using timeouts. Like normal\n// listeners, be sure to Close() them when you are done.\n//\n// This method returns any type, as the implementations of listeners for various\n// network types are not interchangeable. The type of listener returned is switched\n// on the network type. Stream-based networks (\"tcp\", \"unix\", \"unixpacket\", etc.)\n// return a net.Listener; datagram-based networks (\"udp\", \"unixgram\", etc.) return\n// a net.PacketConn; and so forth. The actual concrete types are not guaranteed to\n// be standard, exported types (wrapping is necessary to provide graceful reloads).\n//\n// Unix sockets will be unlinked before being created, to ensure we can bind to\n// it even if the previous program using it exited uncleanly; it will also be\n// unlinked upon a graceful exit (or when a new config does not use that socket).\n// Listen synchronizes binds to unix domain sockets to avoid race conditions\n// while an existing socket is unlinked.\nfunc (na NetworkAddress) Listen(ctx context.Context, portOffset uint, config net.ListenConfig) (any, error) {\n\tif na.IsUnixNetwork() {\n\t\tunixSocketsMu.Lock()\n\t\tdefer unixSocketsMu.Unlock()\n\t}\n\n\t// check to see if plugin provides listener\n\tif ln, err := getListenerFromPlugin(ctx, na.Network, na.Host, na.port(), portOffset, config); ln != nil || err != nil {\n\t\treturn ln, err\n\t}\n\n\t// create (or reuse) the listener ourselves\n\treturn na.listen(ctx, portOffset, config)\n}\n\nfunc (na NetworkAddress) listen(ctx context.Context, portOffset uint, config net.ListenConfig) (any, error) {\n\tvar (\n\t\tln           any\n\t\terr          error\n\t\taddress      string\n\t\tunixFileMode fs.FileMode\n\t)\n\n\t// split unix socket addr early so lnKey\n\t// is independent of permissions bits\n\tif na.IsUnixNetwork() {\n\t\taddress, unixFileMode, err = internal.SplitUnixSocketPermissionsBits(na.Host)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t} else if na.IsFdNetwork() {\n\t\taddress = na.Host\n\t} else {\n\t\taddress = na.JoinHostPort(portOffset)\n\t}\n\n\tif strings.HasPrefix(na.Network, \"ip\") {\n\t\tln, err = config.ListenPacket(ctx, na.Network, address)\n\t} else {\n\t\tif na.IsUnixNetwork() {\n\t\t\t// if this is a unix socket, see if we already have it open\n\t\t\tln, err = reuseUnixSocket(na.Network, address)\n\t\t}\n\n\t\tif ln == nil && err == nil {\n\t\t\t// otherwise, create a new listener\n\t\t\tlnKey := listenerKey(na.Network, address)\n\t\t\tln, err = listenReusable(ctx, lnKey, na.Network, address, config)\n\t\t}\n\t}\n\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif ln == nil {\n\t\treturn nil, fmt.Errorf(\"unsupported network type: %s\", na.Network)\n\t}\n\n\tif IsUnixNetwork(na.Network) {\n\t\tisAbstractUnixSocket := strings.HasPrefix(address, \"@\")\n\t\tif !isAbstractUnixSocket {\n\t\t\terr = os.Chmod(address, unixFileMode)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"unable to set permissions (%s) on %s: %v\", unixFileMode, address, err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ln, nil\n}\n\n// IsUnixNetwork returns true if na.Network is\n// unix, unixgram, or unixpacket.\nfunc (na NetworkAddress) IsUnixNetwork() bool {\n\treturn IsUnixNetwork(na.Network)\n}\n\n// IsFdNetwork returns true if na.Network is\n// fd or fdgram.\nfunc (na NetworkAddress) IsFdNetwork() bool {\n\treturn IsFdNetwork(na.Network)\n}\n\n// JoinHostPort is like net.JoinHostPort, but where the port\n// is StartPort + offset.\nfunc (na NetworkAddress) JoinHostPort(offset uint) string {\n\tif na.IsUnixNetwork() || na.IsFdNetwork() {\n\t\treturn na.Host\n\t}\n\treturn net.JoinHostPort(na.Host, strconv.FormatUint(uint64(na.StartPort+offset), 10))\n}\n\n// Expand returns one NetworkAddress for each port in the port range.\nfunc (na NetworkAddress) Expand() []NetworkAddress {\n\tsize := na.PortRangeSize()\n\taddrs := make([]NetworkAddress, size)\n\tfor portOffset := uint(0); portOffset < size; portOffset++ {\n\t\taddrs[portOffset] = na.At(portOffset)\n\t}\n\treturn addrs\n}\n\n// At returns a NetworkAddress with a port range of just 1\n// at the given port offset; i.e. a NetworkAddress that\n// represents precisely 1 address only.\nfunc (na NetworkAddress) At(portOffset uint) NetworkAddress {\n\tna2 := na\n\tna2.StartPort, na2.EndPort = na.StartPort+portOffset, na.StartPort+portOffset\n\treturn na2\n}\n\n// PortRangeSize returns how many ports are in\n// pa's port range. Port ranges are inclusive,\n// so the size is the difference of start and\n// end ports plus one.\nfunc (na NetworkAddress) PortRangeSize() uint {\n\tif na.EndPort < na.StartPort {\n\t\treturn 0\n\t}\n\treturn (na.EndPort - na.StartPort) + 1\n}\n\nfunc (na NetworkAddress) isLoopback() bool {\n\tif na.IsUnixNetwork() || na.IsFdNetwork() {\n\t\treturn true\n\t}\n\tif na.Host == \"localhost\" {\n\t\treturn true\n\t}\n\tif ip, err := netip.ParseAddr(na.Host); err == nil {\n\t\treturn ip.IsLoopback()\n\t}\n\treturn false\n}\n\nfunc (na NetworkAddress) isWildcardInterface() bool {\n\tif na.Host == \"\" {\n\t\treturn true\n\t}\n\tif ip, err := netip.ParseAddr(na.Host); err == nil {\n\t\treturn ip.IsUnspecified()\n\t}\n\treturn false\n}\n\nfunc (na NetworkAddress) port() string {\n\tif na.StartPort == na.EndPort {\n\t\treturn strconv.FormatUint(uint64(na.StartPort), 10)\n\t}\n\treturn fmt.Sprintf(\"%d-%d\", na.StartPort, na.EndPort)\n}\n\n// String reconstructs the address string for human display.\n// The output can be parsed by ParseNetworkAddress(). If the\n// address is a unix socket, any non-zero port will be dropped.\nfunc (na NetworkAddress) String() string {\n\tif na.Network == \"tcp\" && (na.Host != \"\" || na.port() != \"\") {\n\t\tna.Network = \"\" // omit default network value for brevity\n\t}\n\treturn JoinNetworkAddress(na.Network, na.Host, na.port())\n}\n\n// IsUnixNetwork returns true if the netw is a unix network.\nfunc IsUnixNetwork(netw string) bool {\n\treturn strings.HasPrefix(netw, \"unix\")\n}\n\n// IsFdNetwork returns true if the netw is a fd network.\nfunc IsFdNetwork(netw string) bool {\n\treturn strings.HasPrefix(netw, \"fd\")\n}\n\n// ParseNetworkAddress parses addr into its individual\n// components. The input string is expected to be of\n// the form \"network/host:port-range\" where any part is\n// optional. The default network, if unspecified, is tcp.\n// Port ranges are inclusive.\n//\n// Network addresses are distinct from URLs and do not\n// use URL syntax.\nfunc ParseNetworkAddress(addr string) (NetworkAddress, error) {\n\treturn ParseNetworkAddressWithDefaults(addr, \"tcp\", 0)\n}\n\n// ParseNetworkAddressWithDefaults is like ParseNetworkAddress but allows\n// the default network and port to be specified.\nfunc ParseNetworkAddressWithDefaults(addr, defaultNetwork string, defaultPort uint) (NetworkAddress, error) {\n\tvar host, port string\n\tnetwork, host, port, err := SplitNetworkAddress(addr)\n\tif err != nil {\n\t\treturn NetworkAddress{}, err\n\t}\n\tif network == \"\" {\n\t\tnetwork = defaultNetwork\n\t}\n\tif IsUnixNetwork(network) {\n\t\t_, _, err := internal.SplitUnixSocketPermissionsBits(host)\n\t\treturn NetworkAddress{\n\t\t\tNetwork: network,\n\t\t\tHost:    host,\n\t\t}, err\n\t}\n\tif IsFdNetwork(network) {\n\t\treturn NetworkAddress{\n\t\t\tNetwork: network,\n\t\t\tHost:    host,\n\t\t}, nil\n\t}\n\tvar start, end uint64\n\tif port == \"\" {\n\t\tstart = uint64(defaultPort)\n\t\tend = uint64(defaultPort)\n\t} else {\n\t\tbefore, after, found := strings.Cut(port, \"-\")\n\t\tif !found {\n\t\t\tafter = before\n\t\t}\n\t\tstart, err = strconv.ParseUint(before, 10, 16)\n\t\tif err != nil {\n\t\t\treturn NetworkAddress{}, fmt.Errorf(\"invalid start port: %v\", err)\n\t\t}\n\t\tend, err = strconv.ParseUint(after, 10, 16)\n\t\tif err != nil {\n\t\t\treturn NetworkAddress{}, fmt.Errorf(\"invalid end port: %v\", err)\n\t\t}\n\t\tif end < start {\n\t\t\treturn NetworkAddress{}, fmt.Errorf(\"end port must not be less than start port\")\n\t\t}\n\t\tif (end - start) > maxPortSpan {\n\t\t\treturn NetworkAddress{}, fmt.Errorf(\"port range exceeds %d ports\", maxPortSpan)\n\t\t}\n\t}\n\treturn NetworkAddress{\n\t\tNetwork:   network,\n\t\tHost:      host,\n\t\tStartPort: uint(start),\n\t\tEndPort:   uint(end),\n\t}, nil\n}\n\n// SplitNetworkAddress splits a into its network, host, and port components.\n// Note that port may be a port range (:X-Y), or omitted for unix sockets.\nfunc SplitNetworkAddress(a string) (network, host, port string, err error) {\n\tbeforeSlash, afterSlash, slashFound := strings.Cut(a, \"/\")\n\tif slashFound {\n\t\tnetwork = strings.ToLower(strings.TrimSpace(beforeSlash))\n\t\ta = afterSlash\n\t\tif IsUnixNetwork(network) || IsFdNetwork(network) {\n\t\t\thost = a\n\t\t\treturn\n\t\t}\n\t}\n\n\thost, port, err = net.SplitHostPort(a)\n\tfirstErr := err\n\n\tif err != nil {\n\t\t// in general, if there was an error, it was likely \"missing port\",\n\t\t// so try removing square brackets around an IPv6 host, adding a bogus\n\t\t// port to take advantage of standard library's robust parser, then\n\t\t// strip the artificial port.\n\t\thost, _, err = net.SplitHostPort(net.JoinHostPort(strings.Trim(a, \"[]\"), \"0\"))\n\t\tport = \"\"\n\t}\n\n\tif err != nil {\n\t\terr = errors.Join(firstErr, err)\n\t}\n\n\treturn\n}\n\n// JoinNetworkAddress combines network, host, and port into a single\n// address string of the form accepted by ParseNetworkAddress(). For\n// unix sockets, the network should be \"unix\" (or \"unixgram\" or\n// \"unixpacket\") and the path to the socket should be given as the\n// host parameter.\nfunc JoinNetworkAddress(network, host, port string) string {\n\tvar a string\n\tif network != \"\" {\n\t\ta = network + \"/\"\n\t}\n\tif (host != \"\" && port == \"\") || IsUnixNetwork(network) || IsFdNetwork(network) {\n\t\ta += host\n\t} else if port != \"\" {\n\t\ta += net.JoinHostPort(host, port)\n\t}\n\treturn a\n}\n\n// ListenQUIC returns a http3.QUICEarlyListener suitable for use in a Caddy module.\n//\n// The network will be transformed into a QUIC-compatible type if the same address can be used with\n// different networks. Currently this just means that for tcp, udp will be used with the same\n// address instead.\n//\n// NOTE: This API is EXPERIMENTAL and may be changed or removed.\nfunc (na NetworkAddress) ListenQUIC(ctx context.Context, portOffset uint, config net.ListenConfig, tlsConf *tls.Config) (http3.QUICEarlyListener, error) {\n\tlnKey := listenerKey(\"quic\"+na.Network, na.JoinHostPort(portOffset))\n\n\tsharedEarlyListener, _, err := listenerPool.LoadOrNew(lnKey, func() (Destructor, error) {\n\t\tlnAny, err := na.Listen(ctx, portOffset, config)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tln := lnAny.(net.PacketConn)\n\n\t\th3ln := ln\n\t\tfor {\n\t\t\t// retrieve the underlying socket, so quic-go can optimize.\n\t\t\tif unwrapper, ok := h3ln.(interface{ Unwrap() net.PacketConn }); ok {\n\t\t\t\th3ln = unwrapper.Unwrap()\n\t\t\t} else {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\tsqs := newSharedQUICState(tlsConf)\n\t\t// http3.ConfigureTLSConfig only uses this field and tls App sets this field as well\n\t\t//nolint:gosec\n\t\tquicTlsConfig := &tls.Config{GetConfigForClient: sqs.getConfigForClient}\n\t\t// Require clients to verify their source address when we're handling more than 1000 handshakes per second.\n\t\t// TODO: make tunable?\n\t\tlimiter := rate.NewLimiter(1000, 1000)\n\t\ttr := &quic.Transport{\n\t\t\tConn:                h3ln,\n\t\t\tVerifySourceAddress: func(addr net.Addr) bool { return !limiter.Allow() },\n\t\t}\n\t\tearlyLn, err := tr.ListenEarly(\n\t\t\thttp3.ConfigureTLSConfig(quicTlsConfig),\n\t\t\t&quic.Config{\n\t\t\t\tAllow0RTT: true,\n\t\t\t\tTracer:    qlog.DefaultConnectionTracer,\n\t\t\t},\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// TODO: figure out when to close the listener and the transport\n\t\t// using the original net.PacketConn to close them properly\n\t\treturn &sharedQuicListener{EarlyListener: earlyLn, packetConn: ln, sqs: sqs, key: lnKey}, nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tsql := sharedEarlyListener.(*sharedQuicListener)\n\t// add current tls.Config to sqs, so GetConfigForClient will always return the latest tls.Config in case of context cancellation\n\tctx, cancel := sql.sqs.addState(tlsConf)\n\n\treturn &fakeCloseQuicListener{\n\t\tsharedQuicListener: sql,\n\t\tcontext:            ctx,\n\t\tcontextCancel:      cancel,\n\t}, nil\n}\n\n// ListenerUsage returns the current usage count of the given listener address.\nfunc ListenerUsage(network, addr string) int {\n\tcount, _ := listenerPool.References(listenerKey(network, addr))\n\treturn count\n}\n\n// contextAndCancelFunc groups context and its cancelFunc\ntype contextAndCancelFunc struct {\n\tcontext.Context\n\tcontext.CancelFunc\n}\n\n// sharedQUICState manages GetConfigForClient\n// see issue: https://github.com/caddyserver/caddy/pull/4849\ntype sharedQUICState struct {\n\trmu           sync.RWMutex\n\ttlsConfs      map[*tls.Config]contextAndCancelFunc\n\tactiveTlsConf *tls.Config\n}\n\n// newSharedQUICState creates a new sharedQUICState\nfunc newSharedQUICState(tlsConfig *tls.Config) *sharedQUICState {\n\tsqtc := &sharedQUICState{\n\t\ttlsConfs:      make(map[*tls.Config]contextAndCancelFunc),\n\t\tactiveTlsConf: tlsConfig,\n\t}\n\tsqtc.addState(tlsConfig)\n\treturn sqtc\n}\n\n// getConfigForClient is used as tls.Config's GetConfigForClient field\nfunc (sqs *sharedQUICState) getConfigForClient(ch *tls.ClientHelloInfo) (*tls.Config, error) {\n\tsqs.rmu.RLock()\n\tdefer sqs.rmu.RUnlock()\n\treturn sqs.activeTlsConf.GetConfigForClient(ch)\n}\n\n// addState adds tls.Config and activeRequests to the map if not present and returns the corresponding context and its cancelFunc\n// so that when cancelled, the active tls.Config will change\nfunc (sqs *sharedQUICState) addState(tlsConfig *tls.Config) (context.Context, context.CancelFunc) {\n\tsqs.rmu.Lock()\n\tdefer sqs.rmu.Unlock()\n\n\tif cacc, ok := sqs.tlsConfs[tlsConfig]; ok {\n\t\treturn cacc.Context, cacc.CancelFunc\n\t}\n\n\tctx, cancel := context.WithCancel(context.Background())\n\twrappedCancel := func() {\n\t\tcancel()\n\n\t\tsqs.rmu.Lock()\n\t\tdefer sqs.rmu.Unlock()\n\n\t\tdelete(sqs.tlsConfs, tlsConfig)\n\t\tif sqs.activeTlsConf == tlsConfig {\n\t\t\t// select another tls.Config, if there is none,\n\t\t\t// related sharedQuicListener will be destroyed anyway\n\t\t\tfor tc := range sqs.tlsConfs {\n\t\t\t\tsqs.activeTlsConf = tc\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\tsqs.tlsConfs[tlsConfig] = contextAndCancelFunc{ctx, wrappedCancel}\n\t// there should be at most 2 tls.Configs\n\tif len(sqs.tlsConfs) > 2 {\n\t\tLog().Warn(\"quic listener tls configs are more than 2\", zap.Int(\"number of configs\", len(sqs.tlsConfs)))\n\t}\n\treturn ctx, wrappedCancel\n}\n\n// sharedQuicListener is like sharedListener, but for quic.EarlyListeners.\ntype sharedQuicListener struct {\n\t*quic.EarlyListener\n\tpacketConn net.PacketConn // we have to hold these because quic-go won't close listeners it didn't create\n\tsqs        *sharedQUICState\n\tkey        string\n}\n\n// Destruct closes the underlying QUIC listener and its associated net.PacketConn.\nfunc (sql *sharedQuicListener) Destruct() error {\n\t// close EarlyListener first to stop any operations being done to the net.PacketConn\n\t_ = sql.EarlyListener.Close()\n\t// then close the net.PacketConn\n\treturn sql.packetConn.Close()\n}\n\n// fakeClosedErr returns an error value that is not temporary\n// nor a timeout, suitable for making the caller think the\n// listener is actually closed\nfunc fakeClosedErr(l interface{ Addr() net.Addr }) error {\n\treturn &net.OpError{\n\t\tOp:   \"accept\",\n\t\tNet:  l.Addr().Network(),\n\t\tAddr: l.Addr(),\n\t\tErr:  errFakeClosed,\n\t}\n}\n\n// errFakeClosed is the underlying error value returned by\n// fakeCloseListener.Accept() after Close() has been called,\n// indicating that it is pretending to be closed so that the\n// server using it can terminate, while the underlying\n// socket is actually left open.\nvar errFakeClosed = fmt.Errorf(\"listener 'closed' \ud83d\ude09\")\n\ntype fakeCloseQuicListener struct {\n\tclosed              int32 // accessed atomically; belongs to this struct only\n\t*sharedQuicListener       // embedded, so we also become a quic.EarlyListener\n\tcontext             context.Context\n\tcontextCancel       context.CancelFunc\n}\n\n// Currently Accept ignores the passed context, however a situation where\n// someone would need a hotswappable QUIC-only (not http3, since it uses context.Background here)\n// server on which Accept would be called with non-empty contexts\n// (mind that the default net listeners' Accept doesn't take a context argument)\n// sounds way too rare for us to sacrifice efficiency here.\nfunc (fcql *fakeCloseQuicListener) Accept(_ context.Context) (quic.EarlyConnection, error) {\n\tconn, err := fcql.sharedQuicListener.Accept(fcql.context)\n\tif err == nil {\n\t\treturn conn, nil\n\t}\n\n\t// if the listener is \"closed\", return a fake closed error instead\n\tif atomic.LoadInt32(&fcql.closed) == 1 && errors.Is(err, context.Canceled) {\n\t\treturn nil, fakeClosedErr(fcql)\n\t}\n\treturn nil, err\n}\n\nfunc (fcql *fakeCloseQuicListener) Close() error {\n\tif atomic.CompareAndSwapInt32(&fcql.closed, 0, 1) {\n\t\tfcql.contextCancel()\n\t\t_, _ = listenerPool.Delete(fcql.sharedQuicListener.key)\n\t}\n\treturn nil\n}\n\n// RegisterNetwork registers a network type with Caddy so that if a listener is\n// created for that network type, getListener will be invoked to get the listener.\n// This should be called during init() and will panic if the network type is standard\n// or reserved, or if it is already registered. EXPERIMENTAL and subject to change.\nfunc RegisterNetwork(network string, getListener ListenerFunc) {\n\tnetwork = strings.TrimSpace(strings.ToLower(network))\n\n\tif network == \"tcp\" || network == \"tcp4\" || network == \"tcp6\" ||\n\t\tnetwork == \"udp\" || network == \"udp4\" || network == \"udp6\" ||\n\t\tnetwork == \"unix\" || network == \"unixpacket\" || network == \"unixgram\" ||\n\t\tstrings.HasPrefix(network, \"ip:\") || strings.HasPrefix(network, \"ip4:\") || strings.HasPrefix(network, \"ip6:\") ||\n\t\tnetwork == \"fd\" || network == \"fdgram\" {\n\t\tpanic(\"network type \" + network + \" is reserved\")\n\t}\n\n\tif _, ok := networkTypes[strings.ToLower(network)]; ok {\n\t\tpanic(\"network type \" + network + \" is already registered\")\n\t}\n\n\tnetworkTypes[network] = getListener\n}\n\nvar unixSocketsMu sync.Mutex\n\n// getListenerFromPlugin returns a listener on the given network and address\n// if a plugin has registered the network name. It may return (nil, nil) if\n// no plugin can provide a listener.\nfunc getListenerFromPlugin(ctx context.Context, network, host, port string, portOffset uint, config net.ListenConfig) (any, error) {\n\t// get listener from plugin if network type is registered\n\tif getListener, ok := networkTypes[network]; ok {\n\t\tLog().Debug(\"getting listener from plugin\", zap.String(\"network\", network))\n\t\treturn getListener(ctx, network, host, port, portOffset, config)\n\t}\n\n\treturn nil, nil\n}\n\nfunc listenerKey(network, addr string) string {\n\treturn network + \"/\" + addr\n}\n\n// ListenerFunc is a function that can return a listener given a network and address.\n// The listeners must be capable of overlapping: with Caddy, new configs are loaded\n// before old ones are unloaded, so listeners may overlap briefly if the configs\n// both need the same listener. EXPERIMENTAL and subject to change.\ntype ListenerFunc func(ctx context.Context, network, host, portRange string, portOffset uint, cfg net.ListenConfig) (any, error)\n\nvar networkTypes = map[string]ListenerFunc{}\n\n// ListenerWrapper is a type that wraps a listener\n// so it can modify the input listener's methods.\n// Modules that implement this interface are found\n// in the caddy.listeners namespace. Usually, to\n// wrap a listener, you will define your own struct\n// type that embeds the input listener, then\n// implement your own methods that you want to wrap,\n// calling the underlying listener's methods where\n// appropriate.\ntype ListenerWrapper interface {\n\tWrapListener(net.Listener) net.Listener\n}\n\n// listenerPool stores and allows reuse of active listeners.\nvar listenerPool = NewUsagePool()\n\nconst maxPortSpan = 65535\n",
    "source_file": "listeners.go",
    "chunk_type": "code"
  },
  {
    "content": "module github.com/caddyserver/caddy/v2\n\ngo 1.24\n\nrequire (\n\tgithub.com/BurntSushi/toml v1.4.0\n\tgithub.com/KimMachineGun/automemlimit v0.7.1\n\tgithub.com/Masterminds/sprig/v3 v3.3.0\n\tgithub.com/alecthomas/chroma/v2 v2.15.0\n\tgithub.com/aryann/difflib v0.0.0-20210328193216-ff5ff6dc229b\n\tgithub.com/caddyserver/certmagic v0.23.0\n\tgithub.com/caddyserver/zerossl v0.1.3\n\tgithub.com/cloudflare/circl v1.6.1\n\tgithub.com/dustin/go-humanize v1.0.1\n\tgithub.com/go-chi/chi/v5 v5.2.1\n\tgithub.com/google/cel-go v0.24.1\n\tgithub.com/google/uuid v1.6.0\n\tgithub.com/klauspost/compress v1.18.0\n\tgithub.com/klauspost/cpuid/v2 v2.2.10\n\tgithub.com/mholt/acmez/v3 v3.1.2\n\tgithub.com/prometheus/client_golang v1.19.1\n\tgithub.com/quic-go/quic-go v0.51.0\n\tgithub.com/smallstep/certificates v0.26.1\n\tgithub.com/smallstep/nosql v0.6.1\n\tgithub.com/smallstep/truststore v0.13.0\n\tgithub.com/spf13/cobra v1.9.1\n\tgithub.com/spf13/pflag v1.0.6\n\tgithub.com/stretchr/testify v1.10.0\n\tgithub.com/tailscale/tscert v0.0.0-20240608151842-d3f834017e53\n\tgithub.com/yuin/goldmark v1.7.8\n\tgithub.com/yuin/goldmark-highlighting/v2 v2.0.0-20230729083705-37449abec8cc\n\tgo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.56.0\n\tgo.opentelemetry.io/contrib/propagators/autoprop v0.42.0\n\tgo.opentelemetry.io/otel v1.31.0\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.31.0\n\tgo.opentelemetry.io/otel/sdk v1.31.0\n\tgo.uber.org/automaxprocs v1.6.0\n\tgo.uber.org/zap v1.27.0\n\tgo.uber.org/zap/exp v0.3.0\n\tgolang.org/x/crypto v0.36.0\n\tgolang.org/x/crypto/x509roots/fallback v0.0.0-20250305170421-49bf5b80c810\n\tgolang.org/x/net v0.38.0\n\tgolang.org/x/sync v0.12.0\n\tgolang.org/x/term v0.30.0\n\tgolang.org/x/time v0.11.0\n\tgopkg.in/natefinch/lumberjack.v2 v2.2.1\n\tgopkg.in/yaml.v3 v3.0.1\n)\n\nrequire (\n\tcel.dev/expr v0.19.1 // indirect\n\tdario.cat/mergo v1.0.1 // indirect\n\tgithub.com/Microsoft/go-winio v0.6.0 // indirect\n\tgithub.com/antlr4-go/antlr/v4 v4.13.0 // indirect\n\tgithub.com/davecgh/go-spew v1.1.1 // indirect\n\tgithub.com/francoispqt/gojay v1.2.13 // indirect\n\tgithub.com/fxamacker/cbor/v2 v2.6.0 // indirect\n\tgithub.com/go-jose/go-jose/v3 v3.0.4 // indirect\n\tgithub.com/go-kit/log v0.2.1 // indirect\n\tgithub.com/google/certificate-transparency-go v1.1.8-0.20240110162603-74a5dd331745 // indirect\n\tgithub.com/google/go-tpm v0.9.0 // indirect\n\tgithub.com/google/go-tspi v0.3.0 // indirect\n\tgithub.com/google/pprof v0.0.0-20231212022811-ec68065c825e // indirect\n\tgithub.com/grpc-ecosystem/grpc-gateway/v2 v2.22.0 // indirect\n\tgithub.com/onsi/ginkgo/v2 v2.13.2 // indirect\n\tgithub.com/pbnjay/memory v0.0.0-20210728143218-7b4eea64cf58 // indirect\n\tgithub.com/pmezard/go-difflib v1.0.0 // indirect\n\tgithub.com/quic-go/qpack v0.5.1 // indirect\n\tgithub.com/smallstep/go-attestation v0.4.4-0.20240109183208-413678f90935 // indirect\n\tgithub.com/smallstep/pkcs7 v0.0.0-20231024181729-3b98ecc1ca81 // indirect\n\tgithub.com/smallstep/scep v0.0.0-20231024192529-aee96d7ad34d // indirect\n\tgithub.com/x448/float16 v0.8.4 // indirect\n\tgithub.com/zeebo/blake3 v0.2.4 // indirect\n\tgo.opentelemetry.io/contrib/propagators/aws v1.17.0 // indirect\n\tgo.opentelemetry.io/contrib/propagators/b3 v1.17.0 // indirect\n\tgo.opentelemetry.io/contrib/propagators/jaeger v1.17.0 // indirect\n\tgo.opentelemetry.io/contrib/propagators/ot v1.17.0 // indirect\n\tgo.uber.org/mock v0.5.0 // indirect\n\tgolang.org/x/exp v0.0.0-20240506185415-9bf2ced13842 // indirect\n\tgoogle.golang.org/genproto/googleapis/api v0.0.0-20241007155032-5fefd90f89a9 // indirect\n\tgoogle.golang.org/genproto/googleapis/rpc v0.0.0-20241007155032-5fefd90f89a9 // indirect\n)\n\nrequire (\n\tfilippo.io/edwards25519 v1.1.0 // indirect\n\tgithub.com/AndreasBriese/bbloom v0.0.0-20190825152654-46b345b51c96 // indirect\n\tgithub.com/Masterminds/goutils v1.1.1 // indirect\n\tgithub.com/Masterminds/semver/v3 v3.3.0 // indirect\n\tgithub.com/beorn7/perks v1.0.1 // indirect\n\tgithub.com/cenkalti/backoff/v4 v4.3.0 // indirect\n\tgithub.com/cespare/xxhash v1.1.0 // indirect\n\tgithub.com/cespare/xxhash/v2 v2.3.0\n\tgithub.com/chzyer/readline v1.5.1 // indirect\n\tgithub.com/cpuguy83/go-md2man/v2 v2.0.6 // indirect\n\tgithub.com/dgraph-io/badger v1.6.2 // indirect\n\tgithub.com/dgraph-io/badger/v2 v2.2007.4 // indirect\n\tgithub.com/dgraph-io/ristretto v0.2.0 // indirect\n\tgithub.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13 // indirect\n\tgithub.com/dlclark/regexp2 v1.11.4 // indirect\n\tgithub.com/felixge/httpsnoop v1.0.4 // indirect\n\tgithub.com/go-kit/kit v0.13.0 // indirect\n\tgithub.com/go-logfmt/logfmt v0.6.0 // indirect\n\tgithub.com/go-logr/logr v1.4.2 // indirect\n\tgithub.com/go-logr/stdr v1.2.2 // indirect\n\tgithub.com/go-sql-driver/mysql v1.7.1 // indirect\n\tgithub.com/go-task/slim-sprig v0.0.0-20230315185526-52ccab3ef572 // indirect\n\tgithub.com/golang/protobuf v1.5.4 // indirect\n\tgithub.com/golang/snappy v0.0.4 // indirect\n\tgithub.com/huandu/xstrings v1.5.0 // indirect\n\tgithub.com/inconshreveable/mousetrap v1.1.0 // indirect\n\tgithub.com/jackc/chunkreader/v2 v2.0.1 // indirect\n\tgithub.com/jackc/pgconn v1.14.3 // indirect\n\tgithub.com/jackc/pgio v1.0.0 // indirect\n\tgithub.com/jackc/pgpassfile v1.0.0 // indirect\n\tgithub.com/jackc/pgproto3/v2 v2.3.3 // indirect\n\tgithub.com/jackc/pgservicefile v0.0.0-20221227161230-091c0ba34f0a // indirect\n\tgithub.com/jackc/pgtype v1.14.0 // indirect\n\tgithub.com/jackc/pgx/v4 v4.18.3 // indirect\n\tgithub.com/libdns/libdns v1.0.0-beta.1\n\tgithub.com/manifoldco/promptui v0.9.0 // indirect\n\tgithub.com/mattn/go-colorable v0.1.13 // indirect\n\tgithub.com/mattn/go-isatty v0.0.20 // indirect\n\tgithub.com/mgutz/ansi v0.0.0-20200706080929-d51e80ef957d // indirect\n\tgithub.com/miekg/dns v1.1.63 // indirect\n\tgithub.com/mitchellh/copystructure v1.2.0 // indirect\n\tgithub.com/mitchellh/go-ps v1.0.0 // indirect\n\tgithub.com/mitchellh/reflectwalk v1.0.2 // indirect\n\tgithub.com/pires/go-proxyproto v0.7.1-0.20240628150027-b718e7ce4964\n\tgithub.com/pkg/errors v0.9.1 // indirect\n\tgithub.com/prometheus/client_model v0.5.0\n\tgithub.com/prometheus/common v0.48.0 // indirect\n\tgithub.com/prometheus/procfs v0.12.0 // indirect\n\tgithub.com/rs/xid v1.5.0 // indirect\n\tgithub.com/russross/blackfriday/v2 v2.1.0 // indirect\n\tgithub.com/shopspring/decimal v1.4.0 // indirect\n\tgithub.com/shurcooL/sanitized_anchor_name v1.0.0 // indirect\n\tgithub.com/sirupsen/logrus v1.9.3 // indirect\n\tgithub.com/slackhq/nebula v1.6.1 // indirect\n\tgithub.com/spf13/cast v1.7.0 // indirect\n\tgithub.com/stoewer/go-strcase v1.2.0 // indirect\n\tgithub.com/urfave/cli v1.22.14 // indirect\n\tgo.etcd.io/bbolt v1.3.9 // indirect\n\tgo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.31.0 // indirect\n\tgo.opentelemetry.io/otel/metric v1.31.0 // indirect\n\tgo.opentelemetry.io/otel/trace v1.31.0\n\tgo.opentelemetry.io/proto/otlp v1.3.1 // indirect\n\tgo.step.sm/cli-utils v0.9.0 // indirect\n\tgo.step.sm/crypto v0.45.0\n\tgo.step.sm/linkedca v0.20.1 // indirect\n\tgo.uber.org/multierr v1.11.0 // indirect\n\tgolang.org/x/mod v0.24.0 // indirect\n\tgolang.org/x/sys v0.31.0\n\tgolang.org/x/text v0.23.0 // indirect\n\tgolang.org/x/tools v0.31.0 // indirect\n\tgoogle.golang.org/grpc v1.67.1 // indirect\n\tgoogle.golang.org/protobuf v1.35.1 // indirect\n\thowett.net/plist v1.0.0 // indirect\n)\n",
    "source_file": "go.mod",
    "chunk_type": "unknown"
  },
  {
    "content": "package caddy\n\nimport (\n\t\"net/http\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\n\t\"github.com/caddyserver/caddy/v2/internal/metrics\"\n)\n\n// define and register the metrics used in this package.\nfunc init() {\n\tconst ns, sub = \"caddy\", \"admin\"\n\tadminMetrics.requestCount = prometheus.NewCounterVec(prometheus.CounterOpts{\n\t\tNamespace: ns,\n\t\tSubsystem: sub,\n\t\tName:      \"http_requests_total\",\n\t\tHelp:      \"Counter of requests made to the Admin API's HTTP endpoints.\",\n\t}, []string{\"handler\", \"path\", \"code\", \"method\"})\n\tadminMetrics.requestErrors = prometheus.NewCounterVec(prometheus.CounterOpts{\n\t\tNamespace: ns,\n\t\tSubsystem: sub,\n\t\tName:      \"http_request_errors_total\",\n\t\tHelp:      \"Number of requests resulting in middleware errors.\",\n\t}, []string{\"handler\", \"path\", \"method\"})\n\tglobalMetrics.configSuccess = prometheus.NewGauge(prometheus.GaugeOpts{\n\t\tName: \"caddy_config_last_reload_successful\",\n\t\tHelp: \"Whether the last configuration reload attempt was successful.\",\n\t})\n\tglobalMetrics.configSuccessTime = prometheus.NewGauge(prometheus.GaugeOpts{\n\t\tName: \"caddy_config_last_reload_success_timestamp_seconds\",\n\t\tHelp: \"Timestamp of the last successful configuration reload.\",\n\t})\n}\n\n// adminMetrics is a collection of metrics that can be tracked for the admin API.\nvar adminMetrics = struct {\n\trequestCount  *prometheus.CounterVec\n\trequestErrors *prometheus.CounterVec\n}{}\n\n// globalMetrics is a collection of metrics that can be tracked for Caddy global state\nvar globalMetrics = struct {\n\tconfigSuccess     prometheus.Gauge\n\tconfigSuccessTime prometheus.Gauge\n}{}\n\n// Similar to promhttp.InstrumentHandlerCounter, but upper-cases method names\n// instead of lower-casing them.\n//\n// Unlike promhttp.InstrumentHandlerCounter, this assumes a \"code\" and \"method\"\n// label is present, and will panic otherwise.\nfunc instrumentHandlerCounter(counter *prometheus.CounterVec, next http.Handler) http.HandlerFunc {\n\treturn http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\td := newDelegator(w)\n\t\tnext.ServeHTTP(d, r)\n\t\tcounter.With(prometheus.Labels{\n\t\t\t\"code\":   metrics.SanitizeCode(d.status),\n\t\t\t\"method\": metrics.SanitizeMethod(r.Method),\n\t\t}).Inc()\n\t})\n}\n\nfunc newDelegator(w http.ResponseWriter) *delegator {\n\treturn &delegator{\n\t\tResponseWriter: w,\n\t}\n}\n\ntype delegator struct {\n\thttp.ResponseWriter\n\tstatus int\n}\n\nfunc (d *delegator) WriteHeader(code int) {\n\td.status = code\n\td.ResponseWriter.WriteHeader(code)\n}\n\n// Unwrap returns the underlying ResponseWriter, necessary for\n// http.ResponseController to work correctly.\nfunc (d *delegator) Unwrap() http.ResponseWriter {\n\treturn d.ResponseWriter\n}\n",
    "source_file": "metrics.go",
    "chunk_type": "code"
  },
  {
    "content": "\n                                 Apache License\n                           Version 2.0, January 2004\n                        http://www.apache.org/licenses/\n\n   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n\n   1. Definitions.\n\n      \"License\" shall mean the terms and conditions for use, reproduction,\n      and distribution as defined by Sections 1 through 9 of this document.\n\n      \"Licensor\" shall mean the copyright owner or entity authorized by\n      the copyright owner that is granting the License.\n\n      \"Legal Entity\" shall mean the union of the acting entity and all\n      other entities that control, are controlled by, or are under common\n      control with that entity. For the purposes of this definition,\n      \"control\" means (i) the power, direct or indirect, to cause the\n      direction or management of such entity, whether by contract or\n      otherwise, or (ii) ownership of fifty percent (50%) or more of the\n      outstanding shares, or (iii) beneficial ownership of such entity.\n\n      \"You\" (or \"Your\") shall mean an individual or Legal Entity\n      exercising permissions granted by this License.\n\n      \"Source\" form shall mean the preferred form for making modifications,\n      including but not limited to software source code, documentation\n      source, and configuration files.\n\n      \"Object\" form shall mean any form resulting from mechanical\n      transformation or translation of a Source form, including but\n      not limited to compiled object code, generated documentation,\n      and conversions to other media types.\n\n      \"Work\" shall mean the work of authorship, whether in Source or\n      Object form, made available under the License, as indicated by a\n      copyright notice that is included in or attached to the work\n      (an example is provided in the Appendix below).\n\n      \"Derivative Works\" shall mean any work, whether in Source or Object\n      form, that is based on (or derived from) the Work and for which the\n      editorial revisions, annotations, elaborations, or other modifications\n      represent, as a whole, an original work of authorship. For the purposes\n      of this License, Derivative Works shall not include works that remain\n      separable from, or merely link (or bind by name) to the interfaces of,\n      the Work and Derivative Works thereof.\n\n      \"Contribution\" shall mean any work of authorship, including\n      the original version of the Work and any modifications or additions\n      to that Work or Derivative Works thereof, that is intentionally\n      submitted to Licensor for inclusion in the Work by the copyright owner\n      or by an individual or Legal Entity authorized to submit on behalf of\n      the copyright owner. For the purposes of this definition, \"submitted\"\n      means any form of electronic, verbal, or written communication sent\n      to the Licensor or its representatives, including but not limited to\n      communication on electronic mailing lists, source code control systems,\n      and issue tracking systems that are managed by, or on behalf of, the\n      Licensor for the purpose of discussing and improving the Work, but\n      excluding communication that is conspicuously marked or otherwise\n      designated in writing by the copyright owner as \"Not a Contribution.\"\n\n      \"Contributor\" shall mean Licensor and any individual or Legal Entity\n      on behalf of whom a Contribution has been received by Licensor and\n      subsequently incorporated within the Work.\n\n   2. Grant of Copyright License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      copyright license to reproduce, prepare Derivative Works of,\n      publicly display, publicly perform, sublicense, and distribute the\n      Work and such Derivative Works in Source or Object form.\n\n   3. Grant of Patent License. Subject to the terms and conditions of\n      this License, each Contributor hereby grants to You a perpetual,\n      worldwide, non-exclusive, no-charge, royalty-free, irrevocable\n      (except as stated in this section) patent license to make, have made,\n      use, offer to sell, sell, import, and otherwise transfer the Work,\n      where such license applies only to those patent claims licensable\n      by such Contributor that are necessarily infringed by their\n      Contribution(s) alone or by combination of their Contribution(s)\n      with the Work to which such Contribution(s) was submitted. If You\n      institute patent litigation against any entity (including a\n      cross-claim or counterclaim in a lawsuit) alleging that the Work\n      or a Contribution incorporated within the Work constitutes direct\n      or contributory patent infringement, then any patent licenses\n      granted to You under this License for that Work shall terminate\n      as of the date such litigation is filed.\n\n   4. Redistribution. You may reproduce and distribute copies of the\n      Work or Derivative Works thereof in any medium, with or without\n      modifications, and in Source or Object form, provided that You\n      meet the following conditions:\n\n      (a) You must give any other recipients of the Work or\n          Derivative Works a copy of this License; and\n\n      (b) You must cause any modified files to carry prominent notices\n          stating that You changed the files; and\n\n      (c) You must retain, in the Source form of any Derivative Works\n          that You distribute, all copyright, patent, trademark, and\n          attribution notices from the Source form of the Work,\n          excluding those notices that do not pertain to any part of\n          the Derivative Works; and\n\n      (d) If the Work includes a \"NOTICE\" text file as part of its\n          distribution, then any Derivative Works that You distribute must\n          include a readable copy of the attribution notices contained\n          within such NOTICE file, excluding those notices that do not\n          pertain to any part of the Derivative Works, in at least one\n          of the following places: within a NOTICE text file distributed\n          as part of the Derivative Works; within the Source form or\n          documentation, if provided along with the Derivative Works; or,\n          within a display generated by the Derivative Works, if and\n          wherever such third-party notices normally appear. The contents\n          of the NOTICE file are for informational purposes only and\n          do not modify the License. You may add Your own attribution\n          notices within Derivative Works that You distribute, alongside\n          or as an addendum to the NOTICE text from the Work, provided\n          that such additional attribution notices cannot be construed\n          as modifying the License.\n\n      You may add Your own copyright statement to Your modifications and\n      may provide additional or different license terms and conditions\n      for use, reproduction, or distribution of Your modifications, or\n      for any such Derivative Works as a whole, provided Your use,\n      reproduction, and distribution of the Work otherwise complies with\n      the conditions stated in this License.\n\n   5. Submission of Contributions. Unless You explicitly state otherwise,\n      any Contribution intentionally submitted for inclusion in the Work\n      by You to the Licensor shall be under the terms and conditions of\n      this License, without any additional terms or conditions.\n      Notwithstanding the above, nothing herein shall supersede or modify\n      the terms of any separate license agreement you may have executed\n      with Licensor regarding such Contributions.\n\n   6. Trademarks. This License does not grant permission to use the trade\n      names, trademarks, service marks, or product names of the Licensor,\n      except as required for reasonable and customary use in describing the\n      origin of the Work and reproducing the content of the NOTICE file.\n\n   7. Disclaimer of Warranty. Unless required by applicable law or\n      agreed to in writing, Licensor provides the Work (and each\n      Contributor provides its Contributions) on an \"AS IS\" BASIS,\n      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n      implied, including, without limitation, any warranties or conditions\n      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A\n      PARTICULAR PURPOSE. You are solely responsible for determining the\n      appropriateness of using or redistributing the Work and assume any\n      risks associated with Your exercise of permissions under this License.\n\n   8. Limitation of Liability. In no event and under no legal theory,\n      whether in tort (including negligence), contract, or otherwise,\n      unless required by applicable law (such as deliberate and grossly\n      negligent acts) or agreed to in writing, shall any Contributor be\n      liable to You for damages, including any direct, indirect, special,\n      incidental, or consequential damages of any character arising as a\n      result of this License or out of the use or inability to use the\n      Work (including but not limited to damages for loss of goodwill,\n      work stoppage, computer failure or malfunction, or any and all\n      other commercial damages or losses), even if such Contributor\n      has been advised of the possibility of such damages.\n\n   9. Accepting Warranty or Additional Liability. While redistributing\n      the Work or Derivative Works thereof, You may choose to offer,\n      and charge a fee for, acceptance of support, warranty, indemnity,\n      or other liability obligations and/or rights consistent with this\n      License. However, in accepting such obligations, You may act only\n      on Your own behalf and on Your sole responsibility, not on behalf\n      of any other Contributor, and only if You agree to indemnify,\n      defend, and hold each Contributor harmless for any liability\n      incurred by, or claims asserted against, such Contributor by reason\n      of your accepting any such warranty or additional liability.\n\n   END OF TERMS AND CONDITIONS\n\n   APPENDIX: How to apply the Apache License to your work.\n\n      To apply the Apache License to your work, attach the following\n      boilerplate notice, with the fields enclosed by brackets \"[]\"\n      replaced with your own identifying information. (Don't include\n      the brackets!)  The text should be enclosed in the appropriate\n      comment syntax for the file format. We also recommend that a\n      file or class name and description of purpose be included on the\n      same \"printed page\" as the copyright notice for easier\n      identification within third-party archives.\n\n   Copyright [yyyy] [name of copyright owner]\n\n   Licensed under the Apache License, Version 2.0 (the \"License\");\n   you may not use this file except in compliance with the License.\n   You may obtain a copy of the License at\n\n       http://www.apache.org/licenses/LICENSE-2.0\n\n   Unless required by applicable law or agreed to in writing, software\n   distributed under the License is distributed on an \"AS IS\" BASIS,\n   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n   See the License for the specific language governing permissions and\n   limitations under the License.\n",
    "source_file": "LICENSE",
    "chunk_type": "unknown"
  },
  {
    "content": "# This is the official list of Caddy Authors for copyright purposes.\n# Authors may be either individual people or legal entities.\n#\n# Not all individual contributors are authors. For the full list of\n# contributors, refer to the project's page on GitHub or the repo's\n# commit history.\n\nMatthew Holt <Matthew.Holt@gmail.com>\nLight Code Labs <sales@lightcodelabs.com>\nArdan Labs <info@ardanlabs.com>\n",
    "source_file": "AUTHORS",
    "chunk_type": "unknown"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"context\"\n\t\"os\"\n\t\"os/signal\"\n\n\t\"go.uber.org/zap\"\n)\n\n// TrapSignals create signal/interrupt handlers as best it can for the\n// current OS. This is a rather invasive function to call in a Go program\n// that captures signals already, so in that case it would be better to\n// implement these handlers yourself.\nfunc TrapSignals() {\n\ttrapSignalsCrossPlatform()\n\ttrapSignalsPosix()\n}\n\n// trapSignalsCrossPlatform captures SIGINT or interrupt (depending\n// on the OS), which initiates a graceful shutdown. A second SIGINT\n// or interrupt will forcefully exit the process immediately.\nfunc trapSignalsCrossPlatform() {\n\tgo func() {\n\t\tshutdown := make(chan os.Signal, 1)\n\t\tsignal.Notify(shutdown, os.Interrupt)\n\n\t\tfor i := 0; true; i++ {\n\t\t\t<-shutdown\n\n\t\t\tif i > 0 {\n\t\t\t\tLog().Warn(\"force quit\", zap.String(\"signal\", \"SIGINT\"))\n\t\t\t\tos.Exit(ExitCodeForceQuit)\n\t\t\t}\n\n\t\t\tLog().Info(\"shutting down\", zap.String(\"signal\", \"SIGINT\"))\n\t\t\tgo exitProcessFromSignal(\"SIGINT\")\n\t\t}\n\t}()\n}\n\n// exitProcessFromSignal exits the process from a system signal.\nfunc exitProcessFromSignal(sigName string) {\n\tlogger := Log().With(zap.String(\"signal\", sigName))\n\texitProcess(context.TODO(), logger)\n}\n\n// Exit codes. Generally, you should NOT\n// automatically restart the process if the\n// exit code is ExitCodeFailedStartup (1).\nconst (\n\tExitCodeSuccess = iota\n\tExitCodeFailedStartup\n\tExitCodeForceQuit\n\tExitCodeFailedQuit\n)\n",
    "source_file": "sigtrap.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\n\t\"golang.org/x/sys/windows/svc\"\n\n\t\"github.com/caddyserver/caddy/v2/notify\"\n)\n\nfunc init() {\n\tisService, err := svc.IsWindowsService()\n\tif err != nil || !isService {\n\t\treturn\n\t}\n\n\t// Windows services always start in the system32 directory, try to\n\t// switch into the directory where the caddy executable is.\n\texecPath, err := os.Executable()\n\tif err == nil {\n\t\t_ = os.Chdir(filepath.Dir(execPath))\n\t}\n\n\tgo func() {\n\t\t_ = svc.Run(\"\", runner{})\n\t}()\n}\n\ntype runner struct{}\n\nfunc (runner) Execute(args []string, request <-chan svc.ChangeRequest, status chan<- svc.Status) (bool, uint32) {\n\tnotify.SetGlobalStatus(status)\n\tstatus <- svc.Status{State: svc.StartPending}\n\n\tfor {\n\t\treq := <-request\n\t\tswitch req.Cmd {\n\t\tcase svc.Interrogate:\n\t\t\tstatus <- req.CurrentStatus\n\t\tcase svc.Stop, svc.Shutdown:\n\t\t\tstatus <- svc.Status{State: svc.StopPending}\n\t\t\texitProcessFromSignal(\"SIGINT\")\n\t\t\treturn false, 0\n\t\t}\n\t}\n}\n",
    "source_file": "service_windows.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build gofuzz\n\npackage caddy\n\nfunc FuzzReplacer(data []byte) (score int) {\n\tNewReplacer().ReplaceAll(string(data), \"\")\n\tNewReplacer().ReplaceAll(NewReplacer().ReplaceAll(string(data), \"\"), \"\")\n\tNewReplacer().ReplaceAll(NewReplacer().ReplaceAll(string(data), \"\"), NewReplacer().ReplaceAll(string(data), \"\"))\n\tNewReplacer().ReplaceAll(string(data[:len(data)/2]), string(data[len(data)/2:]))\n\treturn 0\n}\n",
    "source_file": "replacer_fuzz.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport \"io/fs\"\n\ntype FileSystems interface {\n\tRegister(k string, v fs.FS)\n\tUnregister(k string)\n\tGet(k string) (v fs.FS, ok bool)\n\tDefault() fs.FS\n}\n",
    "source_file": "filesystem.go",
    "chunk_type": "code"
  },
  {
    "content": "cel.dev/expr v0.19.1 h1:NciYrtDRIR0lNCnH1LFJegdjspNx9fI59O7TWcua/W4=\ncel.dev/expr v0.19.1/go.mod h1:MrpN08Q+lEBs+bGYdLxxHkZoUSsCp0nSKTs0nTymJgw=\ncloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.31.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.34.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=\ncloud.google.com/go v0.37.0/go.mod h1:TS1dMSSfndXH133OKGwekG838Om/cQT0BUHV3HcBgoo=\ncloud.google.com/go v0.112.1 h1:uJSeirPke5UNZHIb4SxfZklVSiWWVqW4oXlETwZziwM=\ncloud.google.com/go/auth v0.4.1 h1:Z7YNIhlWRtrnKlZke7z3GMqzvuYzdc2z98F9D1NV5Hg=\ncloud.google.com/go/auth v0.4.1/go.mod h1:QVBuVEKpCn4Zp58hzRGvL0tjRGU0YqdRTdCHM1IHnro=\ncloud.google.com/go/auth/oauth2adapt v0.2.2 h1:+TTV8aXpjeChS9M+aTtN/TjdQnzJvmzKFt//oWu7HX4=\ncloud.google.com/go/auth/oauth2adapt v0.2.2/go.mod h1:wcYjgpZI9+Yu7LyYBg4pqSiaRkfEK3GQcpb7C/uyF1Q=\ncloud.google.com/go/compute v1.23.3 h1:6sVlXXBmbd7jNX0Ipq0trII3e4n1/MsADLK6a+aiVlk=\ncloud.google.com/go/compute/metadata v0.5.0 h1:Zr0eK8JbFv6+Wi4ilXAR8FJ3wyNdpxHKJNPos6LTZOY=\ncloud.google.com/go/compute/metadata v0.5.0/go.mod h1:aHnloV2TPI38yx4s9+wAZhHykWvVCfu7hQbF+9CWoiY=\ncloud.google.com/go/iam v1.1.8 h1:r7umDwhj+BQyz0ScZMp4QrGXjSTI3ZINnpgU2nlB/K0=\ncloud.google.com/go/iam v1.1.8/go.mod h1:GvE6lyMmfxXauzNq8NbgJbeVQNspG+tcdL/W8QO1+zE=\ncloud.google.com/go/kms v1.16.0 h1:1yZsRPhmargZOmY+fVAh8IKiR9HzCb0U1zsxb5g2nRY=\ncloud.google.com/go/kms v1.16.0/go.mod h1:olQUXy2Xud+1GzYfiBO9N0RhjsJk5IJLU6n/ethLXVc=\ncloud.google.com/go/longrunning v0.5.7 h1:WLbHekDbjK1fVFD3ibpFFVoyizlLRl73I7YKuAKilhU=\ncloud.google.com/go/longrunning v0.5.7/go.mod h1:8GClkudohy1Fxm3owmBGid8W0pSgodEMwEAztp38Xng=\ndario.cat/mergo v1.0.1 h1:Ra4+bf83h2ztPIQYNP99R6m+Y7KfnARDfID+a+vLl4s=\ndario.cat/mergo v1.0.1/go.mod h1:uNxQE+84aUszobStD9th8a29P2fMDhsBdgRYvZOxGmk=\ndmitri.shuralyov.com/app/changes v0.0.0-20180602232624-0a106ad413e3/go.mod h1:Yl+fi1br7+Rr3LqpNJf1/uxUdtRUV+Tnj0o93V2B9MU=\ndmitri.shuralyov.com/html/belt v0.0.0-20180602232347-f7d459c86be0/go.mod h1:JLBrvjyP0v+ecvNYvCpyZgu5/xkfAUhi6wJj28eUfSU=\ndmitri.shuralyov.com/service/change v0.0.0-20181023043359-a85b471d5412/go.mod h1:a1inKt/atXimZ4Mv927x+r7UpyzRUf4emIoiiSC2TN4=\ndmitri.shuralyov.com/state v0.0.0-20180228185332-28bcc343414c/go.mod h1:0PRwlb0D6DFvNNtx+9ybjezNCa8XF0xaYcETyp6rHWU=\nfilippo.io/edwards25519 v1.1.0 h1:FNf4tywRC1HmFuKW5xopWpigGjJKiJSV0Cqo0cJWDaA=\nfilippo.io/edwards25519 v1.1.0/go.mod h1:BxyFTGdWcka3PhytdK4V28tE5sGfRvvvRV7EaN4VDT4=\ngit.apache.org/thrift.git v0.0.0-20180902110319-2566ecd5d999/go.mod h1:fPE2ZNJGynbRyZ4dJvy6G277gSllfV2HJqblrnkyeyg=\ngithub.com/AndreasBriese/bbloom v0.0.0-20190825152654-46b345b51c96 h1:cTp8I5+VIoKjsnZuH8vjyaysT/ses3EvZeaV/1UkF2M=\ngithub.com/AndreasBriese/bbloom v0.0.0-20190825152654-46b345b51c96/go.mod h1:bOvUY6CB00SOBii9/FifXqc0awNKxLFCL/+pkDPuyl8=\ngithub.com/BurntSushi/toml v0.3.1/go.mod h1:xHWCNGjB5oqiDr8zfno3MHue2Ht5sIBksp03qcyfWMU=\ngithub.com/BurntSushi/toml v1.3.2/go.mod h1:CxXYINrC8qIiEnFrOxCa7Jy5BFHlXnUU2pbicEuybxQ=\ngithub.com/BurntSushi/toml v1.4.0 h1:kuoIxZQy2WRRk1pttg9asf+WVv6tWQuBNVmK8+nqPr0=\ngithub.com/BurntSushi/toml v1.4.0/go.mod h1:ukJfTF/6rtPPRCnwkur4qwRxa8vTRFBF0uk2lLoLwho=\ngithub.com/KimMachineGun/automemlimit v0.7.1 h1:QcG/0iCOLChjfUweIMC3YL5Xy9C3VBeNmCZHrZfJMBw=\ngithub.com/KimMachineGun/automemlimit v0.7.1/go.mod h1:QZxpHaGOQoYvFhv/r4u3U0JTC2ZcOwbSr11UZF46UBM=\ngithub.com/Masterminds/goutils v1.1.1 h1:5nUrii3FMTL5diU80unEVvNevw1nH4+ZV4DSLVJLSYI=\ngithub.com/Masterminds/goutils v1.1.1/go.mod h1:8cTjp+g8YejhMuvIA5y2vz3BpJxksy863GQaJW2MFNU=\ngithub.com/Masterminds/semver/v3 v3.1.1/go.mod h1:VPu/7SZ7ePZ3QOrcuXROw5FAcLl4a0cBrbBpGY/8hQs=\ngithub.com/Masterminds/semver/v3 v3.3.0 h1:B8LGeaivUe71a5qox1ICM/JLl0NqZSW5CHyL+hmvYS0=\ngithub.com/Masterminds/semver/v3 v3.3.0/go.mod h1:4V+yj/TJE1HU9XfppCwVMZq3I84lprf4nC11bSS5beM=\ngithub.com/Masterminds/sprig/v3 v3.3.0 h1:mQh0Yrg1XPo6vjYXgtf5OtijNAKJRNcTdOOGZe3tPhs=\ngithub.com/Masterminds/sprig/v3 v3.3.0/go.mod h1:Zy1iXRYNqNLUolqCpL4uhk6SHUMAOSCzdgBfDb35Lz0=\ngithub.com/Microsoft/go-winio v0.6.0 h1:slsWYD/zyx7lCXoZVlvQrj0hPTM1HI4+v1sIda2yDvg=\ngithub.com/Microsoft/go-winio v0.6.0/go.mod h1:cTAf44im0RAYeL23bpB+fzCyDH2MJiz2BO69KH/soAE=\ngithub.com/OneOfOne/xxhash v1.2.2 h1:KMrpdQIwFcEqXDklaen+P1axHaj9BSKzvpUUfnHldSE=\ngithub.com/OneOfOne/xxhash v1.2.2/go.mod h1:HSdplMjZKSmBqAxg5vPj2TmRDmfkzw+cTzAElWljhcU=\ngithub.com/alecthomas/assert/v2 v2.11.0 h1:2Q9r3ki8+JYXvGsDyBXwH3LcJ+WK5D0gc5E8vS6K3D0=\ngithub.com/alecthomas/assert/v2 v2.11.0/go.mod h1:Bze95FyfUr7x34QZrjL+XP+0qgp/zg8yS+TtBj1WA3k=\ngithub.com/alecthomas/chroma/v2 v2.2.0/go.mod h1:vf4zrexSH54oEjJ7EdB65tGNHmH3pGZmVkgTP5RHvAs=\ngithub.com/alecthomas/chroma/v2 v2.15.0 h1:LxXTQHFoYrstG2nnV9y2X5O94sOBzf0CIUpSTbpxvMc=\ngithub.com/alecthomas/chroma/v2 v2.15.0/go.mod h1:gUhVLrPDXPtp/f+L1jo9xepo9gL4eLwRuGAunSZMkio=\ngithub.com/alecthomas/repr v0.0.0-20220113201626-b1b626ac65ae/go.mod h1:2kn6fqh/zIyPLmm3ugklbEi5hg5wS435eygvNfaDQL8=\ngithub.com/alecthomas/repr v0.4.0 h1:GhI2A8MACjfegCPVq9f1FLvIBS+DrQ2KQBFZP1iFzXc=\ngithub.com/alecthomas/repr v0.4.0/go.mod h1:Fr0507jx4eOXV7AlPV6AVZLYrLIuIeSOWtW57eE/O/4=\ngithub.com/anmitsu/go-shlex v0.0.0-20161002113705-648efa622239/go.mod h1:2FmKhYUyUczH0OGQWaF5ceTx0UBShxjsH6f8oGKYe2c=\ngithub.com/antlr4-go/antlr/v4 v4.13.0 h1:lxCg3LAv+EUK6t1i0y1V6/SLeUi0eKEKdhQAlS8TVTI=\ngithub.com/antlr4-go/antlr/v4 v4.13.0/go.mod h1:pfChB/xh/Unjila75QW7+VU4TSnWnnk9UTnmpPaOR2g=\ngithub.com/armon/consul-api v0.0.0-20180202201655-eb2c6b5be1b6/go.mod h1:grANhF5doyWs3UAsr3K4I6qtAmlQcZDesFNEHPZAzj8=\ngithub.com/aryann/difflib v0.0.0-20210328193216-ff5ff6dc229b h1:uUXgbcPDK3KpW29o4iy7GtuappbWT0l5NaMo9H9pJDw=\ngithub.com/aryann/difflib v0.0.0-20210328193216-ff5ff6dc229b/go.mod h1:DAHtR1m6lCRdSC2Tm3DSWRPvIPr6xNKyeHdqDQSQT+A=\ngithub.com/aws/aws-sdk-go-v2 v1.26.1 h1:5554eUqIYVWpU0YmeeYZ0wU64H2VLBs8TlhRB2L+EkA=\ngithub.com/aws/aws-sdk-go-v2 v1.26.1/go.mod h1:ffIFB97e2yNsv4aTSGkqtHnppsIJzw7G7BReUZ3jCXM=\ngithub.com/aws/aws-sdk-go-v2/config v1.27.13 h1:WbKW8hOzrWoOA/+35S5okqO/2Ap8hkkFUzoW8Hzq24A=\ngithub.com/aws/aws-sdk-go-v2/config v1.27.13/go.mod h1:XLiyiTMnguytjRER7u5RIkhIqS8Nyz41SwAWb4xEjxs=\ngithub.com/aws/aws-sdk-go-v2/credentials v1.17.13 h1:XDCJDzk/u5cN7Aple7D/MiAhx1Rjo/0nueJ0La8mRuE=\ngithub.com/aws/aws-sdk-go-v2/credentials v1.17.13/go.mod h1:FMNcjQrmuBYvOTZDtOLCIu0esmxjF7RuA/89iSXWzQI=\ngithub.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.16.1 h1:FVJ0r5XTHSmIHJV6KuDmdYhEpvlHpiSd38RQWhut5J4=\ngithub.com/aws/aws-sdk-go-v2/feature/ec2/imds v1.16.1/go.mod h1:zusuAeqezXzAB24LGuzuekqMAEgWkVYukBec3kr3jUg=\ngithub.com/aws/aws-sdk-go-v2/internal/configsources v1.3.5 h1:aw39xVGeRWlWx9EzGVnhOR4yOjQDHPQ6o6NmBlscyQg=\ngithub.com/aws/aws-sdk-go-v2/internal/configsources v1.3.5/go.mod h1:FSaRudD0dXiMPK2UjknVwwTYyZMRsHv3TtkabsZih5I=\ngithub.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.6.5 h1:PG1F3OD1szkuQPzDw3CIQsRIrtTlUC3lP84taWzHlq0=\ngithub.com/aws/aws-sdk-go-v2/internal/endpoints/v2 v2.6.5/go.mod h1:jU1li6RFryMz+so64PpKtudI+QzbKoIEivqdf6LNpOc=\ngithub.com/aws/aws-sdk-go-v2/internal/ini v1.8.0 h1:hT8rVHwugYE2lEfdFE0QWVo81lF7jMrYJVDWI+f+VxU=\ngithub.com/aws/aws-sdk-go-v2/internal/ini v1.8.0/go.mod h1:8tu/lYfQfFe6IGnaOdrpVgEL2IrrDOf6/m9RQum4NkY=\ngithub.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.11.2 h1:Ji0DY1xUsUr3I8cHps0G+XM3WWU16lP6yG8qu1GAZAs=\ngithub.com/aws/aws-sdk-go-v2/service/internal/accept-encoding v1.11.2/go.mod h1:5CsjAbs3NlGQyZNFACh+zztPDI7fU6eW9QsxjfnuBKg=\ngithub.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.11.7 h1:ogRAwT1/gxJBcSWDMZlgyFUM962F51A5CRhDLbxLdmo=\ngithub.com/aws/aws-sdk-go-v2/service/internal/presigned-url v1.11.7/go.mod h1:YCsIZhXfRPLFFCl5xxY+1T9RKzOKjCut+28JSX2DnAk=\ngithub.com/aws/aws-sdk-go-v2/service/kms v1.31.1 h1:5wtyAwuUiJiM3DHYeGZmP5iMonM7DFBWAEaaVPHYZA0=\ngithub.com/aws/aws-sdk-go-v2/service/kms v1.31.1/go.mod h1:2snWQJQUKsbN66vAawJuOGX7dr37pfOq9hb0tZDGIqQ=\ngithub.com/aws/aws-sdk-go-v2/service/sso v1.20.6 h1:o5cTaeunSpfXiLTIBx5xo2enQmiChtu1IBbzXnfU9Hs=\ngithub.com/aws/aws-sdk-go-v2/service/sso v1.20.6/go.mod h1:qGzynb/msuZIE8I75DVRCUXw3o3ZyBmUvMwQ2t/BrGM=\ngithub.com/aws/aws-sdk-go-v2/service/ssooidc v1.24.0 h1:Qe0r0lVURDDeBQJ4yP+BOrJkvkiCo/3FH/t+wY11dmw=\ngithub.com/aws/aws-sdk-go-v2/service/ssooidc v1.24.0/go.mod h1:mUYPBhaF2lGiukDEjJX2BLRRKTmoUSitGDUgM4tRxak=\ngithub.com/aws/aws-sdk-go-v2/service/sts v1.28.7 h1:et3Ta53gotFR4ERLXXHIHl/Uuk1qYpP5uU7cvNql8ns=\ngithub.com/aws/aws-sdk-go-v2/service/sts v1.28.7/go.mod h1:FZf1/nKNEkHdGGJP/cI2MoIMquumuRK6ol3QQJNDxmw=\ngithub.com/aws/smithy-go v1.20.2 h1:tbp628ireGtzcHDDmLT/6ADHidqnwgF57XOXZe6tp4Q=\ngithub.com/aws/smithy-go v1.20.2/go.mod h1:krry+ya/rV9RDcV/Q16kpu6ypI4K2czasz0NC3qS14E=\ngithub.com/beorn7/perks v0.0.0-20180321164747-3a771d992973/go.mod h1:Dwedo/Wpr24TaqPxmxbtue+5NUziq4I4S80YR8gNf3Q=\ngithub.com/beorn7/perks v1.0.1 h1:VlbKKnNfV8bJzeqoa4cOKqO6bYr3WgKZxO8Z16+hsOM=\ngithub.com/beorn7/perks v1.0.1/go.mod h1:G2ZrVWU2WbWT9wwq4/hrbKbnv/1ERSJQ0ibhJ6rlkpw=\ngithub.com/bradfitz/go-smtpd v0.0.0-20170404230938-deb6d6237625/go.mod h1:HYsPBTaaSFSlLx/70C2HPIMNZpVV8+vt/A+FMnYP11g=\ngithub.com/buger/jsonparser v0.0.0-20181115193947-bf1c66bbce23/go.mod h1:bbYlZJ7hK1yFx9hf58LP0zeX7UjIGs20ufpu3evjr+s=\ngithub.com/caddyserver/certmagic v0.23.0 h1:CfpZ/50jMfG4+1J/u2LV6piJq4HOfO6ppOnOf7DkFEU=\ngithub.com/caddyserver/certmagic v0.23.0/go.mod h1:9mEZIWqqWoI+Gf+4Trh04MOVPD0tGSxtqsxg87hAIH4=\ngithub.com/caddyserver/zerossl v0.1.3 h1:onS+pxp3M8HnHpN5MMbOMyNjmTheJyWRaZYwn+YTAyA=\ngithub.com/caddyserver/zerossl v0.1.3/go.mod h1:CxA0acn7oEGO6//4rtrRjYgEoa4MFw/XofZnrYwGqG4=\ngithub.com/cenkalti/backoff/v4 v4.3.0 h1:MyRJ/UdXutAwSAT+s3wNd7MfTIcy71VQueUuFK343L8=\ngithub.com/cenkalti/backoff/v4 v4.3.0/go.mod h1:Y3VNntkOUPxTVeUxJ/G5vcM//AlwfmyYozVcomhLiZE=\ngithub.com/cespare/xxhash v1.1.0 h1:a6HrQnmkObjyL+Gs60czilIUGqrzKutQD6XZog3p+ko=\ngithub.com/cespare/xxhash v1.1.0/go.mod h1:XrSqR1VqqWfGrhpAt58auRo0WTKS1nRRg3ghfAqPWnc=\ngithub.com/cespare/xxhash/v2 v2.3.0 h1:UL815xU9SqsFlibzuggzjXhog7bL6oX9BbNZnL2UFvs=\ngithub.com/cespare/xxhash/v2 v2.3.0/go.mod h1:VGX0DQ3Q6kWi7AoAeZDth3/j3BFtOZR5XLFGgcrjCOs=\ngithub.com/chzyer/logex v1.1.10/go.mod h1:+Ywpsq7O8HXn0nuIou7OrIPyXbp3wmkHB+jjWRnGsAI=\ngithub.com/chzyer/logex v1.2.1 h1:XHDu3E6q+gdHgsdTPH6ImJMIp436vR6MPtH8gP05QzM=\ngithub.com/chzyer/logex v1.2.1/go.mod h1:JLbx6lG2kDbNRFnfkgvh4eRJRPX1QCoOIWomwysCBrQ=\ngithub.com/chzyer/readline v0.0.0-20180603132655-2972be24d48e/go.mod h1:nSuG5e5PlCu98SY8svDHJxuZscDgtXS6KTTbou5AhLI=\ngithub.com/chzyer/readline v1.5.1 h1:upd/6fQk4src78LMRzh5vItIt361/o4uq553V8B5sGI=\ngithub.com/chzyer/readline v1.5.1/go.mod h1:Eh+b79XXUwfKfcPLepksvw2tcLE/Ct21YObkaSkeBlk=\ngithub.com/chzyer/test v0.0.0-20180213035817-a1ea475d72b1/go.mod h1:Q3SI9o4m/ZMnBNeIyt5eFwwo7qiLfzFZmjNmxjkiQlU=\ngithub.com/chzyer/test v1.0.0 h1:p3BQDXSxOhOG0P9z6/hGnII4LGiEPOYBhs8asl/fC04=\ngithub.com/chzyer/test v1.0.0/go.mod h1:2JlltgoNkt4TW/z9V/IzDdFaMTM2JPIi26O1pF38GC8=\ngithub.com/client9/misspell v0.3.4/go.mod h1:qj6jICC3Q7zFZvVWo7KLAzC3yx5G7kyvSDkc90ppPyw=\ngithub.com/cloudflare/circl v1.6.1 h1:zqIqSPIndyBh1bjLVVDHMPpVKqp8Su/V+6MeDzzQBQ0=\ngithub.com/cloudflare/circl v1.6.1/go.mod h1:uddAzsPgqdMAYatqJ0lsjX1oECcQLIlRpzZh3pJrofs=\ngithub.com/cockroachdb/apd v1.1.0 h1:3LFP3629v+1aKXU5Q37mxmRxX/pIu1nijXydLShEq5I=\ngithub.com/cockroachdb/apd v1.1.0/go.mod h1:8Sl8LxpKi29FqWXR16WEFZRNSz3SoPzUzeMeY4+DwBQ=\ngithub.com/coreos/etcd v3.3.10+incompatible/go.mod h1:uF7uidLiAD3TWHmW31ZFd/JWoc32PjwdhPthX9715RE=\ngithub.com/coreos/go-etcd v2.0.0+incompatible/go.mod h1:Jez6KQU2B/sWsbdaef3ED8NzMklzPG4d5KIOhIy30Tk=\ngithub.com/coreos/go-semver v0.2.0/go.mod h1:nnelYz7RCh+5ahJtPPxZlU+153eP4D4r3EedlOD2RNk=\ngithub.com/coreos/go-systemd v0.0.0-20181012123002-c6f51f82210d/go.mod h1:F5haX7vjVVG0kc13fIWeqUViNPyEJxv/OmvnBo0Yme4=\ngithub.com/coreos/go-systemd v0.0.0-20190321100706-95778dfbb74e/go.mod h1:F5haX7vjVVG0kc13fIWeqUViNPyEJxv/OmvnBo0Yme4=\ngithub.com/coreos/go-systemd v0.0.0-20190719114852-fd7a80b32e1f/go.mod h1:F5haX7vjVVG0kc13fIWeqUViNPyEJxv/OmvnBo0Yme4=\ngithub.com/cpuguy83/go-md2man v1.0.10/go.mod h1:SmD6nW6nTyfqj6ABTjUi3V3JVMnlJmwcJI5acqYI6dE=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.2/go.mod h1:tgQtvFlXSQOSOSIRvRPT7W67SCa46tRHOmNcaadrF8o=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.6 h1:XJtiaUW6dEEqVuZiMTn1ldk455QWwEIsMIJlo5vtkx0=\ngithub.com/cpuguy83/go-md2man/v2 v2.0.6/go.mod h1:oOW0eioCTA6cOiMLiUPZOpcVxMig6NIQQ7OS05n1F4g=\ngithub.com/creack/pty v1.1.7/go.mod h1:lj5s0c3V2DBrqTV7llrYr5NG6My20zk30Fl46Y7DoTY=\ngithub.com/davecgh/go-spew v1.1.0/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/davecgh/go-spew v1.1.1 h1:vj9j/u1bqnvCEfJOwUhtlOARqs3+rkHYY13jYWTU97c=\ngithub.com/davecgh/go-spew v1.1.1/go.mod h1:J7Y8YcW2NihsgmVo/mv3lAwl/skON4iLHjSsI+c5H38=\ngithub.com/dgraph-io/badger v1.6.2 h1:mNw0qs90GVgGGWylh0umH5iag1j6n/PeJtNvL6KY/x8=\ngithub.com/dgraph-io/badger v1.6.2/go.mod h1:JW2yswe3V058sS0kZ2h/AXeDSqFjxnZcRrVH//y2UQE=\ngithub.com/dgraph-io/badger/v2 v2.2007.4 h1:TRWBQg8UrlUhaFdco01nO2uXwzKS7zd+HVdwV/GHc4o=\ngithub.com/dgraph-io/badger/v2 v2.2007.4/go.mod h1:vSw/ax2qojzbN6eXHIx6KPKtCSHJN/Uz0X0VPruTIhk=\ngithub.com/dgraph-io/ristretto v0.0.2/go.mod h1:KPxhHT9ZxKefz+PCeOGsrHpl1qZ7i70dGTu2u+Ahh6E=\ngithub.com/dgraph-io/ristretto v0.0.3-0.20200630154024-f66de99634de/go.mod h1:KPxhHT9ZxKefz+PCeOGsrHpl1qZ7i70dGTu2u+Ahh6E=\ngithub.com/dgraph-io/ristretto v0.2.0 h1:XAfl+7cmoUDWW/2Lx8TGZQjjxIQ2Ley9DSf52dru4WE=\ngithub.com/dgraph-io/ristretto v0.2.0/go.mod h1:8uBHCU/PBV4Ag0CJrP47b9Ofby5dqWNh4FicAdoqFNU=\ngithub.com/dgryski/go-farm v0.0.0-20190423205320-6a90982ecee2/go.mod h1:SqUrOPUnsFjfmXRMNPybcSiG0BgUW2AuFH8PAnS2iTw=\ngithub.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13 h1:fAjc9m62+UWV/WAFKLNi6ZS0675eEUC9y3AlwSbQu1Y=\ngithub.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13/go.mod h1:SqUrOPUnsFjfmXRMNPybcSiG0BgUW2AuFH8PAnS2iTw=\ngithub.com/dlclark/regexp2 v1.4.0/go.mod h1:2pZnwuY/m+8K6iRw6wQdMtk+rH5tNGR1i55kozfMjCc=\ngithub.com/dlclark/regexp2 v1.7.0/go.mod h1:DHkYz0B9wPfa6wondMfaivmHpzrQ3v9q8cnmRbL6yW8=\ngithub.com/dlclark/regexp2 v1.11.4 h1:rPYF9/LECdNymJufQKmri9gV604RvvABwgOA8un7yAo=\ngithub.com/dlclark/regexp2 v1.11.4/go.mod h1:DHkYz0B9wPfa6wondMfaivmHpzrQ3v9q8cnmRbL6yW8=\ngithub.com/dustin/go-humanize v1.0.0/go.mod h1:HtrtbFcZ19U5GC7JDqmcUSB87Iq5E25KnS6fMYU6eOk=\ngithub.com/dustin/go-humanize v1.0.1 h1:GzkhY7T5VNhEkwH0PVJgjz+fX1rhBrR7pRT3mDkpeCY=\ngithub.com/dustin/go-humanize v1.0.1/go.mod h1:Mu1zIs6XwVuF/gI1OepvI0qD18qycQx+mFykh5fBlto=\ngithub.com/felixge/httpsnoop v1.0.4 h1:NFTV2Zj1bL4mc9sqWACXbQFVBBg2W3GPvqp8/ESS2Wg=\ngithub.com/felixge/httpsnoop v1.0.4/go.mod h1:m8KPJKqk1gH5J9DgRY2ASl2lWCfGKXixSwevea8zH2U=\ngithub.com/flynn/go-shlex v0.0.0-20150515145356-3f9db97f8568/go.mod h1:xEzjJPgXI435gkrCt3MPfRiAkVrwSbHsst4LCFVfpJc=\ngithub.com/francoispqt/gojay v1.2.13 h1:d2m3sFjloqoIUQU3TsHBgj6qg/BVGlTBeHDUmyJnXKk=\ngithub.com/francoispqt/gojay v1.2.13/go.mod h1:ehT5mTG4ua4581f1++1WLG0vPdaA9HaiDsoyrBGkyDY=\ngithub.com/frankban/quicktest v1.14.6 h1:7Xjx+VpznH+oBnejlPUj8oUpdxnVs4f8XU8WnHkI4W8=\ngithub.com/frankban/quicktest v1.14.6/go.mod h1:4ptaffx2x8+WTWXmUCuVU6aPUX1/Mz7zb5vbUoiM6w0=\ngithub.com/fsnotify/fsnotify v1.4.7/go.mod h1:jwhsz4b93w/PPRr/qN1Yymfu8t87LnFCMoQvtojpjFo=\ngithub.com/fxamacker/cbor/v2 v2.6.0 h1:sU6J2usfADwWlYDAFhZBQ6TnLFBHxgesMrQfQgk1tWA=\ngithub.com/fxamacker/cbor/v2 v2.6.0/go.mod h1:pxXPTn3joSm21Gbwsv0w9OSA2y1HFR9qXEeXQVeNoDQ=\ngithub.com/ghodss/yaml v1.0.0/go.mod h1:4dBDuWmgqj2HViK6kFavaiC9ZROes6MMH2rRYeMEF04=\ngithub.com/gliderlabs/ssh v0.1.1/go.mod h1:U7qILu1NlMHj9FlMhZLlkCdDnU1DBEAqr0aevW3Awn0=\ngithub.com/go-chi/chi/v5 v5.2.1 h1:KOIHODQj58PmL80G2Eak4WdvUzjSJSm0vG72crDCqb8=\ngithub.com/go-chi/chi/v5 v5.2.1/go.mod h1:L2yAIGWB3H+phAw1NxKwWM+7eUH/lU8pOMm5hHcoops=\ngithub.com/go-errors/errors v1.0.1/go.mod h1:f4zRHt4oKfwPJE5k8C9vpYG+aDHdBFUsgrm6/TyX73Q=\ngithub.com/go-jose/go-jose/v3 v3.0.4 h1:Wp5HA7bLQcKnf6YYao/4kpRpVMp/yf6+pJKV8WFSaNY=\ngithub.com/go-jose/go-jose/v3 v3.0.4/go.mod h1:5b+7YgP7ZICgJDBdfjZaIt+H/9L9T/YQrVfLAMboGkQ=\ngithub.com/go-kit/kit v0.4.0/go.mod h1:xBxKIO96dXMWWy0MnWVtmwkA9/13aqxPnvrjFYMA2as=\ngithub.com/go-kit/kit v0.13.0 h1:OoneCcHKHQ03LfBpoQCUfCluwd2Vt3ohz+kvbJneZAU=\ngithub.com/go-kit/kit v0.13.0/go.mod h1:phqEHMMUbyrCFCTgH48JueqrM3md2HcAZ8N3XE4FKDg=\ngithub.com/go-kit/log v0.1.0/go.mod h1:zbhenjAZHb184qTLMA9ZjW7ThYL0H2mk7Q6pNt4vbaY=\ngithub.com/go-kit/log v0.2.1 h1:MRVx0/zhvdseW+Gza6N9rVzU/IVzaeE1SFI4raAhmBU=\ngithub.com/go-kit/log v0.2.1/go.mod h1:NwTd00d/i8cPZ3xOwwiv2PO5MOcx78fFErGNcVmBjv0=\ngithub.com/go-logfmt/logfmt v0.5.0/go.mod h1:wCYkCAKZfumFQihp8CzCvQ3paCTfi41vtzG1KdI/P7A=\ngithub.com/go-logfmt/logfmt v0.5.1/go.mod h1:WYhtIu8zTZfxdn5+rREduYbwxfcBr/Vr6KEVveWlfTs=\ngithub.com/go-logfmt/logfmt v0.6.0 h1:wGYYu3uicYdqXVgoYbvnkrPVXkuLM1p1ifugDMEdRi4=\ngithub.com/go-logfmt/logfmt v0.6.0/go.mod h1:WYhtIu8zTZfxdn5+rREduYbwxfcBr/Vr6KEVveWlfTs=\ngithub.com/go-logr/logr v1.2.2/go.mod h1:jdQByPbusPIv2/zmleS9BjJVeZ6kBagPoEUsqbVz/1A=\ngithub.com/go-logr/logr v1.4.2 h1:6pFjapn8bFcIbiKo3XT4j/BhANplGihG6tvd+8rYgrY=\ngithub.com/go-logr/logr v1.4.2/go.mod h1:9T104GzyrTigFIr8wt5mBrctHMim0Nb2HLGrmQ40KvY=\ngithub.com/go-logr/stdr v1.2.2 h1:hSWxHoqTgW2S2qGc0LTAI563KZ5YKYRhT3MFKZMbjag=\ngithub.com/go-logr/stdr v1.2.2/go.mod h1:mMo/vtBO5dYbehREoey6XUKy/eSumjCCveDpRre4VKE=\ngithub.com/go-sql-driver/mysql v1.7.1 h1:lUIinVbN1DY0xBg0eMOzmmtGoHwWBbvnWubQUrtU8EI=\ngithub.com/go-sql-driver/mysql v1.7.1/go.mod h1:OXbVy3sEdcQ2Doequ6Z5BW6fXNQTmx+9S1MCJN5yJMI=\ngithub.com/go-stack/stack v1.6.0/go.mod h1:v0f6uXyyMGvRgIKkXu+yp6POWl0qKG85gN/melR3HDY=\ngithub.com/go-stack/stack v1.8.0/go.mod h1:v0f6uXyyMGvRgIKkXu+yp6POWl0qKG85gN/melR3HDY=\ngithub.com/go-task/slim-sprig v0.0.0-20230315185526-52ccab3ef572 h1:tfuBGBXKqDEevZMzYi5KSi8KkcZtzBcTgAUUtapy0OI=\ngithub.com/go-task/slim-sprig v0.0.0-20230315185526-52ccab3ef572/go.mod h1:9Pwr4B2jHnOSGXyyzV8ROjYa2ojvAY6HCGYYfMoC3Ls=\ngithub.com/gofrs/uuid v4.0.0+incompatible h1:1SD/1F5pU8p29ybwgQSwpQk+mwdRrXCYuPhW6m+TnJw=\ngithub.com/gofrs/uuid v4.0.0+incompatible/go.mod h1:b2aQJv3Z4Fp6yNu3cdSllBxTCLRxnplIgP/c0N/04lM=\ngithub.com/gogo/protobuf v1.1.1/go.mod h1:r8qH/GZQm5c6nD/R0oafs1akxWv10x8SbQlK7atdtwQ=\ngithub.com/golang/glog v0.0.0-20160126235308-23def4e6c14b/go.mod h1:SBH7ygxi8pfUlaOkMMuAQtPIUF8ecWP5IEl/CR7VP2Q=\ngithub.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da h1:oI5xCqsCo564l8iNU+DwB5epxmsaqB+rhGL0m5jtYqE=\ngithub.com/golang/groupcache v0.0.0-20210331224755-41bb18bfe9da/go.mod h1:cIg4eruTrX1D+g88fzRXU5OdNfaM+9IcxsU14FzY7Hc=\ngithub.com/golang/lint v0.0.0-20180702182130-06c8688daad7/go.mod h1:tluoj9z5200jBnyusfRPU2LqT6J+DAorxEvtC7LHB+E=\ngithub.com/golang/mock v1.1.1/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/mock v1.2.0/go.mod h1:oTYuIxOrZwtPieC+H1uAHpcLFnEyAGVDL/k47Jfbm0A=\ngithub.com/golang/protobuf v1.2.0/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.3.1/go.mod h1:6lQm79b+lXiMfvg/cZm0SGofjICqVBUtrP5yJMmIC1U=\ngithub.com/golang/protobuf v1.5.4 h1:i7eJL8qZTpSEXOPTxNKhASYpMn+8e5Q6AdndVa1dWek=\ngithub.com/golang/protobuf v1.5.4/go.mod h1:lnTiLA8Wa4RWRcIUkrtSVa5nRhsEGBg48fD6rSs7xps=\ngithub.com/golang/snappy v0.0.3/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/golang/snappy v0.0.4 h1:yAGX7huGHXlcLOEtBnF4w7FQwA26wojNCwOYAEhLjQM=\ngithub.com/golang/snappy v0.0.4/go.mod h1:/XxbfmMg8lxefKM7IXC3fBNl/7bRcc72aCRzEWrmP2Q=\ngithub.com/google/btree v0.0.0-20180813153112-4030bb1f1f0c/go.mod h1:lNA+9X1NB3Zf8V7Ke586lFgjr2dZNuvo3lPJSGZ5JPQ=\ngithub.com/google/btree v1.1.2 h1:xf4v41cLI2Z6FxbKm+8Bu+m8ifhj15JuZ9sa0jZCMUU=\ngithub.com/google/btree v1.1.2/go.mod h1:qOPhT0dTNdNzV6Z/lhRX0YXUafgPLFUh+gZMl761Gm4=\ngithub.com/google/cel-go v0.24.1 h1:jsBCtxG8mM5wiUJDSGUqU0K7Mtr3w7Eyv00rw4DiZxI=\ngithub.com/google/cel-go v0.24.1/go.mod h1:Hdf9TqOaTNSFQA1ybQaRqATVoK7m/zcf7IMhGXP5zI8=\ngithub.com/google/certificate-transparency-go v1.0.21/go.mod h1:QeJfpSbVSfYc7RgB3gJFj9cbuQMMchQxrWXz8Ruopmg=\ngithub.com/google/certificate-transparency-go v1.1.8-0.20240110162603-74a5dd331745 h1:heyoXNxkRT155x4jTAiSv5BVSVkueifPUm+Q8LUXMRo=\ngithub.com/google/certificate-transparency-go v1.1.8-0.20240110162603-74a5dd331745/go.mod h1:zN0wUQgV9LjwLZeFHnrAbQi8hzMVvEWePyk+MhPOk7k=\ngithub.com/google/go-cmp v0.2.0/go.mod h1:oXzfMopK8JAjlY9xF4vHSVASa0yLyX7SntLO5aqRK0M=\ngithub.com/google/go-cmp v0.5.9/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/go-cmp v0.6.0 h1:ofyhxvXcZhMsU5ulbFiLKl/XBFqE1GSq7atu8tAmTRI=\ngithub.com/google/go-cmp v0.6.0/go.mod h1:17dUlkBOakJ0+DkrSSNjCkIjxS6bF9zb3elmeNGIjoY=\ngithub.com/google/go-github v17.0.0+incompatible/go.mod h1:zLgOLi98H3fifZn+44m+umXrS52loVEgC2AApnigrVQ=\ngithub.com/google/go-querystring v1.0.0/go.mod h1:odCYkC5MyYFN7vkCjXpyrEuKhc/BUO6wN/zVPAxq5ck=\ngithub.com/google/go-tpm v0.9.0 h1:sQF6YqWMi+SCXpsmS3fd21oPy/vSddwZry4JnmltHVk=\ngithub.com/google/go-tpm v0.9.0/go.mod h1:FkNVkc6C+IsvDI9Jw1OveJmxGZUUaKxtrpOS47QWKfU=\ngithub.com/google/go-tpm-tools v0.4.4 h1:oiQfAIkc6xTy9Fl5NKTeTJkBTlXdHsxAofmQyxBKY98=\ngithub.com/google/go-tpm-tools v0.4.4/go.mod h1:T8jXkp2s+eltnCDIsXR84/MTcVU9Ja7bh3Mit0pa4AY=\ngithub.com/google/go-tspi v0.3.0 h1:ADtq8RKfP+jrTyIWIZDIYcKOMecRqNJFOew2IT0Inus=\ngithub.com/google/go-tspi v0.3.0/go.mod h1:xfMGI3G0PhxCdNVcYr1C4C+EizojDg/TXuX5by8CiHI=\ngithub.com/google/martian v2.1.0+incompatible/go.mod h1:9I4somxYTbIHy5NJKHRl3wXiIaQGbYVAs8BPL6v8lEs=\ngithub.com/google/pprof v0.0.0-20181206194817-3ea8567a2e57/go.mod h1:zfwlbNMJ+OItoe0UupaVj+oy1omPYYDuagoSzA8v9mc=\ngithub.com/google/pprof v0.0.0-20231212022811-ec68065c825e h1:bwOy7hAFd0C91URzMIEBfr6BAz29yk7Qj0cy6S7DJlU=\ngithub.com/google/pprof v0.0.0-20231212022811-ec68065c825e/go.mod h1:czg5+yv1E0ZGTi6S6vVK1mke0fV+FaUhNGcd6VRS9Ik=\ngithub.com/google/renameio v0.1.0/go.mod h1:KWCgfxg9yswjAJkECMjeO8J8rahYeXnNhOm40UhjYkI=\ngithub.com/google/s2a-go v0.1.7 h1:60BLSyTrOV4/haCDW4zb1guZItoSq8foHCXrAnjBo/o=\ngithub.com/google/s2a-go v0.1.7/go.mod h1:50CgR4k1jNlWBu4UfS4AcfhVe1r6pdZPygJ3R8F0Qdw=\ngithub.com/google/uuid v1.6.0 h1:NIvaJDMOsjHA8n1jAhLSgzrAzy1Hgr+hNrb57e+94F0=\ngithub.com/google/uuid v1.6.0/go.mod h1:TIyPZe4MgqvfeYDBFedMoGGpEw/LqOeaOT+nhxU+yHo=\ngithub.com/googleapis/enterprise-certificate-proxy v0.3.2 h1:Vie5ybvEvT75RniqhfFxPRy3Bf7vr3h0cechB90XaQs=\ngithub.com/googleapis/enterprise-certificate-proxy v0.3.2/go.mod h1:VLSiSSBs/ksPL8kq3OBOQ6WRI2QnaFynd1DCjZ62+V0=\ngithub.com/googleapis/gax-go v2.0.0+incompatible h1:j0GKcs05QVmm7yesiZq2+9cxHkNK9YM6zKx4D2qucQU=\ngithub.com/googleapis/gax-go v2.0.0+incompatible/go.mod h1:SFVmujtThgffbyetf+mdk2eWhX2bMyUtNHzFKcPA9HY=\ngithub.com/googleapis/gax-go/v2 v2.0.3/go.mod h1:LLvjysVCY1JZeum8Z6l8qUty8fiNwE08qbEPm1M08qg=\ngithub.com/googleapis/gax-go/v2 v2.12.4 h1:9gWcmF85Wvq4ryPFvGFaOgPIs1AQX0d0bcbGw4Z96qg=\ngithub.com/googleapis/gax-go/v2 v2.12.4/go.mod h1:KYEYLorsnIGDi/rPC8b5TdlB9kbKoFubselGIoBMCwI=\ngithub.com/gopherjs/gopherjs v0.0.0-20181017120253-0766667cb4d1/go.mod h1:wJfORRmW1u3UXTncJ5qlYoELFm8eSnnEO6hX4iZ3EWY=\ngithub.com/gregjones/httpcache v0.0.0-20180305231024-9cad4c3443a7/go.mod h1:FecbI9+v66THATjSRHfNgh1IVFe/9kFxbXtjV0ctIMA=\ngithub.com/grpc-ecosystem/grpc-gateway v1.5.0/go.mod h1:RSKVYQBd5MCa4OVpNdGskqpgL2+G+NZTnrVHpWWfpdw=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.22.0 h1:asbCHRVmodnJTuQ3qamDwqVOIjwqUPTYmYuemVOx+Ys=\ngithub.com/grpc-ecosystem/grpc-gateway/v2 v2.22.0/go.mod h1:ggCgvZ2r7uOoQjOyu2Y1NhHmEPPzzuhWgcza5M1Ji1I=\ngithub.com/hashicorp/hcl v1.0.0/go.mod h1:E5yfLk+7swimpb2L/Alb/PJmXilQ/rhwaUYs4T20WEQ=\ngithub.com/hexops/gotextdiff v1.0.3 h1:gitA9+qJrrTCsiCl7+kh75nPqQt1cx4ZkudSTLoUqJM=\ngithub.com/hexops/gotextdiff v1.0.3/go.mod h1:pSWU5MAI3yDq+fZBTazCSJysOMbxWL1BSow5/V2vxeg=\ngithub.com/huandu/xstrings v1.5.0 h1:2ag3IFq9ZDANvthTwTiqSSZLjDc+BedvHPAp5tJy2TI=\ngithub.com/huandu/xstrings v1.5.0/go.mod h1:y5/lhBue+AyNmUVz9RLU9xbLR0o4KIIExikq4ovT0aE=\ngithub.com/inconshreveable/mousetrap v1.0.0/go.mod h1:PxqpIevigyE2G7u3NXJIT2ANytuPF1OarO4DADm73n8=\ngithub.com/inconshreveable/mousetrap v1.1.0 h1:wN+x4NVGpMsO7ErUn/mUI3vEoE6Jt13X2s0bqwp9tc8=\ngithub.com/inconshreveable/mousetrap v1.1.0/go.mod h1:vpF70FUmC8bwa3OWnCshd2FqLfsEA9PFc4w1p2J65bw=\ngithub.com/jackc/chunkreader v1.0.0/go.mod h1:RT6O25fNZIuasFJRyZ4R/Y2BbhasbmZXF9QQ7T3kePo=\ngithub.com/jackc/chunkreader/v2 v2.0.0/go.mod h1:odVSm741yZoC3dpHEUXIqA9tQRhFrgOHwnPIn9lDKlk=\ngithub.com/jackc/chunkreader/v2 v2.0.1 h1:i+RDz65UE+mmpjTfyz0MoVTnzeYxroil2G82ki7MGG8=\ngithub.com/jackc/chunkreader/v2 v2.0.1/go.mod h1:odVSm741yZoC3dpHEUXIqA9tQRhFrgOHwnPIn9lDKlk=\ngithub.com/jackc/pgconn v0.0.0-20190420214824-7e0022ef6ba3/go.mod h1:jkELnwuX+w9qN5YIfX0fl88Ehu4XC3keFuOJJk9pcnA=\ngithub.com/jackc/pgconn v0.0.0-20190824142844-760dd75542eb/go.mod h1:lLjNuW/+OfW9/pnVKPazfWOgNfH2aPem8YQ7ilXGvJE=\ngithub.com/jackc/pgconn v0.0.0-20190831204454-2fabfa3c18b7/go.mod h1:ZJKsE/KZfsUgOEh9hBm+xYTstcNHg7UPMVJqRfQxq4s=\ngithub.com/jackc/pgconn v1.8.0/go.mod h1:1C2Pb36bGIP9QHGBYCjnyhqu7Rv3sGshaQUvmfGIB/o=\ngithub.com/jackc/pgconn v1.9.0/go.mod h1:YctiPyvzfU11JFxoXokUOOKQXQmDMoJL9vJzHH8/2JY=\ngithub.com/jackc/pgconn v1.9.1-0.20210724152538-d89c8390a530/go.mod h1:4z2w8XhRbP1hYxkpTuBjTS3ne3J48K83+u0zoyvg2pI=\ngithub.com/jackc/pgconn v1.14.3 h1:bVoTr12EGANZz66nZPkMInAV/KHD2TxH9npjXXgiB3w=\ngithub.com/jackc/pgconn v1.14.3/go.mod h1:RZbme4uasqzybK2RK5c65VsHxoyaml09lx3tXOcO/VM=\ngithub.com/jackc/pgio v1.0.0 h1:g12B9UwVnzGhueNavwioyEEpAmqMe1E/BN9ES+8ovkE=\ngithub.com/jackc/pgio v1.0.0/go.mod h1:oP+2QK2wFfUWgr+gxjoBH9KGBb31Eio69xUb0w5bYf8=\ngithub.com/jackc/pgmock v0.0.0-20190831213851-13a1b77aafa2/go.mod h1:fGZlG77KXmcq05nJLRkk0+p82V8B8Dw8KN2/V9c/OAE=\ngithub.com/jackc/pgmock v0.0.0-20201204152224-4fe30f7445fd/go.mod h1:hrBW0Enj2AZTNpt/7Y5rr2xe/9Mn757Wtb2xeBzPv2c=\ngithub.com/jackc/pgmock v0.0.0-20210724152146-4ad1a8207f65 h1:DadwsjnMwFjfWc9y5Wi/+Zz7xoE5ALHsRQlOctkOiHc=\ngithub.com/jackc/pgmock v0.0.0-20210724152146-4ad1a8207f65/go.mod h1:5R2h2EEX+qri8jOWMbJCtaPWkrrNc7OHwsp2TCqp7ak=\ngithub.com/jackc/pgpassfile v1.0.0 h1:/6Hmqy13Ss2zCq62VdNG8tM1wchn8zjSGOBJ6icpsIM=\ngithub.com/jackc/pgpassfile v1.0.0/go.mod h1:CEx0iS5ambNFdcRtxPj5JhEz+xB6uRky5eyVu/W2HEg=\ngithub.com/jackc/pgproto3 v1.1.0/go.mod h1:eR5FA3leWg7p9aeAqi37XOTgTIbkABlvcPB3E5rlc78=\ngithub.com/jackc/pgproto3/v2 v2.0.0-alpha1.0.20190420180111-c116219b62db/go.mod h1:bhq50y+xrl9n5mRYyCBFKkpRVTLYJVWeCc+mEAI3yXA=\ngithub.com/jackc/pgproto3/v2 v2.0.0-alpha1.0.20190609003834-432c2951c711/go.mod h1:uH0AWtUmuShn0bcesswc4aBTWGvw0cAxIJp+6OB//Wg=\ngithub.com/jackc/pgproto3/v2 v2.0.0-rc3/go.mod h1:ryONWYqW6dqSg1Lw6vXNMXoBJhpzvWKnT95C46ckYeM=\ngithub.com/jackc/pgproto3/v2 v2.0.0-rc3.0.20190831210041-4c03ce451f29/go.mod h1:ryONWYqW6dqSg1Lw6vXNMXoBJhpzvWKnT95C46ckYeM=\ngithub.com/jackc/pgproto3/v2 v2.0.6/go.mod h1:WfJCnwN3HIg9Ish/j3sgWXnAfK8A9Y0bwXYU5xKaEdA=\ngithub.com/jackc/pgproto3/v2 v2.1.1/go.mod h1:WfJCnwN3HIg9Ish/j3sgWXnAfK8A9Y0bwXYU5xKaEdA=\ngithub.com/jackc/pgproto3/v2 v2.3.3 h1:1HLSx5H+tXR9pW3in3zaztoEwQYRC9SQaYUHjTSUOag=\ngithub.com/jackc/pgproto3/v2 v2.3.3/go.mod h1:WfJCnwN3HIg9Ish/j3sgWXnAfK8A9Y0bwXYU5xKaEdA=\ngithub.com/jackc/pgservicefile v0.0.0-20200714003250-2b9c44734f2b/go.mod h1:vsD4gTJCa9TptPL8sPkXrLZ+hDuNrZCnj29CQpr4X1E=\ngithub.com/jackc/pgservicefile v0.0.0-20221227161230-091c0ba34f0a h1:bbPeKD0xmW/Y25WS6cokEszi5g+S0QxI/d45PkRi7Nk=\ngithub.com/jackc/pgservicefile v0.0.0-20221227161230-091c0ba34f0a/go.mod h1:5TJZWKEWniPve33vlWYSoGYefn3gLQRzjfDlhSJ9ZKM=\ngithub.com/jackc/pgtype v0.0.0-20190421001408-4ed0de4755e0/go.mod h1:hdSHsc1V01CGwFsrv11mJRHWJ6aifDLfdV3aVjFF0zg=\ngithub.com/jackc/pgtype v0.0.0-20190824184912-ab885b375b90/go.mod h1:KcahbBH1nCMSo2DXpzsoWOAfFkdEtEJpPbVLq8eE+mc=\ngithub.com/jackc/pgtype v0.0.0-20190828014616-a8802b16cc59/go.mod h1:MWlu30kVJrUS8lot6TQqcg7mtthZ9T0EoIBFiJcmcyw=\ngithub.com/jackc/pgtype v1.8.1-0.20210724151600-32e20a603178/go.mod h1:C516IlIV9NKqfsMCXTdChteoXmwgUceqaLfjg2e3NlM=\ngithub.com/jackc/pgtype v1.14.0 h1:y+xUdabmyMkJLyApYuPj38mW+aAIqCe5uuBB51rH3Vw=\ngithub.com/jackc/pgtype v1.14.0/go.mod h1:LUMuVrfsFfdKGLw+AFFVv6KtHOFMwRgDDzBt76IqCA4=\ngithub.com/jackc/pgx/v4 v4.0.0-20190420224344-cc3461e65d96/go.mod h1:mdxmSJJuR08CZQyj1PVQBHy9XOp5p8/SHH6a0psbY9Y=\ngithub.com/jackc/pgx/v4 v4.0.0-20190421002000-1b8f0016e912/go.mod h1:no/Y67Jkk/9WuGR0JG/JseM9irFbnEPbuWV2EELPNuM=\ngithub.com/jackc/pgx/v4 v4.0.0-pre1.0.20190824185557-6972a5742186/go.mod h1:X+GQnOEnf1dqHGpw7JmHqHc1NxDoalibchSk9/RWuDc=\ngithub.com/jackc/pgx/v4 v4.12.1-0.20210724153913-640aa07df17c/go.mod h1:1QD0+tgSXP7iUjYm9C1NxKhny7lq6ee99u/z+IHFcgs=\ngithub.com/jackc/pgx/v4 v4.18.3 h1:dE2/TrEsGX3RBprb3qryqSV9Y60iZN1C6i8IrmW9/BA=\ngithub.com/jackc/pgx/v4 v4.18.3/go.mod h1:Ey4Oru5tH5sB6tV7hDmfWFahwF15Eb7DNXlRKx2CkVw=\ngithub.com/jackc/puddle v0.0.0-20190413234325-e4ced69a3a2b/go.mod h1:m4B5Dj62Y0fbyuIc15OsIqK0+JU8nkqQjsgx7dvjSWk=\ngithub.com/jackc/puddle v0.0.0-20190608224051-11cab39313c9/go.mod h1:m4B5Dj62Y0fbyuIc15OsIqK0+JU8nkqQjsgx7dvjSWk=\ngithub.com/jackc/puddle v1.1.3/go.mod h1:m4B5Dj62Y0fbyuIc15OsIqK0+JU8nkqQjsgx7dvjSWk=\ngithub.com/jellevandenhooff/dkim v0.0.0-20150330215556-f50fe3d243e1/go.mod h1:E0B/fFc00Y+Rasa88328GlI/XbtyysCtTHZS8h7IrBU=\ngithub.com/jessevdk/go-flags v1.4.0/go.mod h1:4FA24M0QyGHXBuZZK/XkWh8h0e1EYbRYJSGM75WSRxI=\ngithub.com/json-iterator/go v1.1.6/go.mod h1:+SdeFBvtyEkXs7REEP0seUULqWtbJapLOCVDaaPEHmU=\ngithub.com/jstemmer/go-junit-report v0.0.0-20190106144839-af01ea7f8024/go.mod h1:6v2b51hI/fHJwM22ozAgKL4VKDeJcHhJFhtBdhmNjmU=\ngithub.com/kisielk/gotool v1.0.0/go.mod h1:XhKaO+MFFWcvkIS/tQcRk01m1F5IRFswLeQ+oQHNcck=\ngithub.com/klauspost/compress v1.12.3/go.mod h1:8dP1Hq4DHOhN9w426knH3Rhby4rFm6D8eO+e+Dq5Gzg=\ngithub.com/klauspost/compress v1.18.0 h1:c/Cqfb0r+Yi+JtIEq73FWXVkRonBlf0CRNYc8Zttxdo=\ngithub.com/klauspost/compress v1.18.0/go.mod h1:2Pp+KzxcywXVXMr50+X0Q/Lsb43OQHYWRCY2AiWywWQ=\ngithub.com/klauspost/cpuid/v2 v2.2.10 h1:tBs3QSyvjDyFTq3uoc/9xFpCuOsJQFNPiAhYdw2skhE=\ngithub.com/klauspost/cpuid/v2 v2.2.10/go.mod h1:hqwkgyIinND0mEev00jJYCxPNVRVXFQeu1XKlok6oO0=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.1/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/konsorten/go-windows-terminal-sequences v1.0.2/go.mod h1:T0+1ngSBFLxvqU3pZ+m/2kptfBszLMUkC4ZK/EgS/cQ=\ngithub.com/kr/pretty v0.1.0/go.mod h1:dAy3ld7l9f0ibDNOQOHHMYYIIbhfbHSm3C4ZsoJORNo=\ngithub.com/kr/pretty v0.2.0/go.mod h1:ipq/a2n7PKx3OHsz4KJII5eveXtPO4qwEXGdVfWzfnI=\ngithub.com/kr/pretty v0.3.1 h1:flRD4NNwYAUpkphVc1HcthR4KEIFJ65n8Mw5qdRn3LE=\ngithub.com/kr/pretty v0.3.1/go.mod h1:hoEshYVHaxMs3cyo3Yncou5ZscifuDolrwPKZanG3xk=\ngithub.com/kr/pty v1.1.1/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/pty v1.1.3/go.mod h1:pFQYn66WHrOpPYNljwOMqo10TkYh1fy3cYio2l3bCsQ=\ngithub.com/kr/pty v1.1.8/go.mod h1:O1sed60cT9XZ5uDucP5qwvh+TE3NnUj51EiZO/lmSfw=\ngithub.com/kr/text v0.1.0/go.mod h1:4Jbv+DJW3UT/LiOwJeYQe1efqtUx/iVham/4vfdArNI=\ngithub.com/kr/text v0.2.0 h1:5Nx0Ya0ZqY2ygV366QzturHI13Jq95ApcVaJBhpS+AY=\ngithub.com/kr/text v0.2.0/go.mod h1:eLer722TekiGuMkidMxC/pM04lWEeraHUUmBw8l2grE=\ngithub.com/lib/pq v1.0.0/go.mod h1:5WUZQaWbwv1U+lTReE5YruASi9Al49XbQIvNi/34Woo=\ngithub.com/lib/pq v1.1.0/go.mod h1:5WUZQaWbwv1U+lTReE5YruASi9Al49XbQIvNi/34Woo=\ngithub.com/lib/pq v1.2.0/go.mod h1:5WUZQaWbwv1U+lTReE5YruASi9Al49XbQIvNi/34Woo=\ngithub.com/lib/pq v1.10.2/go.mod h1:AlVN5x4E4T544tWzH6hKfbfQvm3HdbOxrmggDNAPY9o=\ngithub.com/lib/pq v1.10.9 h1:YXG7RB+JIjhP29X+OtkiDnYaXQwpS4JEWq7dtCCRUEw=\ngithub.com/lib/pq v1.10.9/go.mod h1:AlVN5x4E4T544tWzH6hKfbfQvm3HdbOxrmggDNAPY9o=\ngithub.com/libdns/libdns v1.0.0-beta.1 h1:KIf4wLfsrEpXpZ3vmc/poM8zCATXT2klbdPe6hyOBjQ=\ngithub.com/libdns/libdns v1.0.0-beta.1/go.mod h1:4Bj9+5CQiNMVGf87wjX4CY3HQJypUHRuLvlsfsZqLWQ=\ngithub.com/lunixbochs/vtclean v1.0.0/go.mod h1:pHhQNgMf3btfWnGBVipUOjRYhoOsdGqdm/+2c2E2WMI=\ngithub.com/magiconair/properties v1.8.0/go.mod h1:PppfXfuXeibc/6YijjN8zIbojt8czPbwD3XqdrwzmxQ=\ngithub.com/mailru/easyjson v0.0.0-20190312143242-1de009706dbe/go.mod h1:C1wdFJiN94OJF2b5HbByQZoLdCWB1Yqtg26g4irojpc=\ngithub.com/manifoldco/promptui v0.9.0 h1:3V4HzJk1TtXW1MTZMP7mdlwbBpIinw3HztaIlYthEiA=\ngithub.com/manifoldco/promptui v0.9.0/go.mod h1:ka04sppxSGFAtxX0qhlYQjISsg9mR4GWtQEhdbn6Pgg=\ngithub.com/mattn/go-colorable v0.1.1/go.mod h1:FuOcm+DKB9mbwrcAfNl7/TZVBZ6rcnceauSikq3lYCQ=\ngithub.com/mattn/go-colorable v0.1.6/go.mod h1:u6P/XSegPjTcexA+o6vUJrdnUu04hMope9wVRipJSqc=\ngithub.com/mattn/go-colorable v0.1.13 h1:fFA4WZxdEF4tXPZVKMLwD8oUnCTTo08duU7wxecdEvA=\ngithub.com/mattn/go-colorable v0.1.13/go.mod h1:7S9/ev0klgBDR4GtXTXX8a3vIGJpMovkB8vQcUbaXHg=\ngithub.com/mattn/go-isatty v0.0.5/go.mod h1:Iq45c/XA43vh69/j3iqttzPXn0bhXyGjM0Hdxcsrc5s=\ngithub.com/mattn/go-isatty v0.0.7/go.mod h1:Iq45c/XA43vh69/j3iqttzPXn0bhXyGjM0Hdxcsrc5s=\ngithub.com/mattn/go-isatty v0.0.12/go.mod h1:cbi8OIDigv2wuxKPP5vlRcQ1OAZbq2CE4Kysco4FUpU=\ngithub.com/mattn/go-isatty v0.0.16/go.mod h1:kYGgaQfpe5nmfYZH+SKPsOc2e4SrIfOl2e/yFXSvRLM=\ngithub.com/mattn/go-isatty v0.0.20 h1:xfD0iDuEKnDkl03q4limB+vH+GxLEtL/jb4xVJSWWEY=\ngithub.com/mattn/go-isatty v0.0.20/go.mod h1:W+V8PltTTMOvKvAeJH7IuucS94S2C6jfK/D7dTCTo3Y=\ngithub.com/matttproud/golang_protobuf_extensions v1.0.1/go.mod h1:D8He9yQNgCq6Z5Ld7szi9bcBfOoFv/3dc6xSMkL2PC0=\ngithub.com/mgutz/ansi v0.0.0-20200706080929-d51e80ef957d h1:5PJl274Y63IEHC+7izoQE9x6ikvDFZS2mDVS3drnohI=\ngithub.com/mgutz/ansi v0.0.0-20200706080929-d51e80ef957d/go.mod h1:01TrycV0kFyexm33Z7vhZRXopbI8J3TDReVlkTgMUxE=\ngithub.com/mholt/acmez/v3 v3.1.2 h1:auob8J/0FhmdClQicvJvuDavgd5ezwLBfKuYmynhYzc=\ngithub.com/mholt/acmez/v3 v3.1.2/go.mod h1:L1wOU06KKvq7tswuMDwKdcHeKpFFgkppZy/y0DFxagQ=\ngithub.com/microcosm-cc/bluemonday v1.0.1/go.mod h1:hsXNsILzKxV+sX77C5b8FSuKF00vh2OMYv+xgHpAMF4=\ngithub.com/miekg/dns v1.1.63 h1:8M5aAw6OMZfFXTT7K5V0Eu5YiiL8l7nUAkyN6C9YwaY=\ngithub.com/miekg/dns v1.1.63/go.mod h1:6NGHfjhpmr5lt3XPLuyfDJi5AXbNIPM9PY6H6sF1Nfs=\ngithub.com/mitchellh/copystructure v1.2.0 h1:vpKXTN4ewci03Vljg/q9QvCGUDttBOGBIa15WveJJGw=\ngithub.com/mitchellh/copystructure v1.2.0/go.mod h1:qLl+cE2AmVv+CoeAwDPye/v+N2HKCj9FbZEVFJRxO9s=\ngithub.com/mitchellh/go-homedir v1.1.0/go.mod h1:SfyaCUpYCn1Vlf4IUYiD9fPX4A5wJrkLzIz1N1q0pr0=\ngithub.com/mitchellh/go-ps v1.0.0 h1:i6ampVEEF4wQFF+bkYfwYgY+F/uYJDktmvLPf7qIgjc=\ngithub.com/mitchellh/go-ps v1.0.0/go.mod h1:J4lOc8z8yJs6vUwklHw2XEIiT4z4C40KtWVN3nvg8Pg=\ngithub.com/mitchellh/mapstructure v1.1.2/go.mod h1:FVVH3fgwuzCH5S8UJGiWEs2h04kUh9fWfEaFds41c1Y=\ngithub.com/mitchellh/reflectwalk v1.0.2 h1:G2LzWKi524PWgd3mLHV8Y5k7s6XUvT0Gef6zxSIeXaQ=\ngithub.com/mitchellh/reflectwalk v1.0.2/go.mod h1:mSTlrgnPZtwu0c4WaC2kGObEpuNDbx0jmZXqmk4esnw=\ngithub.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd/go.mod h1:6dJC0mAP4ikYIbvyc7fijjWJddQyLn8Ig3JB5CqoB9Q=\ngithub.com/modern-go/reflect2 v1.0.1/go.mod h1:bx2lNnkwVCuqBIxFjflWJWanXIb3RllmbCylyMrvgv0=\ngithub.com/neelance/astrewrite v0.0.0-20160511093645-99348263ae86/go.mod h1:kHJEU3ofeGjhHklVoIGuVj85JJwZ6kWPaJwCIxgnFmo=\ngithub.com/neelance/sourcemap v0.0.0-20151028013722-8c68805598ab/go.mod h1:Qr6/a/Q4r9LP1IltGz7tA7iOK1WonHEYhu1HRBA7ZiM=\ngithub.com/onsi/ginkgo/v2 v2.13.2 h1:Bi2gGVkfn6gQcjNjZJVO8Gf0FHzMPf2phUei9tejVMs=\ngithub.com/onsi/ginkgo/v2 v2.13.2/go.mod h1:XStQ8QcGwLyF4HdfcZB8SFOS/MWCgDuXMSBe6zrvLgM=\ngithub.com/onsi/gomega v1.29.0 h1:KIA/t2t5UBzoirT4H9tsML45GEbo3ouUnBHsCfD2tVg=\ngithub.com/onsi/gomega v1.29.0/go.mod h1:9sxs+SwGrKI0+PWe4Fxa9tFQQBG5xSsSbMXOI8PPpoQ=\ngithub.com/openzipkin/zipkin-go v0.1.1/go.mod h1:NtoC/o8u3JlF1lSlyPNswIbeQH9bJTmOf0Erfk+hxe8=\ngithub.com/pbnjay/memory v0.0.0-20210728143218-7b4eea64cf58 h1:onHthvaw9LFnH4t2DcNVpwGmV9E1BkGknEliJkfwQj0=\ngithub.com/pbnjay/memory v0.0.0-20210728143218-7b4eea64cf58/go.mod h1:DXv8WO4yhMYhSNPKjeNKa5WY9YCIEBRbNzFFPJbWO6Y=\ngithub.com/pelletier/go-toml v1.2.0/go.mod h1:5z9KED0ma1S8pY6P1sdut58dfprrGBbd/94hg7ilaic=\ngithub.com/peterbourgon/diskv/v3 v3.0.1 h1:x06SQA46+PKIUftmEujdwSEpIx8kR+M9eLYsUxeYveU=\ngithub.com/peterbourgon/diskv/v3 v3.0.1/go.mod h1:kJ5Ny7vLdARGU3WUuy6uzO6T0nb/2gWcT1JiBvRmb5o=\ngithub.com/pires/go-proxyproto v0.7.1-0.20240628150027-b718e7ce4964 h1:ct/vxNBgHpASQ4sT8NaBX9LtsEtluZqaUJydLG50U3E=\ngithub.com/pires/go-proxyproto v0.7.1-0.20240628150027-b718e7ce4964/go.mod h1:iknsfgnH8EkjrMeMyvfKByp9TiBZCKZM0jx2xmKqnVY=\ngithub.com/pkg/errors v0.8.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pkg/errors v0.9.1 h1:FEBLx1zS214owpjy7qsBeixbURkuhQAwrK5UwLGTwt4=\ngithub.com/pkg/errors v0.9.1/go.mod h1:bwawxfHBFNV+L2hUp1rHADufV3IMtnDRdf1r5NINEl0=\ngithub.com/pmezard/go-difflib v1.0.0 h1:4DBwDE0NGyQoBHbLQYPwSUPoCMWR5BEzIk/f1lZbAQM=\ngithub.com/pmezard/go-difflib v1.0.0/go.mod h1:iKH77koFhYxTK1pcRnkKkqfTogsbg7gZNVY4sRDYZ/4=\ngithub.com/prashantv/gostub v1.1.0 h1:BTyx3RfQjRHnUWaGF9oQos79AlQ5k8WNktv7VGvVH4g=\ngithub.com/prashantv/gostub v1.1.0/go.mod h1:A5zLQHz7ieHGG7is6LLXLz7I8+3LZzsrV0P1IAHhP5U=\ngithub.com/prometheus/client_golang v0.8.0/go.mod h1:7SWBe2y4D6OKWSNQJUaRYU/AaXPKyh/dDVn+NZz0KFw=\ngithub.com/prometheus/client_golang v1.19.1 h1:wZWJDwK+NameRJuPGDhlnFgx8e8HN3XHQeLaYJFJBOE=\ngithub.com/prometheus/client_golang v1.19.1/go.mod h1:mP78NwGzrVks5S2H6ab8+ZZGJLZUq1hoULYBAYBw1Ho=\ngithub.com/prometheus/client_model v0.0.0-20180712105110-5c3871d89910/go.mod h1:MbSGuTsp3dbXC40dX6PRTWyKYBIrTGTE9sqQNg2J8bo=\ngithub.com/prometheus/client_model v0.5.0 h1:VQw1hfvPvk3Uv6Qf29VrPF32JB6rtbgI6cYPYQjL0Qw=\ngithub.com/prometheus/client_model v0.5.0/go.mod h1:dTiFglRmd66nLR9Pv9f0mZi7B7fk5Pm3gvsjB5tr+kI=\ngithub.com/prometheus/common v0.0.0-20180801064454-c7de2306084e/go.mod h1:daVV7qP5qjZbuso7PdcryaAu0sAZbrN9i7WWcTMWvro=\ngithub.com/prometheus/common v0.48.0 h1:QO8U2CdOzSn1BBsmXJXduaaW+dY/5QLjfB8svtSzKKE=\ngithub.com/prometheus/common v0.48.0/go.mod h1:0/KsvlIEfPQCQ5I2iNSAWKPZziNCvRs5EC6ILDTlAPc=\ngithub.com/prometheus/procfs v0.0.0-20180725123919-05ee40e3a273/go.mod h1:c3At6R/oaqEKCNdg8wHV1ftS6bRYblBhIjjI8uT2IGk=\ngithub.com/prometheus/procfs v0.12.0 h1:jluTpSng7V9hY0O2R9DzzJHYb2xULk9VTR1V1R/k6Bo=\ngithub.com/prometheus/procfs v0.12.0/go.mod h1:pcuDEFsWDnvcgNzo4EEweacyhjeA9Zk3cnaOZAZEfOo=\ngithub.com/quic-go/qpack v0.5.1 h1:giqksBPnT/HDtZ6VhtFKgoLOWmlyo9Ei6u9PqzIMbhI=\ngithub.com/quic-go/qpack v0.5.1/go.mod h1:+PC4XFrEskIVkcLzpEkbLqq1uCoxPhQuvK5rH1ZgaEg=\ngithub.com/quic-go/quic-go v0.51.0 h1:K8exxe9zXxeRKxaXxi/GpUqYiTrtdiWP8bo1KFya6Wc=\ngithub.com/quic-go/quic-go v0.51.0/go.mod h1:MFlGGpcpJqRAfmYi6NC2cptDPSxRWTOGNuP4wqrWmzQ=\ngithub.com/rogpeppe/go-internal v1.3.0/go.mod h1:M8bDsm7K2OlrFYOpmOWEs/qY81heoFRclV5y23lUDJ4=\ngithub.com/rogpeppe/go-internal v1.13.1 h1:KvO1DLK/DRN07sQ1LQKScxyZJuNnedQ5/wKSR38lUII=\ngithub.com/rogpeppe/go-internal v1.13.1/go.mod h1:uMEvuHeurkdAXX61udpOXGD/AzZDWNMNyH2VO9fmH0o=\ngithub.com/rs/xid v1.2.1/go.mod h1:+uKXf+4Djp6Md1KODXJxgGQPKngRmWyn10oCKFzNHOQ=\ngithub.com/rs/xid v1.5.0 h1:mKX4bl4iPYJtEIxp6CYiUuLQ/8DYMoz0PUdtGgMFRVc=\ngithub.com/rs/xid v1.5.0/go.mod h1:trrq9SKmegXys3aeAKXMUTdJsYXVwGY3RLcfgqegfbg=\ngithub.com/rs/zerolog v1.13.0/go.mod h1:YbFCdg8HfsridGWAh22vktObvhZbQsZXe4/zB0OKkWU=\ngithub.com/rs/zerolog v1.15.0/go.mod h1:xYTKnLHcpfU2225ny5qZjxnj9NvkumZYjJHlAThCjNc=\ngithub.com/russross/blackfriday v1.5.2/go.mod h1:JO/DiYxRf+HjHt06OyowR9PTA263kcR/rfWxYHBV53g=\ngithub.com/russross/blackfriday/v2 v2.1.0 h1:JIOH55/0cWyOuilr9/qlrm0BSXldqnqwMsf35Ld67mk=\ngithub.com/russross/blackfriday/v2 v2.1.0/go.mod h1:+Rmxgy9KzJVeS9/2gXHxylqXiyQDYRxCVz55jmeOWTM=\ngithub.com/satori/go.uuid v1.2.0/go.mod h1:dA0hQrYB0VpLJoorglMZABFdXlWrHn1NEOzdhQKdks0=\ngithub.com/schollz/jsonstore v1.1.0 h1:WZBDjgezFS34CHI+myb4s8GGpir3UMpy7vWoCeO0n6E=\ngithub.com/schollz/jsonstore v1.1.0/go.mod h1:15c6+9guw8vDRyozGjN3FoILt0wpruJk9Pi66vjaZfg=\ngithub.com/sergi/go-diff v1.0.0/go.mod h1:0CfEIISq7TuYL3j771MWULgwwjU+GofnZX9QAmXWZgo=\ngithub.com/shopspring/decimal v0.0.0-20180709203117-cd690d0c9e24/go.mod h1:M+9NzErvs504Cn4c5DxATwIqPbtswREoFCre64PpcG4=\ngithub.com/shopspring/decimal v1.2.0/go.mod h1:DKyhrW/HYNuLGql+MJL6WCR6knT2jwCFRcu2hWCYk4o=\ngithub.com/shopspring/decimal v1.4.0 h1:bxl37RwXBklmTi0C79JfXCEBD1cqqHt0bbgBAGFp81k=\ngithub.com/shopspring/decimal v1.4.0/go.mod h1:gawqmDU56v4yIKSwfBSFip1HdCCXN8/+DMd9qYNcwME=\ngithub.com/shurcooL/component v0.0.0-20170202220835-f88ec8f54cc4/go.mod h1:XhFIlyj5a1fBNx5aJTbKoIq0mNaPvOagO+HjB3EtxrY=\ngithub.com/shurcooL/events v0.0.0-20181021180414-410e4ca65f48/go.mod h1:5u70Mqkb5O5cxEA8nxTsgrgLehJeAw6Oc4Ab1c/P1HM=\ngithub.com/shurcooL/github_flavored_markdown v0.0.0-20181002035957-2122de532470/go.mod h1:2dOwnU2uBioM+SGy2aZoq1f/Sd1l9OkAeAUvjSyvgU0=\ngithub.com/shurcooL/go v0.0.0-20180423040247-9e1955d9fb6e/go.mod h1:TDJrrUr11Vxrven61rcy3hJMUqaf/CLWYhHNPmT14Lk=\ngithub.com/shurcooL/go-goon v0.0.0-20170922171312-37c2f522c041/go.mod h1:N5mDOmsrJOB+vfqUK+7DmDyjhSLIIBnXo9lvZJj3MWQ=\ngithub.com/shurcooL/gofontwoff v0.0.0-20180329035133-29b52fc0a18d/go.mod h1:05UtEgK5zq39gLST6uB0cf3NEHjETfB4Fgr3Gx5R9Vw=\ngithub.com/shurcooL/gopherjslib v0.0.0-20160914041154-feb6d3990c2c/go.mod h1:8d3azKNyqcHP1GaQE/c6dDgjkgSx2BZ4IoEi4F1reUI=\ngithub.com/shurcooL/highlight_diff v0.0.0-20170515013008-09bb4053de1b/go.mod h1:ZpfEhSmds4ytuByIcDnOLkTHGUI6KNqRNPDLHDk+mUU=\ngithub.com/shurcooL/highlight_go v0.0.0-20181028180052-98c3abbbae20/go.mod h1:UDKB5a1T23gOMUJrI+uSuH0VRDStOiUVSjBTRDVBVag=\ngithub.com/shurcooL/home v0.0.0-20181020052607-80b7ffcb30f9/go.mod h1:+rgNQw2P9ARFAs37qieuu7ohDNQ3gds9msbT2yn85sg=\ngithub.com/shurcooL/htmlg v0.0.0-20170918183704-d01228ac9e50/go.mod h1:zPn1wHpTIePGnXSHpsVPWEktKXHr6+SS6x/IKRb7cpw=\ngithub.com/shurcooL/httperror v0.0.0-20170206035902-86b7830d14cc/go.mod h1:aYMfkZ6DWSJPJ6c4Wwz3QtW22G7mf/PEgaB9k/ik5+Y=\ngithub.com/shurcooL/httpfs v0.0.0-20171119174359-809beceb2371/go.mod h1:ZY1cvUeJuFPAdZ/B6v7RHavJWZn2YPVFQ1OSXhCGOkg=\ngithub.com/shurcooL/httpgzip v0.0.0-20180522190206-b1c53ac65af9/go.mod h1:919LwcH0M7/W4fcZ0/jy0qGght1GIhqyS/EgWGH2j5Q=\ngithub.com/shurcooL/issues v0.0.0-20181008053335-6292fdc1e191/go.mod h1:e2qWDig5bLteJ4fwvDAc2NHzqFEthkqn7aOZAOpj+PQ=\ngithub.com/shurcooL/issuesapp v0.0.0-20180602232740-048589ce2241/go.mod h1:NPpHK2TI7iSaM0buivtFUc9offApnI0Alt/K8hcHy0I=\ngithub.com/shurcooL/notifications v0.0.0-20181007000457-627ab5aea122/go.mod h1:b5uSkrEVM1jQUspwbixRBhaIjIzL2xazXp6kntxYle0=\ngithub.com/shurcooL/octicon v0.0.0-20181028054416-fa4f57f9efb2/go.mod h1:eWdoE5JD4R5UVWDucdOPg1g2fqQRq78IQa9zlOV1vpQ=\ngithub.com/shurcooL/reactions v0.0.0-20181006231557-f2e0b4ca5b82/go.mod h1:TCR1lToEk4d2s07G3XGfz2QrgHXg4RJBvjrOozvoWfk=\ngithub.com/shurcooL/sanitized_anchor_name v0.0.0-20170918181015-86672fcb3f95/go.mod h1:1NzhyTcUVG4SuEtjjoZeVRXNmyL/1OwPU0+IJeTBvfc=\ngithub.com/shurcooL/sanitized_anchor_name v1.0.0 h1:PdmoCO6wvbs+7yrJyMORt4/BmY5IYyJwS/kOiWx8mHo=\ngithub.com/shurcooL/sanitized_anchor_name v1.0.0/go.mod h1:1NzhyTcUVG4SuEtjjoZeVRXNmyL/1OwPU0+IJeTBvfc=\ngithub.com/shurcooL/users v0.0.0-20180125191416-49c67e49c537/go.mod h1:QJTqeLYEDaXHZDBsXlPCDqdhQuJkuw4NOtaxYe3xii4=\ngithub.com/shurcooL/webdavfs v0.0.0-20170829043945-18c3829fa133/go.mod h1:hKmq5kWdCj2z2KEozexVbfEZIWiTjhE0+UjmZgPqehw=\ngithub.com/sirupsen/logrus v1.4.1/go.mod h1:ni0Sbl8bgC9z8RoU9G6nDWqqs/fq4eDPysMBDgk/93Q=\ngithub.com/sirupsen/logrus v1.4.2/go.mod h1:tLMulIdttU9McNUspp0xgXVQah82FyeX6MwdIuYE2rE=\ngithub.com/sirupsen/logrus v1.7.0/go.mod h1:yWOB1SBYBC5VeMP7gHvWumXLIWorT60ONWic61uBYv0=\ngithub.com/sirupsen/logrus v1.9.3 h1:dueUQJ1C2q9oE3F7wvmSGAaVtTmUizReu6fjN8uqzbQ=\ngithub.com/sirupsen/logrus v1.9.3/go.mod h1:naHLuLoDiP4jHNo9R0sCBMtWGeIprob74mVsIT4qYEQ=\ngithub.com/slackhq/nebula v1.6.1 h1:/OCTR3abj0Sbf2nGoLUrdDXImrCv0ZVFpVPP5qa0DsM=\ngithub.com/slackhq/nebula v1.6.1/go.mod h1:UmkqnXe4O53QwToSl/gG7sM4BroQwAB7dd4hUaT6MlI=\ngithub.com/smallstep/assert v0.0.0-20200723003110-82e2b9b3b262 h1:unQFBIznI+VYD1/1fApl1A+9VcBk+9dcqGfnePY87LY=\ngithub.com/smallstep/assert v0.0.0-20200723003110-82e2b9b3b262/go.mod h1:MyOHs9Po2fbM1LHej6sBUT8ozbxmMOFG+E+rx/GSGuc=\ngithub.com/smallstep/certificates v0.26.1 h1:FIUliEBcExSfJJDhRFA/s8aZgMIFuorexnRSKQd884o=\ngithub.com/smallstep/certificates v0.26.1/go.mod h1:OQMrW39IrGKDViKSHrKcgSQArMZ8c7EcjhYKK7mYqis=\ngithub.com/smallstep/go-attestation v0.4.4-0.20240109183208-413678f90935 h1:kjYvkvS/Wdy0PVRDUAA0gGJIVSEZYhiAJtfwYgOYoGA=\ngithub.com/smallstep/go-attestation v0.4.4-0.20240109183208-413678f90935/go.mod h1:vNAduivU014fubg6ewygkAvQC0IQVXqdc8vaGl/0er4=\ngithub.com/smallstep/nosql v0.6.1 h1:X8IBZFTRIp1gmuf23ne/jlD/BWKJtDQbtatxEn7Et1Y=\ngithub.com/smallstep/nosql v0.6.1/go.mod h1:vrN+CftYYNnDM+DQqd863ATynvYFm/6FuY9D4TeAm2Y=\ngithub.com/smallstep/pkcs7 v0.0.0-20231024181729-3b98ecc1ca81 h1:B6cED3iLJTgxpdh4tuqByDjRRKan2EvtnOfHr2zHJVg=\ngithub.com/smallstep/pkcs7 v0.0.0-20231024181729-3b98ecc1ca81/go.mod h1:SoUAr/4M46rZ3WaLstHxGhLEgoYIDRqxQEXLOmOEB0Y=\ngithub.com/smallstep/scep v0.0.0-20231024192529-aee96d7ad34d h1:06LUHn4Ia2X6syjIaCMNaXXDNdU+1N/oOHynJbWgpXw=\ngithub.com/smallstep/scep v0.0.0-20231024192529-aee96d7ad34d/go.mod h1:4d0ub42ut1mMtvGyMensjuHYEUpRrASvkzLEJvoRQcU=\ngithub.com/smallstep/truststore v0.13.0 h1:90if9htAOblavbMeWlqNLnO9bsjjgVv2hQeQJCi/py4=\ngithub.com/smallstep/truststore v0.13.0/go.mod h1:3tmMp2aLKZ/OA/jnFUB0cYPcho402UG2knuJoPh4j7A=\ngithub.com/sourcegraph/annotate v0.0.0-20160123013949-f4cad6c6324d/go.mod h1:UdhH50NIW0fCiwBSr0co2m7BnFLdv4fQTgdqdJTHFeE=\ngithub.com/sourcegraph/syntaxhighlight v0.0.0-20170531221838-bd320f5d308e/go.mod h1:HuIsMU8RRBOtsCgI77wP899iHVBQpCmg4ErYMZB+2IA=\ngithub.com/spaolacci/murmur3 v0.0.0-20180118202830-f09979ecbc72/go.mod h1:JwIasOWyU6f++ZhiEuf87xNszmSA2myDM2Kzu9HwQUA=\ngithub.com/spaolacci/murmur3 v1.1.0 h1:7c1g84S4BPRrfL5Xrdp6fOJ206sU9y293DDHaoy0bLI=\ngithub.com/spaolacci/murmur3 v1.1.0/go.mod h1:JwIasOWyU6f++ZhiEuf87xNszmSA2myDM2Kzu9HwQUA=\ngithub.com/spf13/afero v1.1.2/go.mod h1:j4pytiNVoe2o6bmDsKpLACNPDBIoEAkihy7loJ1B0CQ=\ngithub.com/spf13/cast v1.3.0/go.mod h1:Qx5cxh0v+4UWYiBimWS+eyWzqEqokIECu5etghLkUJE=\ngithub.com/spf13/cast v1.7.0 h1:ntdiHjuueXFgm5nzDRdOS4yfT43P5Fnud6DH50rz/7w=\ngithub.com/spf13/cast v1.7.0/go.mod h1:ancEpBxwJDODSW/UG4rDrAqiKolqNNh2DX3mk86cAdo=\ngithub.com/spf13/cobra v0.0.5/go.mod h1:3K3wKZymM7VvHMDS9+Akkh4K60UwM26emMESw8tLCHU=\ngithub.com/spf13/cobra v1.9.1 h1:CXSaggrXdbHK9CF+8ywj8Amf7PBRmPCOJugH954Nnlo=\ngithub.com/spf13/cobra v1.9.1/go.mod h1:nDyEzZ8ogv936Cinf6g1RU9MRY64Ir93oCnqb9wxYW0=\ngithub.com/spf13/jwalterweatherman v1.0.0/go.mod h1:cQK4TGJAtQXfYWX+Ddv3mKDzgVb68N+wFjFa4jdeBTo=\ngithub.com/spf13/pflag v1.0.3/go.mod h1:DYY7MBk1bdzusC3SYhjObp+wFpr4gzcvqqNjLnInEg4=\ngithub.com/spf13/pflag v1.0.6 h1:jFzHGLGAlb3ruxLB8MhbI6A8+AQX/2eW4qeyNZXNp2o=\ngithub.com/spf13/pflag v1.0.6/go.mod h1:McXfInJRrz4CZXVZOBLb0bTZqETkiAhM9Iw0y3An2Bg=\ngithub.com/spf13/viper v1.3.2/go.mod h1:ZiWeW+zYFKm7srdB9IoDzzZXaJaI5eL9QjNiN/DMA2s=\ngithub.com/stoewer/go-strcase v1.2.0 h1:Z2iHWqGXH00XYgqDmNgQbIBxf3wrNq0F3feEy0ainaU=\ngithub.com/stoewer/go-strcase v1.2.0/go.mod h1:IBiWB2sKIp3wVVQ3Y035++gc+knqhUQag1KpM8ahLw8=\ngithub.com/stretchr/objx v0.1.0/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.1.1/go.mod h1:HFkY916IF+rwdDfMAkV7OtwuqBVzrE8GR6GFx+wExME=\ngithub.com/stretchr/objx v0.2.0/go.mod h1:qt09Ya8vawLte6SNmTgCsAVtYtaKzEcn8ATUoHMkEqE=\ngithub.com/stretchr/objx v0.4.0/go.mod h1:YvHI0jy2hoMjB+UWwv71VJQ9isScKT/TqJzVSSt89Yw=\ngithub.com/stretchr/objx v0.5.0/go.mod h1:Yh+to48EsGEfYuaHDzXPcE3xhTkx73EhmCGUpEOglKo=\ngithub.com/stretchr/testify v1.2.2/go.mod h1:a8OnRcib4nhh0OaRAV+Yts87kKdq0PP7pXfy6kDkUVs=\ngithub.com/stretchr/testify v1.3.0/go.mod h1:M5WIy9Dh21IEIfnGCwXGc5bZfKNJtfHm1UVUgZn+9EI=\ngithub.com/stretchr/testify v1.4.0/go.mod h1:j7eGeouHqKxXV5pUuKE4zz7dFj8WfuZ+81PSLYec5m4=\ngithub.com/stretchr/testify v1.5.1/go.mod h1:5W2xD1RspED5o8YsWQXVCued0rvSQ+mT+I5cxcmMvtA=\ngithub.com/stretchr/testify v1.6.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.0/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.7.1/go.mod h1:6Fq8oRcR53rry900zMqJjRRixrwX3KX962/h/Wwjteg=\ngithub.com/stretchr/testify v1.8.0/go.mod h1:yNjHg4UonilssWZ8iaSj1OCr/vHnekPRkoO+kdMU+MU=\ngithub.com/stretchr/testify v1.8.4/go.mod h1:sz/lmYIOXD/1dqDmKjjqLyZ2RngseejIcXlSw2iwfAo=\ngithub.com/stretchr/testify v1.10.0 h1:Xv5erBjTwe/5IxqUQTdXv5kgmIvbHo3QQyRwhJsOfJA=\ngithub.com/stretchr/testify v1.10.0/go.mod h1:r2ic/lqez/lEtzL7wO/rwa5dbSLXVDPFyf8C91i36aY=\ngithub.com/tailscale/tscert v0.0.0-20240608151842-d3f834017e53 h1:uxMgm0C+EjytfAqyfBG55ZONKQ7mvd7x4YYCWsf8QHQ=\ngithub.com/tailscale/tscert v0.0.0-20240608151842-d3f834017e53/go.mod h1:kNGUQ3VESx3VZwRwA9MSCUegIl6+saPL8Noq82ozCaU=\ngithub.com/tarm/serial v0.0.0-20180830185346-98f6abe2eb07/go.mod h1:kDXzergiv9cbyO7IOYJZWg1U88JhDg3PB6klq9Hg2pA=\ngithub.com/ugorji/go/codec v0.0.0-20181204163529-d75b2dcb6bc8/go.mod h1:VFNgLljTbGfSG7qAOspJ7OScBnGdDN/yBr0sguwnwf0=\ngithub.com/urfave/cli v1.22.14 h1:ebbhrRiGK2i4naQJr+1Xj92HXZCrK7MsyTS/ob3HnAk=\ngithub.com/urfave/cli v1.22.14/go.mod h1:X0eDS6pD6Exaclxm99NJ3FiCDRED7vIHpx2mDOHLvkA=\ngithub.com/viant/assertly v0.4.8/go.mod h1:aGifi++jvCrUaklKEKT0BU95igDNaqkvz+49uaYMPRU=\ngithub.com/viant/toolbox v0.24.0/go.mod h1:OxMCG57V0PXuIP2HNQrtJf2CjqdmbrOx5EkMILuUhzM=\ngithub.com/x448/float16 v0.8.4 h1:qLwI1I70+NjRFUR3zs1JPUCgaCXSh3SW62uAKT1mSBM=\ngithub.com/x448/float16 v0.8.4/go.mod h1:14CWIYCyZA/cWjXOioeEpHeN/83MdbZDRQHoFcYsOfg=\ngithub.com/xordataexchange/crypt v0.0.3-0.20170626215501-b2862e3d0a77/go.mod h1:aYKd//L2LvnjZzWKhF00oedf4jCCReLcmhLdhm1A27Q=\ngithub.com/yuin/goldmark v1.4.13/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngithub.com/yuin/goldmark v1.4.15/go.mod h1:6yULJ656Px+3vBD8DxQVa3kxgyrAnzto9xy5taEt/CY=\ngithub.com/yuin/goldmark v1.7.8 h1:iERMLn0/QJeHFhxSt3p6PeN9mGnvIKSpG9YYorDMnic=\ngithub.com/yuin/goldmark v1.7.8/go.mod h1:uzxRWxtg69N339t3louHJ7+O03ezfj6PlliRlaOzY1E=\ngithub.com/yuin/goldmark-highlighting/v2 v2.0.0-20230729083705-37449abec8cc h1:+IAOyRda+RLrxa1WC7umKOZRsGq4QrFFMYApOeHzQwQ=\ngithub.com/yuin/goldmark-highlighting/v2 v2.0.0-20230729083705-37449abec8cc/go.mod h1:ovIvrum6DQJA4QsJSovrkC4saKHQVs7TvcaeO8AIl5I=\ngithub.com/zeebo/assert v1.1.0 h1:hU1L1vLTHsnO8x8c9KAR5GmM5QscxHg5RNU5z5qbUWY=\ngithub.com/zeebo/assert v1.1.0/go.mod h1:Pq9JiuJQpG8JLJdtkwrJESF0Foym2/D9XMU5ciN/wJ0=\ngithub.com/zeebo/blake3 v0.2.4 h1:KYQPkhpRtcqh0ssGYcKLG1JYvddkEA8QwCM/yBqhaZI=\ngithub.com/zeebo/blake3 v0.2.4/go.mod h1:7eeQ6d2iXWRGF6npfaxl2CU+xy2Fjo2gxeyZGCRUjcE=\ngithub.com/zeebo/pcg v1.0.1 h1:lyqfGeWiv4ahac6ttHs+I5hwtH/+1mrhlCtVNQM2kHo=\ngithub.com/zeebo/pcg v1.0.1/go.mod h1:09F0S9iiKrwn9rlI5yjLkmrug154/YRW6KnnXVDM/l4=\ngithub.com/zenazn/goji v0.9.0/go.mod h1:7S9M489iMyHBNxwZnk9/EHS098H4/F6TATF2mIxtB1Q=\ngo.etcd.io/bbolt v1.3.9 h1:8x7aARPEXiXbHmtUwAIv7eV2fQFHrLLavdiJ3uzJXoI=\ngo.etcd.io/bbolt v1.3.9/go.mod h1:zaO32+Ti0PK1ivdPtgMESzuzL2VPoIG1PCQNvOdo/dE=\ngo.opencensus.io v0.18.0/go.mod h1:vKdFvxhtzZ9onBp9VKHK8z/sRpBMnKAsufL7wlDrCOA=\ngo.opencensus.io v0.24.0 h1:y73uSU6J157QMP2kn2r30vwW1A2W2WFwSCGnAVxeaD0=\ngo.opencensus.io v0.24.0/go.mod h1:vNK8G9p7aAivkbmorf4v+7Hgx+Zs0yY+0fOtgBfjQKo=\ngo.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc v0.49.0 h1:4Pp6oUg3+e/6M4C0A/3kJ2VYa++dsWVTtGgLVj5xtHg=\ngo.opentelemetry.io/contrib/instrumentation/google.golang.org/grpc/otelgrpc v0.49.0/go.mod h1:Mjt1i1INqiaoZOMGR1RIUJN+i3ChKoFRqzrRQhlkbs0=\ngo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.56.0 h1:UP6IpuHFkUgOQL9FFQFrZ+5LiwhhYRbi7VZSIx6Nj5s=\ngo.opentelemetry.io/contrib/instrumentation/net/http/otelhttp v0.56.0/go.mod h1:qxuZLtbq5QDtdeSHsS7bcf6EH6uO6jUAgk764zd3rhM=\ngo.opentelemetry.io/contrib/propagators/autoprop v0.42.0 h1:s2RzYOAqHVgG23q8fPWYChobUoZM6rJZ98EnylJr66w=\ngo.opentelemetry.io/contrib/propagators/autoprop v0.42.0/go.mod h1:Mv/tWNtZn+NbALDb2XcItP0OM3lWWZjAfSroINxfW+Y=\ngo.opentelemetry.io/contrib/propagators/aws v1.17.0 h1:IX8d7l2uRw61BlmZBOTQFaK+y22j6vytMVTs9wFrO+c=\ngo.opentelemetry.io/contrib/propagators/aws v1.17.0/go.mod h1:pAlCYRWff4uGqRXOVn3WP8pDZ5E0K56bEoG7a1VSL4k=\ngo.opentelemetry.io/contrib/propagators/b3 v1.17.0 h1:ImOVvHnku8jijXqkwCSyYKRDt2YrnGXD4BbhcpfbfJo=\ngo.opentelemetry.io/contrib/propagators/b3 v1.17.0/go.mod h1:IkfUfMpKWmynvvE0264trz0sf32NRTZL4nuAN9AbWRc=\ngo.opentelemetry.io/contrib/propagators/jaeger v1.17.0 h1:Zbpbmwav32Ea5jSotpmkWEl3a6Xvd4tw/3xxGO1i05Y=\ngo.opentelemetry.io/contrib/propagators/jaeger v1.17.0/go.mod h1:tcTUAlmO8nuInPDSBVfG+CP6Mzjy5+gNV4mPxMbL0IA=\ngo.opentelemetry.io/contrib/propagators/ot v1.17.0 h1:ufo2Vsz8l76eI47jFjuVyjyB3Ae2DmfiCV/o6Vc8ii0=\ngo.opentelemetry.io/contrib/propagators/ot v1.17.0/go.mod h1:SbKPj5XGp8K/sGm05XblaIABgMgw2jDczP8gGeuaVLk=\ngo.opentelemetry.io/otel v1.31.0 h1:NsJcKPIW0D0H3NgzPDHmo0WW6SptzPdqg/L1zsIm2hY=\ngo.opentelemetry.io/otel v1.31.0/go.mod h1:O0C14Yl9FgkjqcCZAsE053C13OaddMYr/hz6clDkEJE=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.31.0 h1:K0XaT3DwHAcV4nKLzcQvwAgSyisUghWoY20I7huthMk=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace v1.31.0/go.mod h1:B5Ki776z/MBnVha1Nzwp5arlzBbE3+1jk+pGmaP5HME=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.31.0 h1:FFeLy03iVTXP6ffeN2iXrxfGsZGCjVx0/4KlizjyBwU=\ngo.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc v1.31.0/go.mod h1:TMu73/k1CP8nBUpDLc71Wj/Kf7ZS9FK5b53VapRsP9o=\ngo.opentelemetry.io/otel/metric v1.31.0 h1:FSErL0ATQAmYHUIzSezZibnyVlft1ybhy4ozRPcF2fE=\ngo.opentelemetry.io/otel/metric v1.31.0/go.mod h1:C3dEloVbLuYoX41KpmAhOqNriGbA+qqH6PQ5E5mUfnY=\ngo.opentelemetry.io/otel/sdk v1.31.0 h1:xLY3abVHYZ5HSfOg3l2E5LUj2Cwva5Y7yGxnSW9H5Gk=\ngo.opentelemetry.io/otel/sdk v1.31.0/go.mod h1:TfRbMdhvxIIr/B2N2LQW2S5v9m3gOQ/08KsbbO5BPT0=\ngo.opentelemetry.io/otel/trace v1.31.0 h1:ffjsj1aRouKewfr85U2aGagJ46+MvodynlQ1HYdmJys=\ngo.opentelemetry.io/otel/trace v1.31.0/go.mod h1:TXZkRk7SM2ZQLtR6eoAWQFIHPvzQ06FJAsO1tJg480A=\ngo.opentelemetry.io/proto/otlp v1.3.1 h1:TrMUixzpM0yuc/znrFTP9MMRh8trP93mkCiDVeXrui0=\ngo.opentelemetry.io/proto/otlp v1.3.1/go.mod h1:0X1WI4de4ZsLrrJNLAQbFeLCm3T7yBkR0XqQ7niQU+8=\ngo.step.sm/cli-utils v0.9.0 h1:55jYcsQbnArNqepZyAwcato6Zy2MoZDRkWW+jF+aPfQ=\ngo.step.sm/cli-utils v0.9.0/go.mod h1:Y/CRoWl1FVR9j+7PnAewufAwKmBOTzR6l9+7EYGAnp8=\ngo.step.sm/crypto v0.45.0 h1:Z0WYAaaOYrJmKP9sJkPW+6wy3pgN3Ija8ek/D4serjc=\ngo.step.sm/crypto v0.45.0/go.mod h1:6IYlT0L2jfj81nVyCPpvA5cORy0EVHPhieSgQyuwHIY=\ngo.step.sm/linkedca v0.20.1 h1:bHDn1+UG1NgRrERkWbbCiAIvv4lD5NOFaswPDTyO5vU=\ngo.step.sm/linkedca v0.20.1/go.mod h1:Vaq4+Umtjh7DLFI1KuIxeo598vfBzgSYZUjgVJ7Syxw=\ngo.uber.org/atomic v1.3.2/go.mod h1:gD2HeocX3+yG+ygLZcrzQJaqmWj9AIm7n08wl/qW/PE=\ngo.uber.org/atomic v1.4.0/go.mod h1:gD2HeocX3+yG+ygLZcrzQJaqmWj9AIm7n08wl/qW/PE=\ngo.uber.org/atomic v1.5.0/go.mod h1:sABNBOSYdrvTF6hTgEIbc7YasKWGhgEQZyfxyTvoXHQ=\ngo.uber.org/atomic v1.6.0/go.mod h1:sABNBOSYdrvTF6hTgEIbc7YasKWGhgEQZyfxyTvoXHQ=\ngo.uber.org/automaxprocs v1.6.0 h1:O3y2/QNTOdbF+e/dpXNNW7Rx2hZ4sTIPyybbxyNqTUs=\ngo.uber.org/automaxprocs v1.6.0/go.mod h1:ifeIMSnPZuznNm6jmdzmU3/bfk01Fe2fotchwEFJ8r8=\ngo.uber.org/goleak v1.3.0 h1:2K3zAYmnTNqV73imy9J1T3WC+gmCePx2hEGkimedGto=\ngo.uber.org/goleak v1.3.0/go.mod h1:CoHD4mav9JJNrW/WLlf7HGZPjdw8EucARQHekz1X6bE=\ngo.uber.org/mock v0.5.0 h1:KAMbZvZPyBPWgD14IrIQ38QCyjwpvVVV6K/bHl1IwQU=\ngo.uber.org/mock v0.5.0/go.mod h1:ge71pBPLYDk7QIi1LupWxdAykm7KIEFchiOqd6z7qMM=\ngo.uber.org/multierr v1.1.0/go.mod h1:wR5kodmAFQ0UK8QlbwjlSNy0Z68gJhDJUG5sjR94q/0=\ngo.uber.org/multierr v1.3.0/go.mod h1:VgVr7evmIr6uPjLBxg28wmKNXyqE9akIJ5XnfpiKl+4=\ngo.uber.org/multierr v1.5.0/go.mod h1:FeouvMocqHpRaaGuG9EjoKcStLC43Zu/fmqdUMPcKYU=\ngo.uber.org/multierr v1.11.0 h1:blXXJkSxSSfBVBlC76pxqeO+LN3aDfLQo+309xJstO0=\ngo.uber.org/multierr v1.11.0/go.mod h1:20+QtiLqy0Nd6FdQB9TLXag12DsQkrbs3htMFfDN80Y=\ngo.uber.org/tools v0.0.0-20190618225709-2cfd321de3ee/go.mod h1:vJERXedbb3MVM5f9Ejo0C68/HhF8uaILCdgjnY+goOA=\ngo.uber.org/zap v1.9.1/go.mod h1:vwi/ZaCAaUcBkycHslxD9B2zi4UTXhF60s6SWpuDF0Q=\ngo.uber.org/zap v1.10.0/go.mod h1:vwi/ZaCAaUcBkycHslxD9B2zi4UTXhF60s6SWpuDF0Q=\ngo.uber.org/zap v1.13.0/go.mod h1:zwrFLgMcdUuIBviXEYEH1YKNaOBnKXsx2IPda5bBwHM=\ngo.uber.org/zap v1.27.0 h1:aJMhYGrd5QSmlpLMr2MftRKl7t8J8PTZPA732ud/XR8=\ngo.uber.org/zap v1.27.0/go.mod h1:GB2qFLM7cTU87MWRP2mPIjqfIDnGu+VIO4V/SdhGo2E=\ngo.uber.org/zap/exp v0.3.0 h1:6JYzdifzYkGmTdRR59oYH+Ng7k49H9qVpWwNSsGJj3U=\ngo.uber.org/zap/exp v0.3.0/go.mod h1:5I384qq7XGxYyByIhHm6jg5CHkGY0nsTfbDLgDDlgJQ=\ngo4.org v0.0.0-20180809161055-417644f6feb5/go.mod h1:MkTOUMDaeVYJUOUsaDXIhWPZYa1yOyC1qaOBpL57BhE=\ngolang.org/x/build v0.0.0-20190111050920-041ab4dc3f9d/go.mod h1:OWs+y06UdEOHN4y+MfF/py+xQ/tYqIWW03b70/CG9Rw=\ngolang.org/x/crypto v0.0.0-20181030102418-4d3f4d9ffa16/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20181203042331-505ab145d0a9/go.mod h1:6SG95UA2DQfeDnfUPMdvaQW0Q7yPrPDi9nlGo2tz2b4=\ngolang.org/x/crypto v0.0.0-20190308221718-c2843e01d9a2/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190313024323-a1f597ede03a/go.mod h1:djNgcEr1/C05ACkg1iLfiJU5Ep61QUkGW8qpdssI0+w=\ngolang.org/x/crypto v0.0.0-20190411191339-88737f569e3a/go.mod h1:WFFai1msRO1wXaEeE5yQxYXgSfI8pQAWXbQop6sCtWE=\ngolang.org/x/crypto v0.0.0-20190510104115-cbcb75029529/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20190820162420-60c769a6c586/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20191011191535-87dc89f01550/go.mod h1:yigFU9vqHzYiE8UmvKecakEJjdnWj3jj499lnFckfCI=\ngolang.org/x/crypto v0.0.0-20200622213623-75b288015ac9/go.mod h1:LzIPMQfyMNhhGPhUkYOs5KpL4U8rLKemX1yGLhDgUto=\ngolang.org/x/crypto v0.0.0-20201203163018-be400aefbc4c/go.mod h1:jdWPYTVW3xRLrWPugEBEK3UY2ZEsg3UU495nc5E+M+I=\ngolang.org/x/crypto v0.0.0-20210616213533-5ff15b29337e/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.0.0-20210711020723-a769d52b0f97/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.0.0-20210921155107-089bfa567519/go.mod h1:GvvjBRRGRdwPK5ydBHafDWAxML/pGHZbMvKqRZ5+Abc=\ngolang.org/x/crypto v0.19.0/go.mod h1:Iy9bg/ha4yyC70EfRS8jz+B6ybOBKMaSxLj6P6oBDfU=\ngolang.org/x/crypto v0.36.0 h1:AnAEvhDddvBdpY+uR+MyHmuZzzNqXSe/GvuDeob5L34=\ngolang.org/x/crypto v0.36.0/go.mod h1:Y4J0ReaxCR1IMaabaSMugxJES1EpwhBHhv2bDHklZvc=\ngolang.org/x/crypto/x509roots/fallback v0.0.0-20250305170421-49bf5b80c810 h1:V5+zy0jmgNYmK1uW/sPpBw8ioFvalrhaUrYWmu1Fpe4=\ngolang.org/x/crypto/x509roots/fallback v0.0.0-20250305170421-49bf5b80c810/go.mod h1:lxN5T34bK4Z/i6cMaU7frUU57VkDXFD4Kamfl/cp9oU=\ngolang.org/x/exp v0.0.0-20190121172915-509febef88a4/go.mod h1:CJ0aWSM057203Lf6IL+f9T1iT9GByDxfZKAQTCR3kQA=\ngolang.org/x/exp v0.0.0-20240506185415-9bf2ced13842 h1:vr/HnozRka3pE4EsMEg1lgkXJkTFJCVUX+S/ZT6wYzM=\ngolang.org/x/exp v0.0.0-20240506185415-9bf2ced13842/go.mod h1:XtvwrStGgqGPLc4cjQfWqZHG1YFdYs6swckp8vpsjnc=\ngolang.org/x/lint v0.0.0-20180702182130-06c8688daad7/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20181026193005-c67002cb31c3/go.mod h1:UVdnD1Gm6xHRNCYTkRU2/jEulfH38KcIWyp/GAMgvoE=\ngolang.org/x/lint v0.0.0-20190227174305-5b3e6a55c961/go.mod h1:wehouNa3lNwaWXcvxsM5YxQ5yQlVC4a0KAMCusXpPoU=\ngolang.org/x/lint v0.0.0-20190930215403-16217165b5de/go.mod h1:6SW0HCj/g11FgYtHlgUYUwCkIfeOF89ocIRzGO/8vkc=\ngolang.org/x/mod v0.0.0-20190513183733-4bf6d317e70e/go.mod h1:mXi4GBBbnImb6dmsKGUJ2LatrhH/nqhxcFungHvyanc=\ngolang.org/x/mod v0.1.1-0.20191105210325-c90efee705ee/go.mod h1:QqPTAvyqsEbceGzBzNggFXnrqF1CaUcvgkdR5Ot7KZg=\ngolang.org/x/mod v0.6.0-dev.0.20220419223038-86c51ed26bb4/go.mod h1:jJ57K6gSWd91VN4djpZkiMVwK6gcyfeH4XE8wZrZaV4=\ngolang.org/x/mod v0.8.0/go.mod h1:iBbtSCu2XBx23ZKBPSOrRkjjQPZFPuis4dIYUhu/chs=\ngolang.org/x/mod v0.24.0 h1:ZfthKaKaT4NrhGVZHO1/WDTwGES4De8KtWO0SIbNJMU=\ngolang.org/x/mod v0.24.0/go.mod h1:IXM97Txy2VM4PJ3gI61r1YEk/gAj6zAHN3AdZt6S9Ww=\ngolang.org/x/net v0.0.0-20180724234803-3673e40ba225/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180826012351-8a410e7b638d/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20180906233101-161cd47e91fd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181029044818-c44066c5c816/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20181106065722-10aee1819953/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190108225652-1e06a53dbb7e/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190213061140-3a22650c66bd/go.mod h1:mL1N/T3taQHkDXs73rZJwtUhF3w3ftmwwsq0BUmARs4=\ngolang.org/x/net v0.0.0-20190311183353-d8887717615a/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190313220215-9f648a60d977/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190404232315-eb5bcb51f2a3/go.mod h1:t9HGtf8HONx5eT2rtn7q6eTqICYqUVnKs3thJo3Qplg=\ngolang.org/x/net v0.0.0-20190620200207-3b0461eec859/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20190813141303-74dc4d7220e7/go.mod h1:z5CRVTTTmAJ677TzLLGU+0bjPO0LkuOLi4/5GtJWs/s=\ngolang.org/x/net v0.0.0-20210226172049-e18ecbb05110/go.mod h1:m0MpNAwzfU5UDzcl9v0D8zg8gWTRqZa9RBIspLL5mdg=\ngolang.org/x/net v0.0.0-20220722155237-a158d28d115b/go.mod h1:XRhObCWvk6IyKnWLug+ECip1KBveYUHfp+8e9klMJ9c=\ngolang.org/x/net v0.6.0/go.mod h1:2Tu9+aMcznHK/AK1HMvgo6xiTLG5rD5rZLDS+rp2Bjs=\ngolang.org/x/net v0.10.0/go.mod h1:0qNGK6F8kojg2nk9dLZ2mShWaEBan6FAoqfSigmmuDg=\ngolang.org/x/net v0.38.0 h1:vRMAPTMaeGqVhG5QyLJHqNDwecKTomGeqbnfZyKlBI8=\ngolang.org/x/net v0.38.0/go.mod h1:ivrbrMbzFq5J41QOQh0siUuly180yBYtLp+CKbEaFx8=\ngolang.org/x/oauth2 v0.0.0-20180821212333-d2e6202438be/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20181017192945-9dcd33a902f4/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20181203162652-d668ce993890/go.mod h1:N/0e6XlmueqKjAGxoOufVs8QHGRruUQn6yWY3a++T0U=\ngolang.org/x/oauth2 v0.0.0-20190226205417-e64efc72b421/go.mod h1:gOpvHmFTYa4IltrdGE7lF6nIHvwfUNPOp7c8zoXwtLw=\ngolang.org/x/oauth2 v0.22.0 h1:BzDx2FehcG7jJwgWLELCdmLuxk2i+x9UDpSiss2u0ZA=\ngolang.org/x/oauth2 v0.22.0/go.mod h1:XYTD2NtWslqkgxebSiOHnXEap4TF09sJSc7H1sXbhtI=\ngolang.org/x/perf v0.0.0-20180704124530-6e6d33e29852/go.mod h1:JLpeXjPJfIyPr5TlbXLkXWLhP8nz10XfvxElABhCtcw=\ngolang.org/x/sync v0.0.0-20180314180146-1d60e4601c6f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181108010431-42b317875d0f/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20181221193216-37e7f081c4d4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190227155943-e225da77a7e6/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20190423024810-112230192c58/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.0.0-20220722155255-886fb9371eb4/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.1.0/go.mod h1:RxMgew5VJxzue5/jJTE5uejpjVlOe/izrB70Jof72aM=\ngolang.org/x/sync v0.12.0 h1:MHc5BpPuC30uJk597Ri8TV3CNZcTLu6B6z4lJy+g6Jw=\ngolang.org/x/sync v0.12.0/go.mod h1:1dzgHSNfp02xaA81J2MS99Qcpr2w7fw1gpm99rleRqA=\ngolang.org/x/sys v0.0.0-20180830151530-49385e6e1522/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180905080454-ebe1bf3edb33/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20180909124046-d0be0721c37e/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181029174526-d69651ed3497/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181122145206-62eef0e2fa9b/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20181205085412-a5c9d58dba9a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190215142949-d0b11bdaac8a/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190222072716-a9d3bda3a223/go.mod h1:STP8DvDyc/dI5b8T5hshtkjS+E42TnysNCUPdjciGhY=\ngolang.org/x/sys v0.0.0-20190316082340-a2f829d7f35f/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190403152447-81d4e9dc473e/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190412213103-97732733099d/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190422165155-953cdadca894/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190626221950-04f50cda93cb/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20190813064441-fde4db37ae7a/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20191026070338-33540a1f6037/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200116001909-b77594299b42/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20200223170610-d5e6a3e2c0ae/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20201119102817-f84b799fce68/go.mod h1:h1NjWce9XRLGQEsW7wpKNCjG9DtNlClVuFLEZdDNbEs=\ngolang.org/x/sys v0.0.0-20210615035016-665e8c7367d1/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220310020820-b874c991c1a5/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220520151302-bc2c85ada10a/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220715151400-c0bba94af5f8/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220722155257-8c9f86f7a55f/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.0.0-20220811171246-fbc7d0a398ab/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.5.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.8.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=\ngolang.org/x/sys v0.17.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=\ngolang.org/x/sys v0.31.0 h1:ioabZlmFYtWhL+TRYpcnNlLwhyxaM9kWTDEmfnprqik=\ngolang.org/x/sys v0.31.0/go.mod h1:BJP2sWEmIv4KK5OTEluFJCKSidICx8ciO85XgH3Ak8k=\ngolang.org/x/term v0.0.0-20201117132131-f5c789dd3221/go.mod h1:Nr5EML6q2oocZ2LXRh80K7BxOlk5/8JxuGnuhpl+muw=\ngolang.org/x/term v0.0.0-20201126162022-7de9c90e9dd1/go.mod h1:bj7SfCRtBDWHUb9snDiAeCFNEtKQo2Wmx5Cou7ajbmo=\ngolang.org/x/term v0.0.0-20210927222741-03fcf44c2211/go.mod h1:jbD1KX2456YbFQfuXm/mYQcufACuNUgVhRMnK/tPxf8=\ngolang.org/x/term v0.5.0/go.mod h1:jMB1sMXY+tzblOD4FWmEbocvup2/aLOaQEp7JmGp78k=\ngolang.org/x/term v0.8.0/go.mod h1:xPskH00ivmX89bAKVGSKKtLOWNx2+17Eiy94tnKShWo=\ngolang.org/x/term v0.17.0/go.mod h1:lLRBjIVuehSbZlaOtGMbcMncT+aqLLLmKrsjNrUguwk=\ngolang.org/x/term v0.30.0 h1:PQ39fJZ+mfadBm0y5WlL4vlM7Sx1Hgf13sMIY2+QS9Y=\ngolang.org/x/term v0.30.0/go.mod h1:NYYFdzHoI5wRh/h5tDMdMqCqPJZEuNqVR5xJLd/n67g=\ngolang.org/x/text v0.3.0/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.1-0.20180807135948-17ff2d5776d2/go.mod h1:NqM8EUOU14njkJ3fqMW+pc6Ldnwhi/IjpwHt7yyuwOQ=\ngolang.org/x/text v0.3.2/go.mod h1:bEr9sfX3Q8Zfm5fL9x+3itogRgK3+ptLWKqgva+5dAk=\ngolang.org/x/text v0.3.3/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.4/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.6/go.mod h1:5Zoc/QRtKVWzQhOtBMvqHzDpF6irO9z98xDceosuGiQ=\ngolang.org/x/text v0.3.7/go.mod h1:u+2+/6zg+i71rQMx5EYifcz6MCKuco9NR6JIITiCfzQ=\ngolang.org/x/text v0.7.0/go.mod h1:mrYo+phRRbMaCq/xk9113O4dZlRixOauAjOtrjsXDZ8=\ngolang.org/x/text v0.9.0/go.mod h1:e1OnstbJyHTd6l/uOt8jFFHp6TRDWZR/bV3emEE/zU8=\ngolang.org/x/text v0.14.0/go.mod h1:18ZOQIKpY8NJVqYksKHtTdi31H5itFRjB5/qKTNYzSU=\ngolang.org/x/text v0.23.0 h1:D71I7dUrlY+VX0gQShAThNGHFxZ13dGLBHQLVl1mJlY=\ngolang.org/x/text v0.23.0/go.mod h1:/BLNzu4aZCJ1+kcD0DNRotWKage4q2rGVAg4o22unh4=\ngolang.org/x/time v0.0.0-20180412165947-fbb02b2291d2/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.0.0-20181108054448-85acf8d2951c/go.mod h1:tRJNPiyCQ0inRvYxbN9jk5I+vvW/OXSQhTDSoE431IQ=\ngolang.org/x/time v0.11.0 h1:/bpjEDfN9tkoN/ryeYHnv5hcMlc8ncjMcM4XBk5NWV0=\ngolang.org/x/time v0.11.0/go.mod h1:CDIdPxbZBQxdj6cxyCIdrNogrJKMJ7pr37NYpMcMDSg=\ngolang.org/x/tools v0.0.0-20180828015842-6cd1fcedba52/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20180917221912-90fa682c2a6e/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20181030000716-a0a13e073c7b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190114222345-bf090417da8b/go.mod h1:n7NCudcB/nEzxVGmLbDWY5pfWTLqBcC2KZ6jyYvM4mQ=\ngolang.org/x/tools v0.0.0-20190226205152-f727befe758c/go.mod h1:9Yl7xja0Znq3iFh3HoIrodX9oNMXvdceNzlUR8zjMvY=\ngolang.org/x/tools v0.0.0-20190311212946-11955173bddd/go.mod h1:LCzVGOaR6xXOjkQ3onu1FJEFr0SW1gC7cKk1uF8kGRs=\ngolang.org/x/tools v0.0.0-20190425163242-31fd60d6bfdc/go.mod h1:RgjU9mgBXZiqYHBnxXauZ1Gv1EHHAz9KjViQ78xBX0Q=\ngolang.org/x/tools v0.0.0-20190621195816-6e04913cbbac/go.mod h1:/rFqwRUd4F7ZHNgwSSTFct+R/Kf4OFW1sUzUTQQTgfc=\ngolang.org/x/tools v0.0.0-20190823170909-c4a336ef6a2f/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191029041327-9cc4af7d6b2c/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191029190741-b9c20aec41a5/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20191119224855-298f0cb1881e/go.mod h1:b+2E5dAYhXwXZwtnZ6UAqBI28+e2cm9otk0dWdXHAEo=\ngolang.org/x/tools v0.0.0-20200103221440-774c71fcf114/go.mod h1:TB2adYChydJhpapKDTa4BR/hXlZSLoq2Wpct/0txZ28=\ngolang.org/x/tools v0.1.12/go.mod h1:hNGJHUnrk76NpqgfD5Aqm5Crs+Hm0VOH/i9J2+nxYbc=\ngolang.org/x/tools v0.6.0/go.mod h1:Xwgl3UAJ/d3gWutnCtw505GrjyAbvKui8lOU390QaIU=\ngolang.org/x/tools v0.31.0 h1:0EedkvKDbh+qistFTd0Bcwe/YLh4vHwWEkiI0toFIBU=\ngolang.org/x/tools v0.31.0/go.mod h1:naFTU+Cev749tSJRXJlna0T3WxKvb1kWEx15xA4SdmQ=\ngolang.org/x/xerrors v0.0.0-20190410155217-1f06c39b4373/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20190513163551-3ee3066db522/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20190717185122-a985d3407aa7/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20191011141410-1b5146add898/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngolang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1/go.mod h1:I/5z698sn9Ka8TeJc9MKroUUfqBBauWjQqLJ2OPfmY0=\ngoogle.golang.org/api v0.0.0-20180910000450-7ca32eb868bf/go.mod h1:4mhQ8q/RsB7i+udVvVy5NUi08OU8ZlA0gRVgrF7VFY0=\ngoogle.golang.org/api v0.0.0-20181030000543-1d582fd0359e/go.mod h1:4mhQ8q/RsB7i+udVvVy5NUi08OU8ZlA0gRVgrF7VFY0=\ngoogle.golang.org/api v0.1.0/go.mod h1:UGEZY7KEX120AnNLIHFMKIo4obdJhkp2tPbaPlQx13Y=\ngoogle.golang.org/api v0.180.0 h1:M2D87Yo0rGBPWpo1orwfCLehUUL6E7/TYe5gvMQWDh4=\ngoogle.golang.org/api v0.180.0/go.mod h1:51AiyoEg1MJPSZ9zvklA8VnRILPXxn1iVen9v25XHAE=\ngoogle.golang.org/appengine v1.1.0/go.mod h1:EbEs0AVv82hx2wNQdGPgUI5lhzA/G0D9YwlJXL52JkM=\ngoogle.golang.org/appengine v1.2.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.3.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/appengine v1.4.0/go.mod h1:xpcJRLb0r/rnEns0DIKYYv+WjYCduHsrkT7/EB5XEv4=\ngoogle.golang.org/genproto v0.0.0-20180817151627-c66870c02cf8/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20180831171423-11092d34479b/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20181029155118-b69ba1387ce2/go.mod h1:JiN7NxoALGmiZfu7CAH4rXhgtRTLTxftemlI0sWmxmc=\ngoogle.golang.org/genproto v0.0.0-20181202183823-bd91e49a0898/go.mod h1:7Ep/1NZk928CDR8SjdVbjWNpdIf6nzjE3BTgJDr2Atg=\ngoogle.golang.org/genproto v0.0.0-20190306203927-b5d61aea6440/go.mod h1:VzzqZJRnGkLBvHegQrXjBqPurQTc5/KpmUdxsrq26oE=\ngoogle.golang.org/genproto v0.0.0-20240401170217-c3f982113cda h1:wu/KJm9KJwpfHWhkkZGohVC6KRrc1oJNr4jwtQMOQXw=\ngoogle.golang.org/genproto v0.0.0-20240401170217-c3f982113cda/go.mod h1:g2LLCvCeCSir/JJSWosk19BR4NVxGqHUC6rxIRsd7Aw=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20241007155032-5fefd90f89a9 h1:T6rh4haD3GVYsgEfWExoCZA2o2FmbNyKpTuAxbEFPTg=\ngoogle.golang.org/genproto/googleapis/api v0.0.0-20241007155032-5fefd90f89a9/go.mod h1:wp2WsuBYj6j8wUdo3ToZsdxxixbvQNAHqVJrTgi5E5M=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20241007155032-5fefd90f89a9 h1:QCqS/PdaHTSWGvupk2F/ehwHtGc0/GYkT+3GAcR1CCc=\ngoogle.golang.org/genproto/googleapis/rpc v0.0.0-20241007155032-5fefd90f89a9/go.mod h1:GX3210XPVPUjJbTUbvwI8f2IpZDMZuPJWDzDuebbviI=\ngoogle.golang.org/grpc v1.14.0/go.mod h1:yo6s7OP7yaDglbqo1J04qKzAhqBH6lvTonzMVmEdcZw=\ngoogle.golang.org/grpc v1.16.0/go.mod h1:0JHn/cJsOMiMfNA9+DeHDlAU7KAAB5GDlYFpa9MZMio=\ngoogle.golang.org/grpc v1.17.0/go.mod h1:6QZJwpn2B+Zp71q/5VxRsJ6NXXVCE5NRUHRo+f3cWCs=\ngoogle.golang.org/grpc v1.19.0/go.mod h1:mqu4LbDTu4XGKhr4mRzUsmM4RtVoemTSY81AxZiDr8c=\ngoogle.golang.org/grpc v1.67.1 h1:zWnc1Vrcno+lHZCOofnIMvycFcc0QRGIzm9dhnDX68E=\ngoogle.golang.org/grpc v1.67.1/go.mod h1:1gLDyUQU7CTLJI90u3nXZ9ekeghjeM7pTDZlqFNg2AA=\ngoogle.golang.org/protobuf v1.35.1 h1:m3LfL6/Ca+fqnjnlqQXNpFPABW1UD7mjh8KO2mKFytA=\ngoogle.golang.org/protobuf v1.35.1/go.mod h1:9fA7Ob0pmnwhb644+1+CVWFRbNajQ6iRojtC/QF5bRE=\ngopkg.in/check.v1 v0.0.0-20161208181325-20d25e280405/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20190902080502-41f04d3bba15/go.mod h1:Co6ibVJAznAaIkqp8huTwlJQCZ016jof/cbN4VW5Yz0=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c h1:Hei/4ADfdWqJk1ZMxUNpqntNwaWcugrBjAiHlqqRiVk=\ngopkg.in/check.v1 v1.0.0-20201130134442-10cb98267c6c/go.mod h1:JHkPIbrfpd72SG/EVd6muEfDQjcINNoR0C8j2r3qZ4Q=\ngopkg.in/errgo.v2 v2.1.0/go.mod h1:hNsd1EY+bozCKY1Ytp96fpM3vjJbqLJn88ws8XvfDNI=\ngopkg.in/inconshreveable/log15.v2 v2.0.0-20180818164646-67afb5ed74ec/go.mod h1:aPpfJ7XW+gOuirDoZ8gHhLh3kZ1B08FtV2bbmy7Jv3s=\ngopkg.in/inf.v0 v0.9.1/go.mod h1:cWUDdTG/fYaXco+Dcufb5Vnc6Gp2YChqWtbxRZE0mXw=\ngopkg.in/natefinch/lumberjack.v2 v2.2.1 h1:bBRl1b0OH9s/DuPhuXpNl+VtCaJXFZ5/uEFST95x9zc=\ngopkg.in/natefinch/lumberjack.v2 v2.2.1/go.mod h1:YD8tP3GAjkrDg1eZH7EGmyESg/lsYskCTPBJVb9jqSc=\ngopkg.in/yaml.v1 v1.0.0-20140924161607-9f9df34309c0/go.mod h1:WDnlLJ4WF5VGsH/HVa3CI79GS0ol3YnhVnKP89i0kNg=\ngopkg.in/yaml.v2 v2.2.1/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.2.2/go.mod h1:hI93XBmqTisBFMUTm0b8Fm+jr3Dg1NNxqwp+5A1VGuI=\ngopkg.in/yaml.v2 v2.4.0/go.mod h1:RDklbk79AGWmwhnvt/jBztapEOGDOx6ZbXqjP6csGnQ=\ngopkg.in/yaml.v3 v3.0.0-20200313102051-9f266ea9e77c/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngopkg.in/yaml.v3 v3.0.1 h1:fxVm/GzAzEWqLHuvctI91KS9hhNmmWOoWu0XTYJS7CA=\ngopkg.in/yaml.v3 v3.0.1/go.mod h1:K4uyk7z7BCEPqu6E+C64Yfv1cQ7kz7rIZviUmN+EgEM=\ngrpc.go4.org v0.0.0-20170609214715-11d0a25b4919/go.mod h1:77eQGdRu53HpSqPFJFmuJdjuHRquDANNeA4x7B8WQ9o=\nhonnef.co/go/tools v0.0.0-20180728063816-88497007e858/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190102054323-c2f93a96b099/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.0-20190106161140-3f1c8253044a/go.mod h1:rf3lG4BRIbNafJWhAfAdb/ePZxsR/4RtNHQocxwk9r4=\nhonnef.co/go/tools v0.0.1-2019.2.3/go.mod h1:a3bituU0lyd329TUQxRnasdCoJDkEUEAqEt0JzvZhAg=\nhowett.net/plist v1.0.0 h1:7CrbWYbPPO/PyNy38b2EB/+gYbjCe2DXBxgtOOZbSQM=\nhowett.net/plist v1.0.0/go.mod h1:lqaXoTrLY4hg8tnEzNru53gicrbv7rrk+2xJA/7hw9g=\nsourcegraph.com/sourcegraph/go-diff v0.5.0/go.mod h1:kuch7UrkMzY0X+p9CRK03kfuPQ2zzQcaEFbx8wA8rck=\nsourcegraph.com/sqs/pbtypes v0.0.0-20180604144634-d3ebe8f20ae4/go.mod h1:ketZ/q3QxT9HOBeFhu6RdvsftgpsbFHBF5Cas6cDKZ0=\n",
    "source_file": "go.sum",
    "chunk_type": "unknown"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build gofuzz\n\npackage caddy\n\nfunc FuzzParseNetworkAddress(data []byte) int {\n\t_, err := ParseNetworkAddress(string(data))\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n",
    "source_file": "listeners_fuzz.go",
    "chunk_type": "code"
  },
  {
    "content": "<p align=\"center\">\n\t<a href=\"https://caddyserver.com\">\n\t\t<picture>\n\t\t\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"https://user-images.githubusercontent.com/1128849/210187358-e2c39003-9a5e-4dd5-a783-6deb6483ee72.svg\">\n\t\t\t<source media=\"(prefers-color-scheme: light)\" srcset=\"https://user-images.githubusercontent.com/1128849/210187356-dfb7f1c5-ac2e-43aa-bb23-fc014280ae1f.svg\">\n\t\t\t<img src=\"https://user-images.githubusercontent.com/1128849/210187356-dfb7f1c5-ac2e-43aa-bb23-fc014280ae1f.svg\" alt=\"Caddy\" width=\"550\">\n\t\t</picture>\n\t</a>\n\t<br>\n\t<h3 align=\"center\">a <a href=\"https://zerossl.com\"><img src=\"https://user-images.githubusercontent.com/55066419/208327323-2770dc16-ec09-43a0-9035-c5b872c2ad7f.svg\" height=\"28\" style=\"vertical-align: -7.7px\" valign=\"middle\"></a> project</h3>\n</p>\n<hr>\n<h3 align=\"center\">Every site on HTTPS</h3>\n<p align=\"center\">Caddy is an extensible server platform that uses TLS by default.</p>\n<p align=\"center\">\n\t<a href=\"https://github.com/caddyserver/caddy/actions/workflows/ci.yml\"><img src=\"https://github.com/caddyserver/caddy/actions/workflows/ci.yml/badge.svg\"></a>\n\t<a href=\"https://www.bestpractices.dev/projects/7141\"><img src=\"https://www.bestpractices.dev/projects/7141/badge\"></a>\n\t<a href=\"https://pkg.go.dev/github.com/caddyserver/caddy/v2\"><img src=\"https://img.shields.io/badge/godoc-reference-%23007d9c.svg\"></a>\n\t<br>\n\t<a href=\"https://x.com/caddyserver\" title=\"@caddyserver on Twitter\"><img src=\"https://img.shields.io/twitter/follow/caddyserver\" alt=\"@caddyserver on Twitter\"></a>\n\t<a href=\"https://caddy.community\" title=\"Caddy Forum\"><img src=\"https://img.shields.io/badge/community-forum-ff69b4.svg\" alt=\"Caddy Forum\"></a>\n\t<br>\n\t<a href=\"https://sourcegraph.com/github.com/caddyserver/caddy?badge\" title=\"Caddy on Sourcegraph\"><img src=\"https://sourcegraph.com/github.com/caddyserver/caddy/-/badge.svg\" alt=\"Caddy on Sourcegraph\"></a>\n\t<a href=\"https://cloudsmith.io/~caddy/repos/\"><img src=\"https://img.shields.io/badge/OSS%20hosting%20by-cloudsmith-blue?logo=cloudsmith\" alt=\"Cloudsmith\"></a>\n</p>\n<p align=\"center\">\n\t<a href=\"https://github.com/caddyserver/caddy/releases\">Releases</a> \u00b7\n\t<a href=\"https://caddyserver.com/docs/\">Documentation</a> \u00b7\n\t<a href=\"https://caddy.community\">Get Help</a>\n</p>\n\n\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "### Menu\n\n- [Features](#features)\n- [Install](#install)\n- [Build from source](#build-from-source)\n\t- [For development](#for-development)\n\t- [With version information and/or plugins](#with-version-information-andor-plugins)\n- [Quick start](#quick-start)\n- [Overview](#overview)\n- [Full documentation](#full-documentation)\n- [Getting help](#getting-help)\n- [About](#about)\n\n<p align=\"center\">\n\t<b>Powered by</b>\n\t<br>\n\t<a href=\"https://github.com/caddyserver/certmagic\">\n\t\t<picture>\n\t\t\t<source media=\"(prefers-color-scheme: dark)\" srcset=\"https://user-images.githubusercontent.com/55066419/206946718-740b6371-3df3-4d72-a822-47e4c48af999.png\">\n\t\t\t<source media=\"(prefers-color-scheme: light)\" srcset=\"https://user-images.githubusercontent.com/1128849/49704830-49d37200-fbd5-11e8-8385-767e0cd033c3.png\">\n\t\t\t<img src=\"https://user-images.githubusercontent.com/1128849/49704830-49d37200-fbd5-11e8-8385-767e0cd033c3.png\" alt=\"CertMagic\" width=\"250\">\n\t\t</picture>\n\t</a>\n</p>\n\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "## [Features](https://caddyserver.com/features)\n\n- **Easy configuration** with the [Caddyfile](https://caddyserver.com/docs/caddyfile)\n- **Powerful configuration** with its [native JSON config](https://caddyserver.com/docs/json/)\n- **Dynamic configuration** with the [JSON API](https://caddyserver.com/docs/api)\n- [**Config adapters**](https://caddyserver.com/docs/config-adapters) if you don't like JSON\n- **Automatic HTTPS** by default\n\t- [ZeroSSL](https://zerossl.com) and [Let's Encrypt](https://letsencrypt.org) for public names\n\t- Fully-managed local CA for internal names & IPs\n\t- Can coordinate with other Caddy instances in a cluster\n\t- Multi-issuer fallback\n\t- Encrypted ClientHello (ECH) support\n- **Stays up when other servers go down** due to TLS/OCSP/certificate-related issues\n- **Production-ready** after serving trillions of requests and managing millions of TLS certificates\n- **Scales to hundreds of thousands of sites** as proven in production\n- **HTTP/1.1, HTTP/2, and HTTP/3** all supported by default\n- **Highly extensible** [modular architecture](https://caddyserver.com/docs/architecture) lets Caddy do anything without bloat\n- **Runs anywhere** with **no external dependencies** (not even libc)\n- Written in Go, a language with higher **memory safety guarantees** than other servers\n- Actually **fun to use**\n- So much more to [discover](https://caddyserver.com/features)\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "## Install\n\nThe simplest, cross-platform way to get started is to download Caddy from [GitHub Releases](https://github.com/caddyserver/caddy/releases) and place the executable file in your PATH.\n\nSee [our online documentation](https://caddyserver.com/docs/install) for other install instructions.\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "## Build from source\n\nRequirements:\n\n- [Go 1.24.0 or newer](https://golang.org/dl/)\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "### For development\n\n_**Note:** These steps [will not embed proper version information](https://github.com/golang/go/issues/29228). For that, please follow the instructions in the next section._\n\n```bash\n$ git clone \"https://github.com/caddyserver/caddy.git\"\n$ cd caddy/cmd/caddy/\n$ go build\n```\n\nWhen you run Caddy, it may try to bind to low ports unless otherwise specified in your config. If your OS requires elevated privileges for this, you will need to give your new binary permission to do so. On Linux, this can be done easily with: `sudo setcap cap_net_bind_service=+ep ./caddy`\n\nIf you prefer to use `go run` which only creates temporary binaries, you can still do this with the included `setcap.sh` like so:\n\n```bash\n$ go run -exec ./setcap.sh main.go\n```\n\nIf you don't want to type your password for `setcap`, use `sudo visudo` to edit your sudoers file and allow your user account to run that command without a password, for example:\n\n```\nusername ALL=(ALL:ALL) NOPASSWD: /usr/sbin/setcap\n```\n\nreplacing `username` with your actual username. Please be careful and only do this if you know what you are doing! We are only qualified to document how to use Caddy, not Go tooling or your computer, and we are providing these instructions for convenience only; please learn how to use your own computer at your own risk and make any needful adjustments.\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "### With version information and/or plugins\n\nUsing [our builder tool, `xcaddy`](https://github.com/caddyserver/xcaddy)...\n\n```\n$ xcaddy build\n```\n\n...the following steps are automated:\n\n1. Create a new folder: `mkdir caddy`\n2. Change into it: `cd caddy`\n3. Copy [Caddy's main.go](https://github.com/caddyserver/caddy/blob/master/cmd/caddy/main.go) into the empty folder. Add imports for any custom plugins you want to add.\n4. Initialize a Go module: `go mod init caddy`\n5. (Optional) Pin Caddy version: `go get github.com/caddyserver/caddy/v2@version` replacing `version` with a git tag, commit, or branch name.\n6. (Optional) Add plugins by adding their import: `_ \"import/path/here\"`\n7. Compile: `go build -tags=nobadger,nomysql,nopgx`\n\n\n\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "## Quick start\n\nThe [Caddy website](https://caddyserver.com/docs/) has documentation that includes tutorials, quick-start guides, reference, and more.\n\n**We recommend that all users -- regardless of experience level -- do our [Getting Started](https://caddyserver.com/docs/getting-started) guide to become familiar with using Caddy.**\n\nIf you've only got a minute, [the website has several quick-start tutorials](https://caddyserver.com/docs/quick-starts) to choose from! However, after finishing a quick-start tutorial, please read more documentation to understand how the software works. \ud83d\ude42\n\n\n\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "## Overview\n\nCaddy is most often used as an HTTPS server, but it is suitable for any long-running Go program. First and foremost, it is a platform to run Go applications. Caddy \"apps\" are just Go programs that are implemented as Caddy modules. Two apps -- `tls` and `http` -- ship standard with Caddy.\n\nCaddy apps instantly benefit from [automated documentation](https://caddyserver.com/docs/json/), graceful on-line [config changes via API](https://caddyserver.com/docs/api), and unification with other Caddy apps.\n\nAlthough [JSON](https://caddyserver.com/docs/json/) is Caddy's native config language, Caddy can accept input from [config adapters](https://caddyserver.com/docs/config-adapters) which can essentially convert any config format of your choice into JSON: Caddyfile, JSON 5, YAML, TOML, NGINX config, and more.\n\nThe primary way to configure Caddy is through [its API](https://caddyserver.com/docs/api), but if you prefer config files, the [command-line interface](https://caddyserver.com/docs/command-line) supports those too.\n\nCaddy exposes an unprecedented level of control compared to any web server in existence. In Caddy, you are usually setting the actual values of the initialized types in memory that power everything from your HTTP handlers and TLS handshakes to your storage medium. Caddy is also ridiculously extensible, with a powerful plugin system that makes vast improvements over other web servers.\n\nTo wield the power of this design, you need to know how the config document is structured. Please see [our documentation site](https://caddyserver.com/docs/) for details about [Caddy's config structure](https://caddyserver.com/docs/json/).\n\nNearly all of Caddy's configuration is contained in a single config document, rather than being scattered across CLI flags and env variables and a configuration file as with other web servers. This makes managing your server config more straightforward and reduces hidden variables/factors.\n\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "## Full documentation\n\nOur website has complete documentation:\n\n**https://caddyserver.com/docs/**\n\nThe docs are also open source. You can contribute to them here: https://github.com/caddyserver/website\n\n\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "## Getting help\n\n- We advise companies using Caddy to secure a support contract through [Ardan Labs](https://www.ardanlabs.com) before help is needed.\n\n- A [sponsorship](https://github.com/sponsors/mholt) goes a long way! We can offer private help to sponsors. If Caddy is benefitting your company, please consider a sponsorship. This not only helps fund full-time work to ensure the longevity of the project, it provides your company the resources, support, and discounts you need; along with being a great look for your company to your customers and potential customers!\n\n- Individuals can exchange help for free on our community forum at https://caddy.community. Remember that people give help out of their spare time and good will. The best way to get help is to give it first!\n\nPlease use our [issue tracker](https://github.com/caddyserver/caddy/issues) only for bug reports and feature requests, i.e. actionable development items (support questions will usually be referred to the forums).\n\n\n",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "## About\n\nMatthew Holt began developing Caddy in 2014 while studying computer science at Brigham Young University. (The name \"Caddy\" was chosen because this software helps with the tedious, mundane tasks of serving the Web, and is also a single place for multiple things to be organized together.) It soon became the first web server to use HTTPS automatically and by default, and now has hundreds of contributors and has served trillions of HTTPS requests.\n\n**The name \"Caddy\" is trademarked.** The name of the software is \"Caddy\", not \"Caddy Server\" or \"CaddyServer\". Please call it \"Caddy\" or, if you wish to clarify, \"the Caddy web server\". Caddy is a registered trademark of Stack Holdings GmbH.\n\n- _Project on X: [@caddyserver](https://x.com/caddyserver)_\n- _Author on X: [@mholt6](https://x.com/mholt6)_\n\nCaddy is a project of [ZeroSSL](https://zerossl.com), a Stack Holdings company.\n\nDebian package repository hosting is graciously provided by [Cloudsmith](https://cloudsmith.com). Cloudsmith is the only fully hosted, cloud-native, universal package management solution, that enables your organization to create, store and share packages in any format, to any place, with total confidence.",
    "source_file": "README.md",
    "chunk_type": "doc"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"go.uber.org/zap\"\n)\n\n// StorageConverter is a type that can convert itself\n// to a valid, usable certmagic.Storage value. (The\n// value might be short-lived.) This interface allows\n// us to adapt any CertMagic storage implementation\n// into a consistent API for Caddy configuration.\ntype StorageConverter interface {\n\tCertMagicStorage() (certmagic.Storage, error)\n}\n\n// HomeDir returns the best guess of the current user's home\n// directory from environment variables. If unknown, \".\" (the\n// current directory) is returned instead, except GOOS=android,\n// which returns \"/sdcard\".\nfunc HomeDir() string {\n\thome := homeDirUnsafe()\n\tif home == \"\" && runtime.GOOS == \"android\" {\n\t\thome = \"/sdcard\"\n\t}\n\tif home == \"\" {\n\t\thome = \".\"\n\t}\n\treturn home\n}\n\n// homeDirUnsafe is a low-level function that returns\n// the user's home directory from environment\n// variables. Careful: if it cannot be determined, an\n// empty string is returned. If not accounting for\n// that case, use HomeDir() instead; otherwise you\n// may end up using the root of the file system.\nfunc homeDirUnsafe() string {\n\thome := os.Getenv(\"HOME\")\n\tif home == \"\" && runtime.GOOS == \"windows\" {\n\t\tdrive := os.Getenv(\"HOMEDRIVE\")\n\t\tpath := os.Getenv(\"HOMEPATH\")\n\t\thome = drive + path\n\t\tif drive == \"\" || path == \"\" {\n\t\t\thome = os.Getenv(\"USERPROFILE\")\n\t\t}\n\t}\n\tif home == \"\" && runtime.GOOS == \"plan9\" {\n\t\thome = os.Getenv(\"home\")\n\t}\n\treturn home\n}\n\n// AppConfigDir returns the directory where to store user's config.\n//\n// If XDG_CONFIG_HOME is set, it returns: $XDG_CONFIG_HOME/caddy.\n// Otherwise, os.UserConfigDir() is used; if successful, it appends\n// \"Caddy\" (Windows & Mac) or \"caddy\" (every other OS) to the path.\n// If it returns an error, the fallback path \"./caddy\" is returned.\n//\n// The config directory is not guaranteed to be different from\n// AppDataDir().\n//\n// Unlike os.UserConfigDir(), this function prefers the\n// XDG_CONFIG_HOME env var on all platforms, not just Unix.\n//\n// Ref: https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html\nfunc AppConfigDir() string {\n\tif basedir := os.Getenv(\"XDG_CONFIG_HOME\"); basedir != \"\" {\n\t\treturn filepath.Join(basedir, \"caddy\")\n\t}\n\tbasedir, err := os.UserConfigDir()\n\tif err != nil {\n\t\tLog().Warn(\"unable to determine directory for user configuration; falling back to current directory\", zap.Error(err))\n\t\treturn \"./caddy\"\n\t}\n\tsubdir := \"caddy\"\n\tswitch runtime.GOOS {\n\tcase \"windows\", \"darwin\":\n\t\tsubdir = \"Caddy\"\n\t}\n\treturn filepath.Join(basedir, subdir)\n}\n\n// AppDataDir returns a directory path that is suitable for storing\n// application data on disk. It uses the environment for finding the\n// best place to store data, and appends a \"caddy\" or \"Caddy\" (depending\n// on OS and environment) subdirectory.\n//\n// For a base directory path:\n// If XDG_DATA_HOME is set, it returns: $XDG_DATA_HOME/caddy; otherwise,\n// on Windows it returns: %AppData%/Caddy,\n// on Mac: $HOME/Library/Application Support/Caddy,\n// on Plan9: $home/lib/caddy,\n// on Android: $HOME/caddy,\n// and on everything else: $HOME/.local/share/caddy.\n//\n// If a data directory cannot be determined, it returns \"./caddy\"\n// (this is not ideal, and the environment should be fixed).\n//\n// The data directory is not guaranteed to be different from AppConfigDir().\n//\n// Ref: https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html\nfunc AppDataDir() string {\n\tif basedir := os.Getenv(\"XDG_DATA_HOME\"); basedir != \"\" {\n\t\treturn filepath.Join(basedir, \"caddy\")\n\t}\n\tswitch runtime.GOOS {\n\tcase \"windows\":\n\t\tappData := os.Getenv(\"AppData\")\n\t\tif appData != \"\" {\n\t\t\treturn filepath.Join(appData, \"Caddy\")\n\t\t}\n\tcase \"darwin\":\n\t\thome := homeDirUnsafe()\n\t\tif home != \"\" {\n\t\t\treturn filepath.Join(home, \"Library\", \"Application Support\", \"Caddy\")\n\t\t}\n\tcase \"plan9\":\n\t\thome := homeDirUnsafe()\n\t\tif home != \"\" {\n\t\t\treturn filepath.Join(home, \"lib\", \"caddy\")\n\t\t}\n\tcase \"android\":\n\t\thome := homeDirUnsafe()\n\t\tif home != \"\" {\n\t\t\treturn filepath.Join(home, \"caddy\")\n\t\t}\n\tdefault:\n\t\thome := homeDirUnsafe()\n\t\tif home != \"\" {\n\t\t\treturn filepath.Join(home, \".local\", \"share\", \"caddy\")\n\t\t}\n\t}\n\treturn \"./caddy\"\n}\n\n// ConfigAutosavePath is the default path to which the last config will be persisted.\nvar ConfigAutosavePath = filepath.Join(AppConfigDir(), \"autosave.json\")\n\n// DefaultStorage is Caddy's default storage module.\nvar DefaultStorage = &certmagic.FileStorage{Path: AppDataDir()}\n",
    "source_file": "storage.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"path/filepath\"\n)\n\n// FastAbs can't be optimized on Windows because there\n// are special file paths that require the use of syscall.FullPath\n// to handle correctly.\n// Just call stdlib's implementation which uses that function.\nfunc FastAbs(path string) (string, error) {\n\treturn filepath.Abs(path)\n}\n",
    "source_file": "filepath_windows.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"expvar\"\n\t\"fmt\"\n\t\"hash\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/pprof\"\n\t\"net/url\"\n\t\"os\"\n\t\"path\"\n\t\"regexp\"\n\t\"slices\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/cespare/xxhash/v2\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n)\n\nfunc init() {\n\t// The hard-coded default `DefaultAdminListen` can be overridden\n\t// by setting the `CADDY_ADMIN` environment variable.\n\t// The environment variable may be used by packagers to change\n\t// the default admin address to something more appropriate for\n\t// that platform. See #5317 for discussion.\n\tif env, exists := os.LookupEnv(\"CADDY_ADMIN\"); exists {\n\t\tDefaultAdminListen = env\n\t}\n}\n\n// AdminConfig configures Caddy's API endpoint, which is used\n// to manage Caddy while it is running.\ntype AdminConfig struct {\n\t// If true, the admin endpoint will be completely disabled.\n\t// Note that this makes any runtime changes to the config\n\t// impossible, since the interface to do so is through the\n\t// admin endpoint.\n\tDisabled bool `json:\"disabled,omitempty\"`\n\n\t// The address to which the admin endpoint's listener should\n\t// bind itself. Can be any single network address that can be\n\t// parsed by Caddy. Accepts placeholders.\n\t// Default: the value of the `CADDY_ADMIN` environment variable,\n\t// or `localhost:2019` otherwise.\n\t//\n\t// Remember: When changing this value through a config reload,\n\t// be sure to use the `--address` CLI flag to specify the current\n\t// admin address if the currently-running admin endpoint is not\n\t// the default address.\n\tListen string `json:\"listen,omitempty\"`\n\n\t// If true, CORS headers will be emitted, and requests to the\n\t// API will be rejected if their `Host` and `Origin` headers\n\t// do not match the expected value(s). Use `origins` to\n\t// customize which origins/hosts are allowed. If `origins` is\n\t// not set, the listen address is the only value allowed by\n\t// default. Enforced only on local (plaintext) endpoint.\n\tEnforceOrigin bool `json:\"enforce_origin,omitempty\"`\n\n\t// The list of allowed origins/hosts for API requests. Only needed\n\t// if accessing the admin endpoint from a host different from the\n\t// socket's network interface or if `enforce_origin` is true. If not\n\t// set, the listener address will be the default value. If set but\n\t// empty, no origins will be allowed. Enforced only on local\n\t// (plaintext) endpoint.\n\tOrigins []string `json:\"origins,omitempty\"`\n\n\t// Options pertaining to configuration management.\n\tConfig *ConfigSettings `json:\"config,omitempty\"`\n\n\t// Options that establish this server's identity. Identity refers to\n\t// credentials which can be used to uniquely identify and authenticate\n\t// this server instance. This is required if remote administration is\n\t// enabled (but does not require remote administration to be enabled).\n\t// Default: no identity management.\n\tIdentity *IdentityConfig `json:\"identity,omitempty\"`\n\n\t// Options pertaining to remote administration. By default, remote\n\t// administration is disabled. If enabled, identity management must\n\t// also be configured, as that is how the endpoint is secured.\n\t// See the neighboring \"identity\" object.\n\t//\n\t// EXPERIMENTAL: This feature is subject to change.\n\tRemote *RemoteAdmin `json:\"remote,omitempty\"`\n\n\t// Holds onto the routers so that we can later provision them\n\t// if they require provisioning.\n\trouters []AdminRouter\n}\n\n// ConfigSettings configures the management of configuration.\ntype ConfigSettings struct {\n\t// Whether to keep a copy of the active config on disk. Default is true.\n\t// Note that \"pulled\" dynamic configs (using the neighboring \"load\" module)\n\t// are not persisted; only configs that are pushed to Caddy get persisted.\n\tPersist *bool `json:\"persist,omitempty\"`\n\n\t// Loads a new configuration. This is helpful if your configs are\n\t// managed elsewhere and you want Caddy to pull its config dynamically\n\t// when it starts. The pulled config completely replaces the current\n\t// one, just like any other config load. It is an error if a pulled\n\t// config is configured to pull another config without a load_delay,\n\t// as this creates a tight loop.\n\t//\n\t// EXPERIMENTAL: Subject to change.\n\tLoadRaw json.RawMessage `json:\"load,omitempty\" caddy:\"namespace=caddy.config_loaders inline_key=module\"`\n\n\t// The duration after which to load config. If set, config will be pulled\n\t// from the config loader after this duration. A delay is required if a\n\t// dynamically-loaded config is configured to load yet another config. To\n\t// load configs on a regular interval, ensure this value is set the same\n\t// on all loaded configs; it can also be variable if needed, and to stop\n\t// the loop, simply remove dynamic config loading from the next-loaded\n\t// config.\n\t//\n\t// EXPERIMENTAL: Subject to change.\n\tLoadDelay Duration `json:\"load_delay,omitempty\"`\n}\n\n// IdentityConfig configures management of this server's identity. An identity\n// consists of credentials that uniquely verify this instance; for example,\n// TLS certificates (public + private key pairs).\ntype IdentityConfig struct {\n\t// List of names or IP addresses which refer to this server.\n\t// Certificates will be obtained for these identifiers so\n\t// secure TLS connections can be made using them.\n\tIdentifiers []string `json:\"identifiers,omitempty\"`\n\n\t// Issuers that can provide this admin endpoint its identity\n\t// certificate(s). Default: ACME issuers configured for\n\t// ZeroSSL and Let's Encrypt. Be sure to change this if you\n\t// require credentials for private identifiers.\n\tIssuersRaw []json.RawMessage `json:\"issuers,omitempty\" caddy:\"namespace=tls.issuance inline_key=module\"`\n\n\tissuers []certmagic.Issuer\n}\n\n// RemoteAdmin enables and configures remote administration. If enabled,\n// a secure listener enforcing mutual TLS authentication will be started\n// on a different port from the standard plaintext admin server.\n//\n// This endpoint is secured using identity management, which must be\n// configured separately (because identity management does not depend\n// on remote administration). See the admin/identity config struct.\n//\n// EXPERIMENTAL: Subject to change.\ntype RemoteAdmin struct {\n\t// The address on which to start the secure listener. Accepts placeholders.\n\t// Default: :2021\n\tListen string `json:\"listen,omitempty\"`\n\n\t// List of access controls for this secure admin endpoint.\n\t// This configures TLS mutual authentication (i.e. authorized\n\t// client certificates), but also application-layer permissions\n\t// like which paths and methods each identity is authorized for.\n\tAccessControl []*AdminAccess `json:\"access_control,omitempty\"`\n}\n\n// AdminAccess specifies what permissions an identity or group\n// of identities are granted.\ntype AdminAccess struct {\n\t// Base64-encoded DER certificates containing public keys to accept.\n\t// (The contents of PEM certificate blocks are base64-encoded DER.)\n\t// Any of these public keys can appear in any part of a verified chain.\n\tPublicKeys []string `json:\"public_keys,omitempty\"`\n\n\t// Limits what the associated identities are allowed to do.\n\t// If unspecified, all permissions are granted.\n\tPermissions []AdminPermissions `json:\"permissions,omitempty\"`\n\n\tpublicKeys []crypto.PublicKey\n}\n\n// AdminPermissions specifies what kinds of requests are allowed\n// to be made to the admin endpoint.\ntype AdminPermissions struct {\n\t// The API paths allowed. Paths are simple prefix matches.\n\t// Any subpath of the specified paths will be allowed.\n\tPaths []string `json:\"paths,omitempty\"`\n\n\t// The HTTP methods allowed for the given paths.\n\tMethods []string `json:\"methods,omitempty\"`\n}\n\n// newAdminHandler reads admin's config and returns an http.Handler suitable\n// for use in an admin endpoint server, which will be listening on listenAddr.\nfunc (admin *AdminConfig) newAdminHandler(addr NetworkAddress, remote bool, _ Context) adminHandler {\n\tmuxWrap := adminHandler{mux: http.NewServeMux()}\n\n\t// secure the local or remote endpoint respectively\n\tif remote {\n\t\tmuxWrap.remoteControl = admin.Remote\n\t} else {\n\t\t// see comment in allowedOrigins() as to why we disable the host check for unix/fd networks\n\t\tmuxWrap.enforceHost = !addr.isWildcardInterface() && !addr.IsUnixNetwork() && !addr.IsFdNetwork()\n\t\tmuxWrap.allowedOrigins = admin.allowedOrigins(addr)\n\t\tmuxWrap.enforceOrigin = admin.EnforceOrigin\n\t}\n\n\taddRouteWithMetrics := func(pattern string, handlerLabel string, h http.Handler) {\n\t\tlabels := prometheus.Labels{\"path\": pattern, \"handler\": handlerLabel}\n\t\th = instrumentHandlerCounter(\n\t\t\tadminMetrics.requestCount.MustCurryWith(labels),\n\t\t\th,\n\t\t)\n\t\tmuxWrap.mux.Handle(pattern, h)\n\t}\n\t// addRoute just calls muxWrap.mux.Handle after\n\t// wrapping the handler with error handling\n\taddRoute := func(pattern string, handlerLabel string, h AdminHandler) {\n\t\twrapper := http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {\n\t\t\terr := h.ServeHTTP(w, r)\n\t\t\tif err != nil {\n\t\t\t\tlabels := prometheus.Labels{\n\t\t\t\t\t\"path\":    pattern,\n\t\t\t\t\t\"handler\": handlerLabel,\n\t\t\t\t\t\"method\":  strings.ToUpper(r.Method),\n\t\t\t\t}\n\t\t\t\tadminMetrics.requestErrors.With(labels).Inc()\n\t\t\t}\n\t\t\tmuxWrap.handleError(w, r, err)\n\t\t})\n\t\taddRouteWithMetrics(pattern, handlerLabel, wrapper)\n\t}\n\n\tconst handlerLabel = \"admin\"\n\n\t// register standard config control endpoints\n\taddRoute(\"/\"+rawConfigKey+\"/\", handlerLabel, AdminHandlerFunc(handleConfig))\n\taddRoute(\"/id/\", handlerLabel, AdminHandlerFunc(handleConfigID))\n\taddRoute(\"/stop\", handlerLabel, AdminHandlerFunc(handleStop))\n\n\t// register debugging endpoints\n\taddRouteWithMetrics(\"/debug/pprof/\", handlerLabel, http.HandlerFunc(pprof.Index))\n\taddRouteWithMetrics(\"/debug/pprof/cmdline\", handlerLabel, http.HandlerFunc(pprof.Cmdline))\n\taddRouteWithMetrics(\"/debug/pprof/profile\", handlerLabel, http.HandlerFunc(pprof.Profile))\n\taddRouteWithMetrics(\"/debug/pprof/symbol\", handlerLabel, http.HandlerFunc(pprof.Symbol))\n\taddRouteWithMetrics(\"/debug/pprof/trace\", handlerLabel, http.HandlerFunc(pprof.Trace))\n\taddRouteWithMetrics(\"/debug/vars\", handlerLabel, expvar.Handler())\n\n\t// register third-party module endpoints\n\tfor _, m := range GetModules(\"admin.api\") {\n\t\trouter := m.New().(AdminRouter)\n\t\tfor _, route := range router.Routes() {\n\t\t\taddRoute(route.Pattern, handlerLabel, route.Handler)\n\t\t}\n\t\tadmin.routers = append(admin.routers, router)\n\t}\n\n\treturn muxWrap\n}\n\n// provisionAdminRouters provisions all the router modules\n// in the admin.api namespace that need provisioning.\nfunc (admin *AdminConfig) provisionAdminRouters(ctx Context) error {\n\tfor _, router := range admin.routers {\n\t\tprovisioner, ok := router.(Provisioner)\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\n\t\terr := provisioner.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// We no longer need the routers once provisioned, allow for GC\n\tadmin.routers = nil\n\n\treturn nil\n}\n\n// allowedOrigins returns a list of origins that are allowed.\n// If admin.Origins is nil (null), the provided listen address\n// will be used as the default origin. If admin.Origins is\n// empty, no origins will be allowed, effectively bricking the\n// endpoint for non-unix-socket endpoints, but whatever.\nfunc (admin AdminConfig) allowedOrigins(addr NetworkAddress) []*url.URL {\n\tuniqueOrigins := make(map[string]struct{})\n\tfor _, o := range admin.Origins {\n\t\tuniqueOrigins[o] = struct{}{}\n\t}\n\t// RFC 2616, Section 14.26:\n\t// \"A client MUST include a Host header field in all HTTP/1.1 request\n\t// messages. If the requested URI does not include an Internet host\n\t// name for the service being requested, then the Host header field MUST\n\t// be given with an empty value.\"\n\t//\n\t// UPDATE July 2023: Go broke this by patching a minor security bug in 1.20.6.\n\t// Understandable, but frustrating. See:\n\t// https://github.com/golang/go/issues/60374\n\t// See also the discussion here:\n\t// https://github.com/golang/go/issues/61431\n\t//\n\t// We can no longer conform to RFC 2616 Section 14.26 from either Go or curl\n\t// in purity. (Curl allowed no host between 7.40 and 7.50, but now requires a\n\t// bogus host; see https://superuser.com/a/925610.) If we disable Host/Origin\n\t// security checks, the infosec community assures me that it is secure to do\n\t// so, because:\n\t//\n\t// 1) Browsers do not allow access to unix sockets\n\t// 2) DNS is irrelevant to unix sockets\n\t//\n\t// If either of those two statements ever fail to hold true, it is not the\n\t// fault of Caddy.\n\t//\n\t// Thus, we do not fill out allowed origins and do not enforce Host\n\t// requirements for unix sockets. Enforcing it leads to confusion and\n\t// frustration, when UDS have their own permissions from the OS.\n\t// Enforcing host requirements here is effectively security theater,\n\t// and a false sense of security.\n\t//\n\t// See also the discussion in #6832.\n\tif admin.Origins == nil && !addr.IsUnixNetwork() && !addr.IsFdNetwork() {\n\t\tif addr.isLoopback() {\n\t\t\tuniqueOrigins[net.JoinHostPort(\"localhost\", addr.port())] = struct{}{}\n\t\t\tuniqueOrigins[net.JoinHostPort(\"::1\", addr.port())] = struct{}{}\n\t\t\tuniqueOrigins[net.JoinHostPort(\"127.0.0.1\", addr.port())] = struct{}{}\n\t\t} else {\n\t\t\tuniqueOrigins[addr.JoinHostPort(0)] = struct{}{}\n\t\t}\n\t}\n\tallowed := make([]*url.URL, 0, len(uniqueOrigins))\n\tfor originStr := range uniqueOrigins {\n\t\tvar origin *url.URL\n\t\tif strings.Contains(originStr, \"://\") {\n\t\t\tvar err error\n\t\t\torigin, err = url.Parse(originStr)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\torigin.Path = \"\"\n\t\t\torigin.RawPath = \"\"\n\t\t\torigin.Fragment = \"\"\n\t\t\torigin.RawFragment = \"\"\n\t\t\torigin.RawQuery = \"\"\n\t\t} else {\n\t\t\torigin = &url.URL{Host: originStr}\n\t\t}\n\t\tallowed = append(allowed, origin)\n\t}\n\treturn allowed\n}\n\n// replaceLocalAdminServer replaces the running local admin server\n// according to the relevant configuration in cfg. If no configuration\n// for the admin endpoint exists in cfg, a default one is used, so\n// that there is always an admin server (unless it is explicitly\n// configured to be disabled).\n// Critically note that some elements and functionality of the context\n// may not be ready, e.g. storage. Tread carefully.\nfunc replaceLocalAdminServer(cfg *Config, ctx Context) error {\n\t// always* be sure to close down the old admin endpoint\n\t// as gracefully as possible, even if the new one is\n\t// disabled -- careful to use reference to the current\n\t// (old) admin endpoint since it will be different\n\t// when the function returns\n\t// (* except if the new one fails to start)\n\toldAdminServer := localAdminServer\n\tvar err error\n\tdefer func() {\n\t\t// do the shutdown asynchronously so that any\n\t\t// current API request gets a response; this\n\t\t// goroutine may last a few seconds\n\t\tif oldAdminServer != nil && err == nil {\n\t\t\tgo func(oldAdminServer *http.Server) {\n\t\t\t\terr := stopAdminServer(oldAdminServer)\n\t\t\t\tif err != nil {\n\t\t\t\t\tLog().Named(\"admin\").Error(\"stopping current admin endpoint\", zap.Error(err))\n\t\t\t\t}\n\t\t\t}(oldAdminServer)\n\t\t}\n\t}()\n\n\t// set a default if admin wasn't otherwise configured\n\tif cfg.Admin == nil {\n\t\tcfg.Admin = &AdminConfig{\n\t\t\tListen: DefaultAdminListen,\n\t\t}\n\t}\n\n\t// if new admin endpoint is to be disabled, we're done\n\tif cfg.Admin.Disabled {\n\t\tLog().Named(\"admin\").Warn(\"admin endpoint disabled\")\n\t\treturn nil\n\t}\n\n\t// extract a singular listener address\n\taddr, err := parseAdminListenAddr(cfg.Admin.Listen, DefaultAdminListen)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\thandler := cfg.Admin.newAdminHandler(addr, false, ctx)\n\n\t// run the provisioners for loaded modules to make sure local\n\t// state is properly re-initialized in the new admin server\n\terr = cfg.Admin.provisionAdminRouters(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tln, err := addr.Listen(context.TODO(), 0, net.ListenConfig{})\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tserverMu.Lock()\n\tlocalAdminServer = &http.Server{\n\t\tAddr:              addr.String(), // for logging purposes only\n\t\tHandler:           handler,\n\t\tReadTimeout:       10 * time.Second,\n\t\tReadHeaderTimeout: 5 * time.Second,\n\t\tIdleTimeout:       60 * time.Second,\n\t\tMaxHeaderBytes:    1024 * 64,\n\t}\n\tserverMu.Unlock()\n\n\tadminLogger := Log().Named(\"admin\")\n\tgo func() {\n\t\tserverMu.Lock()\n\t\tserver := localAdminServer\n\t\tserverMu.Unlock()\n\t\tif err := server.Serve(ln.(net.Listener)); !errors.Is(err, http.ErrServerClosed) {\n\t\t\tadminLogger.Error(\"admin server shutdown for unknown reason\", zap.Error(err))\n\t\t}\n\t}()\n\n\tadminLogger.Info(\"admin endpoint started\",\n\t\tzap.String(\"address\", addr.String()),\n\t\tzap.Bool(\"enforce_origin\", cfg.Admin.EnforceOrigin),\n\t\tzap.Array(\"origins\", loggableURLArray(handler.allowedOrigins)))\n\n\tif !handler.enforceHost {\n\t\tadminLogger.Warn(\"admin endpoint on open interface; host checking disabled\",\n\t\t\tzap.String(\"address\", addr.String()))\n\t}\n\n\treturn nil\n}\n\n// manageIdentity sets up automated identity management for this server.\nfunc manageIdentity(ctx Context, cfg *Config) error {\n\tif cfg == nil || cfg.Admin == nil || cfg.Admin.Identity == nil {\n\t\treturn nil\n\t}\n\n\t// set default issuers; this is pretty hacky because we can't\n\t// import the caddytls package -- but it works\n\tif cfg.Admin.Identity.IssuersRaw == nil {\n\t\tcfg.Admin.Identity.IssuersRaw = []json.RawMessage{\n\t\t\tjson.RawMessage(`{\"module\": \"acme\"}`),\n\t\t}\n\t}\n\n\t// load and provision issuer modules\n\tif cfg.Admin.Identity.IssuersRaw != nil {\n\t\tval, err := ctx.LoadModule(cfg.Admin.Identity, \"IssuersRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading identity issuer modules: %s\", err)\n\t\t}\n\t\tfor _, issVal := range val.([]any) {\n\t\t\tcfg.Admin.Identity.issuers = append(cfg.Admin.Identity.issuers, issVal.(certmagic.Issuer))\n\t\t}\n\t}\n\n\t// we'll make a new cache when we make the CertMagic config, so stop any previous cache\n\tif identityCertCache != nil {\n\t\tidentityCertCache.Stop()\n\t}\n\n\tlogger := Log().Named(\"admin.identity\")\n\tcmCfg := cfg.Admin.Identity.certmagicConfig(logger, true)\n\n\t// issuers have circular dependencies with the configs because,\n\t// as explained in the caddytls package, they need access to the\n\t// correct storage and cache to solve ACME challenges\n\tfor _, issuer := range cfg.Admin.Identity.issuers {\n\t\t// avoid import cycle with caddytls package, so manually duplicate the interface here, yuck\n\t\tif annoying, ok := issuer.(interface{ SetConfig(cfg *certmagic.Config) }); ok {\n\t\t\tannoying.SetConfig(cmCfg)\n\t\t}\n\t}\n\n\t// obtain and renew server identity certificate(s)\n\treturn cmCfg.ManageAsync(ctx, cfg.Admin.Identity.Identifiers)\n}\n\n// replaceRemoteAdminServer replaces the running remote admin server\n// according to the relevant configuration in cfg. It stops any previous\n// remote admin server and only starts a new one if configured.\nfunc replaceRemoteAdminServer(ctx Context, cfg *Config) error {\n\tif cfg == nil {\n\t\treturn nil\n\t}\n\n\tremoteLogger := Log().Named(\"admin.remote\")\n\n\toldAdminServer := remoteAdminServer\n\tdefer func() {\n\t\tif oldAdminServer != nil {\n\t\t\tgo func(oldAdminServer *http.Server) {\n\t\t\t\terr := stopAdminServer(oldAdminServer)\n\t\t\t\tif err != nil {\n\t\t\t\t\tLog().Named(\"admin\").Error(\"stopping current secure admin endpoint\", zap.Error(err))\n\t\t\t\t}\n\t\t\t}(oldAdminServer)\n\t\t}\n\t}()\n\n\tif cfg.Admin == nil || cfg.Admin.Remote == nil {\n\t\treturn nil\n\t}\n\n\taddr, err := parseAdminListenAddr(cfg.Admin.Remote.Listen, DefaultRemoteAdminListen)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// make the HTTP handler but disable Host/Origin enforcement\n\t// because we are using TLS authentication instead\n\thandler := cfg.Admin.newAdminHandler(addr, true, ctx)\n\n\t// run the provisioners for loaded modules to make sure local\n\t// state is properly re-initialized in the new admin server\n\terr = cfg.Admin.provisionAdminRouters(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// create client certificate pool for TLS mutual auth, and extract public keys\n\t// so that we can enforce access controls at the application layer\n\tclientCertPool := x509.NewCertPool()\n\tfor i, accessControl := range cfg.Admin.Remote.AccessControl {\n\t\tfor j, certBase64 := range accessControl.PublicKeys {\n\t\t\tcert, err := decodeBase64DERCert(certBase64)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"access control %d public key %d: parsing base64 certificate DER: %v\", i, j, err)\n\t\t\t}\n\t\t\taccessControl.publicKeys = append(accessControl.publicKeys, cert.PublicKey)\n\t\t\tclientCertPool.AddCert(cert)\n\t\t}\n\t}\n\n\t// create TLS config that will enforce mutual authentication\n\tif identityCertCache == nil {\n\t\treturn fmt.Errorf(\"cannot enable remote admin without a certificate cache; configure identity management to initialize a certificate cache\")\n\t}\n\tcmCfg := cfg.Admin.Identity.certmagicConfig(remoteLogger, false)\n\ttlsConfig := cmCfg.TLSConfig()\n\ttlsConfig.NextProtos = nil // this server does not solve ACME challenges\n\ttlsConfig.ClientAuth = tls.RequireAndVerifyClientCert\n\ttlsConfig.ClientCAs = clientCertPool\n\n\t// convert logger to stdlib so it can be used by HTTP server\n\tserverLogger, err := zap.NewStdLogAt(remoteLogger, zap.DebugLevel)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tserverMu.Lock()\n\t// create secure HTTP server\n\tremoteAdminServer = &http.Server{\n\t\tAddr:              addr.String(), // for logging purposes only\n\t\tHandler:           handler,\n\t\tTLSConfig:         tlsConfig,\n\t\tReadTimeout:       10 * time.Second,\n\t\tReadHeaderTimeout: 5 * time.Second,\n\t\tIdleTimeout:       60 * time.Second,\n\t\tMaxHeaderBytes:    1024 * 64,\n\t\tErrorLog:          serverLogger,\n\t}\n\tserverMu.Unlock()\n\n\t// start listener\n\tlnAny, err := addr.Listen(ctx, 0, net.ListenConfig{})\n\tif err != nil {\n\t\treturn err\n\t}\n\tln := lnAny.(net.Listener)\n\tln = tls.NewListener(ln, tlsConfig)\n\n\tgo func() {\n\t\tserverMu.Lock()\n\t\tserver := remoteAdminServer\n\t\tserverMu.Unlock()\n\t\tif err := server.Serve(ln); !errors.Is(err, http.ErrServerClosed) {\n\t\t\tremoteLogger.Error(\"admin remote server shutdown for unknown reason\", zap.Error(err))\n\t\t}\n\t}()\n\n\tremoteLogger.Info(\"secure admin remote control endpoint started\",\n\t\tzap.String(\"address\", addr.String()))\n\n\treturn nil\n}\n\nfunc (ident *IdentityConfig) certmagicConfig(logger *zap.Logger, makeCache bool) *certmagic.Config {\n\tvar cmCfg *certmagic.Config\n\tif ident == nil {\n\t\t// user might not have configured identity; that's OK, we can still make a\n\t\t// certmagic config, although it'll be mostly useless for remote management\n\t\tident = new(IdentityConfig)\n\t}\n\ttemplate := certmagic.Config{\n\t\tStorage: DefaultStorage, // do not act as part of a cluster (this is for the server's local identity)\n\t\tLogger:  logger,\n\t\tIssuers: ident.issuers,\n\t}\n\tif makeCache {\n\t\tidentityCertCache = certmagic.NewCache(certmagic.CacheOptions{\n\t\t\tGetConfigForCert: func(certmagic.Certificate) (*certmagic.Config, error) {\n\t\t\t\treturn cmCfg, nil\n\t\t\t},\n\t\t\tLogger: logger.Named(\"cache\"),\n\t\t})\n\t}\n\tcmCfg = certmagic.New(identityCertCache, template)\n\treturn cmCfg\n}\n\n// IdentityCredentials returns this instance's configured, managed identity credentials\n// that can be used in TLS client authentication.\nfunc (ctx Context) IdentityCredentials(logger *zap.Logger) ([]tls.Certificate, error) {\n\tif ctx.cfg == nil || ctx.cfg.Admin == nil || ctx.cfg.Admin.Identity == nil {\n\t\treturn nil, fmt.Errorf(\"no server identity configured\")\n\t}\n\tident := ctx.cfg.Admin.Identity\n\tif len(ident.Identifiers) == 0 {\n\t\treturn nil, fmt.Errorf(\"no identifiers configured\")\n\t}\n\tif logger == nil {\n\t\tlogger = Log()\n\t}\n\tmagic := ident.certmagicConfig(logger, false)\n\treturn magic.ClientCredentials(ctx, ident.Identifiers)\n}\n\n// enforceAccessControls enforces application-layer access controls for r based on remote.\n// It expects that the TLS server has already established at least one verified chain of\n// trust, and then looks for a matching, authorized public key that is allowed to access\n// the defined path(s) using the defined method(s).\nfunc (remote RemoteAdmin) enforceAccessControls(r *http.Request) error {\n\tfor _, chain := range r.TLS.VerifiedChains {\n\t\tfor _, peerCert := range chain {\n\t\t\tfor _, adminAccess := range remote.AccessControl {\n\t\t\t\tfor _, allowedKey := range adminAccess.publicKeys {\n\t\t\t\t\t// see if we found a matching public key; the TLS server already verified the chain\n\t\t\t\t\t// so we know the client possesses the associated private key; this handy interface\n\t\t\t\t\t// doesn't appear to be defined anywhere in the std lib, but was implemented here:\n\t\t\t\t\t// https://github.com/golang/go/commit/b5f2c0f50297fa5cd14af668ddd7fd923626cf8c\n\t\t\t\t\tcomparer, ok := peerCert.PublicKey.(interface{ Equal(crypto.PublicKey) bool })\n\t\t\t\t\tif !ok || !comparer.Equal(allowedKey) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// key recognized; make sure its HTTP request is permitted\n\t\t\t\t\tfor _, accessPerm := range adminAccess.Permissions {\n\t\t\t\t\t\t// verify method\n\t\t\t\t\t\tmethodFound := accessPerm.Methods == nil || slices.Contains(accessPerm.Methods, r.Method)\n\t\t\t\t\t\tif !methodFound {\n\t\t\t\t\t\t\treturn APIError{\n\t\t\t\t\t\t\t\tHTTPStatus: http.StatusForbidden,\n\t\t\t\t\t\t\t\tMessage:    \"not authorized to use this method\",\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\t// verify path\n\t\t\t\t\t\tpathFound := accessPerm.Paths == nil\n\t\t\t\t\t\tfor _, allowedPath := range accessPerm.Paths {\n\t\t\t\t\t\t\tif strings.HasPrefix(r.URL.Path, allowedPath) {\n\t\t\t\t\t\t\t\tpathFound = true\n\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif !pathFound {\n\t\t\t\t\t\t\treturn APIError{\n\t\t\t\t\t\t\t\tHTTPStatus: http.StatusForbidden,\n\t\t\t\t\t\t\t\tMessage:    \"not authorized to access this path\",\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// public key authorized, method and path allowed\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// in theory, this should never happen; with an unverified chain, the TLS server\n\t// should not accept the connection in the first place, and the acceptable cert\n\t// pool is configured using the same list of public keys we verify against\n\treturn APIError{\n\t\tHTTPStatus: http.StatusUnauthorized,\n\t\tMessage:    \"client identity not authorized\",\n\t}\n}\n\nfunc stopAdminServer(srv *http.Server) error {\n\tif srv == nil {\n\t\treturn fmt.Errorf(\"no admin server\")\n\t}\n\tctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)\n\tdefer cancel()\n\terr := srv.Shutdown(ctx)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"shutting down admin server: %v\", err)\n\t}\n\tLog().Named(\"admin\").Info(\"stopped previous server\", zap.String(\"address\", srv.Addr))\n\treturn nil\n}\n\n// AdminRouter is a type which can return routes for the admin API.\ntype AdminRouter interface {\n\tRoutes() []AdminRoute\n}\n\n// AdminRoute represents a route for the admin endpoint.\ntype AdminRoute struct {\n\tPattern string\n\tHandler AdminHandler\n}\n\ntype adminHandler struct {\n\tmux *http.ServeMux\n\n\t// security for local/plaintext endpoint\n\tenforceOrigin  bool\n\tenforceHost    bool\n\tallowedOrigins []*url.URL\n\n\t// security for remote/encrypted endpoint\n\tremoteControl *RemoteAdmin\n}\n\n// ServeHTTP is the external entry point for API requests.\n// It will only be called once per request.\nfunc (h adminHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\tip, port, err := net.SplitHostPort(r.RemoteAddr)\n\tif err != nil {\n\t\tip = r.RemoteAddr\n\t\tport = \"\"\n\t}\n\tlog := Log().Named(\"admin.api\").With(\n\t\tzap.String(\"method\", r.Method),\n\t\tzap.String(\"host\", r.Host),\n\t\tzap.String(\"uri\", r.RequestURI),\n\t\tzap.String(\"remote_ip\", ip),\n\t\tzap.String(\"remote_port\", port),\n\t\tzap.Reflect(\"headers\", r.Header),\n\t)\n\tif r.TLS != nil {\n\t\tlog = log.With(\n\t\t\tzap.Bool(\"secure\", true),\n\t\t\tzap.Int(\"verified_chains\", len(r.TLS.VerifiedChains)),\n\t\t)\n\t}\n\tif r.RequestURI == \"/metrics\" {\n\t\tlog.Debug(\"received request\")\n\t} else {\n\t\tlog.Info(\"received request\")\n\t}\n\th.serveHTTP(w, r)\n}\n\n// serveHTTP is the internal entry point for API requests. It may\n// be called more than once per request, for example if a request\n// is rewritten (i.e. internal redirect).\nfunc (h adminHandler) serveHTTP(w http.ResponseWriter, r *http.Request) {\n\tif h.remoteControl != nil {\n\t\t// enforce access controls on secure endpoint\n\t\tif err := h.remoteControl.enforceAccessControls(r); err != nil {\n\t\t\th.handleError(w, r, err)\n\t\t\treturn\n\t\t}\n\t}\n\n\tif strings.Contains(r.Header.Get(\"Upgrade\"), \"websocket\") {\n\t\t// I've never been able demonstrate a vulnerability myself, but apparently\n\t\t// WebSocket connections originating from browsers aren't subject to CORS\n\t\t// restrictions, so we'll just be on the safe side\n\t\th.handleError(w, r, fmt.Errorf(\"websocket connections aren't allowed\"))\n\t\treturn\n\t}\n\n\tif h.enforceHost {\n\t\t// DNS rebinding mitigation\n\t\terr := h.checkHost(r)\n\t\tif err != nil {\n\t\t\th.handleError(w, r, err)\n\t\t\treturn\n\t\t}\n\t}\n\n\tif h.enforceOrigin {\n\t\t// cross-site mitigation\n\t\torigin, err := h.checkOrigin(r)\n\t\tif err != nil {\n\t\t\th.handleError(w, r, err)\n\t\t\treturn\n\t\t}\n\n\t\tif r.Method == http.MethodOptions {\n\t\t\tw.Header().Set(\"Access-Control-Allow-Methods\", \"OPTIONS, GET, POST, PUT, PATCH, DELETE\")\n\t\t\tw.Header().Set(\"Access-Control-Allow-Headers\", \"Content-Type, Content-Length, Cache-Control\")\n\t\t\tw.Header().Set(\"Access-Control-Allow-Credentials\", \"true\")\n\t\t}\n\t\tw.Header().Set(\"Access-Control-Allow-Origin\", origin)\n\t}\n\n\th.mux.ServeHTTP(w, r)\n}\n\nfunc (h adminHandler) handleError(w http.ResponseWriter, r *http.Request, err error) {\n\tif err == nil {\n\t\treturn\n\t}\n\tif err == errInternalRedir {\n\t\th.serveHTTP(w, r)\n\t\treturn\n\t}\n\n\tapiErr, ok := err.(APIError)\n\tif !ok {\n\t\tapiErr = APIError{\n\t\t\tHTTPStatus: http.StatusInternalServerError,\n\t\t\tErr:        err,\n\t\t}\n\t}\n\tif apiErr.HTTPStatus == 0 {\n\t\tapiErr.HTTPStatus = http.StatusInternalServerError\n\t}\n\tif apiErr.Message == \"\" && apiErr.Err != nil {\n\t\tapiErr.Message = apiErr.Err.Error()\n\t}\n\n\tLog().Named(\"admin.api\").Error(\"request error\",\n\t\tzap.Error(err),\n\t\tzap.Int(\"status_code\", apiErr.HTTPStatus),\n\t)\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\tw.WriteHeader(apiErr.HTTPStatus)\n\tencErr := json.NewEncoder(w).Encode(apiErr)\n\tif encErr != nil {\n\t\tLog().Named(\"admin.api\").Error(\"failed to encode error response\", zap.Error(encErr))\n\t}\n}\n\n// checkHost returns a handler that wraps next such that\n// it will only be called if the request's Host header matches\n// a trustworthy/expected value. This helps to mitigate DNS\n// rebinding attacks.\nfunc (h adminHandler) checkHost(r *http.Request) error {\n\tallowed := slices.ContainsFunc(h.allowedOrigins, func(u *url.URL) bool {\n\t\treturn r.Host == u.Host\n\t})\n\tif !allowed {\n\t\treturn APIError{\n\t\t\tHTTPStatus: http.StatusForbidden,\n\t\t\tErr:        fmt.Errorf(\"host not allowed: %s\", r.Host),\n\t\t}\n\t}\n\treturn nil\n}\n\n// checkOrigin ensures that the Origin header, if\n// set, matches the intended target; prevents arbitrary\n// sites from issuing requests to our listener. It\n// returns the origin that was obtained from r.\nfunc (h adminHandler) checkOrigin(r *http.Request) (string, error) {\n\toriginStr, origin := h.getOrigin(r)\n\tif origin == nil {\n\t\treturn \"\", APIError{\n\t\t\tHTTPStatus: http.StatusForbidden,\n\t\t\tErr:        fmt.Errorf(\"required Origin header is missing or invalid\"),\n\t\t}\n\t}\n\tif !h.originAllowed(origin) {\n\t\treturn \"\", APIError{\n\t\t\tHTTPStatus: http.StatusForbidden,\n\t\t\tErr:        fmt.Errorf(\"client is not allowed to access from origin '%s'\", originStr),\n\t\t}\n\t}\n\treturn origin.String(), nil\n}\n\nfunc (h adminHandler) getOrigin(r *http.Request) (string, *url.URL) {\n\torigin := r.Header.Get(\"Origin\")\n\tif origin == \"\" {\n\t\torigin = r.Header.Get(\"Referer\")\n\t}\n\toriginURL, err := url.Parse(origin)\n\tif err != nil {\n\t\treturn origin, nil\n\t}\n\toriginURL.Path = \"\"\n\toriginURL.RawPath = \"\"\n\toriginURL.Fragment = \"\"\n\toriginURL.RawFragment = \"\"\n\toriginURL.RawQuery = \"\"\n\treturn origin, originURL\n}\n\nfunc (h adminHandler) originAllowed(origin *url.URL) bool {\n\tfor _, allowedOrigin := range h.allowedOrigins {\n\t\tif allowedOrigin.Scheme != \"\" && origin.Scheme != allowedOrigin.Scheme {\n\t\t\tcontinue\n\t\t}\n\t\tif origin.Host == allowedOrigin.Host {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// etagHasher returns a the hasher we used on the config to both\n// produce and verify ETags.\nfunc etagHasher() hash.Hash { return xxhash.New() }\n\n// makeEtag returns an Etag header value (including quotes) for\n// the given config path and hash of contents at that path.\nfunc makeEtag(path string, hash hash.Hash) string {\n\treturn fmt.Sprintf(`\"%s %x\"`, path, hash.Sum(nil))\n}\n\n// This buffer pool is used to keep buffers for\n// reading the config file during eTag header generation\nvar bufferPool = sync.Pool{\n\tNew: func() any {\n\t\treturn new(bytes.Buffer)\n\t},\n}\n\nfunc handleConfig(w http.ResponseWriter, r *http.Request) error {\n\tswitch r.Method {\n\tcase http.MethodGet:\n\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\thash := etagHasher()\n\n\t\t// Read the config into a buffer instead of writing directly to\n\t\t// the response writer, as we want to set the ETag as the header,\n\t\t// not the trailer.\n\t\tbuf := bufferPool.Get().(*bytes.Buffer)\n\t\tbuf.Reset()\n\t\tdefer bufferPool.Put(buf)\n\n\t\tconfigWriter := io.MultiWriter(buf, hash)\n\t\terr := readConfig(r.URL.Path, configWriter)\n\t\tif err != nil {\n\t\t\treturn APIError{HTTPStatus: http.StatusBadRequest, Err: err}\n\t\t}\n\n\t\t// we could consider setting up a sync.Pool for the summed\n\t\t// hashes to reduce GC pressure.\n\t\tw.Header().Set(\"Etag\", makeEtag(r.URL.Path, hash))\n\t\t_, err = w.Write(buf.Bytes())\n\t\tif err != nil {\n\t\t\treturn APIError{HTTPStatus: http.StatusInternalServerError, Err: err}\n\t\t}\n\n\t\treturn nil\n\n\tcase http.MethodPost,\n\t\thttp.MethodPut,\n\t\thttp.MethodPatch,\n\t\thttp.MethodDelete:\n\n\t\t// DELETE does not use a body, but the others do\n\t\tvar body []byte\n\t\tif r.Method != http.MethodDelete {\n\t\t\tif ct := r.Header.Get(\"Content-Type\"); !strings.Contains(ct, \"/json\") {\n\t\t\t\treturn APIError{\n\t\t\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\t\t\tErr:        fmt.Errorf(\"unacceptable content-type: %v; 'application/json' required\", ct),\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbuf := bufPool.Get().(*bytes.Buffer)\n\t\t\tbuf.Reset()\n\t\t\tdefer bufPool.Put(buf)\n\n\t\t\t_, err := io.Copy(buf, r.Body)\n\t\t\tif err != nil {\n\t\t\t\treturn APIError{\n\t\t\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\t\t\tErr:        fmt.Errorf(\"reading request body: %v\", err),\n\t\t\t\t}\n\t\t\t}\n\t\t\tbody = buf.Bytes()\n\t\t}\n\n\t\tforceReload := r.Header.Get(\"Cache-Control\") == \"must-revalidate\"\n\n\t\terr := changeConfig(r.Method, r.URL.Path, body, r.Header.Get(\"If-Match\"), forceReload)\n\t\tif err != nil && !errors.Is(err, errSameConfig) {\n\t\t\treturn err\n\t\t}\n\n\tdefault:\n\t\treturn APIError{\n\t\t\tHTTPStatus: http.StatusMethodNotAllowed,\n\t\t\tErr:        fmt.Errorf(\"method %s not allowed\", r.Method),\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc handleConfigID(w http.ResponseWriter, r *http.Request) error {\n\tidPath := r.URL.Path\n\n\tparts := strings.Split(idPath, \"/\")\n\tif len(parts) < 3 || parts[2] == \"\" {\n\t\treturn APIError{\n\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\tErr:        fmt.Errorf(\"request path is missing object ID\"),\n\t\t}\n\t}\n\tif parts[0] != \"\" || parts[1] != \"id\" {\n\t\treturn APIError{\n\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\tErr:        fmt.Errorf(\"malformed object path\"),\n\t\t}\n\t}\n\tid := parts[2]\n\n\t// map the ID to the expanded path\n\trawCfgMu.RLock()\n\texpanded, ok := rawCfgIndex[id]\n\trawCfgMu.RUnlock()\n\tif !ok {\n\t\treturn APIError{\n\t\t\tHTTPStatus: http.StatusNotFound,\n\t\t\tErr:        fmt.Errorf(\"unknown object ID '%s'\", id),\n\t\t}\n\t}\n\n\t// piece the full URL path back together\n\tparts = append([]string{expanded}, parts[3:]...)\n\tr.URL.Path = path.Join(parts...)\n\n\treturn errInternalRedir\n}\n\nfunc handleStop(w http.ResponseWriter, r *http.Request) error {\n\tif r.Method != http.MethodPost {\n\t\treturn APIError{\n\t\t\tHTTPStatus: http.StatusMethodNotAllowed,\n\t\t\tErr:        fmt.Errorf(\"method not allowed\"),\n\t\t}\n\t}\n\n\texitProcess(context.Background(), Log().Named(\"admin.api\"))\n\treturn nil\n}\n\n// unsyncedConfigAccess traverses into the current config and performs\n// the operation at path according to method, using body and out as\n// needed. This is a low-level, unsynchronized function; most callers\n// will want to use changeConfig or readConfig instead. This requires a\n// read or write lock on currentCtxMu, depending on method (GET needs\n// only a read lock; all others need a write lock).\nfunc unsyncedConfigAccess(method, path string, body []byte, out io.Writer) error {\n\tvar err error\n\tvar val any\n\n\t// if there is a request body, decode it into the\n\t// variable that will be set in the config according\n\t// to method and path\n\tif len(body) > 0 {\n\t\terr = json.Unmarshal(body, &val)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"decoding request body: %v\", err)\n\t\t}\n\t}\n\n\tenc := json.NewEncoder(out)\n\n\tcleanPath := strings.Trim(path, \"/\")\n\tif cleanPath == \"\" {\n\t\treturn fmt.Errorf(\"no traversable path\")\n\t}\n\n\tparts := strings.Split(cleanPath, \"/\")\n\tif len(parts) == 0 {\n\t\treturn fmt.Errorf(\"path missing\")\n\t}\n\n\t// A path that ends with \"...\" implies:\n\t// 1) the part before it is an array\n\t// 2) the payload is an array\n\t// and means that the user wants to expand the elements\n\t// in the payload array and append each one into the\n\t// destination array, like so:\n\t//     array = append(array, elems...)\n\t// This special case is handled below.\n\tellipses := parts[len(parts)-1] == \"...\"\n\tif ellipses {\n\t\tparts = parts[:len(parts)-1]\n\t}\n\n\tvar ptr any = rawCfg\n\ntraverseLoop:\n\tfor i, part := range parts {\n\t\tswitch v := ptr.(type) {\n\t\tcase map[string]any:\n\t\t\t// if the next part enters a slice, and the slice is our destination,\n\t\t\t// handle it specially (because appending to the slice copies the slice\n\t\t\t// header, which does not replace the original one like we want)\n\t\t\tif arr, ok := v[part].([]any); ok && i == len(parts)-2 {\n\t\t\t\tvar idx int\n\t\t\t\tif method != http.MethodPost {\n\t\t\t\t\tidxStr := parts[len(parts)-1]\n\t\t\t\t\tidx, err = strconv.Atoi(idxStr)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"[%s] invalid array index '%s': %v\",\n\t\t\t\t\t\t\tpath, idxStr, err)\n\t\t\t\t\t}\n\t\t\t\t\tif idx < 0 || (method != http.MethodPut && idx >= len(arr)) || idx > len(arr) {\n\t\t\t\t\t\treturn fmt.Errorf(\"[%s] array index out of bounds: %s\", path, idxStr)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tswitch method {\n\t\t\t\tcase http.MethodGet:\n\t\t\t\t\terr = enc.Encode(arr[idx])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"encoding config: %v\", err)\n\t\t\t\t\t}\n\t\t\t\tcase http.MethodPost:\n\t\t\t\t\tif ellipses {\n\t\t\t\t\t\tvalArray, ok := val.([]any)\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\treturn fmt.Errorf(\"final element is not an array\")\n\t\t\t\t\t\t}\n\t\t\t\t\t\tv[part] = append(arr, valArray...)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tv[part] = append(arr, val)\n\t\t\t\t\t}\n\t\t\t\tcase http.MethodPut:\n\t\t\t\t\t// avoid creation of new slice and a second copy (see\n\t\t\t\t\t// https://github.com/golang/go/wiki/SliceTricks#insert)\n\t\t\t\t\tarr = append(arr, nil)\n\t\t\t\t\tcopy(arr[idx+1:], arr[idx:])\n\t\t\t\t\tarr[idx] = val\n\t\t\t\t\tv[part] = arr\n\t\t\t\tcase http.MethodPatch:\n\t\t\t\t\tarr[idx] = val\n\t\t\t\tcase http.MethodDelete:\n\t\t\t\t\tv[part] = append(arr[:idx], arr[idx+1:]...)\n\t\t\t\tdefault:\n\t\t\t\t\treturn fmt.Errorf(\"unrecognized method %s\", method)\n\t\t\t\t}\n\t\t\t\tbreak traverseLoop\n\t\t\t}\n\n\t\t\tif i == len(parts)-1 {\n\t\t\t\tswitch method {\n\t\t\t\tcase http.MethodGet:\n\t\t\t\t\terr = enc.Encode(v[part])\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"encoding config: %v\", err)\n\t\t\t\t\t}\n\t\t\t\tcase http.MethodPost:\n\t\t\t\t\t// if the part is an existing list, POST appends to\n\t\t\t\t\t// it, otherwise it just sets or creates the value\n\t\t\t\t\tif arr, ok := v[part].([]any); ok {\n\t\t\t\t\t\tif ellipses {\n\t\t\t\t\t\t\tvalArray, ok := val.([]any)\n\t\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\t\treturn fmt.Errorf(\"final element is not an array\")\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tv[part] = append(arr, valArray...)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tv[part] = append(arr, val)\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tv[part] = val\n\t\t\t\t\t}\n\t\t\t\tcase http.MethodPut:\n\t\t\t\t\tif _, ok := v[part]; ok {\n\t\t\t\t\t\treturn APIError{\n\t\t\t\t\t\t\tHTTPStatus: http.StatusConflict,\n\t\t\t\t\t\t\tErr:        fmt.Errorf(\"[%s] key already exists: %s\", path, part),\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv[part] = val\n\t\t\t\tcase http.MethodPatch:\n\t\t\t\t\tif _, ok := v[part]; !ok {\n\t\t\t\t\t\treturn APIError{\n\t\t\t\t\t\t\tHTTPStatus: http.StatusNotFound,\n\t\t\t\t\t\t\tErr:        fmt.Errorf(\"[%s] key does not exist: %s\", path, part),\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tv[part] = val\n\t\t\t\tcase http.MethodDelete:\n\t\t\t\t\tif _, ok := v[part]; !ok {\n\t\t\t\t\t\treturn APIError{\n\t\t\t\t\t\t\tHTTPStatus: http.StatusNotFound,\n\t\t\t\t\t\t\tErr:        fmt.Errorf(\"[%s] key does not exist: %s\", path, part),\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tdelete(v, part)\n\t\t\t\tdefault:\n\t\t\t\t\treturn fmt.Errorf(\"unrecognized method %s\", method)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\t// if we are \"PUTting\" a new resource, the key(s) in its path\n\t\t\t\t// might not exist yet; that's OK but we need to make them as\n\t\t\t\t// we go, while we still have a pointer from the level above\n\t\t\t\tif v[part] == nil && method == http.MethodPut {\n\t\t\t\t\tv[part] = make(map[string]any)\n\t\t\t\t}\n\t\t\t\tptr = v[part]\n\t\t\t}\n\n\t\tcase []any:\n\t\t\tpartInt, err := strconv.Atoi(part)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"[/%s] invalid array index '%s': %v\",\n\t\t\t\t\tstrings.Join(parts[:i+1], \"/\"), part, err)\n\t\t\t}\n\t\t\tif partInt < 0 || partInt >= len(v) {\n\t\t\t\treturn fmt.Errorf(\"[/%s] array index out of bounds: %s\",\n\t\t\t\t\tstrings.Join(parts[:i+1], \"/\"), part)\n\t\t\t}\n\t\t\tptr = v[partInt]\n\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"invalid traversal path at: %s\", strings.Join(parts[:i+1], \"/\"))\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// RemoveMetaFields removes meta fields like \"@id\" from a JSON message\n// by using a simple regular expression. (An alternate way to do this\n// would be to delete them from the raw, map[string]any\n// representation as they are indexed, then iterate the index we made\n// and add them back after encoding as JSON, but this is simpler.)\nfunc RemoveMetaFields(rawJSON []byte) []byte {\n\treturn idRegexp.ReplaceAllFunc(rawJSON, func(in []byte) []byte {\n\t\t// matches with a comma on both sides (when \"@id\" property is\n\t\t// not the first or last in the object) need to keep exactly\n\t\t// one comma for correct JSON syntax\n\t\tcomma := []byte{','}\n\t\tif bytes.HasPrefix(in, comma) && bytes.HasSuffix(in, comma) {\n\t\t\treturn comma\n\t\t}\n\t\treturn []byte{}\n\t})\n}\n\n// AdminHandler is like http.Handler except ServeHTTP may return an error.\n//\n// If any handler encounters an error, it should be returned for proper\n// handling.\ntype AdminHandler interface {\n\tServeHTTP(http.ResponseWriter, *http.Request) error\n}\n\n// AdminHandlerFunc is a convenience type like http.HandlerFunc.\ntype AdminHandlerFunc func(http.ResponseWriter, *http.Request) error\n\n// ServeHTTP implements the Handler interface.\nfunc (f AdminHandlerFunc) ServeHTTP(w http.ResponseWriter, r *http.Request) error {\n\treturn f(w, r)\n}\n\n// APIError is a structured error that every API\n// handler should return for consistency in logging\n// and client responses. If Message is unset, then\n// Err.Error() will be serialized in its place.\ntype APIError struct {\n\tHTTPStatus int    `json:\"-\"`\n\tErr        error  `json:\"-\"`\n\tMessage    string `json:\"error\"`\n}\n\nfunc (e APIError) Error() string {\n\tif e.Err != nil {\n\t\treturn e.Err.Error()\n\t}\n\treturn e.Message\n}\n\n// parseAdminListenAddr extracts a singular listen address from either addr\n// or defaultAddr, returning the network and the address of the listener.\nfunc parseAdminListenAddr(addr string, defaultAddr string) (NetworkAddress, error) {\n\tinput, err := NewReplacer().ReplaceOrErr(addr, true, true)\n\tif err != nil {\n\t\treturn NetworkAddress{}, fmt.Errorf(\"replacing listen address: %v\", err)\n\t}\n\tif input == \"\" {\n\t\tinput = defaultAddr\n\t}\n\tlistenAddr, err := ParseNetworkAddress(input)\n\tif err != nil {\n\t\treturn NetworkAddress{}, fmt.Errorf(\"parsing listener address: %v\", err)\n\t}\n\tif listenAddr.PortRangeSize() != 1 {\n\t\treturn NetworkAddress{}, fmt.Errorf(\"must be exactly one listener address; cannot listen on: %s\", listenAddr)\n\t}\n\treturn listenAddr, nil\n}\n\n// decodeBase64DERCert base64-decodes, then DER-decodes, certStr.\nfunc decodeBase64DERCert(certStr string) (*x509.Certificate, error) {\n\tderBytes, err := base64.StdEncoding.DecodeString(certStr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn x509.ParseCertificate(derBytes)\n}\n\ntype loggableURLArray []*url.URL\n\nfunc (ua loggableURLArray) MarshalLogArray(enc zapcore.ArrayEncoder) error {\n\tif ua == nil {\n\t\treturn nil\n\t}\n\tfor _, u := range ua {\n\t\tenc.AppendString(u.String())\n\t}\n\treturn nil\n}\n\nvar (\n\t// DefaultAdminListen is the address for the local admin\n\t// listener, if none is specified at startup.\n\tDefaultAdminListen = \"localhost:2019\"\n\n\t// DefaultRemoteAdminListen is the address for the remote\n\t// (TLS-authenticated) admin listener, if enabled and not\n\t// specified otherwise.\n\tDefaultRemoteAdminListen = \":2021\"\n)\n\n// PIDFile writes a pidfile to the file at filename. It\n// will get deleted before the process gracefully exits.\nfunc PIDFile(filename string) error {\n\tpid := []byte(strconv.Itoa(os.Getpid()) + \"\\n\")\n\terr := os.WriteFile(filename, pid, 0o600)\n\tif err != nil {\n\t\treturn err\n\t}\n\tpidfile = filename\n\treturn nil\n}\n\n// idRegexp is used to match ID fields and their associated values\n// in the config. It also matches adjacent commas so that syntax\n// can be preserved no matter where in the object the field appears.\n// It supports string and most numeric values.\nvar idRegexp = regexp.MustCompile(`(?m),?\\s*\"` + idKey + `\"\\s*:\\s*(-?[0-9]+(\\.[0-9]+)?|(?U)\".*\")\\s*,?`)\n\n// pidfile is the name of the pidfile, if any.\nvar pidfile string\n\n// errInternalRedir indicates an internal redirect\n// and is useful when admin API handlers rewrite\n// the request; in that case, authentication and\n// authorization needs to happen again for the\n// rewritten request.\nvar errInternalRedir = fmt.Errorf(\"internal redirect; re-authorization required\")\n\nconst (\n\trawConfigKey = \"config\"\n\tidKey        = \"@id\"\n)\n\nvar bufPool = sync.Pool{\n\tNew: func() any {\n\t\treturn new(bytes.Buffer)\n\t},\n}\n\n// keep a reference to admin endpoint singletons while they're active\nvar (\n\tserverMu                            sync.Mutex\n\tlocalAdminServer, remoteAdminServer *http.Server\n\tidentityCertCache                   *certmagic.Cache\n)\n",
    "source_file": "admin.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"log/slog\"\n\t\"reflect\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/collectors\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/exp/zapslog\"\n\n\t\"github.com/caddyserver/caddy/v2/internal/filesystems\"\n)\n\n// Context is a type which defines the lifetime of modules that\n// are loaded and provides access to the parent configuration\n// that spawned the modules which are loaded. It should be used\n// with care and wrapped with derivation functions from the\n// standard context package only if you don't need the Caddy\n// specific features. These contexts are canceled when the\n// lifetime of the modules loaded from it is over.\n//\n// Use NewContext() to get a valid value (but most modules will\n// not actually need to do this).\ntype Context struct {\n\tcontext.Context\n\n\tmoduleInstances map[string][]Module\n\tcfg             *Config\n\tancestry        []Module\n\tcleanupFuncs    []func()                // invoked at every config unload\n\texitFuncs       []func(context.Context) // invoked at config unload ONLY IF the process is exiting (EXPERIMENTAL)\n\tmetricsRegistry *prometheus.Registry\n}\n\n// NewContext provides a new context derived from the given\n// context ctx. Normally, you will not need to call this\n// function unless you are loading modules which have a\n// different lifespan than the ones for the context the\n// module was provisioned with. Be sure to call the cancel\n// func when the context is to be cleaned up so that\n// modules which are loaded will be properly unloaded.\n// See standard library context package's documentation.\nfunc NewContext(ctx Context) (Context, context.CancelFunc) {\n\tnewCtx := Context{moduleInstances: make(map[string][]Module), cfg: ctx.cfg, metricsRegistry: prometheus.NewPedanticRegistry()}\n\tc, cancel := context.WithCancel(ctx.Context)\n\twrappedCancel := func() {\n\t\tcancel()\n\n\t\tfor _, f := range ctx.cleanupFuncs {\n\t\t\tf()\n\t\t}\n\n\t\tfor modName, modInstances := range newCtx.moduleInstances {\n\t\t\tfor _, inst := range modInstances {\n\t\t\t\tif cu, ok := inst.(CleanerUpper); ok {\n\t\t\t\t\terr := cu.Cleanup()\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\tlog.Printf(\"[ERROR] %s (%p): cleanup: %v\", modName, inst, err)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tnewCtx.Context = c\n\tnewCtx.initMetrics()\n\treturn newCtx, wrappedCancel\n}\n\n// OnCancel executes f when ctx is canceled.\nfunc (ctx *Context) OnCancel(f func()) {\n\tctx.cleanupFuncs = append(ctx.cleanupFuncs, f)\n}\n\n// FileSystems returns a ref to the FilesystemMap.\n// EXPERIMENTAL: This API is subject to change.\nfunc (ctx *Context) FileSystems() FileSystems {\n\t// if no config is loaded, we use a default filesystemmap, which includes the osfs\n\tif ctx.cfg == nil {\n\t\treturn &filesystems.FileSystemMap{}\n\t}\n\treturn ctx.cfg.fileSystems\n}\n\n// Returns the active metrics registry for the context\n// EXPERIMENTAL: This API is subject to change.\nfunc (ctx *Context) GetMetricsRegistry() *prometheus.Registry {\n\treturn ctx.metricsRegistry\n}\n\nfunc (ctx *Context) initMetrics() {\n\tctx.metricsRegistry.MustRegister(\n\t\tcollectors.NewBuildInfoCollector(),\n\t\tcollectors.NewProcessCollector(collectors.ProcessCollectorOpts{}),\n\t\tcollectors.NewGoCollector(),\n\t\tadminMetrics.requestCount,\n\t\tadminMetrics.requestErrors,\n\t\tglobalMetrics.configSuccess,\n\t\tglobalMetrics.configSuccessTime,\n\t)\n}\n\n// OnExit executes f when the process exits gracefully.\n// The function is only executed if the process is gracefully\n// shut down while this context is active.\n//\n// EXPERIMENTAL API: subject to change or removal.\nfunc (ctx *Context) OnExit(f func(context.Context)) {\n\tctx.exitFuncs = append(ctx.exitFuncs, f)\n}\n\n// LoadModule loads the Caddy module(s) from the specified field of the parent struct\n// pointer and returns the loaded module(s). The struct pointer and its field name as\n// a string are necessary so that reflection can be used to read the struct tag on the\n// field to get the module namespace and inline module name key (if specified).\n//\n// The field can be any one of the supported raw module types: json.RawMessage,\n// []json.RawMessage, map[string]json.RawMessage, or []map[string]json.RawMessage.\n// ModuleMap may be used in place of map[string]json.RawMessage. The return value's\n// underlying type mirrors the input field's type:\n//\n//\tjson.RawMessage              => any\n//\t[]json.RawMessage            => []any\n//\t[][]json.RawMessage          => [][]any\n//\tmap[string]json.RawMessage   => map[string]any\n//\t[]map[string]json.RawMessage => []map[string]any\n//\n// The field must have a \"caddy\" struct tag in this format:\n//\n//\tcaddy:\"key1=val1 key2=val2\"\n//\n// To load modules, a \"namespace\" key is required. For example, to load modules\n// in the \"http.handlers\" namespace, you'd put: `namespace=http.handlers` in the\n// Caddy struct tag.\n//\n// The module name must also be available. If the field type is a map or slice of maps,\n// then key is assumed to be the module name if an \"inline_key\" is NOT specified in the\n// caddy struct tag. In this case, the module name does NOT need to be specified in-line\n// with the module itself.\n//\n// If not a map, or if inline_key is non-empty, then the module name must be embedded\n// into the values, which must be objects; then there must be a key in those objects\n// where its associated value is the module name. This is called the \"inline key\",\n// meaning the key containing the module's name that is defined inline with the module\n// itself. You must specify the inline key in a struct tag, along with the namespace:\n//\n//\tcaddy:\"namespace=http.handlers inline_key=handler\"\n//\n// This will look for a key/value pair like `\"handler\": \"...\"` in the json.RawMessage\n// in order to know the module name.\n//\n// To make use of the loaded module(s) (the return value), you will probably want\n// to type-assert each 'any' value(s) to the types that are useful to you\n// and store them on the same struct. Storing them on the same struct makes for\n// easy garbage collection when your host module is no longer needed.\n//\n// Loaded modules have already been provisioned and validated. Upon returning\n// successfully, this method clears the json.RawMessage(s) in the field since\n// the raw JSON is no longer needed, and this allows the GC to free up memory.\nfunc (ctx Context) LoadModule(structPointer any, fieldName string) (any, error) {\n\tval := reflect.ValueOf(structPointer).Elem().FieldByName(fieldName)\n\ttyp := val.Type()\n\n\tfield, ok := reflect.TypeOf(structPointer).Elem().FieldByName(fieldName)\n\tif !ok {\n\t\tpanic(fmt.Sprintf(\"field %s does not exist in %#v\", fieldName, structPointer))\n\t}\n\n\topts, err := ParseStructTag(field.Tag.Get(\"caddy\"))\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"malformed tag on field %s: %v\", fieldName, err))\n\t}\n\n\tmoduleNamespace, ok := opts[\"namespace\"]\n\tif !ok {\n\t\tpanic(fmt.Sprintf(\"missing 'namespace' key in struct tag on field %s\", fieldName))\n\t}\n\tinlineModuleKey := opts[\"inline_key\"]\n\n\tvar result any\n\n\tswitch val.Kind() {\n\tcase reflect.Slice:\n\t\tif isJSONRawMessage(typ) {\n\t\t\t// val is `json.RawMessage` ([]uint8 under the hood)\n\n\t\t\tif inlineModuleKey == \"\" {\n\t\t\t\tpanic(\"unable to determine module name without inline_key when type is not a ModuleMap\")\n\t\t\t}\n\t\t\tval, err := ctx.loadModuleInline(inlineModuleKey, moduleNamespace, val.Interface().(json.RawMessage))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tresult = val\n\t\t} else if isJSONRawMessage(typ.Elem()) {\n\t\t\t// val is `[]json.RawMessage`\n\n\t\t\tif inlineModuleKey == \"\" {\n\t\t\t\tpanic(\"unable to determine module name without inline_key because type is not a ModuleMap\")\n\t\t\t}\n\t\t\tvar all []any\n\t\t\tfor i := 0; i < val.Len(); i++ {\n\t\t\t\tval, err := ctx.loadModuleInline(inlineModuleKey, moduleNamespace, val.Index(i).Interface().(json.RawMessage))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"position %d: %v\", i, err)\n\t\t\t\t}\n\t\t\t\tall = append(all, val)\n\t\t\t}\n\t\t\tresult = all\n\t\t} else if typ.Elem().Kind() == reflect.Slice && isJSONRawMessage(typ.Elem().Elem()) {\n\t\t\t// val is `[][]json.RawMessage`\n\n\t\t\tif inlineModuleKey == \"\" {\n\t\t\t\tpanic(\"unable to determine module name without inline_key because type is not a ModuleMap\")\n\t\t\t}\n\t\t\tvar all [][]any\n\t\t\tfor i := 0; i < val.Len(); i++ {\n\t\t\t\tinnerVal := val.Index(i)\n\t\t\t\tvar allInner []any\n\t\t\t\tfor j := 0; j < innerVal.Len(); j++ {\n\t\t\t\t\tinnerInnerVal, err := ctx.loadModuleInline(inlineModuleKey, moduleNamespace, innerVal.Index(j).Interface().(json.RawMessage))\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"position %d: %v\", j, err)\n\t\t\t\t\t}\n\t\t\t\t\tallInner = append(allInner, innerInnerVal)\n\t\t\t\t}\n\t\t\t\tall = append(all, allInner)\n\t\t\t}\n\t\t\tresult = all\n\t\t} else if isModuleMapType(typ.Elem()) {\n\t\t\t// val is `[]map[string]json.RawMessage`\n\n\t\t\tvar all []map[string]any\n\t\t\tfor i := 0; i < val.Len(); i++ {\n\t\t\t\tthisSet, err := ctx.loadModulesFromSomeMap(moduleNamespace, inlineModuleKey, val.Index(i))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tall = append(all, thisSet)\n\t\t\t}\n\t\t\tresult = all\n\t\t}\n\n\tcase reflect.Map:\n\t\t// val is a ModuleMap or some other kind of map\n\t\tresult, err = ctx.loadModulesFromSomeMap(moduleNamespace, inlineModuleKey, val)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unrecognized type for module: %s\", typ)\n\t}\n\n\t// we're done with the raw bytes; allow GC to deallocate\n\tval.Set(reflect.Zero(typ))\n\n\treturn result, nil\n}\n\n// emitEvent is a small convenience method so the caddy core can emit events, if the event app is configured.\nfunc (ctx Context) emitEvent(name string, data map[string]any) Event {\n\tif ctx.cfg == nil || ctx.cfg.eventEmitter == nil {\n\t\treturn Event{}\n\t}\n\treturn ctx.cfg.eventEmitter.Emit(ctx, name, data)\n}\n\n// loadModulesFromSomeMap loads modules from val, which must be a type of map[string]any.\n// Depending on inlineModuleKey, it will be interpreted as either a ModuleMap (key is the module\n// name) or as a regular map (key is not the module name, and module name is defined inline).\nfunc (ctx Context) loadModulesFromSomeMap(namespace, inlineModuleKey string, val reflect.Value) (map[string]any, error) {\n\t// if no inline_key is specified, then val must be a ModuleMap,\n\t// where the key is the module name\n\tif inlineModuleKey == \"\" {\n\t\tif !isModuleMapType(val.Type()) {\n\t\t\tpanic(fmt.Sprintf(\"expected ModuleMap because inline_key is empty; but we do not recognize this type: %s\", val.Type()))\n\t\t}\n\t\treturn ctx.loadModuleMap(namespace, val)\n\t}\n\n\t// otherwise, val is a map with modules, but the module name is\n\t// inline with each value (the key means something else)\n\treturn ctx.loadModulesFromRegularMap(namespace, inlineModuleKey, val)\n}\n\n// loadModulesFromRegularMap loads modules from val, where val is a map[string]json.RawMessage.\n// Map keys are NOT interpreted as module names, so module names are still expected to appear\n// inline with the objects.\nfunc (ctx Context) loadModulesFromRegularMap(namespace, inlineModuleKey string, val reflect.Value) (map[string]any, error) {\n\tmods := make(map[string]any)\n\titer := val.MapRange()\n\tfor iter.Next() {\n\t\tk := iter.Key()\n\t\tv := iter.Value()\n\t\tmod, err := ctx.loadModuleInline(inlineModuleKey, namespace, v.Interface().(json.RawMessage))\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"key %s: %v\", k, err)\n\t\t}\n\t\tmods[k.String()] = mod\n\t}\n\treturn mods, nil\n}\n\n// loadModuleMap loads modules from a ModuleMap, i.e. map[string]any, where the key is the\n// module name. With a module map, module names do not need to be defined inline with their values.\nfunc (ctx Context) loadModuleMap(namespace string, val reflect.Value) (map[string]any, error) {\n\tall := make(map[string]any)\n\titer := val.MapRange()\n\tfor iter.Next() {\n\t\tk := iter.Key().Interface().(string)\n\t\tv := iter.Value().Interface().(json.RawMessage)\n\t\tmoduleName := namespace + \".\" + k\n\t\tif namespace == \"\" {\n\t\t\tmoduleName = k\n\t\t}\n\t\tval, err := ctx.LoadModuleByID(moduleName, v)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"module name '%s': %v\", k, err)\n\t\t}\n\t\tall[k] = val\n\t}\n\treturn all, nil\n}\n\n// LoadModuleByID decodes rawMsg into a new instance of mod and\n// returns the value. If mod.New is nil, an error is returned.\n// If the module implements Validator or Provisioner interfaces,\n// those methods are invoked to ensure the module is fully\n// configured and valid before being used.\n//\n// This is a lower-level method and will usually not be called\n// directly by most modules. However, this method is useful when\n// dynamically loading/unloading modules in their own context,\n// like from embedded scripts, etc.\nfunc (ctx Context) LoadModuleByID(id string, rawMsg json.RawMessage) (any, error) {\n\tmodulesMu.RLock()\n\tmodInfo, ok := modules[id]\n\tmodulesMu.RUnlock()\n\tif !ok {\n\t\treturn nil, fmt.Errorf(\"unknown module: %s\", id)\n\t}\n\n\tif modInfo.New == nil {\n\t\treturn nil, fmt.Errorf(\"module '%s' has no constructor\", modInfo.ID)\n\t}\n\n\tval := modInfo.New()\n\n\t// value must be a pointer for unmarshaling into concrete type, even if\n\t// the module's concrete type is a slice or map; New() *should* return\n\t// a pointer, otherwise unmarshaling errors or panics will occur\n\tif rv := reflect.ValueOf(val); rv.Kind() != reflect.Ptr {\n\t\tlog.Printf(\"[WARNING] ModuleInfo.New() for module '%s' did not return a pointer,\"+\n\t\t\t\" so we are using reflection to make a pointer instead; please fix this by\"+\n\t\t\t\" using new(Type) or &Type notation in your module's New() function.\", id)\n\t\tval = reflect.New(rv.Type()).Elem().Addr().Interface().(Module)\n\t}\n\n\t// fill in its config only if there is a config to fill in\n\tif len(rawMsg) > 0 {\n\t\terr := StrictUnmarshalJSON(rawMsg, &val)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"decoding module config: %s: %v\", modInfo, err)\n\t\t}\n\t}\n\n\tif val == nil {\n\t\t// returned module values are almost always type-asserted\n\t\t// before being used, so a nil value would panic; and there\n\t\t// is no good reason to explicitly declare null modules in\n\t\t// a config; it might be because the user is trying to achieve\n\t\t// a result the developer isn't expecting, which is a smell\n\t\treturn nil, fmt.Errorf(\"module value cannot be null\")\n\t}\n\n\t// if this is an app module, keep a reference to it,\n\t// since submodules may need to reference it during\n\t// provisioning (even though the parent app module\n\t// may not be fully provisioned yet; this is the case\n\t// with the tls app's automation policies, which may\n\t// refer to the tls app to check if a global DNS\n\t// module has been configured for DNS challenges)\n\tif appModule, ok := val.(App); ok {\n\t\tctx.cfg.apps[id] = appModule\n\t}\n\n\tctx.ancestry = append(ctx.ancestry, val)\n\n\tif prov, ok := val.(Provisioner); ok {\n\t\terr := prov.Provision(ctx)\n\t\tif err != nil {\n\t\t\t// incomplete provisioning could have left state\n\t\t\t// dangling, so make sure it gets cleaned up\n\t\t\tif cleanerUpper, ok := val.(CleanerUpper); ok {\n\t\t\t\terr2 := cleanerUpper.Cleanup()\n\t\t\t\tif err2 != nil {\n\t\t\t\t\terr = fmt.Errorf(\"%v; additionally, cleanup: %v\", err, err2)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"provision %s: %v\", modInfo, err)\n\t\t}\n\t}\n\n\tif validator, ok := val.(Validator); ok {\n\t\terr := validator.Validate()\n\t\tif err != nil {\n\t\t\t// since the module was already provisioned, make sure we clean up\n\t\t\tif cleanerUpper, ok := val.(CleanerUpper); ok {\n\t\t\t\terr2 := cleanerUpper.Cleanup()\n\t\t\t\tif err2 != nil {\n\t\t\t\t\terr = fmt.Errorf(\"%v; additionally, cleanup: %v\", err, err2)\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn nil, fmt.Errorf(\"%s: invalid configuration: %v\", modInfo, err)\n\t\t}\n\t}\n\n\tctx.moduleInstances[id] = append(ctx.moduleInstances[id], val)\n\n\t// if the loaded module happens to be an app that can emit events, store it so the\n\t// core can have access to emit events without an import cycle\n\tif ee, ok := val.(eventEmitter); ok {\n\t\tif _, ok := ee.(App); ok {\n\t\t\tctx.cfg.eventEmitter = ee\n\t\t}\n\t}\n\n\treturn val, nil\n}\n\n// loadModuleInline loads a module from a JSON raw message which decodes to\n// a map[string]any, where one of the object keys is moduleNameKey\n// and the corresponding value is the module name (as a string) which can\n// be found in the given scope. In other words, the module name is declared\n// in-line with the module itself.\n//\n// This allows modules to be decoded into their concrete types and used when\n// their names cannot be the unique key in a map, such as when there are\n// multiple instances in the map or it appears in an array (where there are\n// no custom keys). In other words, the key containing the module name is\n// treated special/separate from all the other keys in the object.\nfunc (ctx Context) loadModuleInline(moduleNameKey, moduleScope string, raw json.RawMessage) (any, error) {\n\tmoduleName, raw, err := getModuleNameInline(moduleNameKey, raw)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tval, err := ctx.LoadModuleByID(moduleScope+\".\"+moduleName, raw)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"loading module '%s': %v\", moduleName, err)\n\t}\n\n\treturn val, nil\n}\n\n// App returns the configured app named name. If that app has\n// not yet been loaded and provisioned, it will be immediately\n// loaded and provisioned. If no app with that name is\n// configured, a new empty one will be instantiated instead.\n// (The app module must still be registered.) This must not be\n// called during the Provision/Validate phase to reference a\n// module's own host app (since the parent app module is still\n// in the process of being provisioned, it is not yet ready).\n//\n// We return any type instead of the App type because it is NOT\n// intended for the caller of this method to be the one to start\n// or stop App modules. The caller is expected to assert to the\n// concrete type.\nfunc (ctx Context) App(name string) (any, error) {\n\tif app, ok := ctx.cfg.apps[name]; ok {\n\t\treturn app, nil\n\t}\n\tappRaw := ctx.cfg.AppsRaw[name]\n\tmodVal, err := ctx.LoadModuleByID(name, appRaw)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"loading %s app module: %v\", name, err)\n\t}\n\tif appRaw != nil {\n\t\tctx.cfg.AppsRaw[name] = nil // allow GC to deallocate\n\t}\n\treturn modVal, nil\n}\n\n// AppIfConfigured is like App, but it returns an error if the\n// app has not been configured. This is useful when the app is\n// required and its absence is a configuration error; or when\n// the app is optional and you don't want to instantiate a\n// new one that hasn't been explicitly configured. If the app\n// is not in the configuration, the error wraps ErrNotConfigured.\nfunc (ctx Context) AppIfConfigured(name string) (any, error) {\n\tif ctx.cfg == nil {\n\t\treturn nil, fmt.Errorf(\"app module %s: %w\", name, ErrNotConfigured)\n\t}\n\tif app, ok := ctx.cfg.apps[name]; ok {\n\t\treturn app, nil\n\t}\n\tappRaw := ctx.cfg.AppsRaw[name]\n\tif appRaw == nil {\n\t\treturn nil, fmt.Errorf(\"app module %s: %w\", name, ErrNotConfigured)\n\t}\n\treturn ctx.App(name)\n}\n\n// ErrNotConfigured indicates a module is not configured.\nvar ErrNotConfigured = fmt.Errorf(\"module not configured\")\n\n// Storage returns the configured Caddy storage implementation.\nfunc (ctx Context) Storage() certmagic.Storage {\n\treturn ctx.cfg.storage\n}\n\n// Logger returns a logger that is intended for use by the most\n// recent module associated with the context. Callers should not\n// pass in any arguments unless they want to associate with a\n// different module; it panics if more than 1 value is passed in.\n//\n// Originally, this method's signature was `Logger(mod Module)`,\n// requiring that an instance of a Caddy module be passed in.\n// However, that is no longer necessary, as the closest module\n// most recently associated with the context will be automatically\n// assumed. To prevent a sudden breaking change, this method's\n// signature has been changed to be variadic, but we may remove\n// the parameter altogether in the future. Callers should not\n// pass in any argument. If there is valid need to specify a\n// different module, please open an issue to discuss.\n//\n// PARTIALLY DEPRECATED: The Logger(module) form is deprecated and\n// may be removed in the future. Do not pass in any arguments.\nfunc (ctx Context) Logger(module ...Module) *zap.Logger {\n\tif len(module) > 1 {\n\t\tpanic(\"more than 1 module passed in\")\n\t}\n\tif ctx.cfg == nil {\n\t\t// often the case in tests; just use a dev logger\n\t\tl, err := zap.NewDevelopment()\n\t\tif err != nil {\n\t\t\tpanic(\"config missing, unable to create dev logger: \" + err.Error())\n\t\t}\n\t\treturn l\n\t}\n\tmod := ctx.Module()\n\tif len(module) > 0 {\n\t\tmod = module[0]\n\t}\n\tif mod == nil {\n\t\treturn Log()\n\t}\n\treturn ctx.cfg.Logging.Logger(mod)\n}\n\n// Slogger returns a slog logger that is intended for use by\n// the most recent module associated with the context.\nfunc (ctx Context) Slogger() *slog.Logger {\n\tif ctx.cfg == nil {\n\t\t// often the case in tests; just use a dev logger\n\t\tl, err := zap.NewDevelopment()\n\t\tif err != nil {\n\t\t\tpanic(\"config missing, unable to create dev logger: \" + err.Error())\n\t\t}\n\t\treturn slog.New(zapslog.NewHandler(l.Core()))\n\t}\n\tmod := ctx.Module()\n\tif mod == nil {\n\t\treturn slog.New(zapslog.NewHandler(Log().Core()))\n\t}\n\treturn slog.New(zapslog.NewHandler(ctx.cfg.Logging.Logger(mod).Core(),\n\t\tzapslog.WithName(string(mod.CaddyModule().ID)),\n\t))\n}\n\n// Modules returns the lineage of modules that this context provisioned,\n// with the most recent/current module being last in the list.\nfunc (ctx Context) Modules() []Module {\n\tmods := make([]Module, len(ctx.ancestry))\n\tcopy(mods, ctx.ancestry)\n\treturn mods\n}\n\n// Module returns the current module, or the most recent one\n// provisioned by the context.\nfunc (ctx Context) Module() Module {\n\tif len(ctx.ancestry) == 0 {\n\t\treturn nil\n\t}\n\treturn ctx.ancestry[len(ctx.ancestry)-1]\n}\n\n// WithValue returns a new context with the given key-value pair.\nfunc (ctx *Context) WithValue(key, value any) Context {\n\treturn Context{\n\t\tContext:         context.WithValue(ctx.Context, key, value),\n\t\tmoduleInstances: ctx.moduleInstances,\n\t\tcfg:             ctx.cfg,\n\t\tancestry:        ctx.ancestry,\n\t\tcleanupFuncs:    ctx.cleanupFuncs,\n\t\texitFuncs:       ctx.exitFuncs,\n\t}\n}\n\n// eventEmitter is a small interface that inverts dependencies for\n// the caddyevents package, so the core can emit events without an\n// import cycle (i.e. the caddy package doesn't have to import\n// the caddyevents package, which imports the caddy package).\ntype eventEmitter interface {\n\tEmit(ctx Context, eventName string, data map[string]any) Event\n}\n",
    "source_file": "context.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Even though the filename ends in _unix.go, we still have to specify the\n// build constraint here, because the filename convention only works for\n// literal GOOS values, and \"unix\" is a shortcut unique to build tags.\n//go:build unix && !solaris\n\npackage caddy\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"net\"\n\t\"os\"\n\t\"slices\"\n\t\"strconv\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"syscall\"\n\n\t\"go.uber.org/zap\"\n\t\"golang.org/x/sys/unix\"\n)\n\n// reuseUnixSocket copies and reuses the unix domain socket (UDS) if we already\n// have it open; if not, unlink it so we can have it.\n// No-op if not a unix network.\nfunc reuseUnixSocket(network, addr string) (any, error) {\n\tsocketKey := listenerKey(network, addr)\n\n\tsocket, exists := unixSockets[socketKey]\n\tif exists {\n\t\t// make copy of file descriptor\n\t\tsocketFile, err := socket.File() // does dup() deep down\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// use copied fd to make new Listener or PacketConn, then replace\n\t\t// it in the map so that future copies always come from the most\n\t\t// recent fd (as the previous ones will be closed, and we'd get\n\t\t// \"use of closed network connection\" errors) -- note that we\n\t\t// preserve the *pointer* to the counter (not just the value) so\n\t\t// that all socket wrappers will refer to the same value\n\t\tswitch unixSocket := socket.(type) {\n\t\tcase *unixListener:\n\t\t\tln, err := net.FileListener(socketFile)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tatomic.AddInt32(unixSocket.count, 1)\n\t\t\tunixSockets[socketKey] = &unixListener{ln.(*net.UnixListener), socketKey, unixSocket.count}\n\n\t\tcase *unixConn:\n\t\t\tpc, err := net.FilePacketConn(socketFile)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tatomic.AddInt32(unixSocket.count, 1)\n\t\t\tunixSockets[socketKey] = &unixConn{pc.(*net.UnixConn), socketKey, unixSocket.count}\n\t\t}\n\n\t\treturn unixSockets[socketKey], nil\n\t}\n\n\t// from what I can tell after some quick research, it's quite common for programs to\n\t// leave their socket file behind after they close, so the typical pattern is to\n\t// unlink it before you bind to it -- this is often crucial if the last program using\n\t// it was killed forcefully without a chance to clean up the socket, but there is a\n\t// race, as the comment in net.UnixListener.close() explains... oh well, I guess?\n\tif err := syscall.Unlink(addr); err != nil && !errors.Is(err, fs.ErrNotExist) {\n\t\treturn nil, err\n\t}\n\n\treturn nil, nil\n}\n\n// listenReusable creates a new listener for the given network and address, and adds it to listenerPool.\nfunc listenReusable(ctx context.Context, lnKey string, network, address string, config net.ListenConfig) (any, error) {\n\t// even though SO_REUSEPORT lets us bind the socket multiple times,\n\t// we still put it in the listenerPool so we can count how many\n\t// configs are using this socket; necessary to ensure we can know\n\t// whether to enforce shutdown delays, for example (see #5393).\n\tvar (\n\t\tln         io.Closer\n\t\terr        error\n\t\tsocketFile *os.File\n\t)\n\n\tfd := slices.Contains([]string{\"fd\", \"fdgram\"}, network)\n\tif fd {\n\t\tsocketFd, err := strconv.ParseUint(address, 0, strconv.IntSize)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid file descriptor: %v\", err)\n\t\t}\n\n\t\tfunc() {\n\t\t\tsocketFilesMu.Lock()\n\t\t\tdefer socketFilesMu.Unlock()\n\n\t\t\tsocketFdWide := uintptr(socketFd)\n\t\t\tvar ok bool\n\n\t\t\tsocketFile, ok = socketFiles[socketFdWide]\n\n\t\t\tif !ok {\n\t\t\t\tsocketFile = os.NewFile(socketFdWide, lnKey)\n\t\t\t\tif socketFile != nil {\n\t\t\t\t\tsocketFiles[socketFdWide] = socketFile\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\tif socketFile == nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid socket file descriptor: %d\", socketFd)\n\t\t}\n\t} else {\n\t\t// wrap any Control function set by the user so we can also add our reusePort control without clobbering theirs\n\t\toldControl := config.Control\n\t\tconfig.Control = func(network, address string, c syscall.RawConn) error {\n\t\t\tif oldControl != nil {\n\t\t\t\tif err := oldControl(network, address, c); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn reusePort(network, address, c)\n\t\t}\n\t}\n\n\tdatagram := slices.Contains([]string{\"udp\", \"udp4\", \"udp6\", \"unixgram\", \"fdgram\"}, network)\n\tif datagram {\n\t\tif fd {\n\t\t\tln, err = net.FilePacketConn(socketFile)\n\t\t} else {\n\t\t\tln, err = config.ListenPacket(ctx, network, address)\n\t\t}\n\t} else {\n\t\tif fd {\n\t\t\tln, err = net.FileListener(socketFile)\n\t\t} else {\n\t\t\tln, err = config.Listen(ctx, network, address)\n\t\t}\n\t}\n\n\tif err == nil {\n\t\tlistenerPool.LoadOrStore(lnKey, nil)\n\t}\n\n\tif datagram {\n\t\tif !fd {\n\t\t\t// TODO: Not 100% sure this is necessary, but we do this for net.UnixListener, so...\n\t\t\tif unix, ok := ln.(*net.UnixConn); ok {\n\t\t\t\tone := int32(1)\n\t\t\t\tln = &unixConn{unix, lnKey, &one}\n\t\t\t\tunixSockets[lnKey] = ln.(*unixConn)\n\t\t\t}\n\t\t}\n\t\t// lightly wrap the connection so that when it is closed,\n\t\t// we can decrement the usage pool counter\n\t\tif specificLn, ok := ln.(net.PacketConn); ok {\n\t\t\tln = deletePacketConn{specificLn, lnKey}\n\t\t}\n\t} else {\n\t\tif !fd {\n\t\t\t// if new listener is a unix socket, make sure we can reuse it later\n\t\t\t// (we do our own \"unlink on close\" -- not required, but more tidy)\n\t\t\tif unix, ok := ln.(*net.UnixListener); ok {\n\t\t\t\tunix.SetUnlinkOnClose(false)\n\t\t\t\tone := int32(1)\n\t\t\t\tln = &unixListener{unix, lnKey, &one}\n\t\t\t\tunixSockets[lnKey] = ln.(*unixListener)\n\t\t\t}\n\t\t}\n\t\t// lightly wrap the listener so that when it is closed,\n\t\t// we can decrement the usage pool counter\n\t\tif specificLn, ok := ln.(net.Listener); ok {\n\t\t\tln = deleteListener{specificLn, lnKey}\n\t\t}\n\t}\n\n\t// other types, I guess we just return them directly\n\treturn ln, err\n}\n\n// reusePort sets SO_REUSEPORT. Ineffective for unix sockets.\nfunc reusePort(network, address string, conn syscall.RawConn) error {\n\tif IsUnixNetwork(network) {\n\t\treturn nil\n\t}\n\treturn conn.Control(func(descriptor uintptr) {\n\t\tif err := unix.SetsockoptInt(int(descriptor), unix.SOL_SOCKET, unixSOREUSEPORT, 1); err != nil {\n\t\t\tLog().Error(\"setting SO_REUSEPORT\",\n\t\t\t\tzap.String(\"network\", network),\n\t\t\t\tzap.String(\"address\", address),\n\t\t\t\tzap.Uintptr(\"descriptor\", descriptor),\n\t\t\t\tzap.Error(err))\n\t\t}\n\t})\n}\n\ntype unixListener struct {\n\t*net.UnixListener\n\tmapKey string\n\tcount  *int32 // accessed atomically\n}\n\nfunc (uln *unixListener) Close() error {\n\tnewCount := atomic.AddInt32(uln.count, -1)\n\tif newCount == 0 {\n\t\tfile, err := uln.File()\n\t\tvar name string\n\t\tif err == nil {\n\t\t\tname = file.Name()\n\t\t}\n\t\tdefer func() {\n\t\t\tunixSocketsMu.Lock()\n\t\t\tdelete(unixSockets, uln.mapKey)\n\t\t\tunixSocketsMu.Unlock()\n\t\t\tif err == nil {\n\t\t\t\t_ = syscall.Unlink(name)\n\t\t\t}\n\t\t}()\n\t}\n\treturn uln.UnixListener.Close()\n}\n\ntype unixConn struct {\n\t*net.UnixConn\n\tmapKey string\n\tcount  *int32 // accessed atomically\n}\n\nfunc (uc *unixConn) Close() error {\n\tnewCount := atomic.AddInt32(uc.count, -1)\n\tif newCount == 0 {\n\t\tfile, err := uc.File()\n\t\tvar name string\n\t\tif err == nil {\n\t\t\tname = file.Name()\n\t\t}\n\t\tdefer func() {\n\t\t\tunixSocketsMu.Lock()\n\t\t\tdelete(unixSockets, uc.mapKey)\n\t\t\tunixSocketsMu.Unlock()\n\t\t\tif err == nil {\n\t\t\t\t_ = syscall.Unlink(name)\n\t\t\t}\n\t\t}()\n\t}\n\treturn uc.UnixConn.Close()\n}\n\nfunc (uc *unixConn) Unwrap() net.PacketConn {\n\treturn uc.UnixConn\n}\n\n// unixSockets keeps track of the currently-active unix sockets\n// so we can transfer their FDs gracefully during reloads.\nvar unixSockets = make(map[string]interface {\n\tFile() (*os.File, error)\n})\n\n// socketFiles is a fd -> *os.File map used to make a FileListener/FilePacketConn from a socket file descriptor.\nvar socketFiles = map[uintptr]*os.File{}\n\n// socketFilesMu synchronizes socketFiles insertions\nvar socketFilesMu sync.Mutex\n\n// deleteListener is a type that simply deletes itself\n// from the listenerPool when it closes. It is used\n// solely for the purpose of reference counting (i.e.\n// counting how many configs are using a given socket).\ntype deleteListener struct {\n\tnet.Listener\n\tlnKey string\n}\n\nfunc (dl deleteListener) Close() error {\n\t_, _ = listenerPool.Delete(dl.lnKey)\n\treturn dl.Listener.Close()\n}\n\n// deletePacketConn is like deleteListener, but\n// for net.PacketConns.\ntype deletePacketConn struct {\n\tnet.PacketConn\n\tlnKey string\n}\n\nfunc (dl deletePacketConn) Close() error {\n\t_, _ = listenerPool.Delete(dl.lnKey)\n\treturn dl.PacketConn.Close()\n}\n\nfunc (dl deletePacketConn) Unwrap() net.PacketConn {\n\treturn dl.PacketConn\n}\n",
    "source_file": "listen_unix.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n)\n\n// NewReplacer returns a new Replacer.\nfunc NewReplacer() *Replacer {\n\trep := &Replacer{\n\t\tstatic:   make(map[string]any),\n\t\tmapMutex: &sync.RWMutex{},\n\t}\n\trep.providers = []replacementProvider{\n\t\tglobalDefaultReplacementProvider{},\n\t\tfileReplacementProvider{},\n\t\tReplacerFunc(rep.fromStatic),\n\t}\n\treturn rep\n}\n\n// NewEmptyReplacer returns a new Replacer,\n// without the global default replacements.\nfunc NewEmptyReplacer() *Replacer {\n\trep := &Replacer{\n\t\tstatic:   make(map[string]any),\n\t\tmapMutex: &sync.RWMutex{},\n\t}\n\trep.providers = []replacementProvider{\n\t\tReplacerFunc(rep.fromStatic),\n\t}\n\treturn rep\n}\n\n// Replacer can replace values in strings.\n// A default/empty Replacer is not valid;\n// use NewReplacer to make one.\ntype Replacer struct {\n\tproviders []replacementProvider\n\tstatic    map[string]any\n\tmapMutex  *sync.RWMutex\n}\n\n// WithoutFile returns a copy of the current Replacer\n// without support for the {file.*} placeholder, which\n// may be unsafe in some contexts.\n//\n// EXPERIMENTAL: Subject to change or removal.\nfunc (r *Replacer) WithoutFile() *Replacer {\n\trep := &Replacer{static: r.static}\n\tfor _, v := range r.providers {\n\t\tif _, ok := v.(fileReplacementProvider); ok {\n\t\t\tcontinue\n\t\t}\n\t\trep.providers = append(rep.providers, v)\n\t}\n\treturn rep\n}\n\n// Map adds mapFunc to the list of value providers.\n// mapFunc will be executed only at replace-time.\nfunc (r *Replacer) Map(mapFunc ReplacerFunc) {\n\tr.providers = append(r.providers, mapFunc)\n}\n\n// Set sets a custom variable to a static value.\nfunc (r *Replacer) Set(variable string, value any) {\n\tr.mapMutex.Lock()\n\tr.static[variable] = value\n\tr.mapMutex.Unlock()\n}\n\n// Get gets a value from the replacer. It returns\n// the value and whether the variable was known.\nfunc (r *Replacer) Get(variable string) (any, bool) {\n\tfor _, mapFunc := range r.providers {\n\t\tif val, ok := mapFunc.replace(variable); ok {\n\t\t\treturn val, true\n\t\t}\n\t}\n\treturn nil, false\n}\n\n// GetString is the same as Get, but coerces the value to a\n// string representation as efficiently as possible.\nfunc (r *Replacer) GetString(variable string) (string, bool) {\n\ts, found := r.Get(variable)\n\treturn ToString(s), found\n}\n\n// Delete removes a variable with a static value\n// that was created using Set.\nfunc (r *Replacer) Delete(variable string) {\n\tr.mapMutex.Lock()\n\tdelete(r.static, variable)\n\tr.mapMutex.Unlock()\n}\n\n// fromStatic provides values from r.static.\nfunc (r *Replacer) fromStatic(key string) (any, bool) {\n\tr.mapMutex.RLock()\n\tdefer r.mapMutex.RUnlock()\n\tval, ok := r.static[key]\n\treturn val, ok\n}\n\n// ReplaceOrErr is like ReplaceAll, but any placeholders\n// that are empty or not recognized will cause an error to\n// be returned.\nfunc (r *Replacer) ReplaceOrErr(input string, errOnEmpty, errOnUnknown bool) (string, error) {\n\treturn r.replace(input, \"\", false, errOnEmpty, errOnUnknown, nil)\n}\n\n// ReplaceKnown is like ReplaceAll but only replaces\n// placeholders that are known (recognized). Unrecognized\n// placeholders will remain in the output.\nfunc (r *Replacer) ReplaceKnown(input, empty string) string {\n\tout, _ := r.replace(input, empty, false, false, false, nil)\n\treturn out\n}\n\n// ReplaceAll efficiently replaces placeholders in input with\n// their values. All placeholders are replaced in the output\n// whether they are recognized or not. Values that are empty\n// string will be substituted with empty.\nfunc (r *Replacer) ReplaceAll(input, empty string) string {\n\tout, _ := r.replace(input, empty, true, false, false, nil)\n\treturn out\n}\n\n// ReplaceFunc is the same as ReplaceAll, but calls f for every\n// replacement to be made, in case f wants to change or inspect\n// the replacement.\nfunc (r *Replacer) ReplaceFunc(input string, f ReplacementFunc) (string, error) {\n\treturn r.replace(input, \"\", true, false, false, f)\n}\n\nfunc (r *Replacer) replace(input, empty string,\n\ttreatUnknownAsEmpty, errOnEmpty, errOnUnknown bool,\n\tf ReplacementFunc,\n) (string, error) {\n\tif !strings.Contains(input, string(phOpen)) && !strings.Contains(input, string(phClose)) {\n\t\treturn input, nil\n\t}\n\n\tvar sb strings.Builder\n\n\t// it is reasonable to assume that the output\n\t// will be approximately as long as the input\n\tsb.Grow(len(input))\n\n\t// iterate the input to find each placeholder\n\tvar lastWriteCursor int\n\n\t// fail fast if too many placeholders are unclosed\n\tvar unclosedCount int\n\nscan:\n\tfor i := 0; i < len(input); i++ {\n\t\t// check for escaped braces\n\t\tif i > 0 && input[i-1] == phEscape && (input[i] == phClose || input[i] == phOpen) {\n\t\t\tsb.WriteString(input[lastWriteCursor : i-1])\n\t\t\tlastWriteCursor = i\n\t\t\tcontinue\n\t\t}\n\n\t\tif input[i] != phOpen {\n\t\t\tcontinue\n\t\t}\n\n\t\t// our iterator is now on an unescaped open brace (start of placeholder)\n\n\t\t// too many unclosed placeholders in absolutely ridiculous input can be extremely slow (issue #4170)\n\t\tif unclosedCount > 100 {\n\t\t\treturn \"\", fmt.Errorf(\"too many unclosed placeholders\")\n\t\t}\n\n\t\t// find the end of the placeholder\n\t\tend := strings.Index(input[i:], string(phClose)) + i\n\t\tif end < i {\n\t\t\tunclosedCount++\n\t\t\tcontinue\n\t\t}\n\n\t\t// if necessary look for the first closing brace that is not escaped\n\t\tfor end > 0 && end < len(input)-1 && input[end-1] == phEscape {\n\t\t\tnextEnd := strings.Index(input[end+1:], string(phClose))\n\t\t\tif nextEnd < 0 {\n\t\t\t\tunclosedCount++\n\t\t\t\tcontinue scan\n\t\t\t}\n\t\t\tend += nextEnd + 1\n\t\t}\n\n\t\t// write the substring from the last cursor to this point\n\t\tsb.WriteString(input[lastWriteCursor:i])\n\n\t\t// trim opening bracket\n\t\tkey := input[i+1 : end]\n\n\t\t// try to get a value for this key, handle empty values accordingly\n\t\tval, found := r.Get(key)\n\t\tif !found {\n\t\t\t// placeholder is unknown (unrecognized); handle accordingly\n\t\t\tif errOnUnknown {\n\t\t\t\treturn \"\", fmt.Errorf(\"unrecognized placeholder %s%s%s\",\n\t\t\t\t\tstring(phOpen), key, string(phClose))\n\t\t\t} else if !treatUnknownAsEmpty {\n\t\t\t\t// if treatUnknownAsEmpty is true, we'll handle an empty\n\t\t\t\t// val later; so only continue otherwise\n\t\t\t\tlastWriteCursor = i\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// apply any transformations\n\t\tif f != nil {\n\t\t\tvar err error\n\t\t\tval, err = f(key, val)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", err\n\t\t\t}\n\t\t}\n\n\t\t// convert val to a string as efficiently as possible\n\t\tvalStr := ToString(val)\n\n\t\t// write the value; if it's empty, either return\n\t\t// an error or write a default value\n\t\tif valStr == \"\" {\n\t\t\tif errOnEmpty {\n\t\t\t\treturn \"\", fmt.Errorf(\"evaluated placeholder %s%s%s is empty\",\n\t\t\t\t\tstring(phOpen), key, string(phClose))\n\t\t\t} else if empty != \"\" {\n\t\t\t\tsb.WriteString(empty)\n\t\t\t}\n\t\t} else {\n\t\t\tsb.WriteString(valStr)\n\t\t}\n\n\t\t// advance cursor to end of placeholder\n\t\ti = end\n\t\tlastWriteCursor = i + 1\n\t}\n\n\t// flush any unwritten remainder\n\tsb.WriteString(input[lastWriteCursor:])\n\n\treturn sb.String(), nil\n}\n\n// ToString returns val as a string, as efficiently as possible.\n// EXPERIMENTAL: may be changed or removed later.\nfunc ToString(val any) string {\n\tswitch v := val.(type) {\n\tcase nil:\n\t\treturn \"\"\n\tcase string:\n\t\treturn v\n\tcase fmt.Stringer:\n\t\treturn v.String()\n\tcase error:\n\t\treturn v.Error()\n\tcase byte:\n\t\treturn string(v)\n\tcase []byte:\n\t\treturn string(v)\n\tcase []rune:\n\t\treturn string(v)\n\tcase int:\n\t\treturn strconv.Itoa(v)\n\tcase int32:\n\t\treturn strconv.Itoa(int(v))\n\tcase int64:\n\t\treturn strconv.Itoa(int(v))\n\tcase uint:\n\t\treturn strconv.FormatUint(uint64(v), 10)\n\tcase uint32:\n\t\treturn strconv.FormatUint(uint64(v), 10)\n\tcase uint64:\n\t\treturn strconv.FormatUint(v, 10)\n\tcase float32:\n\t\treturn strconv.FormatFloat(float64(v), 'f', -1, 32)\n\tcase float64:\n\t\treturn strconv.FormatFloat(v, 'f', -1, 64)\n\tcase bool:\n\t\tif v {\n\t\t\treturn \"true\"\n\t\t}\n\t\treturn \"false\"\n\tdefault:\n\t\treturn fmt.Sprintf(\"%+v\", v)\n\t}\n}\n\n// ReplacerFunc is a function that returns a replacement for the\n// given key along with true if the function is able to service\n// that key (even if the value is blank). If the function does\n// not recognize the key, false should be returned.\ntype ReplacerFunc func(key string) (any, bool)\n\nfunc (f ReplacerFunc) replace(key string) (any, bool) {\n\treturn f(key)\n}\n\n// replacementProvider is a type that can provide replacements\n// for placeholders. Allows for type assertion to determine\n// which type of provider it is.\ntype replacementProvider interface {\n\treplace(key string) (any, bool)\n}\n\n// fileReplacementsProvider handles {file.*} replacements,\n// reading a file from disk and replacing with its contents.\ntype fileReplacementProvider struct{}\n\nfunc (f fileReplacementProvider) replace(key string) (any, bool) {\n\tif !strings.HasPrefix(key, filePrefix) {\n\t\treturn nil, false\n\t}\n\n\tfilename := key[len(filePrefix):]\n\tmaxSize := 1024 * 1024\n\tbody, err := readFileIntoBuffer(filename, maxSize)\n\tif err != nil {\n\t\twd, _ := os.Getwd()\n\t\tLog().Error(\"placeholder: failed to read file\",\n\t\t\tzap.String(\"file\", filename),\n\t\t\tzap.String(\"working_dir\", wd),\n\t\t\tzap.Error(err))\n\t\treturn nil, true\n\t}\n\tbody = bytes.TrimSuffix(body, []byte(\"\\n\"))\n\tbody = bytes.TrimSuffix(body, []byte(\"\\r\"))\n\treturn string(body), true\n}\n\n// globalDefaultReplacementsProvider handles replacements\n// that can be used in any context, such as system variables,\n// time, or environment variables.\ntype globalDefaultReplacementProvider struct{}\n\nfunc (f globalDefaultReplacementProvider) replace(key string) (any, bool) {\n\t// check environment variable\n\tconst envPrefix = \"env.\"\n\tif strings.HasPrefix(key, envPrefix) {\n\t\treturn os.Getenv(key[len(envPrefix):]), true\n\t}\n\n\tswitch key {\n\tcase \"system.hostname\":\n\t\t// OK if there is an error; just return empty string\n\t\tname, _ := os.Hostname()\n\t\treturn name, true\n\tcase \"system.slash\":\n\t\treturn string(filepath.Separator), true\n\tcase \"system.os\":\n\t\treturn runtime.GOOS, true\n\tcase \"system.wd\":\n\t\t// OK if there is an error; just return empty string\n\t\twd, _ := os.Getwd()\n\t\treturn wd, true\n\tcase \"system.arch\":\n\t\treturn runtime.GOARCH, true\n\tcase \"time.now\":\n\t\treturn nowFunc(), true\n\tcase \"time.now.http\":\n\t\t// According to the comment for http.TimeFormat, the timezone must be in UTC\n\t\t// to generate the correct format.\n\t\t// https://github.com/caddyserver/caddy/issues/5773\n\t\treturn nowFunc().UTC().Format(http.TimeFormat), true\n\tcase \"time.now.common_log\":\n\t\treturn nowFunc().Format(\"02/Jan/2006:15:04:05 -0700\"), true\n\tcase \"time.now.year\":\n\t\treturn strconv.Itoa(nowFunc().Year()), true\n\tcase \"time.now.unix\":\n\t\treturn strconv.FormatInt(nowFunc().Unix(), 10), true\n\tcase \"time.now.unix_ms\":\n\t\treturn strconv.FormatInt(nowFunc().UnixNano()/int64(time.Millisecond), 10), true\n\t}\n\n\treturn nil, false\n}\n\n// readFileIntoBuffer reads the file at filePath into a size limited buffer.\nfunc readFileIntoBuffer(filename string, size int) ([]byte, error) {\n\tfile, err := os.Open(filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer file.Close()\n\n\tbuffer := make([]byte, size)\n\tn, err := file.Read(buffer)\n\tif err != nil && err != io.EOF {\n\t\treturn nil, err\n\t}\n\n\t// slice the buffer to the actual size\n\treturn buffer[:n], nil\n}\n\n// ReplacementFunc is a function that is called when a\n// replacement is being performed. It receives the\n// variable (i.e. placeholder name) and the value that\n// will be the replacement, and returns the value that\n// will actually be the replacement, or an error. Note\n// that errors are sometimes ignored by replacers.\ntype ReplacementFunc func(variable string, val any) (any, error)\n\n// nowFunc is a variable so tests can change it\n// in order to obtain a deterministic time.\nvar nowFunc = time.Now\n\n// ReplacerCtxKey is the context key for a replacer.\nconst ReplacerCtxKey CtxKey = \"replacer\"\n\nconst phOpen, phClose, phEscape = '{', '}', '\\\\'\n\nconst filePrefix = \"file.\"\n",
    "source_file": "replacer.go",
    "chunk_type": "code"
  },
  {
    "content": "//go:build unix && !freebsd && !solaris\n\npackage caddy\n\nimport \"golang.org/x/sys/unix\"\n\nconst unixSOREUSEPORT = unix.SO_REUSEPORT\n",
    "source_file": "listen_unix_setopt.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build windows || plan9 || nacl || js\n\npackage caddy\n\nfunc trapSignalsPosix() {}\n",
    "source_file": "sigtrap_nonposix.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"log\"\n\t\"net/http\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"runtime/debug\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/google/uuid\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2/internal/filesystems\"\n\t\"github.com/caddyserver/caddy/v2/notify\"\n)\n\n// Config is the top (or beginning) of the Caddy configuration structure.\n// Caddy config is expressed natively as a JSON document. If you prefer\n// not to work with JSON directly, there are [many config adapters](/docs/config-adapters)\n// available that can convert various inputs into Caddy JSON.\n//\n// Many parts of this config are extensible through the use of Caddy modules.\n// Fields which have a json.RawMessage type and which appear as dots (\u2022\u2022\u2022) in\n// the online docs can be fulfilled by modules in a certain module\n// namespace. The docs show which modules can be used in a given place.\n//\n// Whenever a module is used, its name must be given either inline as part of\n// the module, or as the key to the module's value. The docs will make it clear\n// which to use.\n//\n// Generally, all config settings are optional, as it is Caddy convention to\n// have good, documented default values. If a parameter is required, the docs\n// should say so.\n//\n// Go programs which are directly building a Config struct value should take\n// care to populate the JSON-encodable fields of the struct (i.e. the fields\n// with `json` struct tags) if employing the module lifecycle (e.g. Provision\n// method calls).\ntype Config struct {\n\tAdmin   *AdminConfig `json:\"admin,omitempty\"`\n\tLogging *Logging     `json:\"logging,omitempty\"`\n\n\t// StorageRaw is a storage module that defines how/where Caddy\n\t// stores assets (such as TLS certificates). The default storage\n\t// module is `caddy.storage.file_system` (the local file system),\n\t// and the default path\n\t// [depends on the OS and environment](/docs/conventions#data-directory).\n\tStorageRaw json.RawMessage `json:\"storage,omitempty\" caddy:\"namespace=caddy.storage inline_key=module\"`\n\n\t// AppsRaw are the apps that Caddy will load and run. The\n\t// app module name is the key, and the app's config is the\n\t// associated value.\n\tAppsRaw ModuleMap `json:\"apps,omitempty\" caddy:\"namespace=\"`\n\n\tapps         map[string]App\n\tstorage      certmagic.Storage\n\teventEmitter eventEmitter\n\n\tcancelFunc context.CancelFunc\n\n\t// fileSystems is a dict of fileSystems that will later be loaded from and added to.\n\tfileSystems FileSystems\n}\n\n// App is a thing that Caddy runs.\ntype App interface {\n\tStart() error\n\tStop() error\n}\n\n// Run runs the given config, replacing any existing config.\nfunc Run(cfg *Config) error {\n\tcfgJSON, err := json.Marshal(cfg)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn Load(cfgJSON, true)\n}\n\n// Load loads the given config JSON and runs it only\n// if it is different from the current config or\n// forceReload is true.\nfunc Load(cfgJSON []byte, forceReload bool) error {\n\tif err := notify.Reloading(); err != nil {\n\t\tLog().Error(\"unable to notify service manager of reloading state\", zap.Error(err))\n\t}\n\n\t// after reload, notify system of success or, if\n\t// failure, update with status (error message)\n\tvar err error\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tif notifyErr := notify.Error(err, 0); notifyErr != nil {\n\t\t\t\tLog().Error(\"unable to notify to service manager of reload error\",\n\t\t\t\t\tzap.Error(notifyErr),\n\t\t\t\t\tzap.String(\"reload_err\", err.Error()))\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tif err := notify.Ready(); err != nil {\n\t\t\tLog().Error(\"unable to notify to service manager of ready state\", zap.Error(err))\n\t\t}\n\t}()\n\n\terr = changeConfig(http.MethodPost, \"/\"+rawConfigKey, cfgJSON, \"\", forceReload)\n\tif errors.Is(err, errSameConfig) {\n\t\terr = nil // not really an error\n\t}\n\n\treturn err\n}\n\n// changeConfig changes the current config (rawCfg) according to the\n// method, traversed via the given path, and uses the given input as\n// the new value (if applicable; i.e. \"DELETE\" doesn't have an input).\n// If the resulting config is the same as the previous, no reload will\n// occur unless forceReload is true. If the config is unchanged and not\n// forcefully reloaded, then errConfigUnchanged This function is safe for\n// concurrent use.\n// The ifMatchHeader can optionally be given a string of the format:\n//\n//\t\"<path> <hash>\"\n//\n// where <path> is the absolute path in the config and <hash> is the expected hash of\n// the config at that path. If the hash in the ifMatchHeader doesn't match\n// the hash of the config, then an APIError with status 412 will be returned.\nfunc changeConfig(method, path string, input []byte, ifMatchHeader string, forceReload bool) error {\n\tswitch method {\n\tcase http.MethodGet,\n\t\thttp.MethodHead,\n\t\thttp.MethodOptions,\n\t\thttp.MethodConnect,\n\t\thttp.MethodTrace:\n\t\treturn fmt.Errorf(\"method not allowed\")\n\t}\n\n\trawCfgMu.Lock()\n\tdefer rawCfgMu.Unlock()\n\n\tif ifMatchHeader != \"\" {\n\t\t// expect the first and last character to be quotes\n\t\tif len(ifMatchHeader) < 2 || ifMatchHeader[0] != '\"' || ifMatchHeader[len(ifMatchHeader)-1] != '\"' {\n\t\t\treturn APIError{\n\t\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\t\tErr:        fmt.Errorf(\"malformed If-Match header; expect quoted string\"),\n\t\t\t}\n\t\t}\n\n\t\t// read out the parts\n\t\tparts := strings.Fields(ifMatchHeader[1 : len(ifMatchHeader)-1])\n\t\tif len(parts) != 2 {\n\t\t\treturn APIError{\n\t\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\t\tErr:        fmt.Errorf(\"malformed If-Match header; expect format \\\"<path> <hash>\\\"\"),\n\t\t\t}\n\t\t}\n\n\t\t// get the current hash of the config\n\t\t// at the given path\n\t\thash := etagHasher()\n\t\terr := unsyncedConfigAccess(http.MethodGet, parts[0], nil, hash)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif hex.EncodeToString(hash.Sum(nil)) != parts[1] {\n\t\t\treturn APIError{\n\t\t\t\tHTTPStatus: http.StatusPreconditionFailed,\n\t\t\t\tErr:        fmt.Errorf(\"If-Match header did not match current config hash\"),\n\t\t\t}\n\t\t}\n\t}\n\n\terr := unsyncedConfigAccess(method, path, input, nil)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// the mutation is complete, so encode the entire config as JSON\n\tnewCfg, err := json.Marshal(rawCfg[rawConfigKey])\n\tif err != nil {\n\t\treturn APIError{\n\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\tErr:        fmt.Errorf(\"encoding new config: %v\", err),\n\t\t}\n\t}\n\n\t// if nothing changed, no need to do a whole reload unless the client forces it\n\tif !forceReload && bytes.Equal(rawCfgJSON, newCfg) {\n\t\tLog().Info(\"config is unchanged\")\n\t\treturn errSameConfig\n\t}\n\n\t// find any IDs in this config and index them\n\tidx := make(map[string]string)\n\terr = indexConfigObjects(rawCfg[rawConfigKey], \"/\"+rawConfigKey, idx)\n\tif err != nil {\n\t\treturn APIError{\n\t\t\tHTTPStatus: http.StatusInternalServerError,\n\t\t\tErr:        fmt.Errorf(\"indexing config: %v\", err),\n\t\t}\n\t}\n\n\t// load this new config; if it fails, we need to revert to\n\t// our old representation of caddy's actual config\n\terr = unsyncedDecodeAndRun(newCfg, true)\n\tif err != nil {\n\t\tif len(rawCfgJSON) > 0 {\n\t\t\t// restore old config state to keep it consistent\n\t\t\t// with what caddy is still running; we need to\n\t\t\t// unmarshal it again because it's likely that\n\t\t\t// pointers deep in our rawCfg map were modified\n\t\t\tvar oldCfg any\n\t\t\terr2 := json.Unmarshal(rawCfgJSON, &oldCfg)\n\t\t\tif err2 != nil {\n\t\t\t\terr = fmt.Errorf(\"%v; additionally, restoring old config: %v\", err, err2)\n\t\t\t}\n\t\t\trawCfg[rawConfigKey] = oldCfg\n\t\t}\n\n\t\treturn fmt.Errorf(\"loading new config: %v\", err)\n\t}\n\n\t// success, so update our stored copy of the encoded\n\t// config to keep it consistent with what caddy is now\n\t// running (storing an encoded copy is not strictly\n\t// necessary, but avoids an extra json.Marshal for\n\t// each config change)\n\trawCfgJSON = newCfg\n\trawCfgIndex = idx\n\n\treturn nil\n}\n\n// readConfig traverses the current config to path\n// and writes its JSON encoding to out.\nfunc readConfig(path string, out io.Writer) error {\n\trawCfgMu.RLock()\n\tdefer rawCfgMu.RUnlock()\n\treturn unsyncedConfigAccess(http.MethodGet, path, nil, out)\n}\n\n// indexConfigObjects recursively searches ptr for object fields named\n// \"@id\" and maps that ID value to the full configPath in the index.\n// This function is NOT safe for concurrent access; obtain a write lock\n// on currentCtxMu.\nfunc indexConfigObjects(ptr any, configPath string, index map[string]string) error {\n\tswitch val := ptr.(type) {\n\tcase map[string]any:\n\t\tfor k, v := range val {\n\t\t\tif k == idKey {\n\t\t\t\tswitch idVal := v.(type) {\n\t\t\t\tcase string:\n\t\t\t\t\tindex[idVal] = configPath\n\t\t\t\tcase float64: // all JSON numbers decode as float64\n\t\t\t\t\tindex[fmt.Sprintf(\"%v\", idVal)] = configPath\n\t\t\t\tdefault:\n\t\t\t\t\treturn fmt.Errorf(\"%s: %s field must be a string or number\", configPath, idKey)\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// traverse this object property recursively\n\t\t\terr := indexConfigObjects(val[k], path.Join(configPath, k), index)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\tcase []any:\n\t\t// traverse each element of the array recursively\n\t\tfor i := range val {\n\t\t\terr := indexConfigObjects(val[i], path.Join(configPath, strconv.Itoa(i)), index)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// unsyncedDecodeAndRun removes any meta fields (like @id tags)\n// from cfgJSON, decodes the result into a *Config, and runs\n// it as the new config, replacing any other current config.\n// It does NOT update the raw config state, as this is a\n// lower-level function; most callers will want to use Load\n// instead. A write lock on rawCfgMu is required! If\n// allowPersist is false, it will not be persisted to disk,\n// even if it is configured to.\nfunc unsyncedDecodeAndRun(cfgJSON []byte, allowPersist bool) error {\n\t// remove any @id fields from the JSON, which would cause\n\t// loading to break since the field wouldn't be recognized\n\tstrippedCfgJSON := RemoveMetaFields(cfgJSON)\n\n\tvar newCfg *Config\n\terr := StrictUnmarshalJSON(strippedCfgJSON, &newCfg)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// prevent recursive config loads; that is a user error, and\n\t// although frequent config loads should be safe, we cannot\n\t// guarantee that in the presence of third party plugins, nor\n\t// do we want this error to go unnoticed (we assume it was a\n\t// pulled config if we're not allowed to persist it)\n\tif !allowPersist &&\n\t\tnewCfg != nil &&\n\t\tnewCfg.Admin != nil &&\n\t\tnewCfg.Admin.Config != nil &&\n\t\tnewCfg.Admin.Config.LoadRaw != nil &&\n\t\tnewCfg.Admin.Config.LoadDelay <= 0 {\n\t\treturn fmt.Errorf(\"recursive config loading detected: pulled configs cannot pull other configs without positive load_delay\")\n\t}\n\n\t// run the new config and start all its apps\n\tctx, err := run(newCfg, true)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// swap old context (including its config) with the new one\n\tcurrentCtxMu.Lock()\n\toldCtx := currentCtx\n\tcurrentCtx = ctx\n\tcurrentCtxMu.Unlock()\n\n\t// Stop, Cleanup each old app\n\tunsyncedStop(oldCtx)\n\n\t// autosave a non-nil config, if not disabled\n\tif allowPersist &&\n\t\tnewCfg != nil &&\n\t\t(newCfg.Admin == nil ||\n\t\t\tnewCfg.Admin.Config == nil ||\n\t\t\tnewCfg.Admin.Config.Persist == nil ||\n\t\t\t*newCfg.Admin.Config.Persist) {\n\t\tdir := filepath.Dir(ConfigAutosavePath)\n\t\terr := os.MkdirAll(dir, 0o700)\n\t\tif err != nil {\n\t\t\tLog().Error(\"unable to create folder for config autosave\",\n\t\t\t\tzap.String(\"dir\", dir),\n\t\t\t\tzap.Error(err))\n\t\t} else {\n\t\t\terr := os.WriteFile(ConfigAutosavePath, cfgJSON, 0o600)\n\t\t\tif err == nil {\n\t\t\t\tLog().Info(\"autosaved config (load with --resume flag)\", zap.String(\"file\", ConfigAutosavePath))\n\t\t\t} else {\n\t\t\t\tLog().Error(\"unable to autosave config\",\n\t\t\t\t\tzap.String(\"file\", ConfigAutosavePath),\n\t\t\t\t\tzap.Error(err))\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// run runs newCfg and starts all its apps if\n// start is true. If any errors happen, cleanup\n// is performed if any modules were provisioned;\n// apps that were started already will be stopped,\n// so this function should not leak resources if\n// an error is returned. However, if no error is\n// returned and start == false, you should cancel\n// the config if you are not going to start it,\n// so that each provisioned module will be\n// cleaned up.\n//\n// This is a low-level function; most callers\n// will want to use Run instead, which also\n// updates the config's raw state.\nfunc run(newCfg *Config, start bool) (Context, error) {\n\tctx, err := provisionContext(newCfg, start)\n\tif err != nil {\n\t\tglobalMetrics.configSuccess.Set(0)\n\t\treturn ctx, err\n\t}\n\n\tif !start {\n\t\treturn ctx, nil\n\t}\n\n\tdefer func() {\n\t\t// if newCfg fails to start completely, clean up the already provisioned modules\n\t\t// partially copied from provisionContext\n\t\tif err != nil {\n\t\t\tglobalMetrics.configSuccess.Set(0)\n\t\t\tctx.cfg.cancelFunc()\n\n\t\t\tif currentCtx.cfg != nil {\n\t\t\t\tcertmagic.Default.Storage = currentCtx.cfg.storage\n\t\t\t}\n\t\t}\n\t}()\n\n\t// Provision any admin routers which may need to access\n\t// some of the other apps at runtime\n\terr = ctx.cfg.Admin.provisionAdminRouters(ctx)\n\tif err != nil {\n\t\treturn ctx, err\n\t}\n\n\t// Start\n\terr = func() error {\n\t\tstarted := make([]string, 0, len(ctx.cfg.apps))\n\t\tfor name, a := range ctx.cfg.apps {\n\t\t\terr := a.Start()\n\t\t\tif err != nil {\n\t\t\t\t// an app failed to start, so we need to stop\n\t\t\t\t// all other apps that were already started\n\t\t\t\tfor _, otherAppName := range started {\n\t\t\t\t\terr2 := ctx.cfg.apps[otherAppName].Stop()\n\t\t\t\t\tif err2 != nil {\n\t\t\t\t\t\terr = fmt.Errorf(\"%v; additionally, aborting app %s: %v\",\n\t\t\t\t\t\t\terr, otherAppName, err2)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\treturn fmt.Errorf(\"%s app module: start: %v\", name, err)\n\t\t\t}\n\t\t\tstarted = append(started, name)\n\t\t}\n\t\treturn nil\n\t}()\n\tif err != nil {\n\t\treturn ctx, err\n\t}\n\tglobalMetrics.configSuccess.Set(1)\n\tglobalMetrics.configSuccessTime.SetToCurrentTime()\n\n\t// TODO: This event is experimental and subject to change.\n\tctx.emitEvent(\"started\", nil)\n\n\t// now that the user's config is running, finish setting up anything else,\n\t// such as remote admin endpoint, config loader, etc.\n\terr = finishSettingUp(ctx, ctx.cfg)\n\treturn ctx, err\n}\n\n// provisionContext creates a new context from the given configuration and provisions\n// storage and apps.\n// If `newCfg` is nil a new empty configuration will be created.\n// If `replaceAdminServer` is true any currently active admin server will be replaced\n// with a new admin server based on the provided configuration.\nfunc provisionContext(newCfg *Config, replaceAdminServer bool) (Context, error) {\n\t// because we will need to roll back any state\n\t// modifications if this function errors, we\n\t// keep a single error value and scope all\n\t// sub-operations to their own functions to\n\t// ensure this error value does not get\n\t// overridden or missed when it should have\n\t// been set by a short assignment\n\tvar err error\n\n\tif newCfg == nil {\n\t\tnewCfg = new(Config)\n\t}\n\n\t// create a context within which to load\n\t// modules - essentially our new config's\n\t// execution environment; be sure that\n\t// cleanup occurs when we return if there\n\t// was an error; if no error, it will get\n\t// cleaned up on next config cycle\n\tctx, cancel := NewContext(Context{Context: context.Background(), cfg: newCfg})\n\tdefer func() {\n\t\tif err != nil {\n\t\t\tglobalMetrics.configSuccess.Set(0)\n\t\t\t// if there were any errors during startup,\n\t\t\t// we should cancel the new context we created\n\t\t\t// since the associated config won't be used;\n\t\t\t// this will cause all modules that were newly\n\t\t\t// provisioned to clean themselves up\n\t\t\tcancel()\n\n\t\t\t// also undo any other state changes we made\n\t\t\tif currentCtx.cfg != nil {\n\t\t\t\tcertmagic.Default.Storage = currentCtx.cfg.storage\n\t\t\t}\n\t\t}\n\t}()\n\tnewCfg.cancelFunc = cancel // clean up later\n\n\t// set up logging before anything bad happens\n\tif newCfg.Logging == nil {\n\t\tnewCfg.Logging = new(Logging)\n\t}\n\terr = newCfg.Logging.openLogs(ctx)\n\tif err != nil {\n\t\treturn ctx, err\n\t}\n\n\t// create the new filesystem map\n\tnewCfg.fileSystems = &filesystems.FileSystemMap{}\n\n\t// prepare the new config for use\n\tnewCfg.apps = make(map[string]App)\n\n\t// set up global storage and make it CertMagic's default storage, too\n\terr = func() error {\n\t\tif newCfg.StorageRaw != nil {\n\t\t\tval, err := ctx.LoadModule(newCfg, \"StorageRaw\")\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading storage module: %v\", err)\n\t\t\t}\n\t\t\tstor, err := val.(StorageConverter).CertMagicStorage()\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"creating storage value: %v\", err)\n\t\t\t}\n\t\t\tnewCfg.storage = stor\n\t\t}\n\n\t\tif newCfg.storage == nil {\n\t\t\tnewCfg.storage = DefaultStorage\n\t\t}\n\t\tcertmagic.Default.Storage = newCfg.storage\n\n\t\treturn nil\n\t}()\n\tif err != nil {\n\t\treturn ctx, err\n\t}\n\n\t// start the admin endpoint (and stop any prior one)\n\tif replaceAdminServer {\n\t\terr = replaceLocalAdminServer(newCfg, ctx)\n\t\tif err != nil {\n\t\t\treturn ctx, fmt.Errorf(\"starting caddy administration endpoint: %v\", err)\n\t\t}\n\t}\n\n\t// Load and Provision each app and their submodules\n\terr = func() error {\n\t\tfor appName := range newCfg.AppsRaw {\n\t\t\tif _, err := ctx.App(appName); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}()\n\treturn ctx, err\n}\n\n// ProvisionContext creates a new context from the configuration and provisions storage\n// and app modules.\n// The function is intended for testing and advanced use cases only, typically `Run` should be\n// use to ensure a fully functional caddy instance.\n// EXPERIMENTAL: While this is public the interface and implementation details of this function may change.\nfunc ProvisionContext(newCfg *Config) (Context, error) {\n\treturn provisionContext(newCfg, false)\n}\n\n// finishSettingUp should be run after all apps have successfully started.\nfunc finishSettingUp(ctx Context, cfg *Config) error {\n\t// establish this server's identity (only after apps are loaded\n\t// so that cert management of this endpoint doesn't prevent user's\n\t// servers from starting which likely also use HTTP/HTTPS ports;\n\t// but before remote management which may depend on these creds)\n\terr := manageIdentity(ctx, cfg)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"provisioning remote admin endpoint: %v\", err)\n\t}\n\n\t// replace any remote admin endpoint\n\terr = replaceRemoteAdminServer(ctx, cfg)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"provisioning remote admin endpoint: %v\", err)\n\t}\n\n\t// if dynamic config is requested, set that up and run it\n\tif cfg != nil && cfg.Admin != nil && cfg.Admin.Config != nil && cfg.Admin.Config.LoadRaw != nil {\n\t\tval, err := ctx.LoadModule(cfg.Admin.Config, \"LoadRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading config loader module: %s\", err)\n\t\t}\n\n\t\tlogger := Log().Named(\"config_loader\").With(\n\t\t\tzap.String(\"module\", val.(Module).CaddyModule().ID.Name()),\n\t\t\tzap.Int(\"load_delay\", int(cfg.Admin.Config.LoadDelay)))\n\n\t\trunLoadedConfig := func(config []byte) error {\n\t\t\tlogger.Info(\"applying dynamically-loaded config\")\n\t\t\terr := changeConfig(http.MethodPost, \"/\"+rawConfigKey, config, \"\", false)\n\t\t\tif errors.Is(err, errSameConfig) {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tlogger.Error(\"failed to run dynamically-loaded config\", zap.Error(err))\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tlogger.Info(\"successfully applied dynamically-loaded config\")\n\t\t\treturn nil\n\t\t}\n\n\t\tif cfg.Admin.Config.LoadDelay > 0 {\n\t\t\tgo func() {\n\t\t\t\t// the loop is here to iterate ONLY if there is an error, a no-op config load,\n\t\t\t\t// or an unchanged config; in which case we simply wait the delay and try again\n\t\t\t\tfor {\n\t\t\t\t\ttimer := time.NewTimer(time.Duration(cfg.Admin.Config.LoadDelay))\n\t\t\t\t\tselect {\n\t\t\t\t\tcase <-timer.C:\n\t\t\t\t\t\tloadedConfig, err := val.(ConfigLoader).LoadConfig(ctx)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\tlogger.Error(\"failed loading dynamic config; will retry\", zap.Error(err))\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif loadedConfig == nil {\n\t\t\t\t\t\t\tlogger.Info(\"dynamically-loaded config was nil; will retry\")\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\terr = runLoadedConfig(loadedConfig)\n\t\t\t\t\t\tif errors.Is(err, errSameConfig) {\n\t\t\t\t\t\t\tlogger.Info(\"dynamically-loaded config was unchanged; will retry\")\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\t\tif !timer.Stop() {\n\t\t\t\t\t\t\t<-timer.C\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlogger.Info(\"stopping dynamic config loading\")\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}()\n\t\t} else {\n\t\t\t// if no LoadDelay is provided, will load config synchronously\n\t\t\tloadedConfig, err := val.(ConfigLoader).LoadConfig(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading dynamic config from %T: %v\", val, err)\n\t\t\t}\n\t\t\t// do this in a goroutine so current config can finish being loaded; otherwise deadlock\n\t\t\tgo func() { _ = runLoadedConfig(loadedConfig) }()\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// ConfigLoader is a type that can load a Caddy config. If\n// the return value is non-nil, it must be valid Caddy JSON;\n// if nil or with non-nil error, it is considered to be a\n// no-op load and may be retried later.\ntype ConfigLoader interface {\n\tLoadConfig(Context) ([]byte, error)\n}\n\n// Stop stops running the current configuration.\n// It is the antithesis of Run(). This function\n// will log any errors that occur during the\n// stopping of individual apps and continue to\n// stop the others. Stop should only be called\n// if not replacing with a new config.\nfunc Stop() error {\n\tcurrentCtxMu.RLock()\n\tctx := currentCtx\n\tcurrentCtxMu.RUnlock()\n\n\trawCfgMu.Lock()\n\tunsyncedStop(ctx)\n\n\tcurrentCtxMu.Lock()\n\tcurrentCtx = Context{}\n\tcurrentCtxMu.Unlock()\n\n\trawCfgJSON = nil\n\trawCfgIndex = nil\n\trawCfg[rawConfigKey] = nil\n\trawCfgMu.Unlock()\n\n\treturn nil\n}\n\n// unsyncedStop stops ctx from running, but has\n// no locking around ctx. It is a no-op if ctx has a\n// nil cfg. If any app returns an error when stopping,\n// it is logged and the function continues stopping\n// the next app. This function assumes all apps in\n// ctx were successfully started first.\n//\n// A lock on rawCfgMu is required, even though this\n// function does not access rawCfg, that lock\n// synchronizes the stop/start of apps.\nfunc unsyncedStop(ctx Context) {\n\tif ctx.cfg == nil {\n\t\treturn\n\t}\n\n\t// TODO: This event is experimental and subject to change.\n\tctx.emitEvent(\"stopping\", nil)\n\n\t// stop each app\n\tfor name, a := range ctx.cfg.apps {\n\t\terr := a.Stop()\n\t\tif err != nil {\n\t\t\tlog.Printf(\"[ERROR] stop %s: %v\", name, err)\n\t\t}\n\t}\n\n\t// clean up all modules\n\tctx.cfg.cancelFunc()\n}\n\n// Validate loads, provisions, and validates\n// cfg, but does not start running it.\nfunc Validate(cfg *Config) error {\n\t_, err := run(cfg, false)\n\tif err == nil {\n\t\tcfg.cancelFunc() // call Cleanup on all modules\n\t}\n\treturn err\n}\n\n// exitProcess exits the process as gracefully as possible,\n// but it always exits, even if there are errors doing so.\n// It stops all apps, cleans up external locks, removes any\n// PID file, and shuts down admin endpoint(s) in a goroutine.\n// Errors are logged along the way, and an appropriate exit\n// code is emitted.\nfunc exitProcess(ctx context.Context, logger *zap.Logger) {\n\t// let the rest of the program know we're quitting; only do it once\n\tif !atomic.CompareAndSwapInt32(exiting, 0, 1) {\n\t\treturn\n\t}\n\n\t// give the OS or service/process manager our 2 weeks' notice: we quit\n\tif err := notify.Stopping(); err != nil {\n\t\tLog().Error(\"unable to notify service manager of stopping state\", zap.Error(err))\n\t}\n\n\tif logger == nil {\n\t\tlogger = Log()\n\t}\n\tlogger.Warn(\"exiting; byeee!! \ud83d\udc4b\")\n\n\texitCode := ExitCodeSuccess\n\tlastContext := ActiveContext()\n\n\t// stop all apps\n\tif err := Stop(); err != nil {\n\t\tlogger.Error(\"failed to stop apps\", zap.Error(err))\n\t\texitCode = ExitCodeFailedQuit\n\t}\n\n\t// clean up certmagic locks\n\tcertmagic.CleanUpOwnLocks(ctx, logger)\n\n\t// remove pidfile\n\tif pidfile != \"\" {\n\t\terr := os.Remove(pidfile)\n\t\tif err != nil {\n\t\t\tlogger.Error(\"cleaning up PID file:\",\n\t\t\t\tzap.String(\"pidfile\", pidfile),\n\t\t\t\tzap.Error(err))\n\t\t\texitCode = ExitCodeFailedQuit\n\t\t}\n\t}\n\n\t// execute any process-exit callbacks\n\tfor _, exitFunc := range lastContext.exitFuncs {\n\t\texitFunc(ctx)\n\t}\n\texitFuncsMu.Lock()\n\tfor _, exitFunc := range exitFuncs {\n\t\texitFunc(ctx)\n\t}\n\texitFuncsMu.Unlock()\n\n\t// shut down admin endpoint(s) in goroutines so that\n\t// if this function was called from an admin handler,\n\t// it has a chance to return gracefully\n\t// use goroutine so that we can finish responding to API request\n\tgo func() {\n\t\tdefer func() {\n\t\t\tlogger = logger.With(zap.Int(\"exit_code\", exitCode))\n\t\t\tif exitCode == ExitCodeSuccess {\n\t\t\t\tlogger.Info(\"shutdown complete\")\n\t\t\t} else {\n\t\t\t\tlogger.Error(\"unclean shutdown\")\n\t\t\t}\n\t\t\tos.Exit(exitCode)\n\t\t}()\n\n\t\tif remoteAdminServer != nil {\n\t\t\terr := stopAdminServer(remoteAdminServer)\n\t\t\tif err != nil {\n\t\t\t\texitCode = ExitCodeFailedQuit\n\t\t\t\tlogger.Error(\"failed to stop remote admin server gracefully\", zap.Error(err))\n\t\t\t}\n\t\t}\n\t\tif localAdminServer != nil {\n\t\t\terr := stopAdminServer(localAdminServer)\n\t\t\tif err != nil {\n\t\t\t\texitCode = ExitCodeFailedQuit\n\t\t\t\tlogger.Error(\"failed to stop local admin server gracefully\", zap.Error(err))\n\t\t\t}\n\t\t}\n\t}()\n}\n\nvar exiting = new(int32) // accessed atomically\n\n// Exiting returns true if the process is exiting.\n// EXPERIMENTAL API: subject to change or removal.\nfunc Exiting() bool { return atomic.LoadInt32(exiting) == 1 }\n\n// OnExit registers a callback to invoke during process exit.\n// This registration is PROCESS-GLOBAL, meaning that each\n// function should only be registered once forever, NOT once\n// per config load (etc).\n//\n// EXPERIMENTAL API: subject to change or removal.\nfunc OnExit(f func(context.Context)) {\n\texitFuncsMu.Lock()\n\texitFuncs = append(exitFuncs, f)\n\texitFuncsMu.Unlock()\n}\n\nvar (\n\texitFuncs   []func(context.Context)\n\texitFuncsMu sync.Mutex\n)\n\n// Duration can be an integer or a string. An integer is\n// interpreted as nanoseconds. If a string, it is a Go\n// time.Duration value such as `300ms`, `1.5h`, or `2h45m`;\n// valid units are `ns`, `us`/`\u00b5s`, `ms`, `s`, `m`, `h`, and `d`.\ntype Duration time.Duration\n\n// UnmarshalJSON satisfies json.Unmarshaler.\nfunc (d *Duration) UnmarshalJSON(b []byte) error {\n\tif len(b) == 0 {\n\t\treturn io.EOF\n\t}\n\tvar dur time.Duration\n\tvar err error\n\tif b[0] == byte('\"') && b[len(b)-1] == byte('\"') {\n\t\tdur, err = ParseDuration(strings.Trim(string(b), `\"`))\n\t} else {\n\t\terr = json.Unmarshal(b, &dur)\n\t}\n\t*d = Duration(dur)\n\treturn err\n}\n\n// ParseDuration parses a duration string, adding\n// support for the \"d\" unit meaning number of days,\n// where a day is assumed to be 24h. The maximum\n// input string length is 1024.\nfunc ParseDuration(s string) (time.Duration, error) {\n\tif len(s) > 1024 {\n\t\treturn 0, fmt.Errorf(\"parsing duration: input string too long\")\n\t}\n\tvar inNumber bool\n\tvar numStart int\n\tfor i := 0; i < len(s); i++ {\n\t\tch := s[i]\n\t\tif ch == 'd' {\n\t\t\tdaysStr := s[numStart:i]\n\t\t\tdays, err := strconv.ParseFloat(daysStr, 64)\n\t\t\tif err != nil {\n\t\t\t\treturn 0, err\n\t\t\t}\n\t\t\thours := days * 24.0\n\t\t\thoursStr := strconv.FormatFloat(hours, 'f', -1, 64)\n\t\t\ts = s[:numStart] + hoursStr + \"h\" + s[i+1:]\n\t\t\ti--\n\t\t\tcontinue\n\t\t}\n\t\tif !inNumber {\n\t\t\tnumStart = i\n\t\t}\n\t\tinNumber = (ch >= '0' && ch <= '9') || ch == '.' || ch == '-' || ch == '+'\n\t}\n\treturn time.ParseDuration(s)\n}\n\n// InstanceID returns the UUID for this instance, and generates one if it\n// does not already exist. The UUID is stored in the local data directory,\n// regardless of storage configuration, since each instance is intended to\n// have its own unique ID.\nfunc InstanceID() (uuid.UUID, error) {\n\tappDataDir := AppDataDir()\n\tuuidFilePath := filepath.Join(appDataDir, \"instance.uuid\")\n\tuuidFileBytes, err := os.ReadFile(uuidFilePath)\n\tif errors.Is(err, fs.ErrNotExist) {\n\t\tuuid, err := uuid.NewRandom()\n\t\tif err != nil {\n\t\t\treturn uuid, err\n\t\t}\n\t\terr = os.MkdirAll(appDataDir, 0o700)\n\t\tif err != nil {\n\t\t\treturn uuid, err\n\t\t}\n\t\terr = os.WriteFile(uuidFilePath, []byte(uuid.String()), 0o600)\n\t\treturn uuid, err\n\t} else if err != nil {\n\t\treturn [16]byte{}, err\n\t}\n\treturn uuid.ParseBytes(uuidFileBytes)\n}\n\n// CustomVersion is an optional string that overrides Caddy's\n// reported version. It can be helpful when downstream packagers\n// need to manually set Caddy's version. If no other version\n// information is available, the short form version (see\n// Version()) will be set to CustomVersion, and the full version\n// will include CustomVersion at the beginning.\n//\n// Set this variable during `go build` with `-ldflags`:\n//\n//\t-ldflags '-X github.com/caddyserver/caddy/v2.CustomVersion=v2.6.2'\n//\n// for example.\nvar CustomVersion string\n\n// Version returns the Caddy version in a simple/short form, and\n// a full version string. The short form will not have spaces and\n// is intended for User-Agent strings and similar, but may be\n// omitting valuable information. Note that Caddy must be compiled\n// in a special way to properly embed complete version information.\n// First this function tries to get the version from the embedded\n// build info provided by go.mod dependencies; then it tries to\n// get info from embedded VCS information, which requires having\n// built Caddy from a git repository. If no version is available,\n// this function returns \"(devel)\" because Go uses that, but for\n// the simple form we change it to \"unknown\". If still no version\n// is available (e.g. no VCS repo), then it will use CustomVersion;\n// CustomVersion is always prepended to the full version string.\n//\n// See relevant Go issues: https://github.com/golang/go/issues/29228\n// and https://github.com/golang/go/issues/50603.\n//\n// This function is experimental and subject to change or removal.\nfunc Version() (simple, full string) {\n\t// the currently-recommended way to build Caddy involves\n\t// building it as a dependency so we can extract version\n\t// information from go.mod tooling; once the upstream\n\t// Go issues are fixed, we should just be able to use\n\t// bi.Main... hopefully.\n\tvar module *debug.Module\n\tbi, ok := debug.ReadBuildInfo()\n\tif !ok {\n\t\tif CustomVersion != \"\" {\n\t\t\tfull = CustomVersion\n\t\t\tsimple = CustomVersion\n\t\t\treturn\n\t\t}\n\t\tfull = \"unknown\"\n\t\tsimple = \"unknown\"\n\t\treturn\n\t}\n\t// find the Caddy module in the dependency list\n\tfor _, dep := range bi.Deps {\n\t\tif dep.Path == ImportPath {\n\t\t\tmodule = dep\n\t\t\tbreak\n\t\t}\n\t}\n\tif module != nil {\n\t\tsimple, full = module.Version, module.Version\n\t\tif module.Sum != \"\" {\n\t\t\tfull += \" \" + module.Sum\n\t\t}\n\t\tif module.Replace != nil {\n\t\t\tfull += \" => \" + module.Replace.Path\n\t\t\tif module.Replace.Version != \"\" {\n\t\t\t\tsimple = module.Replace.Version + \"_custom\"\n\t\t\t\tfull += \"@\" + module.Replace.Version\n\t\t\t}\n\t\t\tif module.Replace.Sum != \"\" {\n\t\t\t\tfull += \" \" + module.Replace.Sum\n\t\t\t}\n\t\t}\n\t}\n\n\tif full == \"\" {\n\t\tvar vcsRevision string\n\t\tvar vcsTime time.Time\n\t\tvar vcsModified bool\n\t\tfor _, setting := range bi.Settings {\n\t\t\tswitch setting.Key {\n\t\t\tcase \"vcs.revision\":\n\t\t\t\tvcsRevision = setting.Value\n\t\t\tcase \"vcs.time\":\n\t\t\t\tvcsTime, _ = time.Parse(time.RFC3339, setting.Value)\n\t\t\tcase \"vcs.modified\":\n\t\t\t\tvcsModified, _ = strconv.ParseBool(setting.Value)\n\t\t\t}\n\t\t}\n\n\t\tif vcsRevision != \"\" {\n\t\t\tvar modified string\n\t\t\tif vcsModified {\n\t\t\t\tmodified = \"+modified\"\n\t\t\t}\n\t\t\tfull = fmt.Sprintf(\"%s%s (%s)\", vcsRevision, modified, vcsTime.Format(time.RFC822))\n\t\t\tsimple = vcsRevision\n\n\t\t\t// use short checksum for simple, if hex-only\n\t\t\tif _, err := hex.DecodeString(simple); err == nil {\n\t\t\t\tsimple = simple[:8]\n\t\t\t}\n\n\t\t\t// append date to simple since it can be convenient\n\t\t\t// to know the commit date as part of the version\n\t\t\tif !vcsTime.IsZero() {\n\t\t\t\tsimple += \"-\" + vcsTime.Format(\"20060102\")\n\t\t\t}\n\t\t}\n\t}\n\n\tif full == \"\" {\n\t\tif CustomVersion != \"\" {\n\t\t\tfull = CustomVersion\n\t\t} else {\n\t\t\tfull = \"unknown\"\n\t\t}\n\t} else if CustomVersion != \"\" {\n\t\tfull = CustomVersion + \" \" + full\n\t}\n\n\tif simple == \"\" || simple == \"(devel)\" {\n\t\tif CustomVersion != \"\" {\n\t\t\tsimple = CustomVersion\n\t\t} else {\n\t\t\tsimple = \"unknown\"\n\t\t}\n\t}\n\n\treturn\n}\n\n// Event represents something that has happened or is happening.\n// An Event value is not synchronized, so it should be copied if\n// being used in goroutines.\n//\n// EXPERIMENTAL: Events are subject to change.\ntype Event struct {\n\t// If non-nil, the event has been aborted, meaning\n\t// propagation has stopped to other handlers and\n\t// the code should stop what it was doing. Emitters\n\t// may choose to use this as a signal to adjust their\n\t// code path appropriately.\n\tAborted error\n\n\t// The data associated with the event. Usually the\n\t// original emitter will be the only one to set or\n\t// change these values, but the field is exported\n\t// so handlers can have full access if needed.\n\t// However, this map is not synchronized, so\n\t// handlers must not use this map directly in new\n\t// goroutines; instead, copy the map to use it in a\n\t// goroutine. Data may be nil.\n\tData map[string]any\n\n\tid     uuid.UUID\n\tts     time.Time\n\tname   string\n\torigin Module\n}\n\n// NewEvent creates a new event, but does not emit the event. To emit an\n// event, call Emit() on the current instance of the caddyevents app insteaad.\n//\n// EXPERIMENTAL: Subject to change.\nfunc NewEvent(ctx Context, name string, data map[string]any) (Event, error) {\n\tid, err := uuid.NewRandom()\n\tif err != nil {\n\t\treturn Event{}, fmt.Errorf(\"generating new event ID: %v\", err)\n\t}\n\tname = strings.ToLower(name)\n\treturn Event{\n\t\tData:   data,\n\t\tid:     id,\n\t\tts:     time.Now(),\n\t\tname:   name,\n\t\torigin: ctx.Module(),\n\t}, nil\n}\n\nfunc (e Event) ID() uuid.UUID        { return e.id }\nfunc (e Event) Timestamp() time.Time { return e.ts }\nfunc (e Event) Name() string         { return e.name }\nfunc (e Event) Origin() Module       { return e.origin } // Returns the module that originated the event. May be nil, usually if caddy core emits the event.\n\n// CloudEvent exports event e as a structure that, when\n// serialized as JSON, is compatible with the\n// CloudEvents spec.\nfunc (e Event) CloudEvent() CloudEvent {\n\tdataJSON, _ := json.Marshal(e.Data)\n\tvar source string\n\tif e.Origin() == nil {\n\t\tsource = \"caddy\"\n\t} else {\n\t\tsource = string(e.Origin().CaddyModule().ID)\n\t}\n\treturn CloudEvent{\n\t\tID:              e.id.String(),\n\t\tSource:          source,\n\t\tSpecVersion:     \"1.0\",\n\t\tType:            e.name,\n\t\tTime:            e.ts,\n\t\tDataContentType: \"application/json\",\n\t\tData:            dataJSON,\n\t}\n}\n\n// CloudEvent is a JSON-serializable structure that\n// is compatible with the CloudEvents specification.\n// See https://cloudevents.io.\n// EXPERIMENTAL: Subject to change.\ntype CloudEvent struct {\n\tID              string          `json:\"id\"`\n\tSource          string          `json:\"source\"`\n\tSpecVersion     string          `json:\"specversion\"`\n\tType            string          `json:\"type\"`\n\tTime            time.Time       `json:\"time\"`\n\tDataContentType string          `json:\"datacontenttype,omitempty\"`\n\tData            json.RawMessage `json:\"data,omitempty\"`\n}\n\n// ErrEventAborted cancels an event.\nvar ErrEventAborted = errors.New(\"event aborted\")\n\n// ActiveContext returns the currently-active context.\n// This function is experimental and might be changed\n// or removed in the future.\nfunc ActiveContext() Context {\n\tcurrentCtxMu.RLock()\n\tdefer currentCtxMu.RUnlock()\n\treturn currentCtx\n}\n\n// CtxKey is a value type for use with context.WithValue.\ntype CtxKey string\n\n// This group of variables pertains to the current configuration.\nvar (\n\t// currentCtx is the root context for the currently-running\n\t// configuration, which can be accessed through this value.\n\t// If the Config contained in this value is not nil, then\n\t// a config is currently active/running.\n\tcurrentCtx   Context\n\tcurrentCtxMu sync.RWMutex\n\n\t// rawCfg is the current, generic-decoded configuration;\n\t// we initialize it as a map with one field (\"config\")\n\t// to maintain parity with the API endpoint and to avoid\n\t// the special case of having to access/mutate the variable\n\t// directly without traversing into it.\n\trawCfg = map[string]any{\n\t\trawConfigKey: nil,\n\t}\n\n\t// rawCfgJSON is the JSON-encoded form of rawCfg. Keeping\n\t// this around avoids an extra Marshal call during changes.\n\trawCfgJSON []byte\n\n\t// rawCfgIndex is the map of user-assigned ID to expanded\n\t// path, for converting /id/ paths to /config/ paths.\n\trawCfgIndex map[string]string\n\n\t// rawCfgMu protects all the rawCfg fields and also\n\t// essentially synchronizes config changes/reloads.\n\trawCfgMu sync.RWMutex\n)\n\n// errSameConfig is returned if the new config is the same\n// as the old one. This isn't usually an actual, actionable\n// error; it's mostly a sentinel value.\nvar errSameConfig = errors.New(\"config is unchanged\")\n\n// ImportPath is the package import path for Caddy core.\n// This identifier may be removed in the future.\nconst ImportPath = \"github.com/caddyserver/caddy/v2\"\n",
    "source_file": "caddy.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build gofuzz\n\npackage caddy\n\nfunc FuzzParseDuration(data []byte) int {\n\t_, err := ParseDuration(string(data))\n\tif err != nil {\n\t\treturn 0\n\t}\n\treturn 1\n}\n",
    "source_file": "duration_fuzz.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build !unix || solaris\n\npackage caddy\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net\"\n\t\"os\"\n\t\"slices\"\n\t\"strconv\"\n\t\"sync\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n)\n\nfunc reuseUnixSocket(_, _ string) (any, error) {\n\treturn nil, nil\n}\n\nfunc listenReusable(ctx context.Context, lnKey string, network, address string, config net.ListenConfig) (any, error) {\n\tvar socketFile *os.File\n\n\tfd := slices.Contains([]string{\"fd\", \"fdgram\"}, network)\n\tif fd {\n\t\tsocketFd, err := strconv.ParseUint(address, 0, strconv.IntSize)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid file descriptor: %v\", err)\n\t\t}\n\n\t\tfunc() {\n\t\t\tsocketFilesMu.Lock()\n\t\t\tdefer socketFilesMu.Unlock()\n\n\t\t\tsocketFdWide := uintptr(socketFd)\n\t\t\tvar ok bool\n\n\t\t\tsocketFile, ok = socketFiles[socketFdWide]\n\n\t\t\tif !ok {\n\t\t\t\tsocketFile = os.NewFile(socketFdWide, lnKey)\n\t\t\t\tif socketFile != nil {\n\t\t\t\t\tsocketFiles[socketFdWide] = socketFile\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\tif socketFile == nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid socket file descriptor: %d\", socketFd)\n\t\t}\n\t}\n\n\tdatagram := slices.Contains([]string{\"udp\", \"udp4\", \"udp6\", \"unixgram\", \"fdgram\"}, network)\n\tif datagram {\n\t\tsharedPc, _, err := listenerPool.LoadOrNew(lnKey, func() (Destructor, error) {\n\t\t\tvar (\n\t\t\t\tpc  net.PacketConn\n\t\t\t\terr error\n\t\t\t)\n\t\t\tif fd {\n\t\t\t\tpc, err = net.FilePacketConn(socketFile)\n\t\t\t} else {\n\t\t\t\tpc, err = config.ListenPacket(ctx, network, address)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn &sharedPacketConn{PacketConn: pc, key: lnKey}, nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &fakeClosePacketConn{sharedPacketConn: sharedPc.(*sharedPacketConn)}, nil\n\t}\n\n\tsharedLn, _, err := listenerPool.LoadOrNew(lnKey, func() (Destructor, error) {\n\t\tvar (\n\t\t\tln  net.Listener\n\t\t\terr error\n\t\t)\n\t\tif fd {\n\t\t\tln, err = net.FileListener(socketFile)\n\t\t} else {\n\t\t\tln, err = config.Listen(ctx, network, address)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn &sharedListener{Listener: ln, key: lnKey}, nil\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn &fakeCloseListener{sharedListener: sharedLn.(*sharedListener), keepAlivePeriod: config.KeepAlive}, nil\n}\n\n// fakeCloseListener is a private wrapper over a listener that\n// is shared. The state of fakeCloseListener is not shared.\n// This allows one user of a socket to \"close\" the listener\n// while in reality the socket stays open for other users of\n// the listener. In this way, servers become hot-swappable\n// while the listener remains running. Listeners should be\n// re-wrapped in a new fakeCloseListener each time the listener\n// is reused. This type is atomic and values must not be copied.\ntype fakeCloseListener struct {\n\tclosed          int32 // accessed atomically; belongs to this struct only\n\t*sharedListener       // embedded, so we also become a net.Listener\n\tkeepAlivePeriod time.Duration\n}\n\ntype canSetKeepAlive interface {\n\tSetKeepAlivePeriod(d time.Duration) error\n\tSetKeepAlive(bool) error\n}\n\nfunc (fcl *fakeCloseListener) Accept() (net.Conn, error) {\n\t// if the listener is already \"closed\", return error\n\tif atomic.LoadInt32(&fcl.closed) == 1 {\n\t\treturn nil, fakeClosedErr(fcl)\n\t}\n\n\t// call underlying accept\n\tconn, err := fcl.sharedListener.Accept()\n\tif err == nil {\n\t\t// if 0, do nothing, Go's default is already set\n\t\t// and if the connection allows setting KeepAlive, set it\n\t\tif tconn, ok := conn.(canSetKeepAlive); ok && fcl.keepAlivePeriod != 0 {\n\t\t\tif fcl.keepAlivePeriod > 0 {\n\t\t\t\terr = tconn.SetKeepAlivePeriod(fcl.keepAlivePeriod)\n\t\t\t} else { // negative\n\t\t\t\terr = tconn.SetKeepAlive(false)\n\t\t\t}\n\t\t\tif err != nil {\n\t\t\t\tLog().With(zap.String(\"server\", fcl.sharedListener.key)).Warn(\"unable to set keepalive for new connection:\", zap.Error(err))\n\t\t\t}\n\t\t}\n\t\treturn conn, nil\n\t}\n\n\t// since Accept() returned an error, it may be because our reference to\n\t// the listener (this fakeCloseListener) may have been closed, i.e. the\n\t// server is shutting down; in that case, we need to clear the deadline\n\t// that we set when Close() was called, and return a non-temporary and\n\t// non-timeout error value to the caller, masking the \"true\" error, so\n\t// that server loops / goroutines won't retry, linger, and leak\n\tif atomic.LoadInt32(&fcl.closed) == 1 {\n\t\t// we dereference the sharedListener explicitly even though it's embedded\n\t\t// so that it's clear in the code that side-effects are shared with other\n\t\t// users of this listener, not just our own reference to it; we also don't\n\t\t// do anything with the error because all we could do is log it, but we\n\t\t// explicitly assign it to nothing so we don't forget it's there if needed\n\t\t_ = fcl.sharedListener.clearDeadline()\n\n\t\tif netErr, ok := err.(net.Error); ok && netErr.Timeout() {\n\t\t\treturn nil, fakeClosedErr(fcl)\n\t\t}\n\t}\n\n\treturn nil, err\n}\n\n// Close stops accepting new connections without closing the\n// underlying listener. The underlying listener is only closed\n// if the caller is the last known user of the socket.\nfunc (fcl *fakeCloseListener) Close() error {\n\tif atomic.CompareAndSwapInt32(&fcl.closed, 0, 1) {\n\t\t// There are two ways I know of to get an Accept()\n\t\t// function to return to the server loop that called\n\t\t// it: close the listener, or set a deadline in the\n\t\t// past. Obviously, we can't close the socket yet\n\t\t// since others may be using it (hence this whole\n\t\t// file). But we can set the deadline in the past,\n\t\t// and this is kind of cheating, but it works, and\n\t\t// it apparently even works on Windows.\n\t\t_ = fcl.sharedListener.setDeadline()\n\t\t_, _ = listenerPool.Delete(fcl.sharedListener.key)\n\t}\n\treturn nil\n}\n\n// sharedListener is a wrapper over an underlying listener. The listener\n// and the other fields on the struct are shared state that is synchronized,\n// so sharedListener structs must never be copied (always use a pointer).\ntype sharedListener struct {\n\tnet.Listener\n\tkey        string // uniquely identifies this listener\n\tdeadline   bool   // whether a deadline is currently set\n\tdeadlineMu sync.Mutex\n}\n\nfunc (sl *sharedListener) clearDeadline() error {\n\tvar err error\n\tsl.deadlineMu.Lock()\n\tif sl.deadline {\n\t\tswitch ln := sl.Listener.(type) {\n\t\tcase *net.TCPListener:\n\t\t\terr = ln.SetDeadline(time.Time{})\n\t\t}\n\t\tsl.deadline = false\n\t}\n\tsl.deadlineMu.Unlock()\n\treturn err\n}\n\nfunc (sl *sharedListener) setDeadline() error {\n\ttimeInPast := time.Now().Add(-1 * time.Minute)\n\tvar err error\n\tsl.deadlineMu.Lock()\n\tif !sl.deadline {\n\t\tswitch ln := sl.Listener.(type) {\n\t\tcase *net.TCPListener:\n\t\t\terr = ln.SetDeadline(timeInPast)\n\t\t}\n\t\tsl.deadline = true\n\t}\n\tsl.deadlineMu.Unlock()\n\treturn err\n}\n\n// Destruct is called by the UsagePool when the listener is\n// finally not being used anymore. It closes the socket.\nfunc (sl *sharedListener) Destruct() error {\n\treturn sl.Listener.Close()\n}\n\n// fakeClosePacketConn is like fakeCloseListener, but for PacketConns,\n// or more specifically, *net.UDPConn\ntype fakeClosePacketConn struct {\n\tclosed            int32 // accessed atomically; belongs to this struct only\n\t*sharedPacketConn       // embedded, so we also become a net.PacketConn; its key is used in Close\n}\n\nfunc (fcpc *fakeClosePacketConn) ReadFrom(p []byte) (n int, addr net.Addr, err error) {\n\t// if the listener is already \"closed\", return error\n\tif atomic.LoadInt32(&fcpc.closed) == 1 {\n\t\treturn 0, nil, &net.OpError{\n\t\t\tOp:   \"readfrom\",\n\t\t\tNet:  fcpc.LocalAddr().Network(),\n\t\t\tAddr: fcpc.LocalAddr(),\n\t\t\tErr:  errFakeClosed,\n\t\t}\n\t}\n\n\t// call underlying readfrom\n\tn, addr, err = fcpc.sharedPacketConn.ReadFrom(p)\n\tif err != nil {\n\t\t// this server was stopped, so clear the deadline and let\n\t\t// any new server continue reading; but we will exit\n\t\tif atomic.LoadInt32(&fcpc.closed) == 1 {\n\t\t\tif netErr, ok := err.(net.Error); ok && netErr.Timeout() {\n\t\t\t\tif err = fcpc.SetReadDeadline(time.Time{}); err != nil {\n\t\t\t\t\treturn\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn\n\t}\n\n\treturn\n}\n\n// Close won't close the underlying socket unless there is no more reference, then listenerPool will close it.\nfunc (fcpc *fakeClosePacketConn) Close() error {\n\tif atomic.CompareAndSwapInt32(&fcpc.closed, 0, 1) {\n\t\t_ = fcpc.SetReadDeadline(time.Now()) // unblock ReadFrom() calls to kick old servers out of their loops\n\t\t_, _ = listenerPool.Delete(fcpc.sharedPacketConn.key)\n\t}\n\treturn nil\n}\n\nfunc (fcpc *fakeClosePacketConn) Unwrap() net.PacketConn {\n\treturn fcpc.sharedPacketConn.PacketConn\n}\n\n// sharedPacketConn is like sharedListener, but for net.PacketConns.\ntype sharedPacketConn struct {\n\tnet.PacketConn\n\tkey string\n}\n\n// Destruct closes the underlying socket.\nfunc (spc *sharedPacketConn) Destruct() error {\n\treturn spc.PacketConn.Close()\n}\n\n// Unwrap returns the underlying socket\nfunc (spc *sharedPacketConn) Unwrap() net.PacketConn {\n\treturn spc.PacketConn\n}\n\n// Interface guards (see https://github.com/caddyserver/caddy/issues/3998)\nvar (\n\t_ (interface {\n\t\tUnwrap() net.PacketConn\n\t}) = (*fakeClosePacketConn)(nil)\n)\n\n// socketFiles is a fd -> *os.File map used to make a FileListener/FilePacketConn from a socket file descriptor.\nvar socketFiles = map[uintptr]*os.File{}\n\n// socketFilesMu synchronizes socketFiles insertions\nvar socketFilesMu sync.Mutex\n",
    "source_file": "listen.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build !windows && !plan9 && !nacl && !js\n\npackage caddy\n\nimport (\n\t\"context\"\n\t\"os\"\n\t\"os/signal\"\n\t\"syscall\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"go.uber.org/zap\"\n)\n\n// trapSignalsPosix captures POSIX-only signals.\nfunc trapSignalsPosix() {\n\t// Ignore all SIGPIPE signals to prevent weird issues with systemd: https://github.com/dunglas/frankenphp/issues/1020\n\t// Docker/Moby has a similar hack: https://github.com/moby/moby/blob/d828b032a87606ae34267e349bf7f7ccb1f6495a/cmd/dockerd/docker.go#L87-L90\n\tsignal.Ignore(syscall.SIGPIPE)\n\n\tgo func() {\n\t\tsigchan := make(chan os.Signal, 1)\n\t\tsignal.Notify(sigchan, syscall.SIGTERM, syscall.SIGHUP, syscall.SIGQUIT, syscall.SIGUSR1, syscall.SIGUSR2)\n\n\t\tfor sig := range sigchan {\n\t\t\tswitch sig {\n\t\t\tcase syscall.SIGQUIT:\n\t\t\t\tLog().Info(\"quitting process immediately\", zap.String(\"signal\", \"SIGQUIT\"))\n\t\t\t\tcertmagic.CleanUpOwnLocks(context.TODO(), Log()) // try to clean up locks anyway, it's important\n\t\t\t\tos.Exit(ExitCodeForceQuit)\n\n\t\t\tcase syscall.SIGTERM:\n\t\t\t\tLog().Info(\"shutting down apps, then terminating\", zap.String(\"signal\", \"SIGTERM\"))\n\t\t\t\texitProcessFromSignal(\"SIGTERM\")\n\n\t\t\tcase syscall.SIGUSR1:\n\t\t\t\tLog().Info(\"not implemented\", zap.String(\"signal\", \"SIGUSR1\"))\n\n\t\t\tcase syscall.SIGUSR2:\n\t\t\t\tLog().Info(\"not implemented\", zap.String(\"signal\", \"SIGUSR2\"))\n\n\t\t\tcase syscall.SIGHUP:\n\t\t\t\t// ignore; this signal is sometimes sent outside of the user's control\n\t\t\t\tLog().Info(\"not implemented\", zap.String(\"signal\", \"SIGHUP\"))\n\t\t\t}\n\t\t}\n\t}()\n}\n",
    "source_file": "sigtrap_posix.go",
    "chunk_type": "code"
  },
  {
    "content": "//go:build freebsd\n\npackage caddy\n\nimport \"golang.org/x/sys/unix\"\n\nconst unixSOREUSEPORT = unix.SO_REUSEPORT_LB\n",
    "source_file": "listen_unix_setopt_freebsd.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build !windows\n\npackage caddy\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n)\n\n// FastAbs is an optimized version of filepath.Abs for Unix systems,\n// since we don't expect the working directory to ever change once\n// Caddy is running. Avoid the os.Getwd() syscall overhead.\n// It's overall the same as stdlib's implementation, the difference\n// being cached working directory.\nfunc FastAbs(path string) (string, error) {\n\tif filepath.IsAbs(path) {\n\t\treturn filepath.Clean(path), nil\n\t}\n\tif wderr != nil {\n\t\treturn \"\", wderr\n\t}\n\treturn filepath.Join(wd, path), nil\n}\n\nvar wd, wderr = os.Getwd()\n",
    "source_file": "filepath.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddy\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"reflect\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n)\n\n// Module is a type that is used as a Caddy module. In\n// addition to this interface, most modules will implement\n// some interface expected by their host module in order\n// to be useful. To learn which interface(s) to implement,\n// see the documentation for the host module. At a bare\n// minimum, this interface, when implemented, only provides\n// the module's ID and constructor function.\n//\n// Modules will often implement additional interfaces\n// including Provisioner, Validator, and CleanerUpper.\n// If a module implements these interfaces, their\n// methods are called during the module's lifespan.\n//\n// When a module is loaded by a host module, the following\n// happens: 1) ModuleInfo.New() is called to get a new\n// instance of the module. 2) The module's configuration is\n// unmarshaled into that instance. 3) If the module is a\n// Provisioner, the Provision() method is called. 4) If the\n// module is a Validator, the Validate() method is called.\n// 5) The module will probably be type-asserted from\n// 'any' to some other, more useful interface expected\n// by the host module. For example, HTTP handler modules are\n// type-asserted as caddyhttp.MiddlewareHandler values.\n// 6) When a module's containing Context is canceled, if it is\n// a CleanerUpper, its Cleanup() method is called.\ntype Module interface {\n\t// This method indicates that the type is a Caddy\n\t// module. The returned ModuleInfo must have both\n\t// a name and a constructor function. This method\n\t// must not have any side-effects.\n\tCaddyModule() ModuleInfo\n}\n\n// ModuleInfo represents a registered Caddy module.\ntype ModuleInfo struct {\n\t// ID is the \"full name\" of the module. It\n\t// must be unique and properly namespaced.\n\tID ModuleID\n\n\t// New returns a pointer to a new, empty\n\t// instance of the module's type. This\n\t// method must not have any side-effects,\n\t// and no other initialization should\n\t// occur within it. Any initialization\n\t// of the returned value should be done\n\t// in a Provision() method (see the\n\t// Provisioner interface).\n\tNew func() Module\n}\n\n// ModuleID is a string that uniquely identifies a Caddy module. A\n// module ID is lightly structured. It consists of dot-separated\n// labels which form a simple hierarchy from left to right. The last\n// label is the module name, and the labels before that constitute\n// the namespace (or scope).\n//\n// Thus, a module ID has the form: <namespace>.<name>\n//\n// An ID with no dot has the empty namespace, which is appropriate\n// for app modules (these are \"top-level\" modules that Caddy core\n// loads and runs).\n//\n// Module IDs should be lowercase and use underscores (_) instead of\n// spaces.\n//\n// Examples of valid IDs:\n// - http\n// - http.handlers.file_server\n// - caddy.logging.encoders.json\ntype ModuleID string\n\n// Namespace returns the namespace (or scope) portion of a module ID,\n// which is all but the last label of the ID. If the ID has only one\n// label, then the namespace is empty.\nfunc (id ModuleID) Namespace() string {\n\tlastDot := strings.LastIndex(string(id), \".\")\n\tif lastDot < 0 {\n\t\treturn \"\"\n\t}\n\treturn string(id)[:lastDot]\n}\n\n// Name returns the Name (last element) of a module ID.\nfunc (id ModuleID) Name() string {\n\tif id == \"\" {\n\t\treturn \"\"\n\t}\n\tparts := strings.Split(string(id), \".\")\n\treturn parts[len(parts)-1]\n}\n\nfunc (mi ModuleInfo) String() string { return string(mi.ID) }\n\n// ModuleMap is a map that can contain multiple modules,\n// where the map key is the module's name. (The namespace\n// is usually read from an associated field's struct tag.)\n// Because the module's name is given as the key in a\n// module map, the name does not have to be given in the\n// json.RawMessage.\ntype ModuleMap map[string]json.RawMessage\n\n// RegisterModule registers a module by receiving a\n// plain/empty value of the module. For registration to\n// be properly recorded, this should be called in the\n// init phase of runtime. Typically, the module package\n// will do this as a side-effect of being imported.\n// This function panics if the module's info is\n// incomplete or invalid, or if the module is already\n// registered.\nfunc RegisterModule(instance Module) {\n\tmod := instance.CaddyModule()\n\n\tif mod.ID == \"\" {\n\t\tpanic(\"module ID missing\")\n\t}\n\tif mod.ID == \"caddy\" || mod.ID == \"admin\" {\n\t\tpanic(fmt.Sprintf(\"module ID '%s' is reserved\", mod.ID))\n\t}\n\tif mod.New == nil {\n\t\tpanic(\"missing ModuleInfo.New\")\n\t}\n\tif val := mod.New(); val == nil {\n\t\tpanic(\"ModuleInfo.New must return a non-nil module instance\")\n\t}\n\n\tmodulesMu.Lock()\n\tdefer modulesMu.Unlock()\n\n\tif _, ok := modules[string(mod.ID)]; ok {\n\t\tpanic(fmt.Sprintf(\"module already registered: %s\", mod.ID))\n\t}\n\tmodules[string(mod.ID)] = mod\n}\n\n// GetModule returns module information from its ID (full name).\nfunc GetModule(name string) (ModuleInfo, error) {\n\tmodulesMu.RLock()\n\tdefer modulesMu.RUnlock()\n\tm, ok := modules[name]\n\tif !ok {\n\t\treturn ModuleInfo{}, fmt.Errorf(\"module not registered: %s\", name)\n\t}\n\treturn m, nil\n}\n\n// GetModuleName returns a module's name (the last label of its ID)\n// from an instance of its value. If the value is not a module, an\n// empty string will be returned.\nfunc GetModuleName(instance any) string {\n\tvar name string\n\tif mod, ok := instance.(Module); ok {\n\t\tname = mod.CaddyModule().ID.Name()\n\t}\n\treturn name\n}\n\n// GetModuleID returns a module's ID from an instance of its value.\n// If the value is not a module, an empty string will be returned.\nfunc GetModuleID(instance any) string {\n\tvar id string\n\tif mod, ok := instance.(Module); ok {\n\t\tid = string(mod.CaddyModule().ID)\n\t}\n\treturn id\n}\n\n// GetModules returns all modules in the given scope/namespace.\n// For example, a scope of \"foo\" returns modules named \"foo.bar\",\n// \"foo.loo\", but not \"bar\", \"foo.bar.loo\", etc. An empty scope\n// returns top-level modules, for example \"foo\" or \"bar\". Partial\n// scopes are not matched (i.e. scope \"foo.ba\" does not match\n// name \"foo.bar\").\n//\n// Because modules are registered to a map under the hood, the\n// returned slice will be sorted to keep it deterministic.\nfunc GetModules(scope string) []ModuleInfo {\n\tmodulesMu.RLock()\n\tdefer modulesMu.RUnlock()\n\n\tscopeParts := strings.Split(scope, \".\")\n\n\t// handle the special case of an empty scope, which\n\t// should match only the top-level modules\n\tif scope == \"\" {\n\t\tscopeParts = []string{}\n\t}\n\n\tvar mods []ModuleInfo\niterateModules:\n\tfor id, m := range modules {\n\t\tmodParts := strings.Split(id, \".\")\n\n\t\t// match only the next level of nesting\n\t\tif len(modParts) != len(scopeParts)+1 {\n\t\t\tcontinue\n\t\t}\n\n\t\t// specified parts must be exact matches\n\t\tfor i := range scopeParts {\n\t\t\tif modParts[i] != scopeParts[i] {\n\t\t\t\tcontinue iterateModules\n\t\t\t}\n\t\t}\n\n\t\tmods = append(mods, m)\n\t}\n\n\t// make return value deterministic\n\tsort.Slice(mods, func(i, j int) bool {\n\t\treturn mods[i].ID < mods[j].ID\n\t})\n\n\treturn mods\n}\n\n// Modules returns the names of all registered modules\n// in ascending lexicographical order.\nfunc Modules() []string {\n\tmodulesMu.RLock()\n\tdefer modulesMu.RUnlock()\n\n\tnames := make([]string, 0, len(modules))\n\tfor name := range modules {\n\t\tnames = append(names, name)\n\t}\n\n\tsort.Strings(names)\n\n\treturn names\n}\n\n// getModuleNameInline loads the string value from raw of moduleNameKey,\n// where raw must be a JSON encoding of a map. It returns that value,\n// along with the result of removing that key from raw.\nfunc getModuleNameInline(moduleNameKey string, raw json.RawMessage) (string, json.RawMessage, error) {\n\tvar tmp map[string]any\n\terr := json.Unmarshal(raw, &tmp)\n\tif err != nil {\n\t\treturn \"\", nil, err\n\t}\n\n\tmoduleName, ok := tmp[moduleNameKey].(string)\n\tif !ok || moduleName == \"\" {\n\t\treturn \"\", nil, fmt.Errorf(\"module name not specified with key '%s' in %+v\", moduleNameKey, tmp)\n\t}\n\n\t// remove key from the object, otherwise decoding it later\n\t// will yield an error because the struct won't recognize it\n\t// (this is only needed because we strictly enforce that\n\t// all keys are recognized when loading modules)\n\tdelete(tmp, moduleNameKey)\n\tresult, err := json.Marshal(tmp)\n\tif err != nil {\n\t\treturn \"\", nil, fmt.Errorf(\"re-encoding module configuration: %v\", err)\n\t}\n\n\treturn moduleName, result, nil\n}\n\n// Provisioner is implemented by modules which may need to perform\n// some additional \"setup\" steps immediately after being loaded.\n// Provisioning should be fast (imperceptible running time). If\n// any side-effects result in the execution of this function (e.g.\n// creating global state, any other allocations which require\n// garbage collection, opening files, starting goroutines etc.),\n// be sure to clean up properly by implementing the CleanerUpper\n// interface to avoid leaking resources.\ntype Provisioner interface {\n\tProvision(Context) error\n}\n\n// Validator is implemented by modules which can verify that their\n// configurations are valid. This method will be called after\n// Provision() (if implemented). Validation should always be fast\n// (imperceptible running time) and an error must be returned if\n// the module's configuration is invalid.\ntype Validator interface {\n\tValidate() error\n}\n\n// CleanerUpper is implemented by modules which may have side-effects\n// such as opened files, spawned goroutines, or allocated some sort\n// of non-stack state when they were provisioned. This method should\n// deallocate/cleanup those resources to prevent memory leaks. Cleanup\n// should be fast and efficient. Cleanup should work even if Provision\n// returns an error, to allow cleaning up from partial provisionings.\ntype CleanerUpper interface {\n\tCleanup() error\n}\n\n// ParseStructTag parses a caddy struct tag into its keys and values.\n// It is very simple. The expected syntax is:\n// `caddy:\"key1=val1 key2=val2 ...\"`\nfunc ParseStructTag(tag string) (map[string]string, error) {\n\tresults := make(map[string]string)\n\tpairs := strings.Split(tag, \" \")\n\tfor i, pair := range pairs {\n\t\tif pair == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tbefore, after, isCut := strings.Cut(pair, \"=\")\n\t\tif !isCut {\n\t\t\treturn nil, fmt.Errorf(\"missing key in '%s' (pair %d)\", pair, i)\n\t\t}\n\t\tresults[before] = after\n\t}\n\treturn results, nil\n}\n\n// StrictUnmarshalJSON is like json.Unmarshal but returns an error\n// if any of the fields are unrecognized. Useful when decoding\n// module configurations, where you want to be more sure they're\n// correct.\nfunc StrictUnmarshalJSON(data []byte, v any) error {\n\tdec := json.NewDecoder(bytes.NewReader(data))\n\tdec.DisallowUnknownFields()\n\treturn dec.Decode(v)\n}\n\n// isJSONRawMessage returns true if the type is encoding/json.RawMessage.\nfunc isJSONRawMessage(typ reflect.Type) bool {\n\treturn typ.PkgPath() == \"encoding/json\" && typ.Name() == \"RawMessage\"\n}\n\n// isModuleMapType returns true if the type is map[string]json.RawMessage.\n// It assumes that the string key is the module name, but this is not\n// always the case. To know for sure, this function must return true, but\n// also the struct tag where this type appears must NOT define an inline_key\n// attribute, which would mean that the module names appear inline with the\n// values, not in the key.\nfunc isModuleMapType(typ reflect.Type) bool {\n\treturn typ.Kind() == reflect.Map &&\n\t\ttyp.Key().Kind() == reflect.String &&\n\t\tisJSONRawMessage(typ.Elem())\n}\n\n// ProxyFuncProducer is implemented by modules which produce a\n// function that returns a URL to use as network proxy. Modules\n// in the namespace `caddy.network_proxy` must implement this\n// interface.\ntype ProxyFuncProducer interface {\n\tProxyFunc() func(*http.Request) (*url.URL, error)\n}\n\nvar (\n\tmodules   = make(map[string]ModuleInfo)\n\tmodulesMu sync.RWMutex\n)\n",
    "source_file": "modules.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddycmd\n\nimport (\n\t// For running in minimal environments, this can ease\n\t// headaches related to establishing TLS connections.\n\t// \"Package fallback embeds a set of fallback X.509 trusted\n\t// roots in the application by automatically invoking\n\t// x509.SetFallbackRoots. This allows the application to\n\t// work correctly even if the operating system does not\n\t// provide a verifier or system roots pool. ... It's\n\t// recommended that only binaries, and not libraries,\n\t// import this package. This package must be kept up to\n\t// date for security and compatibility reasons.\"\n\t//\n\t// This is in its own file only because of conflicts\n\t// between gci and goimports when in main.go.\n\t// See https://github.com/daixiang0/gci/issues/76\n\t_ \"golang.org/x/crypto/x509roots/fallback\"\n)\n",
    "source_file": "cmd/x509rootsfallback.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddycmd\n\nimport (\n\t\"os\"\n\t\"path/filepath\"\n\t\"syscall\"\n)\n\n// removeCaddyBinary removes the Caddy binary at the given path.\n//\n// On Windows, this uses a syscall to indirectly remove the file,\n// because otherwise we get an \"Access is denied.\" error when trying\n// to delete the binary while Caddy is still running and performing\n// the upgrade. \"cmd.exe /C\" executes a command specified by the\n// following arguments, i.e. \"del\" which will run as a separate process,\n// which avoids the \"Access is denied.\" error.\nfunc removeCaddyBinary(path string) error {\n\tvar sI syscall.StartupInfo\n\tvar pI syscall.ProcessInformation\n\targv, err := syscall.UTF16PtrFromString(filepath.Join(os.Getenv(\"windir\"), \"system32\", \"cmd.exe\") + \" /C del \" + path)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn syscall.CreateProcess(nil, argv, nil, nil, true, 0, nil, nil, &sI, &pI)\n}\n",
    "source_file": "cmd/removebinary_windows.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddycmd\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/rand\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"log\"\n\t\"maps\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"os/exec\"\n\t\"runtime\"\n\t\"runtime/debug\"\n\t\"strings\"\n\n\t\"github.com/aryann/difflib\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/internal\"\n)\n\nfunc cmdStart(fl Flags) (int, error) {\n\tconfigFlag := fl.String(\"config\")\n\tconfigAdapterFlag := fl.String(\"adapter\")\n\tpidfileFlag := fl.String(\"pidfile\")\n\twatchFlag := fl.Bool(\"watch\")\n\n\tvar err error\n\tvar envfileFlag []string\n\tenvfileFlag, err = fl.GetStringSlice(\"envfile\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"reading envfile flag: %v\", err)\n\t}\n\n\t// open a listener to which the child process will connect when\n\t// it is ready to confirm that it has successfully started\n\tln, err := net.Listen(\"tcp\", \"127.0.0.1:0\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"opening listener for success confirmation: %v\", err)\n\t}\n\tdefer ln.Close()\n\n\t// craft the command with a pingback address and with a\n\t// pipe for its stdin, so we can tell it our confirmation\n\t// code that we expect so that some random port scan at\n\t// the most unfortunate time won't fool us into thinking\n\t// the child succeeded (i.e. the alternative is to just\n\t// wait for any connection on our listener, but better to\n\t// ensure it's the process we're expecting - we can be\n\t// sure by giving it some random bytes and having it echo\n\t// them back to us)\n\tcmd := exec.Command(os.Args[0], \"run\", \"--pingback\", ln.Addr().String())\n\t// we should be able to run caddy in relative paths\n\tif errors.Is(cmd.Err, exec.ErrDot) {\n\t\tcmd.Err = nil\n\t}\n\tif configFlag != \"\" {\n\t\tcmd.Args = append(cmd.Args, \"--config\", configFlag)\n\t}\n\n\tfor _, envfile := range envfileFlag {\n\t\tcmd.Args = append(cmd.Args, \"--envfile\", envfile)\n\t}\n\tif configAdapterFlag != \"\" {\n\t\tcmd.Args = append(cmd.Args, \"--adapter\", configAdapterFlag)\n\t}\n\tif watchFlag {\n\t\tcmd.Args = append(cmd.Args, \"--watch\")\n\t}\n\tif pidfileFlag != \"\" {\n\t\tcmd.Args = append(cmd.Args, \"--pidfile\", pidfileFlag)\n\t}\n\tstdinPipe, err := cmd.StdinPipe()\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"creating stdin pipe: %v\", err)\n\t}\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\n\t// generate the random bytes we'll send to the child process\n\texpect := make([]byte, 32)\n\t_, err = rand.Read(expect)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"generating random confirmation bytes: %v\", err)\n\t}\n\n\t// begin writing the confirmation bytes to the child's\n\t// stdin; use a goroutine since the child hasn't been\n\t// started yet, and writing synchronously would result\n\t// in a deadlock\n\tgo func() {\n\t\t_, _ = stdinPipe.Write(expect)\n\t\tstdinPipe.Close()\n\t}()\n\n\t// start the process\n\terr = cmd.Start()\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"starting caddy process: %v\", err)\n\t}\n\n\t// there are two ways we know we're done: either\n\t// the process will connect to our listener, or\n\t// it will exit with an error\n\tsuccess, exit := make(chan struct{}), make(chan error)\n\n\t// in one goroutine, we await the success of the child process\n\tgo func() {\n\t\tfor {\n\t\t\tconn, err := ln.Accept()\n\t\t\tif err != nil {\n\t\t\t\tif !errors.Is(err, net.ErrClosed) {\n\t\t\t\t\tlog.Println(err)\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t\terr = handlePingbackConn(conn, expect)\n\t\t\tif err == nil {\n\t\t\t\tclose(success)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tlog.Println(err)\n\t\t}\n\t}()\n\n\t// in another goroutine, we await the failure of the child process\n\tgo func() {\n\t\terr := cmd.Wait() // don't send on this line! Wait blocks, but send starts before it unblocks\n\t\texit <- err       // sending on separate line ensures select won't trigger until after Wait unblocks\n\t}()\n\n\t// when one of the goroutines unblocks, we're done and can exit\n\tselect {\n\tcase <-success:\n\t\tfmt.Printf(\"Successfully started Caddy (pid=%d) - Caddy is running in the background\\n\", cmd.Process.Pid)\n\tcase err := <-exit:\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"caddy process exited with error: %v\", err)\n\t}\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdRun(fl Flags) (int, error) {\n\tcaddy.TrapSignals()\n\n\tlogger := caddy.Log()\n\tundoMaxProcs := setResourceLimits(logger)\n\tdefer undoMaxProcs()\n\n\tconfigFlag := fl.String(\"config\")\n\tconfigAdapterFlag := fl.String(\"adapter\")\n\tresumeFlag := fl.Bool(\"resume\")\n\tprintEnvFlag := fl.Bool(\"environ\")\n\twatchFlag := fl.Bool(\"watch\")\n\tpidfileFlag := fl.String(\"pidfile\")\n\tpingbackFlag := fl.String(\"pingback\")\n\n\t// load all additional envs as soon as possible\n\terr := handleEnvFileFlag(fl)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// if we are supposed to print the environment, do that first\n\tif printEnvFlag {\n\t\tprintEnvironment()\n\t}\n\n\t// load the config, depending on flags\n\tvar config []byte\n\tif resumeFlag {\n\t\tconfig, err = os.ReadFile(caddy.ConfigAutosavePath)\n\t\tif errors.Is(err, fs.ErrNotExist) {\n\t\t\t// not a bad error; just can't resume if autosave file doesn't exist\n\t\t\tlogger.Info(\"no autosave file exists\", zap.String(\"autosave_file\", caddy.ConfigAutosavePath))\n\t\t\tresumeFlag = false\n\t\t} else if err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t} else {\n\t\t\tif configFlag == \"\" {\n\t\t\t\tlogger.Info(\"resuming from last configuration\",\n\t\t\t\t\tzap.String(\"autosave_file\", caddy.ConfigAutosavePath))\n\t\t\t} else {\n\t\t\t\t// if they also specified a config file, user should be aware that we're not\n\t\t\t\t// using it (doing so could lead to data/config loss by overwriting!)\n\t\t\t\tlogger.Warn(\"--config and --resume flags were used together; ignoring --config and resuming from last configuration\",\n\t\t\t\t\tzap.String(\"autosave_file\", caddy.ConfigAutosavePath))\n\t\t\t}\n\t\t}\n\t}\n\t// we don't use 'else' here since this value might have been changed in 'if' block; i.e. not mutually exclusive\n\tvar configFile string\n\tif !resumeFlag {\n\t\tconfig, configFile, err = LoadConfig(configFlag, configAdapterFlag)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\t}\n\n\t// create pidfile now, in case loading config takes a while (issue #5477)\n\tif pidfileFlag != \"\" {\n\t\terr := caddy.PIDFile(pidfileFlag)\n\t\tif err != nil {\n\t\t\tlogger.Error(\"unable to write PID file\",\n\t\t\t\tzap.String(\"pidfile\", pidfileFlag),\n\t\t\t\tzap.Error(err))\n\t\t}\n\t}\n\n\t// run the initial config\n\terr = caddy.Load(config, true)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"loading initial config: %v\", err)\n\t}\n\tlogger.Info(\"serving initial configuration\")\n\n\t// if we are to report to another process the successful start\n\t// of the server, do so now by echoing back contents of stdin\n\tif pingbackFlag != \"\" {\n\t\tconfirmationBytes, err := io.ReadAll(os.Stdin)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\t\tfmt.Errorf(\"reading confirmation bytes from stdin: %v\", err)\n\t\t}\n\t\tconn, err := net.Dial(\"tcp\", pingbackFlag)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\t\tfmt.Errorf(\"dialing confirmation address: %v\", err)\n\t\t}\n\t\tdefer conn.Close()\n\t\t_, err = conn.Write(confirmationBytes)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\t\tfmt.Errorf(\"writing confirmation bytes to %s: %v\", pingbackFlag, err)\n\t\t}\n\t}\n\n\t// if enabled, reload config file automatically on changes\n\t// (this better only be used in dev!)\n\tif watchFlag {\n\t\tgo watchConfigFile(configFile, configAdapterFlag)\n\t}\n\n\t// warn if the environment does not provide enough information about the disk\n\thasXDG := os.Getenv(\"XDG_DATA_HOME\") != \"\" &&\n\t\tos.Getenv(\"XDG_CONFIG_HOME\") != \"\" &&\n\t\tos.Getenv(\"XDG_CACHE_HOME\") != \"\"\n\tswitch runtime.GOOS {\n\tcase \"windows\":\n\t\tif os.Getenv(\"HOME\") == \"\" && os.Getenv(\"USERPROFILE\") == \"\" && !hasXDG {\n\t\t\tlogger.Warn(\"neither HOME nor USERPROFILE environment variables are set - please fix; some assets might be stored in ./caddy\")\n\t\t}\n\tcase \"plan9\":\n\t\tif os.Getenv(\"home\") == \"\" && !hasXDG {\n\t\t\tlogger.Warn(\"$home environment variable is empty - please fix; some assets might be stored in ./caddy\")\n\t\t}\n\tdefault:\n\t\tif os.Getenv(\"HOME\") == \"\" && !hasXDG {\n\t\t\tlogger.Warn(\"$HOME environment variable is empty - please fix; some assets might be stored in ./caddy\")\n\t\t}\n\t}\n\n\tselect {}\n}\n\nfunc cmdStop(fl Flags) (int, error) {\n\taddressFlag := fl.String(\"address\")\n\tconfigFlag := fl.String(\"config\")\n\tconfigAdapterFlag := fl.String(\"adapter\")\n\n\tadminAddr, err := DetermineAdminAPIAddress(addressFlag, nil, configFlag, configAdapterFlag)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"couldn't determine admin API address: %v\", err)\n\t}\n\n\tresp, err := AdminAPIRequest(adminAddr, http.MethodPost, \"/stop\", nil, nil)\n\tif err != nil {\n\t\tcaddy.Log().Warn(\"failed using API to stop instance\", zap.Error(err))\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\tdefer resp.Body.Close()\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdReload(fl Flags) (int, error) {\n\tconfigFlag := fl.String(\"config\")\n\tconfigAdapterFlag := fl.String(\"adapter\")\n\taddressFlag := fl.String(\"address\")\n\tforceFlag := fl.Bool(\"force\")\n\n\t// get the config in caddy's native format\n\tconfig, configFile, err := LoadConfig(configFlag, configAdapterFlag)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\tif configFile == \"\" {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"no config file to load\")\n\t}\n\n\tadminAddr, err := DetermineAdminAPIAddress(addressFlag, config, configFlag, configAdapterFlag)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"couldn't determine admin API address: %v\", err)\n\t}\n\n\t// optionally force a config reload\n\theaders := make(http.Header)\n\tif forceFlag {\n\t\theaders.Set(\"Cache-Control\", \"must-revalidate\")\n\t}\n\n\tresp, err := AdminAPIRequest(adminAddr, http.MethodPost, \"/load\", headers, bytes.NewReader(config))\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"sending configuration to instance: %v\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdVersion(_ Flags) (int, error) {\n\t_, full := caddy.Version()\n\tfmt.Println(full)\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdBuildInfo(_ Flags) (int, error) {\n\tbi, ok := debug.ReadBuildInfo()\n\tif !ok {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"no build information\")\n\t}\n\tfmt.Println(bi)\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdListModules(fl Flags) (int, error) {\n\tpackages := fl.Bool(\"packages\")\n\tversions := fl.Bool(\"versions\")\n\tskipStandard := fl.Bool(\"skip-standard\")\n\n\tprintModuleInfo := func(mi moduleInfo) {\n\t\tfmt.Print(mi.caddyModuleID)\n\t\tif versions && mi.goModule != nil {\n\t\t\tfmt.Print(\" \" + mi.goModule.Version)\n\t\t}\n\t\tif packages && mi.goModule != nil {\n\t\t\tfmt.Print(\" \" + mi.goModule.Path)\n\t\t\tif mi.goModule.Replace != nil {\n\t\t\t\tfmt.Print(\" => \" + mi.goModule.Replace.Path)\n\t\t\t}\n\t\t}\n\t\tif mi.err != nil {\n\t\t\tfmt.Printf(\" [%v]\", mi.err)\n\t\t}\n\t\tfmt.Println()\n\t}\n\n\t// organize modules by whether they come with the standard distribution\n\tstandard, nonstandard, unknown, err := getModules()\n\tif err != nil {\n\t\t// oh well, just print the module IDs and exit\n\t\tfor _, m := range caddy.Modules() {\n\t\t\tfmt.Println(m)\n\t\t}\n\t\treturn caddy.ExitCodeSuccess, nil\n\t}\n\n\t// Standard modules (always shipped with Caddy)\n\tif !skipStandard {\n\t\tif len(standard) > 0 {\n\t\t\tfor _, mod := range standard {\n\t\t\t\tprintModuleInfo(mod)\n\t\t\t}\n\t\t}\n\t\tfmt.Printf(\"\\n  Standard modules: %d\\n\", len(standard))\n\t}\n\n\t// Non-standard modules (third party plugins)\n\tif len(nonstandard) > 0 {\n\t\tif len(standard) > 0 && !skipStandard {\n\t\t\tfmt.Println()\n\t\t}\n\t\tfor _, mod := range nonstandard {\n\t\t\tprintModuleInfo(mod)\n\t\t}\n\t}\n\tfmt.Printf(\"\\n  Non-standard modules: %d\\n\", len(nonstandard))\n\n\t// Unknown modules (couldn't get Caddy module info)\n\tif len(unknown) > 0 {\n\t\tif (len(standard) > 0 && !skipStandard) || len(nonstandard) > 0 {\n\t\t\tfmt.Println()\n\t\t}\n\t\tfor _, mod := range unknown {\n\t\t\tprintModuleInfo(mod)\n\t\t}\n\t}\n\tfmt.Printf(\"\\n  Unknown modules: %d\\n\", len(unknown))\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdEnviron(fl Flags) (int, error) {\n\t// load all additional envs as soon as possible\n\terr := handleEnvFileFlag(fl)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tprintEnvironment()\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdAdaptConfig(fl Flags) (int, error) {\n\tinputFlag := fl.String(\"config\")\n\tadapterFlag := fl.String(\"adapter\")\n\tprettyFlag := fl.Bool(\"pretty\")\n\tvalidateFlag := fl.Bool(\"validate\")\n\n\tvar err error\n\tinputFlag, err = configFileWithRespectToDefault(caddy.Log(), inputFlag)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// load all additional envs as soon as possible\n\terr = handleEnvFileFlag(fl)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tif adapterFlag == \"\" {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"adapter name is required (use --adapt flag or leave unspecified for default)\")\n\t}\n\n\tcfgAdapter := caddyconfig.GetAdapter(adapterFlag)\n\tif cfgAdapter == nil {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"unrecognized config adapter: %s\", adapterFlag)\n\t}\n\n\tinput, err := os.ReadFile(inputFlag)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"reading input file: %v\", err)\n\t}\n\n\topts := map[string]any{\"filename\": inputFlag}\n\n\tadaptedConfig, warnings, err := cfgAdapter.Adapt(input, opts)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tif prettyFlag {\n\t\tvar prettyBuf bytes.Buffer\n\t\terr = json.Indent(&prettyBuf, adaptedConfig, \"\", \"\\t\")\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\t\tadaptedConfig = prettyBuf.Bytes()\n\t}\n\n\t// print result to stdout\n\tfmt.Println(string(adaptedConfig))\n\n\t// print warnings to stderr\n\tfor _, warn := range warnings {\n\t\tmsg := warn.Message\n\t\tif warn.Directive != \"\" {\n\t\t\tmsg = fmt.Sprintf(\"%s: %s\", warn.Directive, warn.Message)\n\t\t}\n\t\tcaddy.Log().Named(adapterFlag).Warn(msg,\n\t\t\tzap.String(\"file\", warn.File),\n\t\t\tzap.Int(\"line\", warn.Line))\n\t}\n\n\t// validate output if requested\n\tif validateFlag {\n\t\tvar cfg *caddy.Config\n\t\terr = caddy.StrictUnmarshalJSON(adaptedConfig, &cfg)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"decoding config: %v\", err)\n\t\t}\n\t\terr = caddy.Validate(cfg)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"validation: %v\", err)\n\t\t}\n\t}\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdValidateConfig(fl Flags) (int, error) {\n\tconfigFlag := fl.String(\"config\")\n\tadapterFlag := fl.String(\"adapter\")\n\n\t// load all additional envs as soon as possible\n\terr := handleEnvFileFlag(fl)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// use default config and ensure a config file is specified\n\tconfigFlag, err = configFileWithRespectToDefault(caddy.Log(), configFlag)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\tif configFlag == \"\" {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"input file required when there is no Caddyfile in current directory (use --config flag)\")\n\t}\n\n\tinput, _, err := LoadConfig(configFlag, adapterFlag)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\tinput = caddy.RemoveMetaFields(input)\n\n\tvar cfg *caddy.Config\n\terr = caddy.StrictUnmarshalJSON(input, &cfg)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"decoding config: %v\", err)\n\t}\n\n\terr = caddy.Validate(cfg)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tfmt.Println(\"Valid configuration\")\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdFmt(fl Flags) (int, error) {\n\tconfigFile := fl.Arg(0)\n\tconfigFlag := fl.String(\"config\")\n\tif (len(fl.Args()) > 1) || (configFlag != \"\" && configFile != \"\") {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"fmt does not support multiple files %s %s\", configFlag, strings.Join(fl.Args(), \" \"))\n\t}\n\tif configFile == \"\" && configFlag == \"\" {\n\t\tconfigFile = \"Caddyfile\"\n\t} else if configFile == \"\" {\n\t\tconfigFile = configFlag\n\t}\n\t// as a special case, read from stdin if the file name is \"-\"\n\tif configFile == \"-\" {\n\t\tinput, err := io.ReadAll(os.Stdin)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\t\tfmt.Errorf(\"reading stdin: %v\", err)\n\t\t}\n\t\tfmt.Print(string(caddyfile.Format(input)))\n\t\treturn caddy.ExitCodeSuccess, nil\n\t}\n\n\tinput, err := os.ReadFile(configFile)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup,\n\t\t\tfmt.Errorf(\"reading input file: %v\", err)\n\t}\n\n\toutput := caddyfile.Format(input)\n\n\tif fl.Bool(\"overwrite\") {\n\t\tif err := os.WriteFile(configFile, output, 0o600); err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"overwriting formatted file: %v\", err)\n\t\t}\n\t\treturn caddy.ExitCodeSuccess, nil\n\t}\n\n\tif fl.Bool(\"diff\") {\n\t\tdiff := difflib.Diff(\n\t\t\tstrings.Split(string(input), \"\\n\"),\n\t\t\tstrings.Split(string(output), \"\\n\"))\n\t\tfor _, d := range diff {\n\t\t\tswitch d.Delta {\n\t\t\tcase difflib.Common:\n\t\t\t\tfmt.Printf(\"  %s\\n\", d.Payload)\n\t\t\tcase difflib.LeftOnly:\n\t\t\t\tfmt.Printf(\"- %s\\n\", d.Payload)\n\t\t\tcase difflib.RightOnly:\n\t\t\t\tfmt.Printf(\"+ %s\\n\", d.Payload)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tfmt.Print(string(output))\n\t}\n\n\tif warning, diff := caddyfile.FormattingDifference(configFile, input); diff {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(`%s:%d: Caddyfile input is not formatted; Tip: use '--overwrite' to update your Caddyfile in-place instead of previewing it. Consult '--help' for more options`,\n\t\t\twarning.File,\n\t\t\twarning.Line,\n\t\t)\n\t}\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\n// handleEnvFileFlag loads the environment variables from the given --envfile\n// flag if specified. This should be called as early in the command function.\nfunc handleEnvFileFlag(fl Flags) error {\n\tvar err error\n\tvar envfileFlag []string\n\tenvfileFlag, err = fl.GetStringSlice(\"envfile\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"reading envfile flag: %v\", err)\n\t}\n\n\tfor _, envfile := range envfileFlag {\n\t\tif err := loadEnvFromFile(envfile); err != nil {\n\t\t\treturn fmt.Errorf(\"loading additional environment variables: %v\", err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// AdminAPIRequest makes an API request according to the CLI flags given,\n// with the given HTTP method and request URI. If body is non-nil, it will\n// be assumed to be Content-Type application/json. The caller should close\n// the response body. Should only be used by Caddy CLI commands which\n// need to interact with a running instance of Caddy via the admin API.\nfunc AdminAPIRequest(adminAddr, method, uri string, headers http.Header, body io.Reader) (*http.Response, error) {\n\tparsedAddr, err := caddy.ParseNetworkAddress(adminAddr)\n\tif err != nil || parsedAddr.PortRangeSize() > 1 {\n\t\treturn nil, fmt.Errorf(\"invalid admin address %s: %v\", adminAddr, err)\n\t}\n\torigin := \"http://\" + parsedAddr.JoinHostPort(0)\n\tif parsedAddr.IsUnixNetwork() {\n\t\torigin = \"http://127.0.0.1\" // bogus host is a hack so that http.NewRequest() is happy\n\n\t\t// the unix address at this point might still contain the optional\n\t\t// unix socket permissions, which are part of the address/host.\n\t\t// those need to be removed first, as they aren't part of the\n\t\t// resulting unix file path\n\t\taddr, _, err := internal.SplitUnixSocketPermissionsBits(parsedAddr.Host)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tparsedAddr.Host = addr\n\t} else if parsedAddr.IsFdNetwork() {\n\t\torigin = \"http://127.0.0.1\"\n\t}\n\n\t// form the request\n\treq, err := http.NewRequest(method, origin+uri, body)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"making request: %v\", err)\n\t}\n\tif parsedAddr.IsUnixNetwork() || parsedAddr.IsFdNetwork() {\n\t\t// We used to conform to RFC 2616 Section 14.26 which requires\n\t\t// an empty host header when there is no host, as is the case\n\t\t// with unix sockets and socket fds. However, Go required a\n\t\t// Host value so we used a hack of a space character as the host\n\t\t// (it would see the Host was non-empty, then trim the space later).\n\t\t// As of Go 1.20.6 (July 2023), this hack no longer works. See:\n\t\t// https://github.com/golang/go/issues/60374\n\t\t// See also the discussion here:\n\t\t// https://github.com/golang/go/issues/61431\n\t\t//\n\t\t// After that, we now require a Host value of either 127.0.0.1\n\t\t// or ::1 if one is set. Above I choose to use 127.0.0.1. Even\n\t\t// though the value should be completely irrelevant (it could be\n\t\t// \"srldkjfsd\"), if for some reason the Host *is* used, at least\n\t\t// we can have some reasonable assurance it will stay on the local\n\t\t// machine and that browsers, if they ever allow access to unix\n\t\t// sockets, can still enforce CORS, ensuring it is still coming\n\t\t// from the local machine.\n\t} else {\n\t\treq.Header.Set(\"Origin\", origin)\n\t}\n\tif body != nil {\n\t\treq.Header.Set(\"Content-Type\", \"application/json\")\n\t}\n\tmaps.Copy(req.Header, headers)\n\n\t// make an HTTP client that dials our network type, since admin\n\t// endpoints aren't always TCP, which is what the default transport\n\t// expects; reuse is not of particular concern here\n\tclient := http.Client{\n\t\tTransport: &http.Transport{\n\t\t\tDialContext: func(_ context.Context, _, _ string) (net.Conn, error) {\n\t\t\t\treturn net.Dial(parsedAddr.Network, parsedAddr.JoinHostPort(0))\n\t\t\t},\n\t\t},\n\t}\n\n\tresp, err := client.Do(req)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"performing request: %v\", err)\n\t}\n\n\t// if it didn't work, let the user know\n\tif resp.StatusCode >= 400 {\n\t\trespBody, err := io.ReadAll(io.LimitReader(resp.Body, 1024*1024*2))\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"HTTP %d: reading error message: %v\", resp.StatusCode, err)\n\t\t}\n\t\treturn nil, fmt.Errorf(\"caddy responded with error: HTTP %d: %s\", resp.StatusCode, respBody)\n\t}\n\n\treturn resp, nil\n}\n\n// DetermineAdminAPIAddress determines which admin API endpoint address should\n// be used based on the inputs. By priority: if `address` is specified, then\n// it is returned; if `config` is specified, then that config will be used for\n// finding the admin address; if `configFile` (and `configAdapter`) are specified,\n// then that config will be loaded to find the admin address; otherwise, the\n// default admin listen address will be returned.\nfunc DetermineAdminAPIAddress(address string, config []byte, configFile, configAdapter string) (string, error) {\n\t// Prefer the address if specified and non-empty\n\tif address != \"\" {\n\t\treturn address, nil\n\t}\n\n\t// Try to load the config from file if specified, with the given adapter name\n\tif configFile != \"\" {\n\t\tvar loadedConfigFile string\n\t\tvar err error\n\n\t\t// use the provided loaded config if non-empty\n\t\t// otherwise, load it from the specified file/adapter\n\t\tloadedConfig := config\n\t\tif len(loadedConfig) == 0 {\n\t\t\t// get the config in caddy's native format\n\t\t\tloadedConfig, loadedConfigFile, err = LoadConfig(configFile, configAdapter)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", err\n\t\t\t}\n\t\t\tif loadedConfigFile == \"\" {\n\t\t\t\treturn \"\", fmt.Errorf(\"no config file to load; either use --config flag or ensure Caddyfile exists in current directory\")\n\t\t\t}\n\t\t}\n\n\t\t// get the address of the admin listener from the config\n\t\tif len(loadedConfig) > 0 {\n\t\t\tvar tmpStruct struct {\n\t\t\t\tAdmin caddy.AdminConfig `json:\"admin\"`\n\t\t\t}\n\t\t\terr := json.Unmarshal(loadedConfig, &tmpStruct)\n\t\t\tif err != nil {\n\t\t\t\treturn \"\", fmt.Errorf(\"unmarshaling admin listener address from config: %v\", err)\n\t\t\t}\n\t\t\tif tmpStruct.Admin.Listen != \"\" {\n\t\t\t\treturn tmpStruct.Admin.Listen, nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// Fallback to the default listen address otherwise\n\treturn caddy.DefaultAdminListen, nil\n}\n\n// configFileWithRespectToDefault returns the filename to use for loading the config, based\n// on whether a config file is already specified and a supported default config file exists.\nfunc configFileWithRespectToDefault(logger *zap.Logger, configFile string) (string, error) {\n\tconst defaultCaddyfile = \"Caddyfile\"\n\n\t// if no input file was specified, try a default Caddyfile if the Caddyfile adapter is plugged in\n\tif configFile == \"\" && caddyconfig.GetAdapter(\"caddyfile\") != nil {\n\t\t_, err := os.Stat(defaultCaddyfile)\n\t\tif err == nil {\n\t\t\t// default Caddyfile exists\n\t\t\tif logger != nil {\n\t\t\t\tlogger.Info(\"using adjacent Caddyfile\")\n\t\t\t}\n\t\t\treturn defaultCaddyfile, nil\n\t\t}\n\t\tif !errors.Is(err, fs.ErrNotExist) {\n\t\t\t// problem checking\n\t\t\treturn configFile, fmt.Errorf(\"checking if default Caddyfile exists: %v\", err)\n\t\t}\n\t}\n\n\t// default config file does not exist or is irrelevant\n\treturn configFile, nil\n}\n\ntype moduleInfo struct {\n\tcaddyModuleID string\n\tgoModule      *debug.Module\n\terr           error\n}\n",
    "source_file": "cmd/commandfuncs.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build !windows\n\npackage caddycmd\n\nimport (\n\t\"os\"\n)\n\n// removeCaddyBinary removes the Caddy binary at the given path.\n//\n// On any non-Windows OS, this simply calls os.Remove, since they should\n// probably not exhibit any issue with processes deleting themselves.\nfunc removeCaddyBinary(path string) error {\n\treturn os.Remove(path)\n}\n",
    "source_file": "cmd/removebinary.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddycmd\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/spf13/cobra\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nvar defaultFactory = newRootCommandFactory(func() *cobra.Command {\n\treturn &cobra.Command{\n\t\tUse: \"caddy\",\n\t\tLong: `Caddy is an extensible server platform written in Go.\n\nAt its core, Caddy merely manages configuration. Modules are plugged\nin statically at compile-time to provide useful functionality. Caddy's\nstandard distribution includes common modules to serve HTTP, TLS,\nand PKI applications, including the automation of certificates.\n\nTo run Caddy, use:\n\n\t- 'caddy run' to run Caddy in the foreground (recommended).\n\t- 'caddy start' to start Caddy in the background; only do this\n\t  if you will be keeping the terminal window open until you run\n\t  'caddy stop' to close the server.\n\nWhen Caddy is started, it opens a locally-bound administrative socket\nto which configuration can be POSTed via a restful HTTP API (see\nhttps://caddyserver.com/docs/api).\n\nCaddy's native configuration format is JSON. However, config adapters\ncan be used to convert other config formats to JSON when Caddy receives\nits configuration. The Caddyfile is a built-in config adapter that is\npopular for hand-written configurations due to its straightforward\nsyntax (see https://caddyserver.com/docs/caddyfile). Many third-party\nadapters are available (see https://caddyserver.com/docs/config-adapters).\nUse 'caddy adapt' to see how a config translates to JSON.\n\nFor convenience, the CLI can act as an HTTP client to give Caddy its\ninitial configuration for you. If a file named Caddyfile is in the\ncurrent working directory, it will do this automatically. Otherwise,\nyou can use the --config flag to specify the path to a config file.\n\nSome special-purpose subcommands build and load a configuration file\nfor you directly from command line input; for example:\n\n\t- caddy file-server\n\t- caddy reverse-proxy\n\t- caddy respond\n\nThese commands disable the administration endpoint because their\nconfiguration is specified solely on the command line.\n\nIn general, the most common way to run Caddy is simply:\n\n\t$ caddy run\n\nOr, with a configuration file:\n\n\t$ caddy run --config caddy.json\n\nIf running interactively in a terminal, running Caddy in the\nbackground may be more convenient:\n\n\t$ caddy start\n\t...\n\t$ caddy stop\n\nThis allows you to run other commands while Caddy stays running.\nBe sure to stop Caddy before you close the terminal!\n\nDepending on the system, Caddy may need permission to bind to low\nports. One way to do this on Linux is to use setcap:\n\n\t$ sudo setcap cap_net_bind_service=+ep $(which caddy)\n\nRemember to run that command again after replacing the binary.\n\nSee the Caddy website for tutorials, configuration structure,\nsyntax, and module documentation: https://caddyserver.com/docs/\n\nCustom Caddy builds are available on the Caddy download page at:\nhttps://caddyserver.com/download\n\nThe xcaddy command can be used to build Caddy from source with or\nwithout additional plugins: https://github.com/caddyserver/xcaddy\n\nWhere possible, Caddy should be installed using officially-supported\npackage installers: https://caddyserver.com/docs/install\n\nInstructions for running Caddy in production are also available:\nhttps://caddyserver.com/docs/running\n`,\n\t\tExample: `  $ caddy run\n  $ caddy run --config caddy.json\n  $ caddy reload --config caddy.json\n  $ caddy stop`,\n\n\t\t// kind of annoying to have all the help text printed out if\n\t\t// caddy has an error provisioning its modules, for instance...\n\t\tSilenceUsage: true,\n\t\tVersion:      onlyVersionText(),\n\t}\n})\n\nconst fullDocsFooter = `Full documentation is available at:\nhttps://caddyserver.com/docs/command-line`\n\nfunc init() {\n\tdefaultFactory.Use(func(rootCmd *cobra.Command) {\n\t\trootCmd.SetVersionTemplate(\"{{.Version}}\\n\")\n\t\trootCmd.SetHelpTemplate(rootCmd.HelpTemplate() + \"\\n\" + fullDocsFooter + \"\\n\")\n\t})\n}\n\nfunc onlyVersionText() string {\n\t_, f := caddy.Version()\n\treturn f\n}\n\nfunc caddyCmdToCobra(caddyCmd Command) *cobra.Command {\n\tcmd := &cobra.Command{\n\t\tUse:   caddyCmd.Name + \" \" + caddyCmd.Usage,\n\t\tShort: caddyCmd.Short,\n\t\tLong:  caddyCmd.Long,\n\t}\n\tif caddyCmd.CobraFunc != nil {\n\t\tcaddyCmd.CobraFunc(cmd)\n\t} else {\n\t\tcmd.RunE = WrapCommandFuncForCobra(caddyCmd.Func)\n\t\tcmd.Flags().AddGoFlagSet(caddyCmd.Flags)\n\t}\n\treturn cmd\n}\n\n// WrapCommandFuncForCobra wraps a Caddy CommandFunc for use\n// in a cobra command's RunE field.\nfunc WrapCommandFuncForCobra(f CommandFunc) func(cmd *cobra.Command, _ []string) error {\n\treturn func(cmd *cobra.Command, _ []string) error {\n\t\tstatus, err := f(Flags{cmd.Flags()})\n\t\tif status > 1 {\n\t\t\tcmd.SilenceErrors = true\n\t\t\treturn &exitError{ExitCode: status, Err: err}\n\t\t}\n\t\treturn err\n\t}\n}\n\n// exitError carries the exit code from CommandFunc to Main()\ntype exitError struct {\n\tExitCode int\n\tErr      error\n}\n\nfunc (e *exitError) Error() string {\n\tif e.Err == nil {\n\t\treturn fmt.Sprintf(\"exiting with status %d\", e.ExitCode)\n\t}\n\treturn e.Err.Error()\n}\n",
    "source_file": "cmd/cobra.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddycmd\n\nimport (\n\t\"archive/tar\"\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"os\"\n\n\t\"github.com/caddyserver/certmagic\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\ntype storVal struct {\n\tStorageRaw json.RawMessage `json:\"storage,omitempty\" caddy:\"namespace=caddy.storage inline_key=module\"`\n}\n\n// determineStorage returns the top-level storage module from the given config.\n// It may return nil even if no error.\nfunc determineStorage(configFile string, configAdapter string) (*storVal, error) {\n\tcfg, _, err := LoadConfig(configFile, configAdapter)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// storage defaults to FileStorage if not explicitly\n\t// defined in the config, so the config can be valid\n\t// json but unmarshaling will fail.\n\tif !json.Valid(cfg) {\n\t\treturn nil, &json.SyntaxError{}\n\t}\n\tvar tmpStruct storVal\n\terr = json.Unmarshal(cfg, &tmpStruct)\n\tif err != nil {\n\t\t// default case, ignore the error\n\t\tvar jsonError *json.SyntaxError\n\t\tif errors.As(err, &jsonError) {\n\t\t\treturn nil, nil\n\t\t}\n\t\treturn nil, err\n\t}\n\n\treturn &tmpStruct, nil\n}\n\nfunc cmdImportStorage(fl Flags) (int, error) {\n\timportStorageCmdConfigFlag := fl.String(\"config\")\n\timportStorageCmdImportFile := fl.String(\"input\")\n\n\tif importStorageCmdConfigFlag == \"\" {\n\t\treturn caddy.ExitCodeFailedStartup, errors.New(\"--config is required\")\n\t}\n\tif importStorageCmdImportFile == \"\" {\n\t\treturn caddy.ExitCodeFailedStartup, errors.New(\"--input is required\")\n\t}\n\n\t// extract storage from config if possible\n\tstorageCfg, err := determineStorage(importStorageCmdConfigFlag, \"\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// load specified storage or fallback to default\n\tvar stor certmagic.Storage\n\tctx, cancel := caddy.NewContext(caddy.Context{Context: context.Background()})\n\tdefer cancel()\n\tif storageCfg != nil && storageCfg.StorageRaw != nil {\n\t\tval, err := ctx.LoadModule(storageCfg, \"StorageRaw\")\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\t\tstor, err = val.(caddy.StorageConverter).CertMagicStorage()\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\t} else {\n\t\tstor = caddy.DefaultStorage\n\t}\n\n\t// setup input\n\tvar f *os.File\n\tif importStorageCmdImportFile == \"-\" {\n\t\tf = os.Stdin\n\t} else {\n\t\tf, err = os.Open(importStorageCmdImportFile)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"opening input file: %v\", err)\n\t\t}\n\t\tdefer f.Close()\n\t}\n\n\t// store each archive element\n\ttr := tar.NewReader(f)\n\tfor {\n\t\thdr, err := tr.Next()\n\t\tif err == io.EOF {\n\t\t\tbreak\n\t\t}\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedQuit, fmt.Errorf(\"reading archive: %v\", err)\n\t\t}\n\n\t\tb, err := io.ReadAll(tr)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedQuit, fmt.Errorf(\"reading archive: %v\", err)\n\t\t}\n\n\t\terr = stor.Store(ctx, hdr.Name, b)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedQuit, fmt.Errorf(\"reading archive: %v\", err)\n\t\t}\n\t}\n\n\tfmt.Println(\"Successfully imported storage\")\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdExportStorage(fl Flags) (int, error) {\n\texportStorageCmdConfigFlag := fl.String(\"config\")\n\texportStorageCmdOutputFlag := fl.String(\"output\")\n\n\tif exportStorageCmdConfigFlag == \"\" {\n\t\treturn caddy.ExitCodeFailedStartup, errors.New(\"--config is required\")\n\t}\n\tif exportStorageCmdOutputFlag == \"\" {\n\t\treturn caddy.ExitCodeFailedStartup, errors.New(\"--output is required\")\n\t}\n\n\t// extract storage from config if possible\n\tstorageCfg, err := determineStorage(exportStorageCmdConfigFlag, \"\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// load specified storage or fallback to default\n\tvar stor certmagic.Storage\n\tctx, cancel := caddy.NewContext(caddy.Context{Context: context.Background()})\n\tdefer cancel()\n\tif storageCfg != nil && storageCfg.StorageRaw != nil {\n\t\tval, err := ctx.LoadModule(storageCfg, \"StorageRaw\")\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\t\tstor, err = val.(caddy.StorageConverter).CertMagicStorage()\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\t} else {\n\t\tstor = caddy.DefaultStorage\n\t}\n\n\t// enumerate all keys\n\tkeys, err := stor.List(ctx, \"\", true)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// setup output\n\tvar f *os.File\n\tif exportStorageCmdOutputFlag == \"-\" {\n\t\tf = os.Stdout\n\t} else {\n\t\tf, err = os.Create(exportStorageCmdOutputFlag)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"opening output file: %v\", err)\n\t\t}\n\t\tdefer f.Close()\n\t}\n\n\t// `IsTerminal: true` keys hold the values we\n\t// care about, write them out\n\ttw := tar.NewWriter(f)\n\tfor _, k := range keys {\n\t\tinfo, err := stor.Stat(ctx, k)\n\t\tif err != nil {\n\t\t\tif errors.Is(err, fs.ErrNotExist) {\n\t\t\t\tcaddy.Log().Warn(fmt.Sprintf(\"key: %s removed while export is in-progress\", k))\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn caddy.ExitCodeFailedQuit, err\n\t\t}\n\n\t\tif info.IsTerminal {\n\t\t\tv, err := stor.Load(ctx, k)\n\t\t\tif err != nil {\n\t\t\t\tif errors.Is(err, fs.ErrNotExist) {\n\t\t\t\t\tcaddy.Log().Warn(fmt.Sprintf(\"key: %s removed while export is in-progress\", k))\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\treturn caddy.ExitCodeFailedQuit, err\n\t\t\t}\n\n\t\t\thdr := &tar.Header{\n\t\t\t\tName:    k,\n\t\t\t\tMode:    0o600,\n\t\t\t\tSize:    int64(len(v)),\n\t\t\t\tModTime: info.Modified,\n\t\t\t}\n\n\t\t\tif err = tw.WriteHeader(hdr); err != nil {\n\t\t\t\treturn caddy.ExitCodeFailedQuit, fmt.Errorf(\"writing archive: %v\", err)\n\t\t\t}\n\t\t\tif _, err = tw.Write(v); err != nil {\n\t\t\t\treturn caddy.ExitCodeFailedQuit, fmt.Errorf(\"writing archive: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n\tif err = tw.Close(); err != nil {\n\t\treturn caddy.ExitCodeFailedQuit, fmt.Errorf(\"writing archive: %v\", err)\n\t}\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n",
    "source_file": "cmd/storagefuncs.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddycmd\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"os/exec\"\n\t\"path/filepath\"\n\t\"reflect\"\n\t\"runtime\"\n\t\"runtime/debug\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc cmdUpgrade(fl Flags) (int, error) {\n\t_, nonstandard, _, err := getModules()\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"unable to enumerate installed plugins: %v\", err)\n\t}\n\tpluginPkgs, err := getPluginPackages(nonstandard)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\treturn upgradeBuild(pluginPkgs, fl)\n}\n\nfunc splitModule(arg string) (module, version string, err error) {\n\tconst versionSplit = \"@\"\n\n\t// accommodate module paths that have @ in them, but we can only tolerate that if there's also\n\t// a version, otherwise we don't know if it's a version separator or part of the file path\n\tlastVersionSplit := strings.LastIndex(arg, versionSplit)\n\tif lastVersionSplit < 0 {\n\t\tmodule = arg\n\t} else {\n\t\tmodule, version = arg[:lastVersionSplit], arg[lastVersionSplit+1:]\n\t}\n\n\tif module == \"\" {\n\t\terr = fmt.Errorf(\"module name is required\")\n\t}\n\n\treturn\n}\n\nfunc cmdAddPackage(fl Flags) (int, error) {\n\tif len(fl.Args()) == 0 {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"at least one package name must be specified\")\n\t}\n\t_, nonstandard, _, err := getModules()\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"unable to enumerate installed plugins: %v\", err)\n\t}\n\tpluginPkgs, err := getPluginPackages(nonstandard)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tfor _, arg := range fl.Args() {\n\t\tmodule, version, err := splitModule(arg)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid module name: %v\", err)\n\t\t}\n\t\t// only allow a version to be specified if it's different from the existing version\n\t\tif _, ok := pluginPkgs[module]; ok && (version == \"\" || pluginPkgs[module].Version == version) {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"package is already added\")\n\t\t}\n\t\tpluginPkgs[module] = pluginPackage{Version: version, Path: module}\n\t}\n\n\treturn upgradeBuild(pluginPkgs, fl)\n}\n\nfunc cmdRemovePackage(fl Flags) (int, error) {\n\tif len(fl.Args()) == 0 {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"at least one package name must be specified\")\n\t}\n\t_, nonstandard, _, err := getModules()\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"unable to enumerate installed plugins: %v\", err)\n\t}\n\tpluginPkgs, err := getPluginPackages(nonstandard)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tfor _, arg := range fl.Args() {\n\t\tmodule, _, err := splitModule(arg)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid module name: %v\", err)\n\t\t}\n\t\tif _, ok := pluginPkgs[module]; !ok {\n\t\t\t// package does not exist\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"package is not added\")\n\t\t}\n\t\tdelete(pluginPkgs, arg)\n\t}\n\n\treturn upgradeBuild(pluginPkgs, fl)\n}\n\nfunc upgradeBuild(pluginPkgs map[string]pluginPackage, fl Flags) (int, error) {\n\tl := caddy.Log()\n\n\tthisExecPath, err := os.Executable()\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"determining current executable path: %v\", err)\n\t}\n\tthisExecStat, err := os.Stat(thisExecPath)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"retrieving current executable permission bits: %v\", err)\n\t}\n\tif thisExecStat.Mode()&os.ModeSymlink == os.ModeSymlink {\n\t\tsymSource := thisExecPath\n\t\t// we are a symlink; resolve it\n\t\tthisExecPath, err = filepath.EvalSymlinks(thisExecPath)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"resolving current executable symlink: %v\", err)\n\t\t}\n\t\tl.Info(\"this executable is a symlink\", zap.String(\"source\", symSource), zap.String(\"target\", thisExecPath))\n\t}\n\tl.Info(\"this executable will be replaced\", zap.String(\"path\", thisExecPath))\n\n\t// build the request URL to download this custom build\n\tqs := url.Values{\n\t\t\"os\":   {runtime.GOOS},\n\t\t\"arch\": {runtime.GOARCH},\n\t}\n\tfor _, pkgInfo := range pluginPkgs {\n\t\tqs.Add(\"p\", pkgInfo.String())\n\t}\n\n\t// initiate the build\n\tresp, err := downloadBuild(qs)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"download failed: %v\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\t// back up the current binary, in case something goes wrong we can replace it\n\tbackupExecPath := thisExecPath + \".tmp\"\n\tl.Info(\"build acquired; backing up current executable\",\n\t\tzap.String(\"current_path\", thisExecPath),\n\t\tzap.String(\"backup_path\", backupExecPath))\n\terr = os.Rename(thisExecPath, backupExecPath)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"backing up current binary: %v\", err)\n\t}\n\tdefer func() {\n\t\tif err != nil {\n\t\t\terr2 := os.Rename(backupExecPath, thisExecPath)\n\t\t\tif err2 != nil {\n\t\t\t\tl.Error(\"restoring original executable failed; will need to be restored manually\",\n\t\t\t\t\tzap.String(\"backup_path\", backupExecPath),\n\t\t\t\t\tzap.String(\"original_path\", thisExecPath),\n\t\t\t\t\tzap.Error(err2))\n\t\t\t}\n\t\t}\n\t}()\n\n\t// download the file; do this in a closure to close reliably before we execute it\n\terr = writeCaddyBinary(thisExecPath, &resp.Body, thisExecStat)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tl.Info(\"download successful; displaying new binary details\", zap.String(\"location\", thisExecPath))\n\n\t// use the new binary to print out version and module info\n\tfmt.Print(\"\\nModule versions:\\n\\n\")\n\tif err = listModules(thisExecPath); err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"download succeeded, but unable to execute 'caddy list-modules': %v\", err)\n\t}\n\tfmt.Println(\"\\nVersion:\")\n\tif err = showVersion(thisExecPath); err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"download succeeded, but unable to execute 'caddy version': %v\", err)\n\t}\n\tfmt.Println()\n\n\t// clean up the backup file\n\tif !fl.Bool(\"keep-backup\") {\n\t\tif err = removeCaddyBinary(backupExecPath); err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"download succeeded, but unable to clean up backup binary: %v\", err)\n\t\t}\n\t} else {\n\t\tl.Info(\"skipped cleaning up the backup file\", zap.String(\"backup_path\", backupExecPath))\n\t}\n\n\tl.Info(\"upgrade successful; please restart any running Caddy instances\", zap.String(\"executable\", thisExecPath))\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc getModules() (standard, nonstandard, unknown []moduleInfo, err error) {\n\tbi, ok := debug.ReadBuildInfo()\n\tif !ok {\n\t\terr = fmt.Errorf(\"no build info\")\n\t\treturn\n\t}\n\n\tfor _, modID := range caddy.Modules() {\n\t\tmodInfo, err := caddy.GetModule(modID)\n\t\tif err != nil {\n\t\t\t// that's weird, shouldn't happen\n\t\t\tunknown = append(unknown, moduleInfo{caddyModuleID: modID, err: err})\n\t\t\tcontinue\n\t\t}\n\n\t\t// to get the Caddy plugin's version info, we need to know\n\t\t// the package that the Caddy module's value comes from; we\n\t\t// can use reflection but we need a non-pointer value (I'm\n\t\t// not sure why), and since New() should return a pointer\n\t\t// value, we need to dereference it first\n\t\tiface := any(modInfo.New())\n\t\tif rv := reflect.ValueOf(iface); rv.Kind() == reflect.Ptr {\n\t\t\tiface = reflect.New(reflect.TypeOf(iface).Elem()).Elem().Interface()\n\t\t}\n\t\tmodPkgPath := reflect.TypeOf(iface).PkgPath()\n\n\t\t// now we find the Go module that the Caddy module's package\n\t\t// belongs to; we assume the Caddy module package path will\n\t\t// be prefixed by its Go module path, and we will choose the\n\t\t// longest matching prefix in case there are nested modules\n\t\tvar matched *debug.Module\n\t\tfor _, dep := range bi.Deps {\n\t\t\tif strings.HasPrefix(modPkgPath, dep.Path) {\n\t\t\t\tif matched == nil || len(dep.Path) > len(matched.Path) {\n\t\t\t\t\tmatched = dep\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tcaddyModGoMod := moduleInfo{caddyModuleID: modID, goModule: matched}\n\n\t\tif strings.HasPrefix(modPkgPath, caddy.ImportPath) {\n\t\t\tstandard = append(standard, caddyModGoMod)\n\t\t} else {\n\t\t\tnonstandard = append(nonstandard, caddyModGoMod)\n\t\t}\n\t}\n\treturn\n}\n\nfunc listModules(path string) error {\n\tcmd := exec.Command(path, \"list-modules\", \"--versions\", \"--skip-standard\")\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\treturn cmd.Run()\n}\n\nfunc showVersion(path string) error {\n\tcmd := exec.Command(path, \"version\")\n\tcmd.Stdout = os.Stdout\n\tcmd.Stderr = os.Stderr\n\treturn cmd.Run()\n}\n\nfunc downloadBuild(qs url.Values) (*http.Response, error) {\n\tl := caddy.Log()\n\tl.Info(\"requesting build\",\n\t\tzap.String(\"os\", qs.Get(\"os\")),\n\t\tzap.String(\"arch\", qs.Get(\"arch\")),\n\t\tzap.Strings(\"packages\", qs[\"p\"]))\n\tresp, err := http.Get(fmt.Sprintf(\"%s?%s\", downloadPath, qs.Encode()))\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"secure request failed: %v\", err)\n\t}\n\tif resp.StatusCode >= 400 {\n\t\tvar details struct {\n\t\t\tStatusCode int `json:\"status_code\"`\n\t\t\tError      struct {\n\t\t\t\tMessage string `json:\"message\"`\n\t\t\t\tID      string `json:\"id\"`\n\t\t\t} `json:\"error\"`\n\t\t}\n\t\terr2 := json.NewDecoder(resp.Body).Decode(&details)\n\t\tif err2 != nil {\n\t\t\treturn nil, fmt.Errorf(\"download and error decoding failed: HTTP %d: %v\", resp.StatusCode, err2)\n\t\t}\n\t\treturn nil, fmt.Errorf(\"download failed: HTTP %d: %s (id=%s)\", resp.StatusCode, details.Error.Message, details.Error.ID)\n\t}\n\treturn resp, nil\n}\n\nfunc getPluginPackages(modules []moduleInfo) (map[string]pluginPackage, error) {\n\tpluginPkgs := make(map[string]pluginPackage)\n\tfor _, mod := range modules {\n\t\tif mod.goModule.Replace != nil {\n\t\t\treturn nil, fmt.Errorf(\"cannot auto-upgrade when Go module has been replaced: %s => %s\",\n\t\t\t\tmod.goModule.Path, mod.goModule.Replace.Path)\n\t\t}\n\t\tpluginPkgs[mod.goModule.Path] = pluginPackage{Version: mod.goModule.Version, Path: mod.goModule.Path}\n\t}\n\treturn pluginPkgs, nil\n}\n\nfunc writeCaddyBinary(path string, body *io.ReadCloser, fileInfo os.FileInfo) error {\n\tl := caddy.Log()\n\tdestFile, err := os.OpenFile(path, os.O_RDWR|os.O_CREATE|os.O_TRUNC, fileInfo.Mode())\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to open destination file: %v\", err)\n\t}\n\tdefer destFile.Close()\n\n\tl.Info(\"downloading binary\", zap.String(\"destination\", path))\n\n\t_, err = io.Copy(destFile, *body)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"unable to download file: %v\", err)\n\t}\n\n\terr = destFile.Sync()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"syncing downloaded file to device: %v\", err)\n\t}\n\n\treturn nil\n}\n\nconst downloadPath = \"https://caddyserver.com/api/download\"\n\ntype pluginPackage struct {\n\tVersion string\n\tPath    string\n}\n\nfunc (p pluginPackage) String() string {\n\tif p.Version == \"\" {\n\t\treturn p.Path\n\t}\n\treturn p.Path + \"@\" + p.Version\n}\n",
    "source_file": "cmd/packagesfuncs.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddycmd\n\nimport (\n\t\"github.com/spf13/cobra\"\n)\n\ntype rootCommandFactory struct {\n\tconstructor func() *cobra.Command\n\toptions     []func(*cobra.Command)\n}\n\nfunc newRootCommandFactory(fn func() *cobra.Command) *rootCommandFactory {\n\treturn &rootCommandFactory{\n\t\tconstructor: fn,\n\t}\n}\n\nfunc (f *rootCommandFactory) Use(fn func(cmd *cobra.Command)) {\n\tf.options = append(f.options, fn)\n}\n\nfunc (f *rootCommandFactory) Build() *cobra.Command {\n\to := f.constructor()\n\tfor _, v := range f.options {\n\t\tv(o)\n\t}\n\treturn o\n}\n",
    "source_file": "cmd/commandfactory.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddycmd\n\nimport (\n\t\"flag\"\n\t\"fmt\"\n\t\"os\"\n\t\"regexp\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/spf13/cobra\"\n\t\"github.com/spf13/cobra/doc\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// Command represents a subcommand. Name, Func,\n// and Short are required.\ntype Command struct {\n\t// The name of the subcommand. Must conform to the\n\t// format described by the RegisterCommand() godoc.\n\t// Required.\n\tName string\n\n\t// Usage is a brief message describing the syntax of\n\t// the subcommand's flags and args. Use [] to indicate\n\t// optional parameters and <> to enclose literal values\n\t// intended to be replaced by the user. Do not prefix\n\t// the string with \"caddy\" or the name of the command\n\t// since these will be prepended for you; only include\n\t// the actual parameters for this command.\n\tUsage string\n\n\t// Short is a one-line message explaining what the\n\t// command does. Should not end with punctuation.\n\t// Required.\n\tShort string\n\n\t// Long is the full help text shown to the user.\n\t// Will be trimmed of whitespace on both ends before\n\t// being printed.\n\tLong string\n\n\t// Flags is the flagset for command.\n\t// This is ignored if CobraFunc is set.\n\tFlags *flag.FlagSet\n\n\t// Func is a function that executes a subcommand using\n\t// the parsed flags. It returns an exit code and any\n\t// associated error.\n\t// Required if CobraFunc is not set.\n\tFunc CommandFunc\n\n\t// CobraFunc allows further configuration of the command\n\t// via cobra's APIs. If this is set, then Func and Flags\n\t// are ignored, with the assumption that they are set in\n\t// this function. A caddycmd.WrapCommandFuncForCobra helper\n\t// exists to simplify porting CommandFunc to Cobra's RunE.\n\tCobraFunc func(*cobra.Command)\n}\n\n// CommandFunc is a command's function. It runs the\n// command and returns the proper exit code along with\n// any error that occurred.\ntype CommandFunc func(Flags) (int, error)\n\n// Commands returns a list of commands initialised by\n// RegisterCommand\nfunc Commands() map[string]Command {\n\tcommandsMu.RLock()\n\tdefer commandsMu.RUnlock()\n\n\treturn commands\n}\n\nvar (\n\tcommandsMu sync.RWMutex\n\tcommands   = make(map[string]Command)\n)\n\nfunc init() {\n\tRegisterCommand(Command{\n\t\tName:  \"start\",\n\t\tUsage: \"[--config <path> [--adapter <name>]] [--envfile <path>] [--watch] [--pidfile <file>]\",\n\t\tShort: \"Starts the Caddy process in the background and then returns\",\n\t\tLong: `\nStarts the Caddy process, optionally bootstrapped with an initial config file.\nThis command unblocks after the server starts running or fails to run.\n\nIf --envfile is specified, an environment file with environment variables\nin the KEY=VALUE format will be loaded into the Caddy process.\n\nOn Windows, the spawned child process will remain attached to the terminal, so\nclosing the window will forcefully stop Caddy; to avoid forgetting this, try\nusing 'caddy run' instead to keep it in the foreground.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"config\", \"c\", \"\", \"Configuration file\")\n\t\t\tcmd.Flags().StringP(\"adapter\", \"a\", \"\", \"Name of config adapter to apply\")\n\t\t\tcmd.Flags().StringSliceP(\"envfile\", \"\", []string{}, \"Environment file(s) to load\")\n\t\t\tcmd.Flags().BoolP(\"watch\", \"w\", false, \"Reload changed config file automatically\")\n\t\t\tcmd.Flags().StringP(\"pidfile\", \"\", \"\", \"Path of file to which to write process ID\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdStart)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"run\",\n\t\tUsage: \"[--config <path> [--adapter <name>]] [--envfile <path>] [--environ] [--resume] [--watch] [--pidfile <file>]\",\n\t\tShort: `Starts the Caddy process and blocks indefinitely`,\n\t\tLong: `\nStarts the Caddy process, optionally bootstrapped with an initial config file,\nand blocks indefinitely until the server is stopped; i.e. runs Caddy in\n\"daemon\" mode (foreground).\n\nIf a config file is specified, it will be applied immediately after the process\nis running. If the config file is not in Caddy's native JSON format, you can\nspecify an adapter with --adapter to adapt the given config file to\nCaddy's native format. The config adapter must be a registered module. Any\nwarnings will be printed to the log, but beware that any adaptation without\nerrors will immediately be used. If you want to review the results of the\nadaptation first, use the 'adapt' subcommand.\n\nAs a special case, if the current working directory has a file called\n\"Caddyfile\" and the caddyfile config adapter is plugged in (default), then\nthat file will be loaded and used to configure Caddy, even without any command\nline flags.\n\nIf --envfile is specified, an environment file with environment variables\nin the KEY=VALUE format will be loaded into the Caddy process.\n\nIf --environ is specified, the environment as seen by the Caddy process will\nbe printed before starting. This is the same as the environ command but does\nnot quit after printing, and can be useful for troubleshooting.\n\nThe --resume flag will override the --config flag if there is a config auto-\nsave file. It is not an error if --resume is used and no autosave file exists.\n\nIf --watch is specified, the config file will be loaded automatically after\nchanges. \u26a0\ufe0f This can make unintentional config changes easier; only use this\noption in a local development environment.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"config\", \"c\", \"\", \"Configuration file\")\n\t\t\tcmd.Flags().StringP(\"adapter\", \"a\", \"\", \"Name of config adapter to apply\")\n\t\t\tcmd.Flags().StringSliceP(\"envfile\", \"\", []string{}, \"Environment file(s) to load\")\n\t\t\tcmd.Flags().BoolP(\"environ\", \"e\", false, \"Print environment\")\n\t\t\tcmd.Flags().BoolP(\"resume\", \"r\", false, \"Use saved config, if any (and prefer over --config file)\")\n\t\t\tcmd.Flags().BoolP(\"watch\", \"w\", false, \"Watch config file for changes and reload it automatically\")\n\t\t\tcmd.Flags().StringP(\"pidfile\", \"\", \"\", \"Path of file to which to write process ID\")\n\t\t\tcmd.Flags().StringP(\"pingback\", \"\", \"\", \"Echo confirmation bytes to this address on success\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdRun)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"stop\",\n\t\tUsage: \"[--config <path> [--adapter <name>]] [--address <interface>]\",\n\t\tShort: \"Gracefully stops a started Caddy process\",\n\t\tLong: `\nStops the background Caddy process as gracefully as possible.\n\nIt requires that the admin API is enabled and accessible, since it will\nuse the API's /stop endpoint. The address of this request can be customized\nusing the --address flag, or from the given --config, if not the default.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"config\", \"c\", \"\", \"Configuration file to use to parse the admin address, if --address is not used\")\n\t\t\tcmd.Flags().StringP(\"adapter\", \"a\", \"\", \"Name of config adapter to apply (when --config is used)\")\n\t\t\tcmd.Flags().StringP(\"address\", \"\", \"\", \"The address to use to reach the admin API endpoint, if not the default\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdStop)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"reload\",\n\t\tUsage: \"--config <path> [--adapter <name>] [--address <interface>]\",\n\t\tShort: \"Changes the config of the running Caddy instance\",\n\t\tLong: `\nGives the running Caddy instance a new configuration. This has the same effect\nas POSTing a document to the /load API endpoint, but is convenient for simple\nworkflows revolving around config files.\n\nSince the admin endpoint is configurable, the endpoint configuration is loaded\nfrom the --address flag if specified; otherwise it is loaded from the given\nconfig file; otherwise the default is assumed.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"config\", \"c\", \"\", \"Configuration file (required)\")\n\t\t\tcmd.Flags().StringP(\"adapter\", \"a\", \"\", \"Name of config adapter to apply\")\n\t\t\tcmd.Flags().StringP(\"address\", \"\", \"\", \"Address of the administration listener, if different from config\")\n\t\t\tcmd.Flags().BoolP(\"force\", \"f\", false, \"Force config reload, even if it is the same\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdReload)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"version\",\n\t\tShort: \"Prints the version\",\n\t\tLong: `\nPrints the version of this Caddy binary.\n\nVersion information must be embedded into the binary at compile-time in\norder for Caddy to display anything useful with this command. If Caddy\nis built from within a version control repository, the Go command will\nembed the revision hash if available. However, if Caddy is built in the\nway specified by our online documentation (or by using xcaddy), more\ndetailed version information is printed as given by Go modules.\n\nFor more details about the full version string, see the Go module\ndocumentation: https://go.dev/doc/modules/version-numbers\n`,\n\t\tFunc: cmdVersion,\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"list-modules\",\n\t\tUsage: \"[--packages] [--versions] [--skip-standard]\",\n\t\tShort: \"Lists the installed Caddy modules\",\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().BoolP(\"packages\", \"\", false, \"Print package paths\")\n\t\t\tcmd.Flags().BoolP(\"versions\", \"\", false, \"Print version information\")\n\t\t\tcmd.Flags().BoolP(\"skip-standard\", \"s\", false, \"Skip printing standard modules\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdListModules)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"build-info\",\n\t\tShort: \"Prints information about this build\",\n\t\tFunc:  cmdBuildInfo,\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"environ\",\n\t\tUsage: \"[--envfile <path>]\",\n\t\tShort: \"Prints the environment\",\n\t\tLong: `\nPrints the environment as seen by this Caddy process.\n\nThe environment includes variables set in the system. If your Caddy\nconfiguration uses environment variables (e.g. \"{env.VARIABLE}\") then\nthis command can be useful for verifying that the variables will have\nthe values you expect in your config.\n\nIf --envfile is specified, an environment file with environment variables\nin the KEY=VALUE format will be loaded into the Caddy process.\n\nNote that environments may be different depending on how you run Caddy.\nEnvironments for Caddy instances started by service managers such as\nsystemd are often different than the environment inherited from your\nshell or terminal.\n\nYou can also print the environment the same time you use \"caddy run\"\nby adding the \"--environ\" flag.\n\nEnvironments may contain sensitive data.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringSliceP(\"envfile\", \"\", []string{}, \"Environment file(s) to load\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdEnviron)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"adapt\",\n\t\tUsage: \"--config <path> [--adapter <name>] [--pretty] [--validate] [--envfile <path>]\",\n\t\tShort: \"Adapts a configuration to Caddy's native JSON\",\n\t\tLong: `\nAdapts a configuration to Caddy's native JSON format and writes the\noutput to stdout, along with any warnings to stderr.\n\nIf --pretty is specified, the output will be formatted with indentation\nfor human readability.\n\nIf --validate is used, the adapted config will be checked for validity.\nIf the config is invalid, an error will be printed to stderr and a non-\nzero exit status will be returned.\n\nIf --envfile is specified, an environment file with environment variables\nin the KEY=VALUE format will be loaded into the Caddy process.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"config\", \"c\", \"\", \"Configuration file to adapt (required)\")\n\t\t\tcmd.Flags().StringP(\"adapter\", \"a\", \"caddyfile\", \"Name of config adapter\")\n\t\t\tcmd.Flags().BoolP(\"pretty\", \"p\", false, \"Format the output for human readability\")\n\t\t\tcmd.Flags().BoolP(\"validate\", \"\", false, \"Validate the output\")\n\t\t\tcmd.Flags().StringSliceP(\"envfile\", \"\", []string{}, \"Environment file(s) to load\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdAdaptConfig)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"validate\",\n\t\tUsage: \"--config <path> [--adapter <name>] [--envfile <path>]\",\n\t\tShort: \"Tests whether a configuration file is valid\",\n\t\tLong: `\nLoads and provisions the provided config, but does not start running it.\nThis reveals any errors with the configuration through the loading and\nprovisioning stages.\n\nIf --envfile is specified, an environment file with environment variables\nin the KEY=VALUE format will be loaded into the Caddy process.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"config\", \"c\", \"\", \"Input configuration file\")\n\t\t\tcmd.Flags().StringP(\"adapter\", \"a\", \"\", \"Name of config adapter\")\n\t\t\tcmd.Flags().StringSliceP(\"envfile\", \"\", []string{}, \"Environment file(s) to load\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdValidateConfig)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"storage\",\n\t\tShort: \"Commands for working with Caddy's storage (EXPERIMENTAL)\",\n\t\tLong: `\nAllows exporting and importing Caddy's storage contents. The two commands can be\ncombined in a pipeline to transfer directly from one storage to another:\n\n$ caddy storage export --config Caddyfile.old --output - |\n> caddy storage import --config Caddyfile.new --input -\n\nThe - argument refers to stdout and stdin, respectively.\n\nNOTE: When importing to or exporting from file_system storage (the default), the command\nshould be run as the user that owns the associated root path.\n\nEXPERIMENTAL: May be changed or removed.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\texportCmd := &cobra.Command{\n\t\t\t\tUse:   \"export --config <path> --output <path>\",\n\t\t\t\tShort: \"Exports storage assets as a tarball\",\n\t\t\t\tLong: `\nThe contents of the configured storage module (TLS certificates, etc)\nare exported via a tarball.\n\n--output is required, - can be given for stdout.\n`,\n\t\t\t\tRunE: WrapCommandFuncForCobra(cmdExportStorage),\n\t\t\t}\n\t\t\texportCmd.Flags().StringP(\"config\", \"c\", \"\", \"Input configuration file (required)\")\n\t\t\texportCmd.Flags().StringP(\"output\", \"o\", \"\", \"Output path\")\n\t\t\tcmd.AddCommand(exportCmd)\n\n\t\t\timportCmd := &cobra.Command{\n\t\t\t\tUse:   \"import --config <path> --input <path>\",\n\t\t\t\tShort: \"Imports storage assets from a tarball.\",\n\t\t\t\tLong: `\nImports storage assets to the configured storage module. The import file must be\na tar archive.\n\n--input is required, - can be given for stdin.\n`,\n\t\t\t\tRunE: WrapCommandFuncForCobra(cmdImportStorage),\n\t\t\t}\n\t\t\timportCmd.Flags().StringP(\"config\", \"c\", \"\", \"Configuration file to load (required)\")\n\t\t\timportCmd.Flags().StringP(\"input\", \"i\", \"\", \"Tar of assets to load (required)\")\n\t\t\tcmd.AddCommand(importCmd)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"fmt\",\n\t\tUsage: \"[--overwrite] [--diff] [<path>]\",\n\t\tShort: \"Formats a Caddyfile\",\n\t\tLong: `\nFormats the Caddyfile by adding proper indentation and spaces to improve\nhuman readability. It prints the result to stdout.\n\nIf --overwrite is specified, the output will be written to the config file\ndirectly instead of printing it.\n\nIf --diff is specified, the output will be compared against the input, and\nlines will be prefixed with '-' and '+' where they differ. Note that\nunchanged lines are prefixed with two spaces for alignment, and that this\nis not a valid patch format.\n\nIf you wish you use stdin instead of a regular file, use - as the path.\nWhen reading from stdin, the --overwrite flag has no effect: the result\nis always printed to stdout.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"config\", \"c\", \"\", \"Configuration file\")\n\t\t\tcmd.Flags().BoolP(\"overwrite\", \"w\", false, \"Overwrite the input file with the results\")\n\t\t\tcmd.Flags().BoolP(\"diff\", \"d\", false, \"Print the differences between the input file and the formatted output\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdFmt)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"upgrade\",\n\t\tShort: \"Upgrade Caddy (EXPERIMENTAL)\",\n\t\tLong: `\nDownloads an updated Caddy binary with the same modules/plugins at the\nlatest versions. EXPERIMENTAL: May be changed or removed.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().BoolP(\"keep-backup\", \"k\", false, \"Keep the backed up binary, instead of deleting it\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdUpgrade)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"add-package\",\n\t\tUsage: \"<package[@version]...>\",\n\t\tShort: \"Adds Caddy packages (EXPERIMENTAL)\",\n\t\tLong: `\nDownloads an updated Caddy binary with the specified packages (module/plugin)\nadded, with an optional version specified (e.g., \"package@version\"). Retains\nexisting packages. Returns an error if any of the specified packages are already\nincluded. EXPERIMENTAL: May be changed or removed.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().BoolP(\"keep-backup\", \"k\", false, \"Keep the backed up binary, instead of deleting it\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdAddPackage)\n\t\t},\n\t})\n\n\tRegisterCommand(Command{\n\t\tName:  \"remove-package\",\n\t\tFunc:  cmdRemovePackage,\n\t\tUsage: \"<packages...>\",\n\t\tShort: \"Removes Caddy packages (EXPERIMENTAL)\",\n\t\tLong: `\nDownloads an updated Caddy binaries without the specified packages (module/plugin).\nReturns an error if any of the packages are not included.\nEXPERIMENTAL: May be changed or removed.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().BoolP(\"keep-backup\", \"k\", false, \"Keep the backed up binary, instead of deleting it\")\n\t\t\tcmd.RunE = WrapCommandFuncForCobra(cmdRemovePackage)\n\t\t},\n\t})\n\n\tdefaultFactory.Use(func(rootCmd *cobra.Command) {\n\t\tmanpageCommand := Command{\n\t\t\tName:  \"manpage\",\n\t\t\tUsage: \"--directory <path>\",\n\t\t\tShort: \"Generates the manual pages for Caddy commands\",\n\t\t\tLong: `\nGenerates the manual pages for Caddy commands into the designated directory\ntagged into section 8 (System Administration).\n\nThe manual page files are generated into the directory specified by the\nargument of --directory. If the directory does not exist, it will be created.\n`,\n\t\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\t\tcmd.Flags().StringP(\"directory\", \"o\", \"\", \"The output directory where the manpages are generated\")\n\t\t\t\tcmd.RunE = WrapCommandFuncForCobra(func(fl Flags) (int, error) {\n\t\t\t\t\tdir := strings.TrimSpace(fl.String(\"directory\"))\n\t\t\t\t\tif dir == \"\" {\n\t\t\t\t\t\treturn caddy.ExitCodeFailedQuit, fmt.Errorf(\"designated output directory and specified section are required\")\n\t\t\t\t\t}\n\t\t\t\t\tif err := os.MkdirAll(dir, 0o755); err != nil {\n\t\t\t\t\t\treturn caddy.ExitCodeFailedQuit, err\n\t\t\t\t\t}\n\t\t\t\t\tif err := doc.GenManTree(rootCmd, &doc.GenManHeader{\n\t\t\t\t\t\tTitle:   \"Caddy\",\n\t\t\t\t\t\tSection: \"8\", // https://en.wikipedia.org/wiki/Man_page#Manual_sections\n\t\t\t\t\t}, dir); err != nil {\n\t\t\t\t\t\treturn caddy.ExitCodeFailedQuit, err\n\t\t\t\t\t}\n\t\t\t\t\treturn caddy.ExitCodeSuccess, nil\n\t\t\t\t})\n\t\t\t},\n\t\t}\n\n\t\t// source: https://github.com/spf13/cobra/blob/main/shell_completions.md\n\t\tcompletionCommand := Command{\n\t\t\tName:  \"completion\",\n\t\t\tUsage: \"[bash|zsh|fish|powershell]\",\n\t\t\tShort: \"Generate completion script\",\n\t\t\tLong: fmt.Sprintf(`To load completions:\n\n\tBash:\n\n\t  $ source <(%[1]s completion bash)\n\n\t  # To load completions for each session, execute once:\n\t  # Linux:\n\t  $ %[1]s completion bash > /etc/bash_completion.d/%[1]s\n\t  # macOS:\n\t  $ %[1]s completion bash > $(brew --prefix)/etc/bash_completion.d/%[1]s\n\n\tZsh:\n\n\t  # If shell completion is not already enabled in your environment,\n\t  # you will need to enable it.  You can execute the following once:\n\n\t  $ echo \"autoload -U compinit; compinit\" >> ~/.zshrc\n\n\t  # To load completions for each session, execute once:\n\t  $ %[1]s completion zsh > \"${fpath[1]}/_%[1]s\"\n\n\t  # You will need to start a new shell for this setup to take effect.\n\n\tfish:\n\n\t  $ %[1]s completion fish | source\n\n\t  # To load completions for each session, execute once:\n\t  $ %[1]s completion fish > ~/.config/fish/completions/%[1]s.fish\n\n\tPowerShell:\n\n\t  PS> %[1]s completion powershell | Out-String | Invoke-Expression\n\n\t  # To load completions for every new session, run:\n\t  PS> %[1]s completion powershell > %[1]s.ps1\n\t  # and source this file from your PowerShell profile.\n\t`, rootCmd.Root().Name()),\n\t\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\t\tcmd.DisableFlagsInUseLine = true\n\t\t\t\tcmd.ValidArgs = []string{\"bash\", \"zsh\", \"fish\", \"powershell\"}\n\t\t\t\tcmd.Args = cobra.MatchAll(cobra.ExactArgs(1), cobra.OnlyValidArgs)\n\t\t\t\tcmd.RunE = func(cmd *cobra.Command, args []string) error {\n\t\t\t\t\tswitch args[0] {\n\t\t\t\t\tcase \"bash\":\n\t\t\t\t\t\treturn cmd.Root().GenBashCompletion(os.Stdout)\n\t\t\t\t\tcase \"zsh\":\n\t\t\t\t\t\treturn cmd.Root().GenZshCompletion(os.Stdout)\n\t\t\t\t\tcase \"fish\":\n\t\t\t\t\t\treturn cmd.Root().GenFishCompletion(os.Stdout, true)\n\t\t\t\t\tcase \"powershell\":\n\t\t\t\t\t\treturn cmd.Root().GenPowerShellCompletionWithDesc(os.Stdout)\n\t\t\t\t\tdefault:\n\t\t\t\t\t\treturn fmt.Errorf(\"unrecognized shell: %s\", args[0])\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t},\n\t\t}\n\n\t\trootCmd.AddCommand(caddyCmdToCobra(manpageCommand))\n\t\trootCmd.AddCommand(caddyCmdToCobra(completionCommand))\n\n\t\t// add manpage and completion commands to the map of\n\t\t// available commands, because they're not registered\n\t\t// through RegisterCommand.\n\t\tcommandsMu.Lock()\n\t\tcommands[manpageCommand.Name] = manpageCommand\n\t\tcommands[completionCommand.Name] = completionCommand\n\t\tcommandsMu.Unlock()\n\t})\n}\n\n// RegisterCommand registers the command cmd.\n// cmd.Name must be unique and conform to the\n// following format:\n//\n//   - lowercase\n//   - alphanumeric and hyphen characters only\n//   - cannot start or end with a hyphen\n//   - hyphen cannot be adjacent to another hyphen\n//\n// This function panics if the name is already registered,\n// if the name does not meet the described format, or if\n// any of the fields are missing from cmd.\n//\n// This function should be used in init().\nfunc RegisterCommand(cmd Command) {\n\tcommandsMu.Lock()\n\tdefer commandsMu.Unlock()\n\n\tif cmd.Name == \"\" {\n\t\tpanic(\"command name is required\")\n\t}\n\tif cmd.Func == nil && cmd.CobraFunc == nil {\n\t\tpanic(\"command function missing\")\n\t}\n\tif cmd.Short == \"\" {\n\t\tpanic(\"command short string is required\")\n\t}\n\tif _, exists := commands[cmd.Name]; exists {\n\t\tpanic(\"command already registered: \" + cmd.Name)\n\t}\n\tif !commandNameRegex.MatchString(cmd.Name) {\n\t\tpanic(\"invalid command name\")\n\t}\n\tdefaultFactory.Use(func(rootCmd *cobra.Command) {\n\t\trootCmd.AddCommand(caddyCmdToCobra(cmd))\n\t})\n\tcommands[cmd.Name] = cmd\n}\n\nvar commandNameRegex = regexp.MustCompile(`^[a-z0-9]$|^([a-z0-9]+-?[a-z0-9]*)+[a-z0-9]$`)\n",
    "source_file": "cmd/commands.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddycmd\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"flag\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"log\"\n\t\"log/slog\"\n\t\"net\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"runtime/debug\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/KimMachineGun/automemlimit/memlimit\"\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/spf13/pflag\"\n\t\"go.uber.org/automaxprocs/maxprocs\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/exp/zapslog\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n)\n\nfunc init() {\n\t// set a fitting User-Agent for ACME requests\n\tversion, _ := caddy.Version()\n\tcleanModVersion := strings.TrimPrefix(version, \"v\")\n\tua := \"Caddy/\" + cleanModVersion\n\tif uaEnv, ok := os.LookupEnv(\"USERAGENT\"); ok {\n\t\tua = uaEnv + \" \" + ua\n\t}\n\tcertmagic.UserAgent = ua\n\n\t// by using Caddy, user indicates agreement to CA terms\n\t// (very important, as Caddy is often non-interactive\n\t// and thus ACME account creation will fail!)\n\tcertmagic.DefaultACME.Agreed = true\n}\n\n// Main implements the main function of the caddy command.\n// Call this if Caddy is to be the main() of your program.\nfunc Main() {\n\tif len(os.Args) == 0 {\n\t\tfmt.Printf(\"[FATAL] no arguments provided by OS; args[0] must be command\\n\")\n\t\tos.Exit(caddy.ExitCodeFailedStartup)\n\t}\n\n\tif err := defaultFactory.Build().Execute(); err != nil {\n\t\tvar exitError *exitError\n\t\tif errors.As(err, &exitError) {\n\t\t\tos.Exit(exitError.ExitCode)\n\t\t}\n\t\tos.Exit(1)\n\t}\n}\n\n// handlePingbackConn reads from conn and ensures it matches\n// the bytes in expect, or returns an error if it doesn't.\nfunc handlePingbackConn(conn net.Conn, expect []byte) error {\n\tdefer conn.Close()\n\tconfirmationBytes, err := io.ReadAll(io.LimitReader(conn, 32))\n\tif err != nil {\n\t\treturn err\n\t}\n\tif !bytes.Equal(confirmationBytes, expect) {\n\t\treturn fmt.Errorf(\"wrong confirmation: %x\", confirmationBytes)\n\t}\n\treturn nil\n}\n\n// LoadConfig loads the config from configFile and adapts it\n// using adapterName. If adapterName is specified, configFile\n// must be also. If no configFile is specified, it tries\n// loading a default config file. The lack of a config file is\n// not treated as an error, but false will be returned if\n// there is no config available. It prints any warnings to stderr,\n// and returns the resulting JSON config bytes along with\n// the name of the loaded config file (if any).\nfunc LoadConfig(configFile, adapterName string) ([]byte, string, error) {\n\treturn loadConfigWithLogger(caddy.Log(), configFile, adapterName)\n}\n\nfunc isCaddyfile(configFile, adapterName string) (bool, error) {\n\tif adapterName == \"caddyfile\" {\n\t\treturn true, nil\n\t}\n\n\t// as a special case, if a config file starts with \"caddyfile\" or\n\t// has a \".caddyfile\" extension, and no adapter is specified, and\n\t// no adapter module name matches the extension, assume\n\t// caddyfile adapter for convenience\n\tbaseConfig := strings.ToLower(filepath.Base(configFile))\n\tbaseConfigExt := filepath.Ext(baseConfig)\n\tstartsOrEndsInCaddyfile := strings.HasPrefix(baseConfig, \"caddyfile\") || strings.HasSuffix(baseConfig, \".caddyfile\")\n\n\tif baseConfigExt == \".json\" {\n\t\treturn false, nil\n\t}\n\n\t// If the adapter is not specified,\n\t// the config file starts with \"caddyfile\",\n\t// the config file has an extension,\n\t// and isn't a JSON file (e.g. Caddyfile.yaml),\n\t// then we don't know what the config format is.\n\tif adapterName == \"\" && startsOrEndsInCaddyfile {\n\t\treturn true, nil\n\t}\n\n\t// adapter is not empty,\n\t// adapter is not \"caddyfile\",\n\t// extension is not \".json\",\n\t// extension is not \".caddyfile\"\n\t// file does not start with \"Caddyfile\"\n\treturn false, nil\n}\n\nfunc loadConfigWithLogger(logger *zap.Logger, configFile, adapterName string) ([]byte, string, error) {\n\t// if no logger is provided, use a nop logger\n\t// just so we don't have to check for nil\n\tif logger == nil {\n\t\tlogger = zap.NewNop()\n\t}\n\n\t// specifying an adapter without a config file is ambiguous\n\tif adapterName != \"\" && configFile == \"\" {\n\t\treturn nil, \"\", fmt.Errorf(\"cannot adapt config without config file (use --config)\")\n\t}\n\n\t// load initial config and adapter\n\tvar config []byte\n\tvar cfgAdapter caddyconfig.Adapter\n\tvar err error\n\tif configFile != \"\" {\n\t\tif configFile == \"-\" {\n\t\t\tconfig, err = io.ReadAll(os.Stdin)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, \"\", fmt.Errorf(\"reading config from stdin: %v\", err)\n\t\t\t}\n\t\t\tlogger.Info(\"using config from stdin\")\n\t\t} else {\n\t\t\tconfig, err = os.ReadFile(configFile)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, \"\", fmt.Errorf(\"reading config from file: %v\", err)\n\t\t\t}\n\t\t\tlogger.Info(\"using config from file\", zap.String(\"file\", configFile))\n\t\t}\n\t} else if adapterName == \"\" {\n\t\t// if the Caddyfile adapter is plugged in, we can try using an\n\t\t// adjacent Caddyfile by default\n\t\tcfgAdapter = caddyconfig.GetAdapter(\"caddyfile\")\n\t\tif cfgAdapter != nil {\n\t\t\tconfig, err = os.ReadFile(\"Caddyfile\")\n\t\t\tif errors.Is(err, fs.ErrNotExist) {\n\t\t\t\t// okay, no default Caddyfile; pretend like this never happened\n\t\t\t\tcfgAdapter = nil\n\t\t\t} else if err != nil {\n\t\t\t\t// default Caddyfile exists, but error reading it\n\t\t\t\treturn nil, \"\", fmt.Errorf(\"reading default Caddyfile: %v\", err)\n\t\t\t} else {\n\t\t\t\t// success reading default Caddyfile\n\t\t\t\tconfigFile = \"Caddyfile\"\n\t\t\t\tlogger.Info(\"using adjacent Caddyfile\")\n\t\t\t}\n\t\t}\n\t}\n\n\tif yes, err := isCaddyfile(configFile, adapterName); yes {\n\t\tadapterName = \"caddyfile\"\n\t} else if err != nil {\n\t\treturn nil, \"\", err\n\t}\n\n\t// load config adapter\n\tif adapterName != \"\" {\n\t\tcfgAdapter = caddyconfig.GetAdapter(adapterName)\n\t\tif cfgAdapter == nil {\n\t\t\treturn nil, \"\", fmt.Errorf(\"unrecognized config adapter: %s\", adapterName)\n\t\t}\n\t}\n\n\t// adapt config\n\tif cfgAdapter != nil {\n\t\tadaptedConfig, warnings, err := cfgAdapter.Adapt(config, map[string]any{\n\t\t\t\"filename\": configFile,\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, \"\", fmt.Errorf(\"adapting config using %s: %v\", adapterName, err)\n\t\t}\n\t\tlogger.Info(\"adapted config to JSON\", zap.String(\"adapter\", adapterName))\n\t\tfor _, warn := range warnings {\n\t\t\tmsg := warn.Message\n\t\t\tif warn.Directive != \"\" {\n\t\t\t\tmsg = fmt.Sprintf(\"%s: %s\", warn.Directive, warn.Message)\n\t\t\t}\n\t\t\tlogger.Warn(msg,\n\t\t\t\tzap.String(\"adapter\", adapterName),\n\t\t\t\tzap.String(\"file\", warn.File),\n\t\t\t\tzap.Int(\"line\", warn.Line))\n\t\t}\n\t\tconfig = adaptedConfig\n\t} else if len(config) != 0 {\n\t\t// validate that the config is at least valid JSON\n\t\terr = json.Unmarshal(config, new(any))\n\t\tif err != nil {\n\t\t\treturn nil, \"\", fmt.Errorf(\"config is not valid JSON: %v; did you mean to use a config adapter (the --adapter flag)?\", err)\n\t\t}\n\t}\n\n\treturn config, configFile, nil\n}\n\n// watchConfigFile watches the config file at filename for changes\n// and reloads the config if the file was updated. This function\n// blocks indefinitely; it only quits if the poller has errors for\n// long enough time. The filename passed in must be the actual\n// config file used, not one to be discovered.\n// Each second the config files is loaded and parsed into an object\n// and is compared to the last config object that was loaded\nfunc watchConfigFile(filename, adapterName string) {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tlog.Printf(\"[PANIC] watching config file: %v\\n%s\", err, debug.Stack())\n\t\t}\n\t}()\n\n\t// make our logger; since config reloads can change the\n\t// default logger, we need to get it dynamically each time\n\tlogger := func() *zap.Logger {\n\t\treturn caddy.Log().\n\t\t\tNamed(\"watcher\").\n\t\t\tWith(zap.String(\"config_file\", filename))\n\t}\n\n\t// get current config\n\tlastCfg, _, err := loadConfigWithLogger(nil, filename, adapterName)\n\tif err != nil {\n\t\tlogger().Error(\"unable to load latest config\", zap.Error(err))\n\t\treturn\n\t}\n\n\tlogger().Info(\"watching config file for changes\")\n\n\t// begin poller\n\t//nolint:staticcheck\n\tfor range time.Tick(1 * time.Second) {\n\t\t// get current config\n\t\tnewCfg, _, err := loadConfigWithLogger(nil, filename, adapterName)\n\t\tif err != nil {\n\t\t\tlogger().Error(\"unable to load latest config\", zap.Error(err))\n\t\t\treturn\n\t\t}\n\n\t\t// if it hasn't changed, nothing to do\n\t\tif bytes.Equal(lastCfg, newCfg) {\n\t\t\tcontinue\n\t\t}\n\t\tlogger().Info(\"config file changed; reloading\")\n\n\t\t// remember the current config\n\t\tlastCfg = newCfg\n\n\t\t// apply the updated config\n\t\terr = caddy.Load(lastCfg, false)\n\t\tif err != nil {\n\t\t\tlogger().Error(\"applying latest config\", zap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t}\n}\n\n// Flags wraps a FlagSet so that typed values\n// from flags can be easily retrieved.\ntype Flags struct {\n\t*pflag.FlagSet\n}\n\n// String returns the string representation of the\n// flag given by name. It panics if the flag is not\n// in the flag set.\nfunc (f Flags) String(name string) string {\n\treturn f.FlagSet.Lookup(name).Value.String()\n}\n\n// Bool returns the boolean representation of the\n// flag given by name. It returns false if the flag\n// is not a boolean type. It panics if the flag is\n// not in the flag set.\nfunc (f Flags) Bool(name string) bool {\n\tval, _ := strconv.ParseBool(f.String(name))\n\treturn val\n}\n\n// Int returns the integer representation of the\n// flag given by name. It returns 0 if the flag\n// is not an integer type. It panics if the flag is\n// not in the flag set.\nfunc (f Flags) Int(name string) int {\n\tval, _ := strconv.ParseInt(f.String(name), 0, strconv.IntSize)\n\treturn int(val)\n}\n\n// Float64 returns the float64 representation of the\n// flag given by name. It returns false if the flag\n// is not a float64 type. It panics if the flag is\n// not in the flag set.\nfunc (f Flags) Float64(name string) float64 {\n\tval, _ := strconv.ParseFloat(f.String(name), 64)\n\treturn val\n}\n\n// Duration returns the duration representation of the\n// flag given by name. It returns false if the flag\n// is not a duration type. It panics if the flag is\n// not in the flag set.\nfunc (f Flags) Duration(name string) time.Duration {\n\tval, _ := caddy.ParseDuration(f.String(name))\n\treturn val\n}\n\nfunc loadEnvFromFile(envFile string) error {\n\tfile, err := os.Open(envFile)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"reading environment file: %v\", err)\n\t}\n\tdefer file.Close()\n\n\tenvMap, err := parseEnvFile(file)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"parsing environment file: %v\", err)\n\t}\n\n\tfor k, v := range envMap {\n\t\t// do not overwrite existing environment variables\n\t\t_, exists := os.LookupEnv(k)\n\t\tif !exists {\n\t\t\tif err := os.Setenv(k, v); err != nil {\n\t\t\t\treturn fmt.Errorf(\"setting environment variables: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Update the storage paths to ensure they have the proper\n\t// value after loading a specified env file.\n\tcaddy.ConfigAutosavePath = filepath.Join(caddy.AppConfigDir(), \"autosave.json\")\n\tcaddy.DefaultStorage = &certmagic.FileStorage{Path: caddy.AppDataDir()}\n\n\treturn nil\n}\n\n// parseEnvFile parses an env file from KEY=VALUE format.\n// It's pretty naive. Limited value quotation is supported,\n// but variable and command expansions are not supported.\nfunc parseEnvFile(envInput io.Reader) (map[string]string, error) {\n\tenvMap := make(map[string]string)\n\n\tscanner := bufio.NewScanner(envInput)\n\tvar lineNumber int\n\n\tfor scanner.Scan() {\n\t\tline := strings.TrimSpace(scanner.Text())\n\t\tlineNumber++\n\n\t\t// skip empty lines and lines starting with comment\n\t\tif line == \"\" || strings.HasPrefix(line, \"#\") {\n\t\t\tcontinue\n\t\t}\n\n\t\t// split line into key and value\n\t\tbefore, after, isCut := strings.Cut(line, \"=\")\n\t\tif !isCut {\n\t\t\treturn nil, fmt.Errorf(\"can't parse line %d; line should be in KEY=VALUE format\", lineNumber)\n\t\t}\n\t\tkey, val := before, after\n\n\t\t// sometimes keys are prefixed by \"export \" so file can be sourced in bash; ignore it here\n\t\tkey = strings.TrimPrefix(key, \"export \")\n\n\t\t// validate key and value\n\t\tif key == \"\" {\n\t\t\treturn nil, fmt.Errorf(\"missing or empty key on line %d\", lineNumber)\n\t\t}\n\t\tif strings.Contains(key, \" \") {\n\t\t\treturn nil, fmt.Errorf(\"invalid key on line %d: contains whitespace: %s\", lineNumber, key)\n\t\t}\n\t\tif strings.HasPrefix(val, \" \") || strings.HasPrefix(val, \"\\t\") {\n\t\t\treturn nil, fmt.Errorf(\"invalid value on line %d: whitespace before value: '%s'\", lineNumber, val)\n\t\t}\n\n\t\t// remove any trailing comment after value\n\t\tif commentStart, _, found := strings.Cut(val, \"#\"); found {\n\t\t\tval = strings.TrimRight(commentStart, \" \\t\")\n\t\t}\n\n\t\t// quoted value: support newlines\n\t\tif strings.HasPrefix(val, `\"`) || strings.HasPrefix(val, \"'\") {\n\t\t\tquote := string(val[0])\n\t\t\tfor !strings.HasSuffix(line, quote) || strings.HasSuffix(line, `\\`+quote) {\n\t\t\t\tval = strings.ReplaceAll(val, `\\`+quote, quote)\n\t\t\t\tif !scanner.Scan() {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t\tlineNumber++\n\t\t\t\tline = strings.ReplaceAll(scanner.Text(), `\\`+quote, quote)\n\t\t\t\tval += \"\\n\" + line\n\t\t\t}\n\t\t\tval = strings.TrimPrefix(val, quote)\n\t\t\tval = strings.TrimSuffix(val, quote)\n\t\t}\n\n\t\tenvMap[key] = val\n\t}\n\n\tif err := scanner.Err(); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn envMap, nil\n}\n\nfunc printEnvironment() {\n\t_, version := caddy.Version()\n\tfmt.Printf(\"caddy.HomeDir=%s\\n\", caddy.HomeDir())\n\tfmt.Printf(\"caddy.AppDataDir=%s\\n\", caddy.AppDataDir())\n\tfmt.Printf(\"caddy.AppConfigDir=%s\\n\", caddy.AppConfigDir())\n\tfmt.Printf(\"caddy.ConfigAutosavePath=%s\\n\", caddy.ConfigAutosavePath)\n\tfmt.Printf(\"caddy.Version=%s\\n\", version)\n\tfmt.Printf(\"runtime.GOOS=%s\\n\", runtime.GOOS)\n\tfmt.Printf(\"runtime.GOARCH=%s\\n\", runtime.GOARCH)\n\tfmt.Printf(\"runtime.Compiler=%s\\n\", runtime.Compiler)\n\tfmt.Printf(\"runtime.NumCPU=%d\\n\", runtime.NumCPU())\n\tfmt.Printf(\"runtime.GOMAXPROCS=%d\\n\", runtime.GOMAXPROCS(0))\n\tfmt.Printf(\"runtime.Version=%s\\n\", runtime.Version())\n\tcwd, err := os.Getwd()\n\tif err != nil {\n\t\tcwd = fmt.Sprintf(\"<error: %v>\", err)\n\t}\n\tfmt.Printf(\"os.Getwd=%s\\n\\n\", cwd)\n\tfor _, v := range os.Environ() {\n\t\tfmt.Println(v)\n\t}\n}\n\nfunc setResourceLimits(logger *zap.Logger) func() {\n\t// Configure the maximum number of CPUs to use to match the Linux container quota (if any)\n\t// See https://pkg.go.dev/runtime#GOMAXPROCS\n\tundo, err := maxprocs.Set(maxprocs.Logger(logger.Sugar().Infof))\n\tif err != nil {\n\t\tlogger.Warn(\"failed to set GOMAXPROCS\", zap.Error(err))\n\t}\n\n\t// Configure the maximum memory to use to match the Linux container quota (if any) or system memory\n\t// See https://pkg.go.dev/runtime/debug#SetMemoryLimit\n\t_, _ = memlimit.SetGoMemLimitWithOpts(\n\t\tmemlimit.WithLogger(\n\t\t\tslog.New(zapslog.NewHandler(logger.Core())),\n\t\t),\n\t\tmemlimit.WithProvider(\n\t\t\tmemlimit.ApplyFallback(\n\t\t\t\tmemlimit.FromCgroup,\n\t\t\t\tmemlimit.FromSystem,\n\t\t\t),\n\t\t),\n\t)\n\n\treturn undo\n}\n\n// StringSlice is a flag.Value that enables repeated use of a string flag.\ntype StringSlice []string\n\nfunc (ss StringSlice) String() string { return \"[\" + strings.Join(ss, \", \") + \"]\" }\n\nfunc (ss *StringSlice) Set(value string) error {\n\t*ss = append(*ss, value)\n\treturn nil\n}\n\n// Interface guard\nvar _ flag.Value = (*StringSlice)(nil)\n",
    "source_file": "cmd/main.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Package notify provides facilities for notifying process managers\n// of state changes, mainly for when running as a system service.\npackage notify\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"os\"\n\t\"strings\"\n)\n\n// The documentation about this IPC protocol is available here:\n// https://www.freedesktop.org/software/systemd/man/sd_notify.html\n\nfunc sdNotify(payload string) error {\n\tif socketPath == \"\" {\n\t\treturn nil\n\t}\n\n\tsocketAddr := &net.UnixAddr{\n\t\tName: socketPath,\n\t\tNet:  \"unixgram\",\n\t}\n\n\tconn, err := net.DialUnix(socketAddr.Net, nil, socketAddr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer conn.Close()\n\n\t_, err = conn.Write([]byte(payload))\n\treturn err\n}\n\n// Ready notifies systemd that caddy has finished its\n// initialization routines.\nfunc Ready() error {\n\treturn sdNotify(\"READY=1\")\n}\n\n// Reloading notifies systemd that caddy is reloading its config.\nfunc Reloading() error {\n\treturn sdNotify(\"RELOADING=1\")\n}\n\n// Stopping notifies systemd that caddy is stopping.\nfunc Stopping() error {\n\treturn sdNotify(\"STOPPING=1\")\n}\n\n// Status sends systemd an updated status message.\nfunc Status(msg string) error {\n\treturn sdNotify(\"STATUS=\" + msg)\n}\n\n// Error is like Status, but sends systemd an error message\n// instead, with an optional errno-style error number.\nfunc Error(err error, errno int) error {\n\tcollapsedErr := strings.ReplaceAll(err.Error(), \"\\n\", \" \")\n\tmsg := fmt.Sprintf(\"STATUS=%s\", collapsedErr)\n\tif errno > 0 {\n\t\tmsg += fmt.Sprintf(\"\\nERRNO=%d\", errno)\n\t}\n\treturn sdNotify(msg)\n}\n\nvar socketPath, _ = os.LookupEnv(\"NOTIFY_SOCKET\")\n",
    "source_file": "notify/notify_linux.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build !linux && !windows\n\npackage notify\n\nfunc Ready() error               { return nil }\nfunc Reloading() error           { return nil }\nfunc Stopping() error            { return nil }\nfunc Status(_ string) error      { return nil }\nfunc Error(_ error, _ int) error { return nil }\n",
    "source_file": "notify/notify_other.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage notify\n\nimport \"golang.org/x/sys/windows/svc\"\n\n// globalStatus store windows service status, it can be\n// use to notify caddy status.\nvar globalStatus chan<- svc.Status\n\nfunc SetGlobalStatus(status chan<- svc.Status) {\n\tglobalStatus = status\n}\n\nfunc Ready() error {\n\tif globalStatus != nil {\n\t\tglobalStatus <- svc.Status{\n\t\t\tState:   svc.Running,\n\t\t\tAccepts: svc.AcceptStop | svc.AcceptShutdown,\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc Reloading() error {\n\tif globalStatus != nil {\n\t\tglobalStatus <- svc.Status{State: svc.StartPending}\n\t}\n\treturn nil\n}\n\nfunc Stopping() error {\n\tif globalStatus != nil {\n\t\tglobalStatus <- svc.Status{State: svc.StopPending}\n\t}\n\treturn nil\n}\n\n// TODO: not implemented\nfunc Status(_ string) error { return nil }\n\n// TODO: not implemented\nfunc Error(_ error, _ int) error { return nil }\n",
    "source_file": "notify/notify_windows.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyconfig\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// Adapter is a type which can adapt a configuration to Caddy JSON.\n// It returns the results and any warnings, or an error.\ntype Adapter interface {\n\tAdapt(body []byte, options map[string]any) ([]byte, []Warning, error)\n}\n\n// Warning represents a warning or notice related to conversion.\ntype Warning struct {\n\tFile      string `json:\"file,omitempty\"`\n\tLine      int    `json:\"line,omitempty\"`\n\tDirective string `json:\"directive,omitempty\"`\n\tMessage   string `json:\"message,omitempty\"`\n}\n\nfunc (w Warning) String() string {\n\tvar directive string\n\tif w.Directive != \"\" {\n\t\tdirective = fmt.Sprintf(\" (%s)\", w.Directive)\n\t}\n\treturn fmt.Sprintf(\"%s:%d%s: %s\", w.File, w.Line, directive, w.Message)\n}\n\n// JSON encodes val as JSON, returning it as a json.RawMessage. Any\n// marshaling errors (which are highly unlikely with correct code)\n// are converted to warnings. This is convenient when filling config\n// structs that require a json.RawMessage, without having to worry\n// about errors.\nfunc JSON(val any, warnings *[]Warning) json.RawMessage {\n\tb, err := json.Marshal(val)\n\tif err != nil {\n\t\tif warnings != nil {\n\t\t\t*warnings = append(*warnings, Warning{Message: err.Error()})\n\t\t}\n\t\treturn nil\n\t}\n\treturn b\n}\n\n// JSONModuleObject is like JSON(), except it marshals val into a JSON object\n// with an added key named fieldName with the value fieldVal. This is useful\n// for encoding module values where the module name has to be described within\n// the object by a certain key; for example, `\"handler\": \"file_server\"` for a\n// file server HTTP handler (fieldName=\"handler\" and fieldVal=\"file_server\").\n// The val parameter must encode into a map[string]any (i.e. it must be\n// a struct or map). Any errors are converted into warnings.\nfunc JSONModuleObject(val any, fieldName, fieldVal string, warnings *[]Warning) json.RawMessage {\n\t// encode to a JSON object first\n\tenc, err := json.Marshal(val)\n\tif err != nil {\n\t\tif warnings != nil {\n\t\t\t*warnings = append(*warnings, Warning{Message: err.Error()})\n\t\t}\n\t\treturn nil\n\t}\n\n\t// then decode the object\n\tvar tmp map[string]any\n\terr = json.Unmarshal(enc, &tmp)\n\tif err != nil {\n\t\tif warnings != nil {\n\t\t\t*warnings = append(*warnings, Warning{Message: err.Error()})\n\t\t}\n\t\treturn nil\n\t}\n\n\t// so we can easily add the module's field with its appointed value\n\ttmp[fieldName] = fieldVal\n\n\t// then re-marshal as JSON\n\tresult, err := json.Marshal(tmp)\n\tif err != nil {\n\t\tif warnings != nil {\n\t\t\t*warnings = append(*warnings, Warning{Message: err.Error()})\n\t\t}\n\t\treturn nil\n\t}\n\n\treturn result\n}\n\n// RegisterAdapter registers a config adapter with the given name.\n// This should usually be done at init-time. It panics if the\n// adapter cannot be registered successfully.\nfunc RegisterAdapter(name string, adapter Adapter) {\n\tif _, ok := configAdapters[name]; ok {\n\t\tpanic(fmt.Errorf(\"%s: already registered\", name))\n\t}\n\tconfigAdapters[name] = adapter\n\tcaddy.RegisterModule(adapterModule{name, adapter})\n}\n\n// GetAdapter returns the adapter with the given name,\n// or nil if one with that name is not registered.\nfunc GetAdapter(name string) Adapter {\n\treturn configAdapters[name]\n}\n\n// adapterModule is a wrapper type that can turn any config\n// adapter into a Caddy module, which has the benefit of being\n// counted with other modules, even though they do not\n// technically extend the Caddy configuration structure.\n// See caddyserver/caddy#3132.\ntype adapterModule struct {\n\tname string\n\tAdapter\n}\n\nfunc (am adapterModule) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  caddy.ModuleID(\"caddy.adapters.\" + am.name),\n\t\tNew: func() caddy.Module { return am },\n\t}\n}\n\nvar configAdapters = make(map[string]Adapter)\n",
    "source_file": "caddyconfig/configadapters.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyconfig\n\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"os\"\n\t\"time\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(HTTPLoader{})\n}\n\n// HTTPLoader can load Caddy configs over HTTP(S).\n//\n// If the response is not a JSON config, a config adapter must be specified\n// either in the loader config (`adapter`), or in the Content-Type HTTP header\n// returned in the HTTP response from the server. The Content-Type header is\n// read just like the admin API's `/load` endpoint. If you don't have control\n// over the HTTP server (but can still trust its response), you can override\n// the Content-Type header by setting the `adapter` property in this config.\ntype HTTPLoader struct {\n\t// The method for the request. Default: GET\n\tMethod string `json:\"method,omitempty\"`\n\n\t// The URL of the request.\n\tURL string `json:\"url,omitempty\"`\n\n\t// HTTP headers to add to the request.\n\tHeaders http.Header `json:\"header,omitempty\"`\n\n\t// Maximum time allowed for a complete connection and request.\n\tTimeout caddy.Duration `json:\"timeout,omitempty\"`\n\n\t// The name of the config adapter to use, if any. Only needed\n\t// if the HTTP response is not a JSON config and if the server's\n\t// Content-Type header is missing or incorrect.\n\tAdapter string `json:\"adapter,omitempty\"`\n\n\tTLS *struct {\n\t\t// Present this instance's managed remote identity credentials to the server.\n\t\tUseServerIdentity bool `json:\"use_server_identity,omitempty\"`\n\n\t\t// PEM-encoded client certificate filename to present to the server.\n\t\tClientCertificateFile string `json:\"client_certificate_file,omitempty\"`\n\n\t\t// PEM-encoded key to use with the client certificate.\n\t\tClientCertificateKeyFile string `json:\"client_certificate_key_file,omitempty\"`\n\n\t\t// List of PEM-encoded CA certificate files to add to the same trust\n\t\t// store as RootCAPool (or root_ca_pool in the JSON).\n\t\tRootCAPEMFiles []string `json:\"root_ca_pem_files,omitempty\"`\n\t} `json:\"tls,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (HTTPLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"caddy.config_loaders.http\",\n\t\tNew: func() caddy.Module { return new(HTTPLoader) },\n\t}\n}\n\n// LoadConfig loads a Caddy config.\nfunc (hl HTTPLoader) LoadConfig(ctx caddy.Context) ([]byte, error) {\n\trepl := caddy.NewReplacer()\n\n\tclient, err := hl.makeClient(ctx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmethod := repl.ReplaceAll(hl.Method, \"\")\n\tif method == \"\" {\n\t\tmethod = http.MethodGet\n\t}\n\n\turl := repl.ReplaceAll(hl.URL, \"\")\n\treq, err := http.NewRequest(method, url, nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor key, vals := range hl.Headers {\n\t\tfor _, val := range vals {\n\t\t\treq.Header.Add(repl.ReplaceAll(key, \"\"), repl.ReplaceKnown(val, \"\"))\n\t\t}\n\t}\n\n\tresp, err := doHttpCallWithRetries(ctx, client, req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\tif resp.StatusCode >= 400 {\n\t\treturn nil, fmt.Errorf(\"server responded with HTTP %d\", resp.StatusCode)\n\t}\n\n\tbody, err := io.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// adapt the config based on either manually-configured adapter or server's response header\n\tct := resp.Header.Get(\"Content-Type\")\n\tif hl.Adapter != \"\" {\n\t\tct = \"text/\" + hl.Adapter\n\t}\n\tresult, warnings, err := adaptByContentType(ct, body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tfor _, warn := range warnings {\n\t\tctx.Logger().Warn(warn.String())\n\t}\n\n\treturn result, nil\n}\n\nfunc attemptHttpCall(client *http.Client, request *http.Request) (*http.Response, error) {\n\tresp, err := client.Do(request)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"problem calling http loader url: %v\", err)\n\t} else if resp.StatusCode < 200 || resp.StatusCode > 499 {\n\t\tresp.Body.Close()\n\t\treturn nil, fmt.Errorf(\"bad response status code from http loader url: %v\", resp.StatusCode)\n\t}\n\treturn resp, nil\n}\n\nfunc doHttpCallWithRetries(ctx caddy.Context, client *http.Client, request *http.Request) (*http.Response, error) {\n\tvar resp *http.Response\n\tvar err error\n\tconst maxAttempts = 10\n\n\tfor i := 0; i < maxAttempts; i++ {\n\t\tresp, err = attemptHttpCall(client, request)\n\t\tif err != nil && i < maxAttempts-1 {\n\t\t\tselect {\n\t\t\tcase <-time.After(time.Millisecond * 500):\n\t\t\tcase <-ctx.Done():\n\t\t\t\treturn resp, ctx.Err()\n\t\t\t}\n\t\t} else {\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn resp, err\n}\n\nfunc (hl HTTPLoader) makeClient(ctx caddy.Context) (*http.Client, error) {\n\tclient := &http.Client{\n\t\tTimeout: time.Duration(hl.Timeout),\n\t}\n\n\tif hl.TLS != nil {\n\t\tvar tlsConfig *tls.Config\n\n\t\t// client authentication\n\t\tif hl.TLS.UseServerIdentity {\n\t\t\tcerts, err := ctx.IdentityCredentials(ctx.Logger())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"getting server identity credentials: %v\", err)\n\t\t\t}\n\t\t\t// See https://github.com/securego/gosec/issues/1054#issuecomment-2072235199\n\t\t\t//nolint:gosec\n\t\t\ttlsConfig = &tls.Config{Certificates: certs}\n\t\t} else if hl.TLS.ClientCertificateFile != \"\" && hl.TLS.ClientCertificateKeyFile != \"\" {\n\t\t\tcert, err := tls.LoadX509KeyPair(hl.TLS.ClientCertificateFile, hl.TLS.ClientCertificateKeyFile)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\t//nolint:gosec\n\t\t\ttlsConfig = &tls.Config{Certificates: []tls.Certificate{cert}}\n\t\t}\n\n\t\t// trusted server certs\n\t\tif len(hl.TLS.RootCAPEMFiles) > 0 {\n\t\t\trootPool := x509.NewCertPool()\n\t\t\tfor _, pemFile := range hl.TLS.RootCAPEMFiles {\n\t\t\t\tpemData, err := os.ReadFile(pemFile)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"failed reading ca cert: %v\", err)\n\t\t\t\t}\n\t\t\t\trootPool.AppendCertsFromPEM(pemData)\n\t\t\t}\n\t\t\tif tlsConfig == nil {\n\t\t\t\ttlsConfig = new(tls.Config)\n\t\t\t}\n\t\t\ttlsConfig.RootCAs = rootPool\n\t\t}\n\n\t\tclient.Transport = &http.Transport{TLSClientConfig: tlsConfig}\n\t}\n\n\treturn client, nil\n}\n\nvar _ caddy.ConfigLoader = (*HTTPLoader)(nil)\n",
    "source_file": "caddyconfig/httploader.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyconfig\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"mime\"\n\t\"net/http\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(adminLoad{})\n}\n\n// adminLoad is a module that provides the /load endpoint\n// for the Caddy admin API. The only reason it's not baked\n// into the caddy package directly is because of the import\n// of the caddyconfig package for its GetAdapter function.\n// If the caddy package depends on the caddyconfig package,\n// then the caddyconfig package will not be able to import\n// the caddy package, and it can more easily cause backward\n// edges in the dependency tree (i.e. import cycle).\n// Fortunately, the admin API has first-class support for\n// adding endpoints from modules.\ntype adminLoad struct{}\n\n// CaddyModule returns the Caddy module information.\nfunc (adminLoad) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"admin.api.load\",\n\t\tNew: func() caddy.Module { return new(adminLoad) },\n\t}\n}\n\n// Routes returns a route for the /load endpoint.\nfunc (al adminLoad) Routes() []caddy.AdminRoute {\n\treturn []caddy.AdminRoute{\n\t\t{\n\t\t\tPattern: \"/load\",\n\t\t\tHandler: caddy.AdminHandlerFunc(al.handleLoad),\n\t\t},\n\t\t{\n\t\t\tPattern: \"/adapt\",\n\t\t\tHandler: caddy.AdminHandlerFunc(al.handleAdapt),\n\t\t},\n\t}\n}\n\n// handleLoad replaces the entire current configuration with\n// a new one provided in the response body. It supports config\n// adapters through the use of the Content-Type header. A\n// config that is identical to the currently-running config\n// will be a no-op unless Cache-Control: must-revalidate is set.\nfunc (adminLoad) handleLoad(w http.ResponseWriter, r *http.Request) error {\n\tif r.Method != http.MethodPost {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusMethodNotAllowed,\n\t\t\tErr:        fmt.Errorf(\"method not allowed\"),\n\t\t}\n\t}\n\n\tbuf := bufPool.Get().(*bytes.Buffer)\n\tbuf.Reset()\n\tdefer bufPool.Put(buf)\n\n\t_, err := io.Copy(buf, r.Body)\n\tif err != nil {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\tErr:        fmt.Errorf(\"reading request body: %v\", err),\n\t\t}\n\t}\n\tbody := buf.Bytes()\n\n\t// if the config is formatted other than Caddy's native\n\t// JSON, we need to adapt it before loading it\n\tif ctHeader := r.Header.Get(\"Content-Type\"); ctHeader != \"\" {\n\t\tresult, warnings, err := adaptByContentType(ctHeader, body)\n\t\tif err != nil {\n\t\t\treturn caddy.APIError{\n\t\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\t\tErr:        err,\n\t\t\t}\n\t\t}\n\t\tif len(warnings) > 0 {\n\t\t\trespBody, err := json.Marshal(warnings)\n\t\t\tif err != nil {\n\t\t\t\tcaddy.Log().Named(\"admin.api.load\").Error(err.Error())\n\t\t\t}\n\t\t\t_, _ = w.Write(respBody)\n\t\t}\n\t\tbody = result\n\t}\n\n\tforceReload := r.Header.Get(\"Cache-Control\") == \"must-revalidate\"\n\n\terr = caddy.Load(body, forceReload)\n\tif err != nil {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\tErr:        fmt.Errorf(\"loading config: %v\", err),\n\t\t}\n\t}\n\n\tcaddy.Log().Named(\"admin.api\").Info(\"load complete\")\n\n\treturn nil\n}\n\n// handleAdapt adapts the given Caddy config to JSON and responds with the result.\nfunc (adminLoad) handleAdapt(w http.ResponseWriter, r *http.Request) error {\n\tif r.Method != http.MethodPost {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusMethodNotAllowed,\n\t\t\tErr:        fmt.Errorf(\"method not allowed\"),\n\t\t}\n\t}\n\n\tbuf := bufPool.Get().(*bytes.Buffer)\n\tbuf.Reset()\n\tdefer bufPool.Put(buf)\n\n\t_, err := io.Copy(buf, r.Body)\n\tif err != nil {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\tErr:        fmt.Errorf(\"reading request body: %v\", err),\n\t\t}\n\t}\n\n\tresult, warnings, err := adaptByContentType(r.Header.Get(\"Content-Type\"), buf.Bytes())\n\tif err != nil {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\tErr:        err,\n\t\t}\n\t}\n\n\tout := struct {\n\t\tWarnings []Warning       `json:\"warnings,omitempty\"`\n\t\tResult   json.RawMessage `json:\"result\"`\n\t}{\n\t\tWarnings: warnings,\n\t\tResult:   result,\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\treturn json.NewEncoder(w).Encode(out)\n}\n\n// adaptByContentType adapts body to Caddy JSON using the adapter specified by contentType.\n// If contentType is empty or ends with \"/json\", the input will be returned, as a no-op.\nfunc adaptByContentType(contentType string, body []byte) ([]byte, []Warning, error) {\n\t// assume JSON as the default\n\tif contentType == \"\" {\n\t\treturn body, nil, nil\n\t}\n\n\tct, _, err := mime.ParseMediaType(contentType)\n\tif err != nil {\n\t\treturn nil, nil, caddy.APIError{\n\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\tErr:        fmt.Errorf(\"invalid Content-Type: %v\", err),\n\t\t}\n\t}\n\n\t// if already JSON, no need to adapt\n\tif strings.HasSuffix(ct, \"/json\") {\n\t\treturn body, nil, nil\n\t}\n\n\t// adapter name should be suffix of MIME type\n\t_, adapterName, slashFound := strings.Cut(ct, \"/\")\n\tif !slashFound {\n\t\treturn nil, nil, fmt.Errorf(\"malformed Content-Type\")\n\t}\n\n\tcfgAdapter := GetAdapter(adapterName)\n\tif cfgAdapter == nil {\n\t\treturn nil, nil, fmt.Errorf(\"unrecognized config adapter '%s'\", adapterName)\n\t}\n\n\tresult, warnings, err := cfgAdapter.Adapt(body, nil)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"adapting config using %s adapter: %v\", adapterName, err)\n\t}\n\n\treturn result, warnings, nil\n}\n\nvar bufPool = sync.Pool{\n\tNew: func() any {\n\t\treturn new(bytes.Buffer)\n\t},\n}\n",
    "source_file": "caddyconfig/load.go",
    "chunk_type": "code"
  },
  {
    "content": "package internal\n\n// PrivateRangesCIDR returns a list of private CIDR range\n// strings, which can be used as a configuration shortcut.\nfunc PrivateRangesCIDR() []string {\n\treturn []string{\n\t\t\"192.168.0.0/16\",\n\t\t\"172.16.0.0/12\",\n\t\t\"10.0.0.0/8\",\n\t\t\"127.0.0.1/8\",\n\t\t\"fd00::/8\",\n\t\t\"::1\",\n\t}\n}\n",
    "source_file": "internal/ranges.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage internal\n\nimport (\n\t\"fmt\"\n\t\"io/fs\"\n\t\"strconv\"\n\t\"strings\"\n)\n\n// SplitUnixSocketPermissionsBits takes a unix socket address in the\n// unusual \"path|bits\" format (e.g. /run/caddy.sock|0222) and tries\n// to split it into socket path (host) and permissions bits (port).\n// Colons (\":\") can't be used as separator, as socket paths on Windows\n// may include a drive letter (e.g. `unix/c:\\absolute\\path.sock`).\n// Permission bits will default to 0200 if none are specified.\n// Throws an error, if the first carrying bit does not\n// include write perms (e.g. `0422` or `022`).\n// Symbolic permission representation (e.g. `u=w,g=w,o=w`)\n// is not supported and will throw an error for now!\nfunc SplitUnixSocketPermissionsBits(addr string) (path string, fileMode fs.FileMode, err error) {\n\taddrSplit := strings.SplitN(addr, \"|\", 2)\n\n\tif len(addrSplit) == 2 {\n\t\t// parse octal permission bit string as uint32\n\t\tfileModeUInt64, err := strconv.ParseUint(addrSplit[1], 8, 32)\n\t\tif err != nil {\n\t\t\treturn \"\", 0, fmt.Errorf(\"could not parse octal permission bits in %s: %v\", addr, err)\n\t\t}\n\t\tfileMode = fs.FileMode(fileModeUInt64)\n\n\t\t// FileMode.String() returns a string like `-rwxr-xr--` for `u=rwx,g=rx,o=r` (`0754`)\n\t\tif string(fileMode.String()[2]) != \"w\" {\n\t\t\treturn \"\", 0, fmt.Errorf(\"owner of the socket requires '-w-' (write, octal: '2') permissions at least; got '%s' in %s\", fileMode.String()[1:4], addr)\n\t\t}\n\n\t\treturn addrSplit[0], fileMode, nil\n\t}\n\n\t// default to 0200 (symbolic: `u=w,g=,o=`)\n\t// if no permission bits are specified\n\treturn addr, 0o200, nil\n}\n",
    "source_file": "internal/sockets.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2020 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage metrics\n\nimport (\n\t\"errors\"\n\t\"net/http\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(AdminMetrics{})\n}\n\n// AdminMetrics is a module that serves a metrics endpoint so that any gathered\n// metrics can be exposed for scraping. This module is not configurable, and\n// is permanently mounted to the admin API endpoint at \"/metrics\".\n// See the Metrics module for a configurable endpoint that is usable if the\n// Admin API is disabled.\ntype AdminMetrics struct {\n\tregistry *prometheus.Registry\n\n\tmetricsHandler http.Handler\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (AdminMetrics) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"admin.api.metrics\",\n\t\tNew: func() caddy.Module { return new(AdminMetrics) },\n\t}\n}\n\n// Provision -\nfunc (m *AdminMetrics) Provision(ctx caddy.Context) error {\n\tm.registry = ctx.GetMetricsRegistry()\n\tif m.registry == nil {\n\t\treturn errors.New(\"no metrics registry found\")\n\t}\n\tm.metricsHandler = createMetricsHandler(nil, false, m.registry)\n\treturn nil\n}\n\n// Routes returns a route for the /metrics endpoint.\nfunc (m *AdminMetrics) Routes() []caddy.AdminRoute {\n\treturn []caddy.AdminRoute{{Pattern: \"/metrics\", Handler: caddy.AdminHandlerFunc(m.serveHTTP)}}\n}\n\nfunc (m *AdminMetrics) serveHTTP(w http.ResponseWriter, r *http.Request) error {\n\tm.metricsHandler.ServeHTTP(w, r)\n\treturn nil\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner = (*AdminMetrics)(nil)\n\t_ caddy.AdminRouter = (*AdminMetrics)(nil)\n)\n",
    "source_file": "modules/metrics/adminmetrics.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2020 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage metrics\n\nimport (\n\t\"errors\"\n\t\"net/http\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promhttp\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Metrics{})\n\thttpcaddyfile.RegisterHandlerDirective(\"metrics\", parseCaddyfile)\n}\n\n// Metrics is a module that serves a /metrics endpoint so that any gathered\n// metrics can be exposed for scraping. This module is configurable by end-users\n// unlike AdminMetrics.\ntype Metrics struct {\n\tmetricsHandler http.Handler\n\n\t// Disable OpenMetrics negotiation, enabled by default. May be necessary if\n\t// the produced metrics cannot be parsed by the service scraping metrics.\n\tDisableOpenMetrics bool `json:\"disable_openmetrics,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Metrics) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.metrics\",\n\t\tNew: func() caddy.Module { return new(Metrics) },\n\t}\n}\n\ntype zapLogger struct {\n\tzl *zap.Logger\n}\n\nfunc (l *zapLogger) Println(v ...any) {\n\tl.zl.Sugar().Error(v...)\n}\n\n// Provision sets up m.\nfunc (m *Metrics) Provision(ctx caddy.Context) error {\n\tlog := ctx.Logger()\n\tregistry := ctx.GetMetricsRegistry()\n\tif registry == nil {\n\t\treturn errors.New(\"no metrics registry found\")\n\t}\n\tm.metricsHandler = createMetricsHandler(&zapLogger{log}, !m.DisableOpenMetrics, registry)\n\treturn nil\n}\n\nfunc parseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\tvar m Metrics\n\terr := m.UnmarshalCaddyfile(h.Dispenser)\n\treturn m, err\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens. Syntax:\n//\n//\tmetrics [<matcher>] {\n//\t    disable_openmetrics\n//\t}\nfunc (m *Metrics) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume directive name\n\targs := d.RemainingArgs()\n\tif len(args) > 0 {\n\t\treturn d.ArgErr()\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"disable_openmetrics\":\n\t\t\tm.DisableOpenMetrics = true\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective %q\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (m Metrics) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\tm.metricsHandler.ServeHTTP(w, r)\n\treturn nil\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*Metrics)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*Metrics)(nil)\n\t_ caddyfile.Unmarshaler       = (*Metrics)(nil)\n)\n\nfunc createMetricsHandler(logger promhttp.Logger, enableOpenMetrics bool, registry *prometheus.Registry) http.Handler {\n\treturn promhttp.InstrumentMetricHandler(registry,\n\t\tpromhttp.HandlerFor(registry, promhttp.HandlerOpts{\n\t\t\t// will only log errors if logger is non-nil\n\t\t\tErrorLog: logger,\n\n\t\t\t// Allow OpenMetrics format to be negotiated - largely compatible,\n\t\t\t// except quantile/le label values always have a decimal.\n\t\t\tEnableOpenMetrics: enableOpenMetrics,\n\t\t}),\n\t)\n}\n",
    "source_file": "modules/metrics/metrics.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/netip\"\n\t\"reflect\"\n\t\"strings\"\n\n\t\"github.com/google/cel-go/cel\"\n\t\"github.com/google/cel-go/common/types/ref\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/internal\"\n)\n\n// MatchRemoteIP matches requests by the remote IP address,\n// i.e. the IP address of the direct connection to Caddy.\ntype MatchRemoteIP struct {\n\t// The IPs or CIDR ranges to match.\n\tRanges []string `json:\"ranges,omitempty\"`\n\n\t// cidrs and zones vars should aligned always in the same\n\t// length and indexes for matching later\n\tcidrs  []*netip.Prefix\n\tzones  []string\n\tlogger *zap.Logger\n}\n\n// MatchClientIP matches requests by the client IP address,\n// i.e. the resolved address, considering trusted proxies.\ntype MatchClientIP struct {\n\t// The IPs or CIDR ranges to match.\n\tRanges []string `json:\"ranges,omitempty\"`\n\n\t// cidrs and zones vars should aligned always in the same\n\t// length and indexes for matching later\n\tcidrs  []*netip.Prefix\n\tzones  []string\n\tlogger *zap.Logger\n}\n\nfunc init() {\n\tcaddy.RegisterModule(MatchRemoteIP{})\n\tcaddy.RegisterModule(MatchClientIP{})\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchRemoteIP) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.remote_ip\",\n\t\tNew: func() caddy.Module { return new(MatchRemoteIP) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchRemoteIP) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tfor d.NextArg() {\n\t\t\tif d.Val() == \"forwarded\" {\n\t\t\t\treturn d.Err(\"the 'forwarded' option is no longer supported; use the 'client_ip' matcher instead\")\n\t\t\t}\n\t\t\tif d.Val() == \"private_ranges\" {\n\t\t\t\tm.Ranges = append(m.Ranges, internal.PrivateRangesCIDR()...)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tm.Ranges = append(m.Ranges, d.Val())\n\t\t}\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed remote_ip matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression remote_ip('192.168.0.0/16', '172.16.0.0/12', '10.0.0.0/8')\nfunc (MatchRemoteIP) CELLibrary(ctx caddy.Context) (cel.Library, error) {\n\treturn CELMatcherImpl(\n\t\t// name of the macro, this is the function name that users see when writing expressions.\n\t\t\"remote_ip\",\n\t\t// name of the function that the macro will be rewritten to call.\n\t\t\"remote_ip_match_request_list\",\n\t\t// internal data type of the MatchPath value.\n\t\t[]*cel.Type{cel.ListType(cel.StringType)},\n\t\t// function to convert a constant list of strings to a MatchPath instance.\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tstrList, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tm := MatchRemoteIP{}\n\n\t\t\tfor _, input := range strList.([]string) {\n\t\t\t\tif input == \"forwarded\" {\n\t\t\t\t\treturn nil, errors.New(\"the 'forwarded' option is no longer supported; use the 'client_ip' matcher instead\")\n\t\t\t\t}\n\t\t\t\tm.Ranges = append(m.Ranges, input)\n\t\t\t}\n\n\t\t\terr = m.Provision(ctx)\n\t\t\treturn m, err\n\t\t},\n\t)\n}\n\n// Provision parses m's IP ranges, either from IP or CIDR expressions.\nfunc (m *MatchRemoteIP) Provision(ctx caddy.Context) error {\n\tm.logger = ctx.Logger()\n\tcidrs, zones, err := provisionCidrsZonesFromRanges(m.Ranges)\n\tif err != nil {\n\t\treturn err\n\t}\n\tm.cidrs = cidrs\n\tm.zones = zones\n\n\treturn nil\n}\n\n// Match returns true if r matches m.\nfunc (m MatchRemoteIP) Match(r *http.Request) bool {\n\tmatch, err := m.MatchWithError(r)\n\tif err != nil {\n\t\tSetVar(r.Context(), MatcherErrorVarKey, err)\n\t}\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchRemoteIP) MatchWithError(r *http.Request) (bool, error) {\n\t// if handshake is not finished, we infer 0-RTT that has\n\t// not verified remote IP; could be spoofed, so we throw\n\t// HTTP 425 status to tell the client to try again after\n\t// the handshake is complete\n\tif r.TLS != nil && !r.TLS.HandshakeComplete {\n\t\treturn false, Error(http.StatusTooEarly, fmt.Errorf(\"TLS handshake not complete, remote IP cannot be verified\"))\n\t}\n\n\taddress := r.RemoteAddr\n\tclientIP, zoneID, err := parseIPZoneFromString(address)\n\tif err != nil {\n\t\tif c := m.logger.Check(zapcore.ErrorLevel, \"getting remote \"); c != nil {\n\t\t\tc.Write(zap.Error(err))\n\t\t}\n\n\t\treturn false, nil\n\t}\n\tmatches, zoneFilter := matchIPByCidrZones(clientIP, zoneID, m.cidrs, m.zones)\n\tif !matches && !zoneFilter {\n\t\tif c := m.logger.Check(zapcore.DebugLevel, \"zone ID from remote IP did not match\"); c != nil {\n\t\t\tc.Write(zap.String(\"zone\", zoneID))\n\t\t}\n\t}\n\treturn matches, nil\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchClientIP) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.client_ip\",\n\t\tNew: func() caddy.Module { return new(MatchClientIP) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchClientIP) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tfor d.NextArg() {\n\t\t\tif d.Val() == \"private_ranges\" {\n\t\t\t\tm.Ranges = append(m.Ranges, internal.PrivateRangesCIDR()...)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tm.Ranges = append(m.Ranges, d.Val())\n\t\t}\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed client_ip matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression client_ip('192.168.0.0/16', '172.16.0.0/12', '10.0.0.0/8')\nfunc (MatchClientIP) CELLibrary(ctx caddy.Context) (cel.Library, error) {\n\treturn CELMatcherImpl(\n\t\t// name of the macro, this is the function name that users see when writing expressions.\n\t\t\"client_ip\",\n\t\t// name of the function that the macro will be rewritten to call.\n\t\t\"client_ip_match_request_list\",\n\t\t// internal data type of the MatchPath value.\n\t\t[]*cel.Type{cel.ListType(cel.StringType)},\n\t\t// function to convert a constant list of strings to a MatchPath instance.\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tstrList, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tm := MatchClientIP{\n\t\t\t\tRanges: strList.([]string),\n\t\t\t}\n\n\t\t\terr = m.Provision(ctx)\n\t\t\treturn m, err\n\t\t},\n\t)\n}\n\n// Provision parses m's IP ranges, either from IP or CIDR expressions.\nfunc (m *MatchClientIP) Provision(ctx caddy.Context) error {\n\tm.logger = ctx.Logger()\n\tcidrs, zones, err := provisionCidrsZonesFromRanges(m.Ranges)\n\tif err != nil {\n\t\treturn err\n\t}\n\tm.cidrs = cidrs\n\tm.zones = zones\n\treturn nil\n}\n\n// Match returns true if r matches m.\nfunc (m MatchClientIP) Match(r *http.Request) bool {\n\tmatch, err := m.MatchWithError(r)\n\tif err != nil {\n\t\tSetVar(r.Context(), MatcherErrorVarKey, err)\n\t}\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchClientIP) MatchWithError(r *http.Request) (bool, error) {\n\t// if handshake is not finished, we infer 0-RTT that has\n\t// not verified remote IP; could be spoofed, so we throw\n\t// HTTP 425 status to tell the client to try again after\n\t// the handshake is complete\n\tif r.TLS != nil && !r.TLS.HandshakeComplete {\n\t\treturn false, Error(http.StatusTooEarly, fmt.Errorf(\"TLS handshake not complete, remote IP cannot be verified\"))\n\t}\n\n\taddress := GetVar(r.Context(), ClientIPVarKey).(string)\n\tclientIP, zoneID, err := parseIPZoneFromString(address)\n\tif err != nil {\n\t\tm.logger.Error(\"getting client IP\", zap.Error(err))\n\t\treturn false, nil\n\t}\n\tmatches, zoneFilter := matchIPByCidrZones(clientIP, zoneID, m.cidrs, m.zones)\n\tif !matches && !zoneFilter {\n\t\tm.logger.Debug(\"zone ID from client IP did not match\", zap.String(\"zone\", zoneID))\n\t}\n\treturn matches, nil\n}\n\nfunc provisionCidrsZonesFromRanges(ranges []string) ([]*netip.Prefix, []string, error) {\n\tcidrs := []*netip.Prefix{}\n\tzones := []string{}\n\trepl := caddy.NewReplacer()\n\tfor _, str := range ranges {\n\t\tstr = repl.ReplaceAll(str, \"\")\n\t\t// Exclude the zone_id from the IP\n\t\tif strings.Contains(str, \"%\") {\n\t\t\tsplit := strings.Split(str, \"%\")\n\t\t\tstr = split[0]\n\t\t\t// write zone identifiers in m.zones for matching later\n\t\t\tzones = append(zones, split[1])\n\t\t} else {\n\t\t\tzones = append(zones, \"\")\n\t\t}\n\t\tif strings.Contains(str, \"/\") {\n\t\t\tipNet, err := netip.ParsePrefix(str)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, fmt.Errorf(\"parsing CIDR expression '%s': %v\", str, err)\n\t\t\t}\n\t\t\tcidrs = append(cidrs, &ipNet)\n\t\t} else {\n\t\t\tipAddr, err := netip.ParseAddr(str)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, fmt.Errorf(\"invalid IP address: '%s': %v\", str, err)\n\t\t\t}\n\t\t\tipNew := netip.PrefixFrom(ipAddr, ipAddr.BitLen())\n\t\t\tcidrs = append(cidrs, &ipNew)\n\t\t}\n\t}\n\treturn cidrs, zones, nil\n}\n\nfunc parseIPZoneFromString(address string) (netip.Addr, string, error) {\n\tipStr, _, err := net.SplitHostPort(address)\n\tif err != nil {\n\t\tipStr = address // OK; probably didn't have a port\n\t}\n\n\t// Some IPv6-Addresses can contain zone identifiers at the end,\n\t// which are separated with \"%\"\n\tzoneID := \"\"\n\tif strings.Contains(ipStr, \"%\") {\n\t\tsplit := strings.Split(ipStr, \"%\")\n\t\tipStr = split[0]\n\t\tzoneID = split[1]\n\t}\n\n\tipAddr, err := netip.ParseAddr(ipStr)\n\tif err != nil {\n\t\treturn netip.IPv4Unspecified(), \"\", err\n\t}\n\n\treturn ipAddr, zoneID, nil\n}\n\nfunc matchIPByCidrZones(clientIP netip.Addr, zoneID string, cidrs []*netip.Prefix, zones []string) (bool, bool) {\n\tzoneFilter := true\n\tfor i, ipRange := range cidrs {\n\t\tif ipRange.Contains(clientIP) {\n\t\t\t// Check if there are zone filters assigned and if they match.\n\t\t\tif zones[i] == \"\" || zoneID == zones[i] {\n\t\t\t\treturn true, false\n\t\t\t}\n\t\t\tzoneFilter = false\n\t\t}\n\t}\n\treturn false, zoneFilter\n}\n\n// Interface guards\nvar (\n\t_ RequestMatcherWithError = (*MatchRemoteIP)(nil)\n\t_ caddy.Provisioner       = (*MatchRemoteIP)(nil)\n\t_ caddyfile.Unmarshaler   = (*MatchRemoteIP)(nil)\n\t_ CELLibraryProducer      = (*MatchRemoteIP)(nil)\n\n\t_ RequestMatcherWithError = (*MatchClientIP)(nil)\n\t_ caddy.Provisioner       = (*MatchClientIP)(nil)\n\t_ caddyfile.Unmarshaler   = (*MatchClientIP)(nil)\n\t_ CELLibraryProducer      = (*MatchClientIP)(nil)\n)\n",
    "source_file": "modules/caddyhttp/ip_matchers.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"slices\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/internal\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\n// AutoHTTPSConfig is used to disable automatic HTTPS\n// or certain aspects of it for a specific server.\n// HTTPS is enabled automatically and by default when\n// qualifying hostnames are available from the config.\ntype AutoHTTPSConfig struct {\n\t// If true, automatic HTTPS will be entirely disabled,\n\t// including certificate management and redirects.\n\tDisabled bool `json:\"disable,omitempty\"`\n\n\t// If true, only automatic HTTP->HTTPS redirects will\n\t// be disabled, but other auto-HTTPS features will\n\t// remain enabled.\n\tDisableRedir bool `json:\"disable_redirects,omitempty\"`\n\n\t// If true, automatic certificate management will be\n\t// disabled, but other auto-HTTPS features will\n\t// remain enabled.\n\tDisableCerts bool `json:\"disable_certificates,omitempty\"`\n\n\t// Hosts/domain names listed here will not be included\n\t// in automatic HTTPS (they will not have certificates\n\t// loaded nor redirects applied).\n\tSkip []string `json:\"skip,omitempty\"`\n\n\t// Hosts/domain names listed here will still be enabled\n\t// for automatic HTTPS (unless in the Skip list), except\n\t// that certificates will not be provisioned and managed\n\t// for these names.\n\tSkipCerts []string `json:\"skip_certificates,omitempty\"`\n\n\t// By default, automatic HTTPS will obtain and renew\n\t// certificates for qualifying hostnames. However, if\n\t// a certificate with a matching SAN is already loaded\n\t// into the cache, certificate management will not be\n\t// enabled. To force automated certificate management\n\t// regardless of loaded certificates, set this to true.\n\tIgnoreLoadedCerts bool `json:\"ignore_loaded_certificates,omitempty\"`\n}\n\n// automaticHTTPSPhase1 provisions all route matchers, determines\n// which domain names found in the routes qualify for automatic\n// HTTPS, and sets up HTTP->HTTPS redirects. This phase must occur\n// at the beginning of provisioning, because it may add routes and\n// even servers to the app, which still need to be set up with the\n// rest of them during provisioning.\nfunc (app *App) automaticHTTPSPhase1(ctx caddy.Context, repl *caddy.Replacer) error {\n\tlogger := app.logger.Named(\"auto_https\")\n\n\t// this map acts as a set to store the domain names\n\t// for which we will manage certificates automatically\n\tuniqueDomainsForCerts := make(map[string]struct{})\n\n\t// this maps domain names for automatic HTTP->HTTPS\n\t// redirects to their destination server addresses\n\t// (there might be more than 1 if bind is used; see\n\t// https://github.com/caddyserver/caddy/issues/3443)\n\tredirDomains := make(map[string][]caddy.NetworkAddress)\n\n\t// the log configuration for an HTTPS enabled server\n\tvar logCfg *ServerLogConfig\n\n\tfor srvName, srv := range app.Servers {\n\t\t// as a prerequisite, provision route matchers; this is\n\t\t// required for all routes on all servers, and must be\n\t\t// done before we attempt to do phase 1 of auto HTTPS,\n\t\t// since we have to access the decoded host matchers the\n\t\t// handlers will be provisioned later\n\t\tif srv.Routes != nil {\n\t\t\terr := srv.Routes.ProvisionMatchers(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"server %s: setting up route matchers: %v\", srvName, err)\n\t\t\t}\n\t\t}\n\n\t\t// prepare for automatic HTTPS\n\t\tif srv.AutoHTTPS == nil {\n\t\t\tsrv.AutoHTTPS = new(AutoHTTPSConfig)\n\t\t}\n\t\tif srv.AutoHTTPS.Disabled {\n\t\t\tlogger.Info(\"automatic HTTPS is completely disabled for server\", zap.String(\"server_name\", srvName))\n\t\t\tcontinue\n\t\t}\n\n\t\t// skip if all listeners use the HTTP port\n\t\tif !srv.listenersUseAnyPortOtherThan(app.httpPort()) {\n\t\t\tlogger.Warn(\"server is listening only on the HTTP port, so no automatic HTTPS will be applied to this server\",\n\t\t\t\tzap.String(\"server_name\", srvName),\n\t\t\t\tzap.Int(\"http_port\", app.httpPort()),\n\t\t\t)\n\t\t\tsrv.AutoHTTPS.Disabled = true\n\t\t\tcontinue\n\t\t}\n\n\t\t// if all listeners are on the HTTPS port, make sure\n\t\t// there is at least one TLS connection policy; it\n\t\t// should be obvious that they want to use TLS without\n\t\t// needing to specify one empty policy to enable it\n\t\tif srv.TLSConnPolicies == nil &&\n\t\t\t!srv.listenersUseAnyPortOtherThan(app.httpsPort()) {\n\t\t\tlogger.Info(\"server is listening only on the HTTPS port but has no TLS connection policies; adding one to enable TLS\",\n\t\t\t\tzap.String(\"server_name\", srvName),\n\t\t\t\tzap.Int(\"https_port\", app.httpsPort()),\n\t\t\t)\n\t\t\tsrv.TLSConnPolicies = caddytls.ConnectionPolicies{new(caddytls.ConnectionPolicy)}\n\t\t}\n\n\t\t// find all qualifying domain names (deduplicated) in this server\n\t\t// (this is where we need the provisioned, decoded request matchers)\n\t\tserverDomainSet := make(map[string]struct{})\n\t\tfor routeIdx, route := range srv.Routes {\n\t\t\tfor matcherSetIdx, matcherSet := range route.MatcherSets {\n\t\t\t\tfor matcherIdx, m := range matcherSet {\n\t\t\t\t\tif hm, ok := m.(*MatchHost); ok {\n\t\t\t\t\t\tfor hostMatcherIdx, d := range *hm {\n\t\t\t\t\t\t\tvar err error\n\t\t\t\t\t\t\td, err = repl.ReplaceOrErr(d, true, false)\n\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\treturn fmt.Errorf(\"%s: route %d, matcher set %d, matcher %d, host matcher %d: %v\",\n\t\t\t\t\t\t\t\t\tsrvName, routeIdx, matcherSetIdx, matcherIdx, hostMatcherIdx, err)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tif !slices.Contains(srv.AutoHTTPS.Skip, d) {\n\t\t\t\t\t\t\t\tserverDomainSet[d] = struct{}{}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// build the list of domains that could be used with ECH (if enabled)\n\t\t// so the TLS app can know to publish ECH configs for them\n\t\techDomains := make([]string, 0, len(serverDomainSet))\n\t\tfor d := range serverDomainSet {\n\t\t\techDomains = append(echDomains, d)\n\t\t}\n\t\tapp.tlsApp.RegisterServerNames(echDomains)\n\n\t\t// nothing more to do here if there are no domains that qualify for\n\t\t// automatic HTTPS and there are no explicit TLS connection policies:\n\t\t// if there is at least one domain but no TLS conn policy (F&&T), we'll\n\t\t// add one below; if there are no domains but at least one TLS conn\n\t\t// policy (meaning TLS is enabled) (T&&F), it could be a catch-all with\n\t\t// on-demand TLS -- and in that case we would still need HTTP->HTTPS\n\t\t// redirects, which we set up below; hence these two conditions\n\t\tif len(serverDomainSet) == 0 && len(srv.TLSConnPolicies) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\t// clone the logger so we can apply it to the HTTP server\n\t\t// (not sure if necessary to clone it; but probably safer)\n\t\t// (we choose one log cfg arbitrarily; not sure which is best)\n\t\tif srv.Logs != nil {\n\t\t\tlogCfg = srv.Logs.clone()\n\t\t}\n\n\t\t// for all the hostnames we found, filter them so we have\n\t\t// a deduplicated list of names for which to obtain certs\n\t\t// (only if cert management not disabled for this server)\n\t\tif srv.AutoHTTPS.DisableCerts {\n\t\t\tlogger.Warn(\"skipping automated certificate management for server because it is disabled\", zap.String(\"server_name\", srvName))\n\t\t} else {\n\t\t\tfor d := range serverDomainSet {\n\t\t\t\tif certmagic.SubjectQualifiesForCert(d) &&\n\t\t\t\t\t!slices.Contains(srv.AutoHTTPS.SkipCerts, d) {\n\t\t\t\t\t// if a certificate for this name is already loaded,\n\t\t\t\t\t// don't obtain another one for it, unless we are\n\t\t\t\t\t// supposed to ignore loaded certificates\n\t\t\t\t\tif !srv.AutoHTTPS.IgnoreLoadedCerts && app.tlsApp.HasCertificateForSubject(d) {\n\t\t\t\t\t\tlogger.Info(\"skipping automatic certificate management because one or more matching certificates are already loaded\",\n\t\t\t\t\t\t\tzap.String(\"domain\", d),\n\t\t\t\t\t\t\tzap.String(\"server_name\", srvName),\n\t\t\t\t\t\t)\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// most clients don't accept wildcards like *.tld... we\n\t\t\t\t\t// can handle that, but as a courtesy, warn the user\n\t\t\t\t\tif strings.Contains(d, \"*\") &&\n\t\t\t\t\t\tstrings.Count(strings.Trim(d, \".\"), \".\") == 1 {\n\t\t\t\t\t\tlogger.Warn(\"most clients do not trust second-level wildcard certificates (*.tld)\",\n\t\t\t\t\t\t\tzap.String(\"domain\", d))\n\t\t\t\t\t}\n\n\t\t\t\t\tuniqueDomainsForCerts[d] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// tell the server to use TLS if it is not already doing so\n\t\tif srv.TLSConnPolicies == nil {\n\t\t\tsrv.TLSConnPolicies = caddytls.ConnectionPolicies{new(caddytls.ConnectionPolicy)}\n\t\t}\n\n\t\t// nothing left to do if auto redirects are disabled\n\t\tif srv.AutoHTTPS.DisableRedir {\n\t\t\tlogger.Info(\"automatic HTTP->HTTPS redirects are disabled\", zap.String(\"server_name\", srvName))\n\t\t\tcontinue\n\t\t}\n\n\t\tlogger.Info(\"enabling automatic HTTP->HTTPS redirects\", zap.String(\"server_name\", srvName))\n\n\t\t// create HTTP->HTTPS redirects\n\t\tfor _, listenAddr := range srv.Listen {\n\t\t\t// figure out the address we will redirect to...\n\t\t\taddr, err := caddy.ParseNetworkAddress(listenAddr)\n\t\t\tif err != nil {\n\t\t\t\tmsg := \"%s: invalid listener address: %v\"\n\t\t\t\tif strings.Count(listenAddr, \":\") > 1 {\n\t\t\t\t\tmsg = msg + \", there are too many colons, so the port is ambiguous. Did you mean to wrap the IPv6 address with [] brackets?\"\n\t\t\t\t}\n\t\t\t\treturn fmt.Errorf(msg, srvName, listenAddr)\n\t\t\t}\n\n\t\t\t// this address might not have a hostname, i.e. might be a\n\t\t\t// catch-all address for a particular port; we need to keep\n\t\t\t// track if it is, so we can set up redirects for it anyway\n\t\t\t// (e.g. the user might have enabled on-demand TLS); we use\n\t\t\t// an empty string to indicate a catch-all, which we have to\n\t\t\t// treat special later\n\t\t\tif len(serverDomainSet) == 0 {\n\t\t\t\tredirDomains[\"\"] = append(redirDomains[\"\"], addr)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// ...and associate it with each domain in this server\n\t\t\tfor d := range serverDomainSet {\n\t\t\t\t// if this domain is used on more than one HTTPS-enabled\n\t\t\t\t// port, we'll have to choose one, so prefer the HTTPS port\n\t\t\t\tif _, ok := redirDomains[d]; !ok ||\n\t\t\t\t\taddr.StartPort == uint(app.httpsPort()) {\n\t\t\t\t\tredirDomains[d] = append(redirDomains[d], addr)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// we now have a list of all the unique names for which we need certs\n\tvar internal, tailscale []string\nuniqueDomainsLoop:\n\tfor d := range uniqueDomainsForCerts {\n\t\t// some names we've found might already have automation policies\n\t\t// explicitly specified for them; we should exclude those from\n\t\t// our hidden/implicit policy, since applying a name to more than\n\t\t// one automation policy would be confusing and an error\n\t\tif app.tlsApp.Automation != nil {\n\t\t\tfor _, ap := range app.tlsApp.Automation.Policies {\n\t\t\t\tfor _, apHost := range ap.Subjects() {\n\t\t\t\t\tif apHost == d {\n\t\t\t\t\t\t// if the automation policy has all internal subjects but no issuers,\n\t\t\t\t\t\t// it will default to CertMagic's issuers which are public CAs; use\n\t\t\t\t\t\t// our internal issuer instead\n\t\t\t\t\t\tif len(ap.Issuers) == 0 && ap.AllInternalSubjects() {\n\t\t\t\t\t\t\tiss := new(caddytls.InternalIssuer)\n\t\t\t\t\t\t\tif err := iss.Provision(ctx); err != nil {\n\t\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tap.Issuers = append(ap.Issuers, iss)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tcontinue uniqueDomainsLoop\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// if no automation policy exists for the name yet, we will associate it with an implicit one;\n\t\t// we handle tailscale domains specially, and we also separate out identifiers that need the\n\t\t// internal issuer (self-signed certs); certmagic does not consider public IP addresses to be\n\t\t// disqualified for public certs, because there are public CAs that will issue certs for IPs.\n\t\t// However, with auto-HTTPS, many times there is no issuer explicitly defined, and the default\n\t\t// issuers do not (currently, as of 2024) issue IP certificates; so assign all IP subjects to\n\t\t// the internal issuer when there are no explicit automation policies\n\t\tshouldUseInternal := func(ident string) bool {\n\t\t\tusingDefaultIssuersAndIsIP := certmagic.SubjectIsIP(ident) &&\n\t\t\t\t(app.tlsApp == nil || app.tlsApp.Automation == nil || len(app.tlsApp.Automation.Policies) == 0)\n\t\t\treturn !certmagic.SubjectQualifiesForPublicCert(d) || usingDefaultIssuersAndIsIP\n\t\t}\n\t\tif isTailscaleDomain(d) {\n\t\t\ttailscale = append(tailscale, d)\n\t\t\tdelete(uniqueDomainsForCerts, d) // not managed by us; handled separately\n\t\t} else if shouldUseInternal(d) {\n\t\t\tinternal = append(internal, d)\n\t\t}\n\t}\n\n\t// ensure there is an automation policy to handle these certs\n\terr := app.createAutomationPolicies(ctx, internal, tailscale)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// we need to reduce the mapping, i.e. group domains by address\n\t// since new routes are appended to servers by their address\n\tdomainsByAddr := make(map[string][]string)\n\tfor domain, addrs := range redirDomains {\n\t\tfor _, addr := range addrs {\n\t\t\taddrStr := addr.String()\n\t\t\tdomainsByAddr[addrStr] = append(domainsByAddr[addrStr], domain)\n\t\t}\n\t}\n\n\t// these keep track of the redirect server address(es)\n\t// and the routes for those servers which actually\n\t// respond with the redirects\n\tredirServerAddrs := make(map[string]struct{})\n\tredirServers := make(map[string][]Route)\n\tvar redirRoutes RouteList\n\n\tfor addrStr, domains := range domainsByAddr {\n\t\t// build the matcher set for this redirect route; (note that we happen\n\t\t// to bypass Provision and Validate steps for these matcher modules)\n\t\tmatcherSet := MatcherSet{MatchProtocol(\"http\")}\n\t\t// match on known domain names, unless it's our special case of a\n\t\t// catch-all which is an empty string (common among catch-all sites\n\t\t// that enable on-demand TLS for yet-unknown domain names)\n\t\tif len(domains) != 1 || domains[0] != \"\" {\n\t\t\tmatcherSet = append(matcherSet, MatchHost(domains))\n\t\t}\n\n\t\taddr, err := caddy.ParseNetworkAddress(addrStr)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tredirRoute := app.makeRedirRoute(addr.StartPort, matcherSet)\n\n\t\t// use the network/host information from the address,\n\t\t// but change the port to the HTTP port then rebuild\n\t\tredirAddr := addr\n\t\tredirAddr.StartPort = uint(app.httpPort())\n\t\tredirAddr.EndPort = redirAddr.StartPort\n\t\tredirAddrStr := redirAddr.String()\n\n\t\tredirServers[redirAddrStr] = append(redirServers[redirAddrStr], redirRoute)\n\t}\n\n\t// on-demand TLS means that hostnames may be used which are not\n\t// explicitly defined in the config, and we still need to redirect\n\t// those; so we can append a single catch-all route (notice there\n\t// is no Host matcher) after the other redirect routes which will\n\t// allow us to handle unexpected/new hostnames... however, it's\n\t// not entirely clear what the redirect destination should be,\n\t// so I'm going to just hard-code the app's HTTPS port and call\n\t// it good for now...\n\t// TODO: This implies that all plaintext requests will be blindly\n\t// redirected to their HTTPS equivalent, even if this server\n\t// doesn't handle that hostname at all; I don't think this is a\n\t// bad thing, and it also obscures the actual hostnames that this\n\t// server is configured to match on, which may be desirable, but\n\t// it's not something that should be relied on. We can change this\n\t// if we want to.\n\tappendCatchAll := func(routes []Route) []Route {\n\t\treturn append(routes, app.makeRedirRoute(uint(app.httpsPort()), MatcherSet{MatchProtocol(\"http\")}))\n\t}\n\nredirServersLoop:\n\tfor redirServerAddr, routes := range redirServers {\n\t\t// for each redirect listener, see if there's already a\n\t\t// server configured to listen on that exact address; if so,\n\t\t// insert the redirect route to the end of its route list\n\t\t// after any other routes with host matchers; otherwise,\n\t\t// we'll create a new server for all the listener addresses\n\t\t// that are unused and serve the remaining redirects from it\n\t\tfor _, srv := range app.Servers {\n\t\t\t// only look at servers which listen on an address which\n\t\t\t// we want to add redirects to\n\t\t\tif !srv.hasListenerAddress(redirServerAddr) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// find the index of the route after the last route with a host\n\t\t\t// matcher, then insert the redirects there, but before any\n\t\t\t// user-defined catch-all routes\n\t\t\t// see https://github.com/caddyserver/caddy/issues/3212\n\t\t\tinsertIndex := srv.findLastRouteWithHostMatcher()\n\n\t\t\t// add the redirects at the insert index, except for when\n\t\t\t// we have a catch-all for HTTPS, in which case the user's\n\t\t\t// defined catch-all should take precedence. See #4829\n\t\t\tif len(uniqueDomainsForCerts) != 0 {\n\t\t\t\tsrv.Routes = append(srv.Routes[:insertIndex], append(routes, srv.Routes[insertIndex:]...)...)\n\t\t\t}\n\n\t\t\t// append our catch-all route in case the user didn't define their own\n\t\t\tsrv.Routes = appendCatchAll(srv.Routes)\n\n\t\t\tcontinue redirServersLoop\n\t\t}\n\n\t\t// no server with this listener address exists;\n\t\t// save this address and route for custom server\n\t\tredirServerAddrs[redirServerAddr] = struct{}{}\n\t\tredirRoutes = append(redirRoutes, routes...)\n\t}\n\n\t// if there are routes remaining which do not belong\n\t// in any existing server, make our own to serve the\n\t// rest of the redirects\n\tif len(redirServerAddrs) > 0 {\n\t\tredirServerAddrsList := make([]string, 0, len(redirServerAddrs))\n\t\tfor a := range redirServerAddrs {\n\t\t\tredirServerAddrsList = append(redirServerAddrsList, a)\n\t\t}\n\t\tapp.Servers[\"remaining_auto_https_redirects\"] = &Server{\n\t\t\tListen: redirServerAddrsList,\n\t\t\tRoutes: appendCatchAll(redirRoutes),\n\t\t\tLogs:   logCfg,\n\t\t}\n\t}\n\n\t// persist the domains/IPs we're managing certs for through provisioning/startup\n\tapp.allCertDomains = uniqueDomainsForCerts\n\n\tlogger.Debug(\"adjusted config\",\n\t\tzap.Reflect(\"tls\", app.tlsApp),\n\t\tzap.Reflect(\"http\", app))\n\n\treturn nil\n}\n\nfunc (app *App) makeRedirRoute(redirToPort uint, matcherSet MatcherSet) Route {\n\tredirTo := \"https://{http.request.host}\"\n\n\t// since this is an external redirect, we should only append an explicit\n\t// port if we know it is not the officially standardized HTTPS port, and,\n\t// notably, also not the port that Caddy thinks is the HTTPS port (the\n\t// configurable HTTPSPort parameter) - we can't change the standard HTTPS\n\t// port externally, so that config parameter is for internal use only;\n\t// we also do not append the port if it happens to be the HTTP port as\n\t// well, obviously (for example, user defines the HTTP port explicitly\n\t// in the list of listen addresses for a server)\n\tif redirToPort != uint(app.httpPort()) &&\n\t\tredirToPort != uint(app.httpsPort()) &&\n\t\tredirToPort != DefaultHTTPPort &&\n\t\tredirToPort != DefaultHTTPSPort {\n\t\tredirTo += \":\" + strconv.Itoa(int(redirToPort))\n\t}\n\n\tredirTo += \"{http.request.uri}\"\n\treturn Route{\n\t\tMatcherSets: []MatcherSet{matcherSet},\n\t\tHandlers: []MiddlewareHandler{\n\t\t\tStaticResponse{\n\t\t\t\tStatusCode: WeakString(strconv.Itoa(http.StatusPermanentRedirect)),\n\t\t\t\tHeaders: http.Header{\n\t\t\t\t\t\"Location\": []string{redirTo},\n\t\t\t\t},\n\t\t\t\tClose: true,\n\t\t\t},\n\t\t},\n\t}\n}\n\n// createAutomationPolicies ensures that automated certificates for this\n// app are managed properly. This adds up to two automation policies:\n// one for the public names, and one for the internal names. If a catch-all\n// automation policy exists, it will be shallow-copied and used as the\n// base for the new ones (this is important for preserving behavior the\n// user intends to be \"defaults\").\nfunc (app *App) createAutomationPolicies(ctx caddy.Context, internalNames, tailscaleNames []string) error {\n\t// before we begin, loop through the existing automation policies\n\t// and, for any ACMEIssuers we find, make sure they're filled in\n\t// with default values that might be specified in our HTTP app; also\n\t// look for a base (or \"catch-all\" / default) automation policy,\n\t// which we're going to essentially require, to make sure it has\n\t// those defaults, too\n\tvar basePolicy *caddytls.AutomationPolicy\n\tvar foundBasePolicy bool\n\tif app.tlsApp.Automation == nil {\n\t\t// we will expect this to not be nil from now on\n\t\tapp.tlsApp.Automation = new(caddytls.AutomationConfig)\n\t}\n\tfor _, ap := range app.tlsApp.Automation.Policies {\n\t\t// on-demand policies can have the tailscale manager added implicitly\n\t\t// if there's no explicit manager configured -- for convenience\n\t\tif ap.OnDemand && len(ap.Managers) == 0 {\n\t\t\tvar ts caddytls.Tailscale\n\t\t\tif err := ts.Provision(ctx); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tap.Managers = []certmagic.Manager{ts}\n\n\t\t\t// must reprovision the automation policy so that the underlying\n\t\t\t// CertMagic config knows about the updated Managers\n\t\t\tif err := ap.Provision(app.tlsApp); err != nil {\n\t\t\t\treturn fmt.Errorf(\"re-provisioning automation policy: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\t// set up default issuer -- honestly, this is only\n\t\t// really necessary because the HTTP app is opinionated\n\t\t// and has settings which could be inferred as new\n\t\t// defaults for the ACMEIssuer in the TLS app (such as\n\t\t// what the HTTP and HTTPS ports are)\n\t\tif ap.Issuers == nil {\n\t\t\tvar err error\n\t\t\tap.Issuers, err = caddytls.DefaultIssuersProvisioned(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tfor _, iss := range ap.Issuers {\n\t\t\tif acmeIssuer, ok := iss.(acmeCapable); ok {\n\t\t\t\terr := app.fillInACMEIssuer(acmeIssuer.GetACMEIssuer())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// while we're here, is this the catch-all/base policy?\n\t\tif !foundBasePolicy && len(ap.SubjectsRaw) == 0 {\n\t\t\tbasePolicy = ap\n\t\t\tfoundBasePolicy = true\n\t\t}\n\t}\n\n\tif basePolicy == nil {\n\t\t// no base policy found; we will make one\n\t\tbasePolicy = new(caddytls.AutomationPolicy)\n\t}\n\n\t// if the basePolicy has an existing ACMEIssuer (particularly to\n\t// include any type that embeds/wraps an ACMEIssuer), let's use it\n\t// (I guess we just use the first one?), otherwise we'll make one\n\tvar baseACMEIssuer *caddytls.ACMEIssuer\n\tfor _, iss := range basePolicy.Issuers {\n\t\tif acmeWrapper, ok := iss.(acmeCapable); ok {\n\t\t\tbaseACMEIssuer = acmeWrapper.GetACMEIssuer()\n\t\t\tbreak\n\t\t}\n\t}\n\tif baseACMEIssuer == nil {\n\t\t// note that this happens if basePolicy.Issuers is empty\n\t\t// OR if it is not empty but does not have not an ACMEIssuer\n\t\tbaseACMEIssuer = new(caddytls.ACMEIssuer)\n\t}\n\n\t// if there was a base policy to begin with, we already\n\t// filled in its issuer's defaults; if there wasn't, we\n\t// still need to do that\n\tif !foundBasePolicy {\n\t\terr := app.fillInACMEIssuer(baseACMEIssuer)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// never overwrite any other issuer that might already be configured\n\tif basePolicy.Issuers == nil {\n\t\tvar err error\n\t\tbasePolicy.Issuers, err = caddytls.DefaultIssuersProvisioned(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfor _, iss := range basePolicy.Issuers {\n\t\t\tif acmeIssuer, ok := iss.(acmeCapable); ok {\n\t\t\t\terr := app.fillInACMEIssuer(acmeIssuer.GetACMEIssuer())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif !foundBasePolicy {\n\t\t// there was no base policy to begin with, so add\n\t\t// our base/catch-all policy - this will serve the\n\t\t// public-looking names as well as any other names\n\t\t// that don't match any other policy\n\t\terr := app.tlsApp.AddAutomationPolicy(basePolicy)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t} else {\n\t\t// a base policy already existed; we might have\n\t\t// changed it, so re-provision it\n\t\terr := basePolicy.Provision(app.tlsApp)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// public names will be taken care of by the base (catch-all)\n\t// policy, which we've ensured exists if not already specified;\n\t// internal names, however, need to be handled by an internal\n\t// issuer, which we need to make a new policy for, scoped to\n\t// just those names (yes, this logic is a bit asymmetric, but\n\t// it works, because our assumed/natural default issuer is an\n\t// ACME issuer)\n\tif len(internalNames) > 0 {\n\t\tinternalIssuer := new(caddytls.InternalIssuer)\n\n\t\t// shallow-copy the base policy; we want to inherit\n\t\t// from it, not replace it... this takes two lines to\n\t\t// overrule compiler optimizations\n\t\tpolicyCopy := *basePolicy\n\t\tnewPolicy := &policyCopy\n\n\t\t// very important to provision the issuer, since we\n\t\t// are bypassing the JSON-unmarshaling step\n\t\tif err := internalIssuer.Provision(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// this policy should apply only to the given names\n\t\t// and should use our issuer -- yes, this overrides\n\t\t// any issuer that may have been set in the base\n\t\t// policy, but we do this because these names do not\n\t\t// already have a policy associated with them, which\n\t\t// is easy to do; consider the case of a Caddyfile\n\t\t// that has only \"localhost\" as a name, but sets the\n\t\t// default/global ACME CA to the Let's Encrypt staging\n\t\t// endpoint... they probably don't intend to change the\n\t\t// fundamental set of names that setting applies to,\n\t\t// rather they just want to change the CA for the set\n\t\t// of names that would normally use the production API;\n\t\t// anyway, that gets into the weeds a bit...\n\t\tnewPolicy.SubjectsRaw = internalNames\n\t\tnewPolicy.Issuers = []certmagic.Issuer{internalIssuer}\n\t\terr := app.tlsApp.AddAutomationPolicy(newPolicy)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// tailscale names go in their own automation policies because\n\t// they require on-demand TLS to be enabled, which we obviously\n\t// can't enable for everything\n\tif len(tailscaleNames) > 0 {\n\t\tpolicyCopy := *basePolicy\n\t\tnewPolicy := &policyCopy\n\n\t\tvar ts caddytls.Tailscale\n\t\tif err := ts.Provision(ctx); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tnewPolicy.SubjectsRaw = tailscaleNames\n\t\tnewPolicy.Issuers = nil\n\t\tnewPolicy.Managers = append(newPolicy.Managers, ts)\n\t\terr := app.tlsApp.AddAutomationPolicy(newPolicy)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// we just changed a lot of stuff, so double-check that it's all good\n\terr := app.tlsApp.Validate()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\n// fillInACMEIssuer fills in default values into acmeIssuer that\n// are defined in app; these values at time of writing are just\n// app.HTTPPort and app.HTTPSPort, which are used by ACMEIssuer.\n// Sure, we could just use the global/CertMagic defaults, but if\n// a user has configured those ports in the HTTP app, it makes\n// sense to use them in the TLS app too, even if they forgot (or\n// were too lazy, like me) to set it in each automation policy\n// that uses it -- this just makes things a little less tedious\n// for the user, so they don't have to repeat those ports in\n// potentially many places. This function never steps on existing\n// config values. If any changes are made, acmeIssuer is\n// reprovisioned. acmeIssuer must not be nil.\nfunc (app *App) fillInACMEIssuer(acmeIssuer *caddytls.ACMEIssuer) error {\n\tif app.HTTPPort > 0 || app.HTTPSPort > 0 {\n\t\tif acmeIssuer.Challenges == nil {\n\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t}\n\t}\n\tif app.HTTPPort > 0 {\n\t\tif acmeIssuer.Challenges.HTTP == nil {\n\t\t\tacmeIssuer.Challenges.HTTP = new(caddytls.HTTPChallengeConfig)\n\t\t}\n\t\t// don't overwrite existing explicit config\n\t\tif acmeIssuer.Challenges.HTTP.AlternatePort == 0 {\n\t\t\tacmeIssuer.Challenges.HTTP.AlternatePort = app.HTTPPort\n\t\t}\n\t}\n\tif app.HTTPSPort > 0 {\n\t\tif acmeIssuer.Challenges.TLSALPN == nil {\n\t\t\tacmeIssuer.Challenges.TLSALPN = new(caddytls.TLSALPNChallengeConfig)\n\t\t}\n\t\t// don't overwrite existing explicit config\n\t\tif acmeIssuer.Challenges.TLSALPN.AlternatePort == 0 {\n\t\t\tacmeIssuer.Challenges.TLSALPN.AlternatePort = app.HTTPSPort\n\t\t}\n\t}\n\t// we must provision all ACME issuers, even if nothing\n\t// was changed, because we don't know if they are new\n\t// and haven't been provisioned yet; if an ACME issuer\n\t// never gets provisioned, its Agree field stays false,\n\t// which leads to, um, problems later on\n\treturn acmeIssuer.Provision(app.ctx)\n}\n\n// automaticHTTPSPhase2 begins certificate management for\n// all names in the qualifying domain set for each server.\n// This phase must occur after provisioning and at the end\n// of app start, after all the servers have been started.\n// Doing this last ensures that there won't be any race\n// for listeners on the HTTP or HTTPS ports when management\n// is async (if CertMagic's solvers bind to those ports\n// first, then our servers would fail to bind to them,\n// which would be bad, since CertMagic's bindings are\n// temporary and don't serve the user's sites!).\nfunc (app *App) automaticHTTPSPhase2() error {\n\tif len(app.allCertDomains) == 0 {\n\t\treturn nil\n\t}\n\tapp.logger.Info(\"enabling automatic TLS certificate management\",\n\t\tzap.Strings(\"domains\", internal.MaxSizeSubjectsListForLog(app.allCertDomains, 1000)),\n\t)\n\terr := app.tlsApp.Manage(app.allCertDomains)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"managing certificates for %d domains: %s\", len(app.allCertDomains), err)\n\t}\n\tapp.allCertDomains = nil // no longer needed; allow GC to deallocate\n\treturn nil\n}\n\nfunc isTailscaleDomain(name string) bool {\n\treturn strings.HasSuffix(strings.ToLower(name), \".ts.net\")\n}\n\ntype acmeCapable interface{ GetACMEIssuer() *caddytls.ACMEIssuer }\n",
    "source_file": "modules/caddyhttp/autohttps.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/netip\"\n\t\"net/url\"\n\t\"runtime\"\n\t\"slices\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/quic-go/quic-go\"\n\t\"github.com/quic-go/quic-go/http3\"\n\t\"github.com/quic-go/quic-go/qlog\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyevents\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\n// Server describes an HTTP server.\ntype Server struct {\n\t// Socket addresses to which to bind listeners. Accepts\n\t// [network addresses](/docs/conventions#network-addresses)\n\t// that may include port ranges. Listener addresses must\n\t// be unique; they cannot be repeated across all defined\n\t// servers.\n\tListen []string `json:\"listen,omitempty\"`\n\n\t// A list of listener wrapper modules, which can modify the behavior\n\t// of the base listener. They are applied in the given order.\n\tListenerWrappersRaw []json.RawMessage `json:\"listener_wrappers,omitempty\" caddy:\"namespace=caddy.listeners inline_key=wrapper\"`\n\n\t// How long to allow a read from a client's upload. Setting this\n\t// to a short, non-zero value can mitigate slowloris attacks, but\n\t// may also affect legitimately slow clients.\n\tReadTimeout caddy.Duration `json:\"read_timeout,omitempty\"`\n\n\t// ReadHeaderTimeout is like ReadTimeout but for request headers.\n\t// Default is 1 minute.\n\tReadHeaderTimeout caddy.Duration `json:\"read_header_timeout,omitempty\"`\n\n\t// WriteTimeout is how long to allow a write to a client. Note\n\t// that setting this to a small value when serving large files\n\t// may negatively affect legitimately slow clients.\n\tWriteTimeout caddy.Duration `json:\"write_timeout,omitempty\"`\n\n\t// IdleTimeout is the maximum time to wait for the next request\n\t// when keep-alives are enabled. If zero, a default timeout of\n\t// 5m is applied to help avoid resource exhaustion.\n\tIdleTimeout caddy.Duration `json:\"idle_timeout,omitempty\"`\n\n\t// KeepAliveInterval is the interval at which TCP keepalive packets\n\t// are sent to keep the connection alive at the TCP layer when no other\n\t// data is being transmitted. The default is 15s.\n\tKeepAliveInterval caddy.Duration `json:\"keepalive_interval,omitempty\"`\n\n\t// MaxHeaderBytes is the maximum size to parse from a client's\n\t// HTTP request headers.\n\tMaxHeaderBytes int `json:\"max_header_bytes,omitempty\"`\n\n\t// Enable full-duplex communication for HTTP/1 requests.\n\t// Only has an effect if Caddy was built with Go 1.21 or later.\n\t//\n\t// For HTTP/1 requests, the Go HTTP server by default consumes any\n\t// unread portion of the request body before beginning to write the\n\t// response, preventing handlers from concurrently reading from the\n\t// request and writing the response. Enabling this option disables\n\t// this behavior and permits handlers to continue to read from the\n\t// request while concurrently writing the response.\n\t//\n\t// For HTTP/2 requests, the Go HTTP server always permits concurrent\n\t// reads and responses, so this option has no effect.\n\t//\n\t// Test thoroughly with your HTTP clients, as some older clients may\n\t// not support full-duplex HTTP/1 which can cause them to deadlock.\n\t// See https://github.com/golang/go/issues/57786 for more info.\n\t//\n\t// TODO: This is an EXPERIMENTAL feature. Subject to change or removal.\n\tEnableFullDuplex bool `json:\"enable_full_duplex,omitempty\"`\n\n\t// Routes describes how this server will handle requests.\n\t// Routes are executed sequentially. First a route's matchers\n\t// are evaluated, then its grouping. If it matches and has\n\t// not been mutually-excluded by its grouping, then its\n\t// handlers are executed sequentially. The sequence of invoked\n\t// handlers comprises a compiled middleware chain that flows\n\t// from each matching route and its handlers to the next.\n\t//\n\t// By default, all unrouted requests receive a 200 OK response\n\t// to indicate the server is working.\n\tRoutes RouteList `json:\"routes,omitempty\"`\n\n\t// Errors is how this server will handle errors returned from any\n\t// of the handlers in the primary routes. If the primary handler\n\t// chain returns an error, the error along with its recommended\n\t// status code are bubbled back up to the HTTP server which\n\t// executes a separate error route, specified using this property.\n\t// The error routes work exactly like the normal routes.\n\tErrors *HTTPErrorConfig `json:\"errors,omitempty\"`\n\n\t// NamedRoutes describes a mapping of reusable routes that can be\n\t// invoked by their name. This can be used to optimize memory usage\n\t// when the same route is needed for many subroutes, by having\n\t// the handlers and matchers be only provisioned once, but used from\n\t// many places. These routes are not executed unless they are invoked\n\t// from another route.\n\t//\n\t// EXPERIMENTAL: Subject to change or removal.\n\tNamedRoutes map[string]*Route `json:\"named_routes,omitempty\"`\n\n\t// How to handle TLS connections. At least one policy is\n\t// required to enable HTTPS on this server if automatic\n\t// HTTPS is disabled or does not apply.\n\tTLSConnPolicies caddytls.ConnectionPolicies `json:\"tls_connection_policies,omitempty\"`\n\n\t// AutoHTTPS configures or disables automatic HTTPS within this server.\n\t// HTTPS is enabled automatically and by default when qualifying names\n\t// are present in a Host matcher and/or when the server is listening\n\t// only on the HTTPS port.\n\tAutoHTTPS *AutoHTTPSConfig `json:\"automatic_https,omitempty\"`\n\n\t// If true, will require that a request's Host header match\n\t// the value of the ServerName sent by the client's TLS\n\t// ClientHello; often a necessary safeguard when using TLS\n\t// client authentication.\n\tStrictSNIHost *bool `json:\"strict_sni_host,omitempty\"`\n\n\t// A module which provides a source of IP ranges, from which\n\t// requests should be trusted. By default, no proxies are\n\t// trusted.\n\t//\n\t// On its own, this configuration will not do anything,\n\t// but it can be used as a default set of ranges for\n\t// handlers or matchers in routes to pick up, instead\n\t// of needing to configure each of them. See the\n\t// `reverse_proxy` handler for example, which uses this\n\t// to trust sensitive incoming `X-Forwarded-*` headers.\n\tTrustedProxiesRaw json.RawMessage `json:\"trusted_proxies,omitempty\" caddy:\"namespace=http.ip_sources inline_key=source\"`\n\n\t// The headers from which the client IP address could be\n\t// read from. These will be considered in order, with the\n\t// first good value being used as the client IP.\n\t// By default, only `X-Forwarded-For` is considered.\n\t//\n\t// This depends on `trusted_proxies` being configured and\n\t// the request being validated as coming from a trusted\n\t// proxy, otherwise the client IP will be set to the direct\n\t// remote IP address.\n\tClientIPHeaders []string `json:\"client_ip_headers,omitempty\"`\n\n\t// If greater than zero, enables strict ClientIPHeaders\n\t// (default X-Forwarded-For) parsing. If enabled, the\n\t// ClientIPHeaders will be parsed from right to left, and\n\t// the first value that is both valid and doesn't match the\n\t// trusted proxy list will be used as client IP. If zero,\n\t// the ClientIPHeaders will be parsed from left to right,\n\t// and the first value that is a valid IP address will be\n\t// used as client IP.\n\t//\n\t// This depends on `trusted_proxies` being configured.\n\t// This option is disabled by default.\n\tTrustedProxiesStrict int `json:\"trusted_proxies_strict,omitempty\"`\n\n\t// Enables access logging and configures how access logs are handled\n\t// in this server. To minimally enable access logs, simply set this\n\t// to a non-null, empty struct.\n\tLogs *ServerLogConfig `json:\"logs,omitempty\"`\n\n\t// Protocols specifies which HTTP protocols to enable.\n\t// Supported values are:\n\t//\n\t// - `h1` (HTTP/1.1)\n\t// - `h2` (HTTP/2)\n\t// - `h2c` (cleartext HTTP/2)\n\t// - `h3` (HTTP/3)\n\t//\n\t// If enabling `h2` or `h2c`, `h1` must also be enabled;\n\t// this is due to current limitations in the Go standard\n\t// library.\n\t//\n\t// HTTP/2 operates only over TLS (HTTPS). HTTP/3 opens\n\t// a UDP socket to serve QUIC connections.\n\t//\n\t// H2C operates over plain TCP if the client supports it;\n\t// however, because this is not implemented by the Go\n\t// standard library, other server options are not compatible\n\t// and will not be applied to H2C requests. Do not enable this\n\t// only to achieve maximum client compatibility. In practice,\n\t// very few clients implement H2C, and even fewer require it.\n\t// Enabling H2C can be useful for serving/proxying gRPC\n\t// if encryption is not possible or desired.\n\t//\n\t// We recommend for most users to simply let Caddy use the\n\t// default settings.\n\t//\n\t// Default: `[h1 h2 h3]`\n\tProtocols []string `json:\"protocols,omitempty\"`\n\n\t// ListenProtocols overrides Protocols for each parallel address in Listen.\n\t// A nil value or element indicates that Protocols will be used instead.\n\tListenProtocols [][]string `json:\"listen_protocols,omitempty\"`\n\n\t// If set, metrics observations will be enabled.\n\t// This setting is EXPERIMENTAL and subject to change.\n\t// DEPRECATED: Use the app-level `metrics` field.\n\tMetrics *Metrics `json:\"metrics,omitempty\"`\n\n\tname string\n\n\tprimaryHandlerChain Handler\n\terrorHandlerChain   Handler\n\tlistenerWrappers    []caddy.ListenerWrapper\n\tlisteners           []net.Listener\n\n\ttlsApp       *caddytls.TLS\n\tevents       *caddyevents.App\n\tlogger       *zap.Logger\n\taccessLogger *zap.Logger\n\terrorLogger  *zap.Logger\n\ttraceLogger  *zap.Logger\n\tctx          caddy.Context\n\n\tserver      *http.Server\n\th3server    *http3.Server\n\th2listeners []*http2Listener\n\taddresses   []caddy.NetworkAddress\n\n\ttrustedProxies IPRangeSource\n\n\tshutdownAt   time.Time\n\tshutdownAtMu *sync.RWMutex\n\n\t// registered callback functions\n\tconnStateFuncs   []func(net.Conn, http.ConnState)\n\tconnContextFuncs []func(ctx context.Context, c net.Conn) context.Context\n\tonShutdownFuncs  []func()\n\tonStopFuncs      []func(context.Context) error // TODO: Experimental (Nov. 2023)\n}\n\n// ServeHTTP is the entry point for all HTTP requests.\nfunc (s *Server) ServeHTTP(w http.ResponseWriter, r *http.Request) {\n\t// If there are listener wrappers that process tls connections but don't return a *tls.Conn, this field will be nil.\n\t// TODO: Can be removed if https://github.com/golang/go/pull/56110 is ever merged.\n\tif r.TLS == nil {\n\t\t// not all requests have a conn (like virtual requests) - see #5698\n\t\tif conn, ok := r.Context().Value(ConnCtxKey).(net.Conn); ok {\n\t\t\tif csc, ok := conn.(connectionStateConn); ok {\n\t\t\t\tr.TLS = new(tls.ConnectionState)\n\t\t\t\t*r.TLS = csc.ConnectionState()\n\t\t\t}\n\t\t}\n\t}\n\n\tw.Header().Set(\"Server\", \"Caddy\")\n\n\t// advertise HTTP/3, if enabled\n\tif s.h3server != nil {\n\t\tif r.ProtoMajor < 3 {\n\t\t\terr := s.h3server.SetQUICHeaders(w.Header())\n\t\t\tif err != nil {\n\t\t\t\tif c := s.logger.Check(zapcore.ErrorLevel, \"setting HTTP/3 Alt-Svc header\"); c != nil {\n\t\t\t\t\tc.Write(zap.Error(err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// reject very long methods; probably a mistake or an attack\n\tif len(r.Method) > 32 {\n\t\tif s.shouldLogRequest(r) {\n\t\t\tif c := s.accessLogger.Check(zapcore.DebugLevel, \"rejecting request with long method\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.String(\"method_trunc\", r.Method[:32]),\n\t\t\t\t\tzap.String(\"remote_addr\", r.RemoteAddr),\n\t\t\t\t)\n\t\t\t}\n\t\t}\n\t\tw.WriteHeader(http.StatusMethodNotAllowed)\n\t\treturn\n\t}\n\n\trepl := caddy.NewReplacer()\n\tr = PrepareRequest(r, repl, w, s)\n\n\t// enable full-duplex for HTTP/1, ensuring the entire\n\t// request body gets consumed before writing the response\n\tif s.EnableFullDuplex && r.ProtoMajor == 1 {\n\t\t//nolint:bodyclose\n\t\terr := http.NewResponseController(w).EnableFullDuplex()\n\t\tif err != nil {\n\t\t\tif c := s.logger.Check(zapcore.WarnLevel, \"failed to enable full duplex\"); c != nil {\n\t\t\t\tc.Write(zap.Error(err))\n\t\t\t}\n\t\t}\n\t}\n\n\t// clone the request for logging purposes before\n\t// it enters any handler chain; this is necessary\n\t// to capture the original request in case it gets\n\t// modified during handling\n\t// cloning the request and using .WithLazy is considerably faster\n\t// than using .With, which will JSON encode the request immediately\n\tshouldLogCredentials := s.Logs != nil && s.Logs.ShouldLogCredentials\n\tloggableReq := zap.Object(\"request\", LoggableHTTPRequest{\n\t\tRequest:              r.Clone(r.Context()),\n\t\tShouldLogCredentials: shouldLogCredentials,\n\t})\n\terrLog := s.errorLogger.WithLazy(loggableReq)\n\n\tvar duration time.Duration\n\n\tif s.shouldLogRequest(r) {\n\t\twrec := NewResponseRecorder(w, nil, nil)\n\t\tw = wrec\n\n\t\t// wrap the request body in a LengthReader\n\t\t// so we can track the number of bytes read from it\n\t\tvar bodyReader *lengthReader\n\t\tif r.Body != nil {\n\t\t\tbodyReader = &lengthReader{Source: r.Body}\n\t\t\tr.Body = bodyReader\n\n\t\t\t// should always be true, private interface can only be referenced in the same package\n\t\t\tif setReadSizer, ok := wrec.(interface{ setReadSize(*int) }); ok {\n\t\t\t\tsetReadSizer.setReadSize(&bodyReader.Length)\n\t\t\t}\n\t\t}\n\n\t\t// capture the original version of the request\n\t\taccLog := s.accessLogger.With(loggableReq)\n\n\t\tdefer s.logRequest(accLog, r, wrec, &duration, repl, bodyReader, shouldLogCredentials)\n\t}\n\n\tstart := time.Now()\n\n\t// guarantee ACME HTTP challenges; handle them\n\t// separately from any user-defined handlers\n\tif s.tlsApp.HandleHTTPChallenge(w, r) {\n\t\tduration = time.Since(start)\n\t\treturn\n\t}\n\n\t// execute the primary handler chain\n\terr := s.primaryHandlerChain.ServeHTTP(w, r)\n\tduration = time.Since(start)\n\n\t// if no errors, we're done!\n\tif err == nil {\n\t\treturn\n\t}\n\n\t// restore original request before invoking error handler chain (issue #3717)\n\t// TODO: this does not restore original headers, if modified (for efficiency)\n\torigReq := r.Context().Value(OriginalRequestCtxKey).(http.Request)\n\tr.Method = origReq.Method\n\tr.RemoteAddr = origReq.RemoteAddr\n\tr.RequestURI = origReq.RequestURI\n\tcloneURL(origReq.URL, r.URL)\n\n\t// prepare the error log\n\terrLog = errLog.With(zap.Duration(\"duration\", duration))\n\terrLoggers := []*zap.Logger{errLog}\n\tif s.Logs != nil {\n\t\terrLoggers = s.Logs.wrapLogger(errLog, r)\n\t}\n\n\t// get the values that will be used to log the error\n\terrStatus, errMsg, errFields := errLogValues(err)\n\n\t// add HTTP error information to request context\n\tr = s.Errors.WithError(r, err)\n\n\tvar fields []zapcore.Field\n\tif s.Errors != nil && len(s.Errors.Routes) > 0 {\n\t\t// execute user-defined error handling route\n\t\terr2 := s.errorHandlerChain.ServeHTTP(w, r)\n\t\tif err2 == nil {\n\t\t\t// user's error route handled the error response\n\t\t\t// successfully, so now just log the error\n\t\t\tfor _, logger := range errLoggers {\n\t\t\t\tif c := logger.Check(zapcore.DebugLevel, errMsg); c != nil {\n\t\t\t\t\tif fields == nil {\n\t\t\t\t\t\tfields = errFields()\n\t\t\t\t\t}\n\t\t\t\t\tc.Write(fields...)\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t// well... this is awkward\n\t\t\tfor _, logger := range errLoggers {\n\t\t\t\tif c := logger.Check(zapcore.ErrorLevel, \"error handling handler error\"); c != nil {\n\t\t\t\t\tif fields == nil {\n\t\t\t\t\t\tfields = errFields()\n\t\t\t\t\t\tfields = append([]zapcore.Field{\n\t\t\t\t\t\t\tzap.String(\"error\", err2.Error()),\n\t\t\t\t\t\t\tzap.Namespace(\"first_error\"),\n\t\t\t\t\t\t\tzap.String(\"msg\", errMsg),\n\t\t\t\t\t\t}, fields...)\n\t\t\t\t\t}\n\t\t\t\t\tc.Write(fields...)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif handlerErr, ok := err.(HandlerError); ok {\n\t\t\t\tw.WriteHeader(handlerErr.StatusCode)\n\t\t\t} else {\n\t\t\t\tw.WriteHeader(http.StatusInternalServerError)\n\t\t\t}\n\t\t}\n\t} else {\n\t\tlogLevel := zapcore.DebugLevel\n\t\tif errStatus >= 500 {\n\t\t\tlogLevel = zapcore.ErrorLevel\n\t\t}\n\n\t\tfor _, logger := range errLoggers {\n\t\t\tif c := logger.Check(logLevel, errMsg); c != nil {\n\t\t\t\tif fields == nil {\n\t\t\t\t\tfields = errFields()\n\t\t\t\t}\n\t\t\t\tc.Write(fields...)\n\t\t\t}\n\t\t}\n\t\tw.WriteHeader(errStatus)\n\t}\n}\n\n// wrapPrimaryRoute wraps stack (a compiled middleware handler chain)\n// in s.enforcementHandler which performs crucial security checks, etc.\nfunc (s *Server) wrapPrimaryRoute(stack Handler) Handler {\n\treturn HandlerFunc(func(w http.ResponseWriter, r *http.Request) error {\n\t\treturn s.enforcementHandler(w, r, stack)\n\t})\n}\n\n// enforcementHandler is an implicit middleware which performs\n// standard checks before executing the HTTP middleware chain.\nfunc (s *Server) enforcementHandler(w http.ResponseWriter, r *http.Request, next Handler) error {\n\t// enforce strict host matching, which ensures that the SNI\n\t// value (if any), matches the Host header; essential for\n\t// servers that rely on TLS ClientAuth sharing a listener\n\t// with servers that do not; if not enforced, client could\n\t// bypass by sending benign SNI then restricted Host header\n\tif s.StrictSNIHost != nil && *s.StrictSNIHost && r.TLS != nil {\n\t\thostname, _, err := net.SplitHostPort(r.Host)\n\t\tif err != nil {\n\t\t\thostname = r.Host // OK; probably lacked port\n\t\t}\n\t\tif !strings.EqualFold(r.TLS.ServerName, hostname) {\n\t\t\terr := fmt.Errorf(\"strict host matching: TLS ServerName (%s) and HTTP Host (%s) values differ\",\n\t\t\t\tr.TLS.ServerName, hostname)\n\t\t\tr.Close = true\n\t\t\treturn Error(http.StatusMisdirectedRequest, err)\n\t\t}\n\t}\n\treturn next.ServeHTTP(w, r)\n}\n\n// listenersUseAnyPortOtherThan returns true if there are any\n// listeners in s that use a port which is not otherPort.\nfunc (s *Server) listenersUseAnyPortOtherThan(otherPort int) bool {\n\tfor _, lnAddr := range s.Listen {\n\t\tladdrs, err := caddy.ParseNetworkAddress(lnAddr)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tif uint(otherPort) > laddrs.EndPort || uint(otherPort) < laddrs.StartPort {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// hasListenerAddress returns true if s has a listener\n// at the given address fullAddr. Currently, fullAddr\n// must represent exactly one socket address (port\n// ranges are not supported)\nfunc (s *Server) hasListenerAddress(fullAddr string) bool {\n\tladdrs, err := caddy.ParseNetworkAddress(fullAddr)\n\tif err != nil {\n\t\treturn false\n\t}\n\tif laddrs.PortRangeSize() != 1 {\n\t\treturn false // TODO: support port ranges\n\t}\n\n\tfor _, lnAddr := range s.Listen {\n\t\tthisAddrs, err := caddy.ParseNetworkAddress(lnAddr)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tif thisAddrs.Network != laddrs.Network {\n\t\t\tcontinue\n\t\t}\n\n\t\t// Apparently, Linux requires all bound ports to be distinct\n\t\t// *regardless of host interface* even if the addresses are\n\t\t// in fact different; binding \"192.168.0.1:9000\" and then\n\t\t// \":9000\" will fail for \":9000\" because \"address is already\n\t\t// in use\" even though it's not, and the same bindings work\n\t\t// fine on macOS. I also found on Linux that listening on\n\t\t// \"[::]:9000\" would fail with a similar error, except with\n\t\t// the address \"0.0.0.0:9000\", as if deliberately ignoring\n\t\t// that I specified the IPv6 interface explicitly. This seems\n\t\t// to be a major bug in the Linux network stack and I don't\n\t\t// know why it hasn't been fixed yet, so for now we have to\n\t\t// special-case ourselves around Linux like a doting parent.\n\t\t// The second issue seems very similar to a discussion here:\n\t\t// https://github.com/nodejs/node/issues/9390\n\t\t//\n\t\t// This is very easy to reproduce by creating an HTTP server\n\t\t// that listens to both addresses or just one with a host\n\t\t// interface; or for a more confusing reproduction, try\n\t\t// listening on \"127.0.0.1:80\" and \":443\" and you'll see\n\t\t// the error, if you take away the GOOS condition below.\n\t\t//\n\t\t// So, an address is equivalent if the port is in the port\n\t\t// range, and if not on Linux, the host is the same... sigh.\n\t\tif (runtime.GOOS == \"linux\" || thisAddrs.Host == laddrs.Host) &&\n\t\t\t(laddrs.StartPort <= thisAddrs.EndPort) &&\n\t\t\t(laddrs.StartPort >= thisAddrs.StartPort) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc (s *Server) hasTLSClientAuth() bool {\n\treturn slices.ContainsFunc(s.TLSConnPolicies, func(cp *caddytls.ConnectionPolicy) bool {\n\t\treturn cp.ClientAuthentication != nil && cp.ClientAuthentication.Active()\n\t})\n}\n\n// findLastRouteWithHostMatcher returns the index of the last route\n// in the server which has a host matcher. Used during Automatic HTTPS\n// to determine where to insert the HTTP->HTTPS redirect route, such\n// that it is after any other host matcher but before any \"catch-all\"\n// route without a host matcher.\nfunc (s *Server) findLastRouteWithHostMatcher() int {\n\tfoundHostMatcher := false\n\tlastIndex := len(s.Routes)\n\n\tfor i, route := range s.Routes {\n\t\t// since we want to break out of an inner loop, use a closure\n\t\t// to allow us to use 'return' when we found a host matcher\n\t\tfound := (func() bool {\n\t\t\tfor _, sets := range route.MatcherSets {\n\t\t\t\tfor _, matcher := range sets {\n\t\t\t\t\tswitch matcher.(type) {\n\t\t\t\t\tcase *MatchHost:\n\t\t\t\t\t\tfoundHostMatcher = true\n\t\t\t\t\t\treturn true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn false\n\t\t})()\n\n\t\t// if we found the host matcher, change the lastIndex to\n\t\t// just after the current route\n\t\tif found {\n\t\t\tlastIndex = i + 1\n\t\t}\n\t}\n\n\t// If we didn't actually find a host matcher, return 0\n\t// because that means every defined route was a \"catch-all\".\n\t// See https://caddy.community/t/how-to-set-priority-in-caddyfile/13002/8\n\tif !foundHostMatcher {\n\t\treturn 0\n\t}\n\n\treturn lastIndex\n}\n\n// serveHTTP3 creates a QUIC listener, configures an HTTP/3 server if\n// not already done, and then uses that server to serve HTTP/3 over\n// the listener, with Server s as the handler.\nfunc (s *Server) serveHTTP3(addr caddy.NetworkAddress, tlsCfg *tls.Config) error {\n\th3net, err := getHTTP3Network(addr.Network)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"starting HTTP/3 QUIC listener: %v\", err)\n\t}\n\taddr.Network = h3net\n\th3ln, err := addr.ListenQUIC(s.ctx, 0, net.ListenConfig{}, tlsCfg)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"starting HTTP/3 QUIC listener: %v\", err)\n\t}\n\n\t// create HTTP/3 server if not done already\n\tif s.h3server == nil {\n\t\ts.h3server = &http3.Server{\n\t\t\tHandler:        s,\n\t\t\tTLSConfig:      tlsCfg,\n\t\t\tMaxHeaderBytes: s.MaxHeaderBytes,\n\t\t\tQUICConfig: &quic.Config{\n\t\t\t\tVersions: []quic.Version{quic.Version1, quic.Version2},\n\t\t\t\tTracer:   qlog.DefaultConnectionTracer,\n\t\t\t},\n\t\t\tIdleTimeout: time.Duration(s.IdleTimeout),\n\t\t}\n\t}\n\n\t//nolint:errcheck\n\tgo s.h3server.ServeListener(h3ln)\n\n\treturn nil\n}\n\n// configureServer applies/binds the registered callback functions to the server.\nfunc (s *Server) configureServer(server *http.Server) {\n\tfor _, f := range s.connStateFuncs {\n\t\tif server.ConnState != nil {\n\t\t\tbaseConnStateFunc := server.ConnState\n\t\t\tserver.ConnState = func(conn net.Conn, state http.ConnState) {\n\t\t\t\tbaseConnStateFunc(conn, state)\n\t\t\t\tf(conn, state)\n\t\t\t}\n\t\t} else {\n\t\t\tserver.ConnState = f\n\t\t}\n\t}\n\n\tfor _, f := range s.connContextFuncs {\n\t\tif server.ConnContext != nil {\n\t\t\tbaseConnContextFunc := server.ConnContext\n\t\t\tserver.ConnContext = func(ctx context.Context, c net.Conn) context.Context {\n\t\t\t\treturn f(baseConnContextFunc(ctx, c), c)\n\t\t\t}\n\t\t} else {\n\t\t\tserver.ConnContext = f\n\t\t}\n\t}\n\n\tfor _, f := range s.onShutdownFuncs {\n\t\tserver.RegisterOnShutdown(f)\n\t}\n}\n\n// RegisterConnState registers f to be invoked on s.ConnState.\nfunc (s *Server) RegisterConnState(f func(net.Conn, http.ConnState)) {\n\ts.connStateFuncs = append(s.connStateFuncs, f)\n}\n\n// RegisterConnContext registers f to be invoked as part of s.ConnContext.\nfunc (s *Server) RegisterConnContext(f func(ctx context.Context, c net.Conn) context.Context) {\n\ts.connContextFuncs = append(s.connContextFuncs, f)\n}\n\n// RegisterOnShutdown registers f to be invoked when the server begins to shut down.\nfunc (s *Server) RegisterOnShutdown(f func()) {\n\ts.onShutdownFuncs = append(s.onShutdownFuncs, f)\n}\n\n// RegisterOnStop registers f to be invoked after the server has shut down completely.\n//\n// EXPERIMENTAL: Subject to change or removal.\nfunc (s *Server) RegisterOnStop(f func(context.Context) error) {\n\ts.onStopFuncs = append(s.onStopFuncs, f)\n}\n\n// HTTPErrorConfig determines how to handle errors\n// from the HTTP handlers.\ntype HTTPErrorConfig struct {\n\t// The routes to evaluate after the primary handler\n\t// chain returns an error. In an error route, extra\n\t// placeholders are available:\n\t//\n\t// Placeholder | Description\n\t// ------------|---------------\n\t// `{http.error.status_code}` | The recommended HTTP status code\n\t// `{http.error.status_text}` | The status text associated with the recommended status code\n\t// `{http.error.message}`     | The error message\n\t// `{http.error.trace}`       | The origin of the error\n\t// `{http.error.id}`          | An identifier for this occurrence of the error\n\tRoutes RouteList `json:\"routes,omitempty\"`\n}\n\n// WithError makes a shallow copy of r to add the error to its\n// context, and sets placeholders on the request's replacer\n// related to err. It returns the modified request which has\n// the error information in its context and replacer. It\n// overwrites any existing error values that are stored.\nfunc (*HTTPErrorConfig) WithError(r *http.Request, err error) *http.Request {\n\t// add the raw error value to the request context\n\t// so it can be accessed by error handlers\n\tc := context.WithValue(r.Context(), ErrorCtxKey, err)\n\tr = r.WithContext(c)\n\n\t// add error values to the replacer\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\trepl.Set(\"http.error\", err)\n\tif handlerErr, ok := err.(HandlerError); ok {\n\t\trepl.Set(\"http.error.status_code\", handlerErr.StatusCode)\n\t\trepl.Set(\"http.error.status_text\", http.StatusText(handlerErr.StatusCode))\n\t\trepl.Set(\"http.error.id\", handlerErr.ID)\n\t\trepl.Set(\"http.error.trace\", handlerErr.Trace)\n\t\tif handlerErr.Err != nil {\n\t\t\trepl.Set(\"http.error.message\", handlerErr.Err.Error())\n\t\t} else {\n\t\t\trepl.Set(\"http.error.message\", http.StatusText(handlerErr.StatusCode))\n\t\t}\n\t}\n\n\treturn r\n}\n\n// shouldLogRequest returns true if this request should be logged.\nfunc (s *Server) shouldLogRequest(r *http.Request) bool {\n\tif s.accessLogger == nil || s.Logs == nil {\n\t\t// logging is disabled\n\t\treturn false\n\t}\n\n\t// strip off the port if any, logger names are host only\n\thostWithoutPort, _, err := net.SplitHostPort(r.Host)\n\tif err != nil {\n\t\thostWithoutPort = r.Host\n\t}\n\n\tif _, ok := s.Logs.LoggerNames[hostWithoutPort]; ok {\n\t\t// this host is mapped to a particular logger name\n\t\treturn true\n\t}\n\tfor _, dh := range s.Logs.SkipHosts {\n\t\t// logging for this particular host is disabled\n\t\tif certmagic.MatchWildcard(hostWithoutPort, dh) {\n\t\t\treturn false\n\t\t}\n\t}\n\t// if configured, this host is not mapped and thus must not be logged\n\treturn !s.Logs.SkipUnmappedHosts\n}\n\n// logTrace will log that this middleware handler is being invoked.\n// It emits at DEBUG level.\nfunc (s *Server) logTrace(mh MiddlewareHandler) {\n\tif s.Logs == nil || !s.Logs.Trace {\n\t\treturn\n\t}\n\tif c := s.traceLogger.Check(zapcore.DebugLevel, caddy.GetModuleName(mh)); c != nil {\n\t\tc.Write(zap.Any(\"module\", mh))\n\t}\n}\n\n// logRequest logs the request to access logs, unless skipped.\nfunc (s *Server) logRequest(\n\taccLog *zap.Logger, r *http.Request, wrec ResponseRecorder, duration *time.Duration,\n\trepl *caddy.Replacer, bodyReader *lengthReader, shouldLogCredentials bool,\n) {\n\t// this request may be flagged as omitted from the logs\n\tif skip, ok := GetVar(r.Context(), LogSkipVar).(bool); ok && skip {\n\t\treturn\n\t}\n\n\tstatus := wrec.Status()\n\tsize := wrec.Size()\n\n\trepl.Set(\"http.response.status\", status) // will be 0 if no response is written by us (Go will write 200 to client)\n\trepl.Set(\"http.response.size\", size)\n\trepl.Set(\"http.response.duration\", duration)\n\trepl.Set(\"http.response.duration_ms\", duration.Seconds()*1e3) // multiply seconds to preserve decimal (see #4666)\n\n\tloggers := []*zap.Logger{accLog}\n\tif s.Logs != nil {\n\t\tloggers = s.Logs.wrapLogger(accLog, r)\n\t}\n\n\tmessage := \"handled request\"\n\tif nop, ok := GetVar(r.Context(), \"unhandled\").(bool); ok && nop {\n\t\tmessage = \"NOP\"\n\t}\n\n\tlogLevel := zapcore.InfoLevel\n\tif status >= 500 {\n\t\tlogLevel = zapcore.ErrorLevel\n\t}\n\n\tvar fields []zapcore.Field\n\tfor _, logger := range loggers {\n\t\tc := logger.Check(logLevel, message)\n\t\tif c == nil {\n\t\t\tcontinue\n\t\t}\n\n\t\tif fields == nil {\n\t\t\tuserID, _ := repl.GetString(\"http.auth.user.id\")\n\n\t\t\treqBodyLength := 0\n\t\t\tif bodyReader != nil {\n\t\t\t\treqBodyLength = bodyReader.Length\n\t\t\t}\n\n\t\t\textra := r.Context().Value(ExtraLogFieldsCtxKey).(*ExtraLogFields)\n\n\t\t\tfieldCount := 6\n\t\t\tfields = make([]zapcore.Field, 0, fieldCount+len(extra.fields))\n\t\t\tfields = append(fields,\n\t\t\t\tzap.Int(\"bytes_read\", reqBodyLength),\n\t\t\t\tzap.String(\"user_id\", userID),\n\t\t\t\tzap.Duration(\"duration\", *duration),\n\t\t\t\tzap.Int(\"size\", size),\n\t\t\t\tzap.Int(\"status\", status),\n\t\t\t\tzap.Object(\"resp_headers\", LoggableHTTPHeader{\n\t\t\t\t\tHeader:               wrec.Header(),\n\t\t\t\t\tShouldLogCredentials: shouldLogCredentials,\n\t\t\t\t}),\n\t\t\t)\n\t\t\tfields = append(fields, extra.fields...)\n\t\t}\n\n\t\tc.Write(fields...)\n\t}\n}\n\n// protocol returns true if the protocol proto is configured/enabled.\nfunc (s *Server) protocol(proto string) bool {\n\tif s.ListenProtocols == nil {\n\t\tif slices.Contains(s.Protocols, proto) {\n\t\t\treturn true\n\t\t}\n\t} else {\n\t\tfor _, lnProtocols := range s.ListenProtocols {\n\t\t\tfor _, lnProtocol := range lnProtocols {\n\t\t\t\tif lnProtocol == \"\" && slices.Contains(s.Protocols, proto) || lnProtocol == proto {\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// Listeners returns the server's listeners. These are active listeners,\n// so calling Accept() or Close() on them will probably break things.\n// They are made available here for read-only purposes (e.g. Addr())\n// and for type-asserting for purposes where you know what you're doing.\n//\n// EXPERIMENTAL: Subject to change or removal.\nfunc (s *Server) Listeners() []net.Listener { return s.listeners }\n\n// Name returns the server's name.\nfunc (s *Server) Name() string { return s.name }\n\n// PrepareRequest fills the request r for use in a Caddy HTTP handler chain. w and s can\n// be nil, but the handlers will lose response placeholders and access to the server.\nfunc PrepareRequest(r *http.Request, repl *caddy.Replacer, w http.ResponseWriter, s *Server) *http.Request {\n\t// set up the context for the request\n\tctx := context.WithValue(r.Context(), caddy.ReplacerCtxKey, repl)\n\tctx = context.WithValue(ctx, ServerCtxKey, s)\n\n\ttrusted, clientIP := determineTrustedProxy(r, s)\n\tctx = context.WithValue(ctx, VarsCtxKey, map[string]any{\n\t\tTrustedProxyVarKey: trusted,\n\t\tClientIPVarKey:     clientIP,\n\t})\n\n\tctx = context.WithValue(ctx, routeGroupCtxKey, make(map[string]struct{}))\n\n\tvar url2 url.URL // avoid letting this escape to the heap\n\tctx = context.WithValue(ctx, OriginalRequestCtxKey, originalRequest(r, &url2))\n\n\tctx = context.WithValue(ctx, ExtraLogFieldsCtxKey, new(ExtraLogFields))\n\tr = r.WithContext(ctx)\n\n\t// once the pointer to the request won't change\n\t// anymore, finish setting up the replacer\n\taddHTTPVarsToReplacer(repl, r, w)\n\n\treturn r\n}\n\n// originalRequest returns a partial, shallow copy of\n// req, including: req.Method, deep copy of req.URL\n// (into the urlCopy parameter, which should be on the\n// stack), req.RequestURI, and req.RemoteAddr. Notably,\n// headers are not copied. This function is designed to\n// be very fast and efficient, and useful primarily for\n// read-only/logging purposes.\nfunc originalRequest(req *http.Request, urlCopy *url.URL) http.Request {\n\tcloneURL(req.URL, urlCopy)\n\treturn http.Request{\n\t\tMethod:     req.Method,\n\t\tRemoteAddr: req.RemoteAddr,\n\t\tRequestURI: req.RequestURI,\n\t\tURL:        urlCopy,\n\t}\n}\n\n// determineTrustedProxy parses the remote IP address of\n// the request, and determines (if the server configured it)\n// if the client is a trusted proxy. If trusted, also returns\n// the real client IP if possible.\nfunc determineTrustedProxy(r *http.Request, s *Server) (bool, string) {\n\t// If there's no server, then we can't check anything\n\tif s == nil {\n\t\treturn false, \"\"\n\t}\n\n\t// Parse the remote IP, ignore the error as non-fatal,\n\t// but the remote IP is required to continue, so we\n\t// just return early. This should probably never happen\n\t// though, unless some other module manipulated the request's\n\t// remote address and used an invalid value.\n\tclientIP, _, err := net.SplitHostPort(r.RemoteAddr)\n\tif err != nil {\n\t\treturn false, \"\"\n\t}\n\n\t// Client IP may contain a zone if IPv6, so we need\n\t// to pull that out before parsing the IP\n\tclientIP, _, _ = strings.Cut(clientIP, \"%\")\n\tipAddr, err := netip.ParseAddr(clientIP)\n\tif err != nil {\n\t\treturn false, \"\"\n\t}\n\n\t// Check if the client is a trusted proxy\n\tif s.trustedProxies == nil {\n\t\treturn false, ipAddr.String()\n\t}\n\n\tif isTrustedClientIP(ipAddr, s.trustedProxies.GetIPRanges(r)) {\n\t\tif s.TrustedProxiesStrict > 0 {\n\t\t\treturn true, strictUntrustedClientIp(r, s.ClientIPHeaders, s.trustedProxies.GetIPRanges(r), ipAddr.String())\n\t\t}\n\t\treturn true, trustedRealClientIP(r, s.ClientIPHeaders, ipAddr.String())\n\t}\n\n\treturn false, ipAddr.String()\n}\n\n// isTrustedClientIP returns true if the given IP address is\n// in the list of trusted IP ranges.\nfunc isTrustedClientIP(ipAddr netip.Addr, trusted []netip.Prefix) bool {\n\treturn slices.ContainsFunc(trusted, func(prefix netip.Prefix) bool {\n\t\treturn prefix.Contains(ipAddr)\n\t})\n}\n\n// trustedRealClientIP finds the client IP from the request assuming it is\n// from a trusted client. If there is no client IP headers, then the\n// direct remote address is returned. If there are client IP headers,\n// then the first value from those headers is used.\nfunc trustedRealClientIP(r *http.Request, headers []string, clientIP string) string {\n\t// Read all the values of the configured client IP headers, in order\n\tvar values []string\n\tfor _, field := range headers {\n\t\tvalues = append(values, r.Header.Values(field)...)\n\t}\n\n\t// If we don't have any values, then give up\n\tif len(values) == 0 {\n\t\treturn clientIP\n\t}\n\n\t// Since there can be many header values, we need to\n\t// join them together before splitting to get the full list\n\tallValues := strings.Split(strings.Join(values, \",\"), \",\")\n\n\t// Get first valid left-most IP address\n\tfor _, part := range allValues {\n\t\t// Some proxies may retain the port number, so split if possible\n\t\thost, _, err := net.SplitHostPort(part)\n\t\tif err != nil {\n\t\t\thost = part\n\t\t}\n\n\t\t// Remove any zone identifier from the IP address\n\t\thost, _, _ = strings.Cut(strings.TrimSpace(host), \"%\")\n\n\t\t// Parse the IP address\n\t\tipAddr, err := netip.ParseAddr(host)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\treturn ipAddr.String()\n\t}\n\n\t// We didn't find a valid IP\n\treturn clientIP\n}\n\n// strictUntrustedClientIp iterates through the list of client IP headers,\n// parses them from right-to-left, and returns the first valid IP address\n// that is untrusted. If no valid IP address is found, then the direct\n// remote address is returned.\nfunc strictUntrustedClientIp(r *http.Request, headers []string, trusted []netip.Prefix, clientIP string) string {\n\tfor _, headerName := range headers {\n\t\tparts := strings.Split(strings.Join(r.Header.Values(headerName), \",\"), \",\")\n\n\t\tfor i := len(parts) - 1; i >= 0; i-- {\n\t\t\t// Some proxies may retain the port number, so split if possible\n\t\t\thost, _, err := net.SplitHostPort(parts[i])\n\t\t\tif err != nil {\n\t\t\t\thost = parts[i]\n\t\t\t}\n\n\t\t\t// Remove any zone identifier from the IP address\n\t\t\thost, _, _ = strings.Cut(strings.TrimSpace(host), \"%\")\n\n\t\t\t// Parse the IP address\n\t\t\tipAddr, err := netip.ParseAddr(host)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !isTrustedClientIP(ipAddr, trusted) {\n\t\t\t\treturn ipAddr.String()\n\t\t\t}\n\t\t}\n\t}\n\n\treturn clientIP\n}\n\n// cloneURL makes a copy of r.URL and returns a\n// new value that doesn't reference the original.\nfunc cloneURL(from, to *url.URL) {\n\t*to = *from\n\tif from.User != nil {\n\t\tuserInfo := new(url.Userinfo)\n\t\t*userInfo = *from.User\n\t\tto.User = userInfo\n\t}\n}\n\n// lengthReader is an io.ReadCloser that keeps track of the\n// number of bytes read from the request body.\ntype lengthReader struct {\n\tSource io.ReadCloser\n\tLength int\n}\n\nfunc (r *lengthReader) Read(b []byte) (int, error) {\n\tn, err := r.Source.Read(b)\n\tr.Length += n\n\treturn n, err\n}\n\nfunc (r *lengthReader) Close() error {\n\treturn r.Source.Close()\n}\n\n// Context keys for HTTP request context values.\nconst (\n\t// For referencing the server instance\n\tServerCtxKey caddy.CtxKey = \"server\"\n\n\t// For the request's variable table\n\tVarsCtxKey caddy.CtxKey = \"vars\"\n\n\t// For a partial copy of the unmodified request that\n\t// originally came into the server's entry handler\n\tOriginalRequestCtxKey caddy.CtxKey = \"original_request\"\n\n\t// For referencing underlying net.Conn\n\tConnCtxKey caddy.CtxKey = \"conn\"\n\n\t// For tracking whether the client is a trusted proxy\n\tTrustedProxyVarKey string = \"trusted_proxy\"\n\n\t// For tracking the real client IP (affected by trusted_proxy)\n\tClientIPVarKey string = \"client_ip\"\n)\n\nvar networkTypesHTTP3 = map[string]string{\n\t\"unixgram\": \"unixgram\",\n\t\"udp\":      \"udp\",\n\t\"udp4\":     \"udp4\",\n\t\"udp6\":     \"udp6\",\n\t\"tcp\":      \"udp\",\n\t\"tcp4\":     \"udp4\",\n\t\"tcp6\":     \"udp6\",\n\t\"fdgram\":   \"fdgram\",\n}\n\n// RegisterNetworkHTTP3 registers a mapping from non-HTTP/3 network to HTTP/3\n// network. This should be called during init() and will panic if the network\n// type is standard, reserved, or already registered.\n//\n// EXPERIMENTAL: Subject to change.\nfunc RegisterNetworkHTTP3(originalNetwork, h3Network string) {\n\tif _, ok := networkTypesHTTP3[strings.ToLower(originalNetwork)]; ok {\n\t\tpanic(\"network type \" + originalNetwork + \" is already registered\")\n\t}\n\tnetworkTypesHTTP3[originalNetwork] = h3Network\n}\n\nfunc getHTTP3Network(originalNetwork string) (string, error) {\n\th3Network, ok := networkTypesHTTP3[strings.ToLower(originalNetwork)]\n\tif !ok {\n\t\treturn \"\", fmt.Errorf(\"network '%s' cannot handle HTTP/3 connections\", originalNetwork)\n\t}\n\treturn h3Network, nil\n}\n",
    "source_file": "modules/caddyhttp/server.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddyhttp\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"net/http\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"github.com/prometheus/client_golang/prometheus/promauto\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/internal/metrics\"\n)\n\n// Metrics configures metrics observations.\n// EXPERIMENTAL and subject to change or removal.\ntype Metrics struct {\n\t// Enable per-host metrics. Enabling this option may\n\t// incur high-memory consumption, depending on the number of hosts\n\t// managed by Caddy.\n\tPerHost bool `json:\"per_host,omitempty\"`\n\n\tinit        sync.Once\n\thttpMetrics *httpMetrics `json:\"-\"`\n}\n\ntype httpMetrics struct {\n\trequestInFlight  *prometheus.GaugeVec\n\trequestCount     *prometheus.CounterVec\n\trequestErrors    *prometheus.CounterVec\n\trequestDuration  *prometheus.HistogramVec\n\trequestSize      *prometheus.HistogramVec\n\tresponseSize     *prometheus.HistogramVec\n\tresponseDuration *prometheus.HistogramVec\n}\n\nfunc initHTTPMetrics(ctx caddy.Context, metrics *Metrics) {\n\tconst ns, sub = \"caddy\", \"http\"\n\tregistry := ctx.GetMetricsRegistry()\n\tbasicLabels := []string{\"server\", \"handler\"}\n\tif metrics.PerHost {\n\t\tbasicLabels = append(basicLabels, \"host\")\n\t}\n\tmetrics.httpMetrics.requestInFlight = promauto.With(registry).NewGaugeVec(prometheus.GaugeOpts{\n\t\tNamespace: ns,\n\t\tSubsystem: sub,\n\t\tName:      \"requests_in_flight\",\n\t\tHelp:      \"Number of requests currently handled by this server.\",\n\t}, basicLabels)\n\tmetrics.httpMetrics.requestErrors = promauto.With(registry).NewCounterVec(prometheus.CounterOpts{\n\t\tNamespace: ns,\n\t\tSubsystem: sub,\n\t\tName:      \"request_errors_total\",\n\t\tHelp:      \"Number of requests resulting in middleware errors.\",\n\t}, basicLabels)\n\tmetrics.httpMetrics.requestCount = promauto.With(registry).NewCounterVec(prometheus.CounterOpts{\n\t\tNamespace: ns,\n\t\tSubsystem: sub,\n\t\tName:      \"requests_total\",\n\t\tHelp:      \"Counter of HTTP(S) requests made.\",\n\t}, basicLabels)\n\n\t// TODO: allow these to be customized in the config\n\tdurationBuckets := prometheus.DefBuckets\n\tsizeBuckets := prometheus.ExponentialBuckets(256, 4, 8)\n\n\thttpLabels := []string{\"server\", \"handler\", \"code\", \"method\"}\n\tif metrics.PerHost {\n\t\thttpLabels = append(httpLabels, \"host\")\n\t}\n\tmetrics.httpMetrics.requestDuration = promauto.With(registry).NewHistogramVec(prometheus.HistogramOpts{\n\t\tNamespace: ns,\n\t\tSubsystem: sub,\n\t\tName:      \"request_duration_seconds\",\n\t\tHelp:      \"Histogram of round-trip request durations.\",\n\t\tBuckets:   durationBuckets,\n\t}, httpLabels)\n\tmetrics.httpMetrics.requestSize = promauto.With(registry).NewHistogramVec(prometheus.HistogramOpts{\n\t\tNamespace: ns,\n\t\tSubsystem: sub,\n\t\tName:      \"request_size_bytes\",\n\t\tHelp:      \"Total size of the request. Includes body\",\n\t\tBuckets:   sizeBuckets,\n\t}, httpLabels)\n\tmetrics.httpMetrics.responseSize = promauto.With(registry).NewHistogramVec(prometheus.HistogramOpts{\n\t\tNamespace: ns,\n\t\tSubsystem: sub,\n\t\tName:      \"response_size_bytes\",\n\t\tHelp:      \"Size of the returned response.\",\n\t\tBuckets:   sizeBuckets,\n\t}, httpLabels)\n\tmetrics.httpMetrics.responseDuration = promauto.With(registry).NewHistogramVec(prometheus.HistogramOpts{\n\t\tNamespace: ns,\n\t\tSubsystem: sub,\n\t\tName:      \"response_duration_seconds\",\n\t\tHelp:      \"Histogram of times to first byte in response bodies.\",\n\t\tBuckets:   durationBuckets,\n\t}, httpLabels)\n}\n\n// serverNameFromContext extracts the current server name from the context.\n// Returns \"UNKNOWN\" if none is available (should probably never happen).\nfunc serverNameFromContext(ctx context.Context) string {\n\tsrv, ok := ctx.Value(ServerCtxKey).(*Server)\n\tif !ok || srv == nil || srv.name == \"\" {\n\t\treturn \"UNKNOWN\"\n\t}\n\treturn srv.name\n}\n\ntype metricsInstrumentedHandler struct {\n\thandler string\n\tmh      MiddlewareHandler\n\tmetrics *Metrics\n}\n\nfunc newMetricsInstrumentedHandler(ctx caddy.Context, handler string, mh MiddlewareHandler, metrics *Metrics) *metricsInstrumentedHandler {\n\tmetrics.init.Do(func() {\n\t\tinitHTTPMetrics(ctx, metrics)\n\t})\n\n\treturn &metricsInstrumentedHandler{handler, mh, metrics}\n}\n\nfunc (h *metricsInstrumentedHandler) ServeHTTP(w http.ResponseWriter, r *http.Request, next Handler) error {\n\tserver := serverNameFromContext(r.Context())\n\tlabels := prometheus.Labels{\"server\": server, \"handler\": h.handler}\n\tmethod := metrics.SanitizeMethod(r.Method)\n\t// the \"code\" value is set later, but initialized here to eliminate the possibility\n\t// of a panic\n\tstatusLabels := prometheus.Labels{\"server\": server, \"handler\": h.handler, \"method\": method, \"code\": \"\"}\n\n\tif h.metrics.PerHost {\n\t\tlabels[\"host\"] = strings.ToLower(r.Host)\n\t\tstatusLabels[\"host\"] = strings.ToLower(r.Host)\n\t}\n\n\tinFlight := h.metrics.httpMetrics.requestInFlight.With(labels)\n\tinFlight.Inc()\n\tdefer inFlight.Dec()\n\n\tstart := time.Now()\n\n\t// This is a _bit_ of a hack - it depends on the ShouldBufferFunc always\n\t// being called when the headers are written.\n\t// Effectively the same behaviour as promhttp.InstrumentHandlerTimeToWriteHeader.\n\twriteHeaderRecorder := ShouldBufferFunc(func(status int, header http.Header) bool {\n\t\tstatusLabels[\"code\"] = metrics.SanitizeCode(status)\n\t\tttfb := time.Since(start).Seconds()\n\t\th.metrics.httpMetrics.responseDuration.With(statusLabels).Observe(ttfb)\n\t\treturn false\n\t})\n\twrec := NewResponseRecorder(w, nil, writeHeaderRecorder)\n\terr := h.mh.ServeHTTP(wrec, r, next)\n\tdur := time.Since(start).Seconds()\n\th.metrics.httpMetrics.requestCount.With(labels).Inc()\n\n\tobserveRequest := func(status int) {\n\t\t// If the code hasn't been set yet, and we didn't encounter an error, we're\n\t\t// probably falling through with an empty handler.\n\t\tif statusLabels[\"code\"] == \"\" {\n\t\t\t// we still sanitize it, even though it's likely to be 0. A 200 is\n\t\t\t// returned on fallthrough so we want to reflect that.\n\t\t\tstatusLabels[\"code\"] = metrics.SanitizeCode(status)\n\t\t}\n\n\t\th.metrics.httpMetrics.requestDuration.With(statusLabels).Observe(dur)\n\t\th.metrics.httpMetrics.requestSize.With(statusLabels).Observe(float64(computeApproximateRequestSize(r)))\n\t\th.metrics.httpMetrics.responseSize.With(statusLabels).Observe(float64(wrec.Size()))\n\t}\n\n\tif err != nil {\n\t\tvar handlerErr HandlerError\n\t\tif errors.As(err, &handlerErr) {\n\t\t\tobserveRequest(handlerErr.StatusCode)\n\t\t}\n\n\t\th.metrics.httpMetrics.requestErrors.With(labels).Inc()\n\n\t\treturn err\n\t}\n\n\tobserveRequest(wrec.Status())\n\n\treturn nil\n}\n\n// taken from https://github.com/prometheus/client_golang/blob/6007b2b5cae01203111de55f753e76d8dac1f529/prometheus/promhttp/instrument_server.go#L298\nfunc computeApproximateRequestSize(r *http.Request) int {\n\ts := 0\n\tif r.URL != nil {\n\t\ts += len(r.URL.String())\n\t}\n\n\ts += len(r.Method)\n\ts += len(r.Proto)\n\tfor name, values := range r.Header {\n\t\ts += len(name)\n\t\tfor _, value := range values {\n\t\t\ts += len(value)\n\t\t}\n\t}\n\ts += len(r.Host)\n\n\t// N.B. r.Form and r.MultipartForm are assumed to be included in r.URL.\n\n\tif r.ContentLength != -1 {\n\t\ts += int(r.ContentLength)\n\t}\n\treturn s\n}\n",
    "source_file": "modules/caddyhttp/metrics.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"reflect\"\n\t\"strings\"\n\n\t\"github.com/google/cel-go/cel\"\n\t\"github.com/google/cel-go/common/types/ref\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(VarsMiddleware{})\n\tcaddy.RegisterModule(VarsMatcher{})\n\tcaddy.RegisterModule(MatchVarsRE{})\n}\n\n// VarsMiddleware is an HTTP middleware which sets variables to\n// have values that can be used in the HTTP request handler\n// chain. The primary way to access variables is with placeholders,\n// which have the form: `{http.vars.variable_name}`, or with\n// the `vars` and `vars_regexp` request matchers.\n//\n// The key is the variable name, and the value is the value of the\n// variable. Both the name and value may use or contain placeholders.\ntype VarsMiddleware map[string]any\n\n// CaddyModule returns the Caddy module information.\nfunc (VarsMiddleware) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.vars\",\n\t\tNew: func() caddy.Module { return new(VarsMiddleware) },\n\t}\n}\n\nfunc (m VarsMiddleware) ServeHTTP(w http.ResponseWriter, r *http.Request, next Handler) error {\n\tvars := r.Context().Value(VarsCtxKey).(map[string]any)\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tfor k, v := range m {\n\t\tkeyExpanded := repl.ReplaceAll(k, \"\")\n\t\tif valStr, ok := v.(string); ok {\n\t\t\tv = repl.ReplaceAll(valStr, \"\")\n\t\t}\n\t\tvars[keyExpanded] = v\n\n\t\t// Special case: the user ID is in the replacer, pulled from there\n\t\t// for access logs. Allow users to override it with the vars handler.\n\t\tif keyExpanded == \"http.auth.user.id\" {\n\t\t\trepl.Set(keyExpanded, v)\n\t\t}\n\t}\n\treturn next.ServeHTTP(w, r)\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler. Syntax:\n//\n//\tvars [<name> <val>] {\n//\t    <name> <val>\n//\t    ...\n//\t}\nfunc (m *VarsMiddleware) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume directive name\n\n\tif *m == nil {\n\t\t*m = make(VarsMiddleware)\n\t}\n\n\tnextVar := func(headerLine bool) error {\n\t\tif headerLine {\n\t\t\t// header line is optional\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t\tvarName := d.Val()\n\n\t\tif !d.NextArg() {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t\tvarValue := d.ScalarVal()\n\n\t\t(*m)[varName] = varValue\n\n\t\tif d.NextArg() {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t\treturn nil\n\t}\n\n\tif err := nextVar(true); err != nil {\n\t\treturn err\n\t}\n\tfor d.NextBlock(0) {\n\t\tif err := nextVar(false); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// VarsMatcher is an HTTP request matcher which can match\n// requests based on variables in the context or placeholder\n// values. The key is the placeholder or name of the variable,\n// and the values are possible values the variable can be in\n// order to match (logical OR'ed).\n//\n// If the key is surrounded by `{ }` it is assumed to be a\n// placeholder. Otherwise, it will be considered a variable\n// name.\n//\n// Placeholders in the keys are not expanded, but\n// placeholders in the values are.\ntype VarsMatcher map[string][]string\n\n// CaddyModule returns the Caddy module information.\nfunc (VarsMatcher) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.vars\",\n\t\tNew: func() caddy.Module { return new(VarsMatcher) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *VarsMatcher) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tif *m == nil {\n\t\t*m = make(map[string][]string)\n\t}\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tvar field string\n\t\tif !d.Args(&field) {\n\t\t\treturn d.Errf(\"malformed vars matcher: expected field name\")\n\t\t}\n\t\tvals := d.RemainingArgs()\n\t\tif len(vals) == 0 {\n\t\t\treturn d.Errf(\"malformed vars matcher: expected at least one value to match against\")\n\t\t}\n\t\t(*m)[field] = append((*m)[field], vals...)\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed vars matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Match matches a request based on variables in the context,\n// or placeholders if the key is not a variable.\nfunc (m VarsMatcher) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m VarsMatcher) MatchWithError(r *http.Request) (bool, error) {\n\tif len(m) == 0 {\n\t\treturn true, nil\n\t}\n\n\tvars := r.Context().Value(VarsCtxKey).(map[string]any)\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\tfor key, vals := range m {\n\t\tvar varValue any\n\t\tif strings.HasPrefix(key, \"{\") &&\n\t\t\tstrings.HasSuffix(key, \"}\") &&\n\t\t\tstrings.Count(key, \"{\") == 1 {\n\t\t\tvarValue, _ = repl.Get(strings.Trim(key, \"{}\"))\n\t\t} else {\n\t\t\tvarValue = vars[key]\n\t\t}\n\n\t\t// see if any of the values given in the matcher match the actual value\n\t\tfor _, v := range vals {\n\t\t\tmatcherValExpanded := repl.ReplaceAll(v, \"\")\n\t\t\tvar varStr string\n\t\t\tswitch vv := varValue.(type) {\n\t\t\tcase string:\n\t\t\t\tvarStr = vv\n\t\t\tcase fmt.Stringer:\n\t\t\t\tvarStr = vv.String()\n\t\t\tcase error:\n\t\t\t\tvarStr = vv.Error()\n\t\t\tcase nil:\n\t\t\t\tvarStr = \"\"\n\t\t\tdefault:\n\t\t\t\tvarStr = fmt.Sprintf(\"%v\", vv)\n\t\t\t}\n\t\t\tif varStr == matcherValExpanded {\n\t\t\t\treturn true, nil\n\t\t\t}\n\t\t}\n\t}\n\treturn false, nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression vars({'{magic_number}': ['3', '5']})\n//\texpression vars({'{foo}': 'single_value'})\nfunc (VarsMatcher) CELLibrary(_ caddy.Context) (cel.Library, error) {\n\treturn CELMatcherImpl(\n\t\t\"vars\",\n\t\t\"vars_matcher_request_map\",\n\t\t[]*cel.Type{CELTypeJSON},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\tmapStrListStr, err := CELValueToMapStrList(data)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn VarsMatcher(mapStrListStr), nil\n\t\t},\n\t)\n}\n\n// MatchVarsRE matches the value of the context variables by a given regular expression.\n//\n// Upon a match, it adds placeholders to the request: `{http.regexp.name.capture_group}`\n// where `name` is the regular expression's name, and `capture_group` is either\n// the named or positional capture group from the expression itself. If no name\n// is given, then the placeholder omits the name: `{http.regexp.capture_group}`\n// (potentially leading to collisions).\ntype MatchVarsRE map[string]*MatchRegexp\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchVarsRE) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.vars_regexp\",\n\t\tNew: func() caddy.Module { return new(MatchVarsRE) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchVarsRE) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tif *m == nil {\n\t\t*m = make(map[string]*MatchRegexp)\n\t}\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tvar first, second, third string\n\t\tif !d.Args(&first, &second) {\n\t\t\treturn d.ArgErr()\n\t\t}\n\n\t\tvar name, field, val string\n\t\tif d.Args(&third) {\n\t\t\tname = first\n\t\t\tfield = second\n\t\t\tval = third\n\t\t} else {\n\t\t\tfield = first\n\t\t\tval = second\n\t\t}\n\n\t\t// Default to the named matcher's name, if no regexp name is provided\n\t\tif name == \"\" {\n\t\t\tname = d.GetContextString(caddyfile.MatcherNameCtxKey)\n\t\t}\n\n\t\t(*m)[field] = &MatchRegexp{Pattern: val, Name: name}\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed vars_regexp matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Provision compiles m's regular expressions.\nfunc (m MatchVarsRE) Provision(ctx caddy.Context) error {\n\tfor _, rm := range m {\n\t\terr := rm.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Match returns true if r matches m.\nfunc (m MatchVarsRE) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchVarsRE) MatchWithError(r *http.Request) (bool, error) {\n\tvars := r.Context().Value(VarsCtxKey).(map[string]any)\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tfor key, val := range m {\n\t\tvar varValue any\n\t\tif strings.HasPrefix(key, \"{\") &&\n\t\t\tstrings.HasSuffix(key, \"}\") &&\n\t\t\tstrings.Count(key, \"{\") == 1 {\n\t\t\tvarValue, _ = repl.Get(strings.Trim(key, \"{}\"))\n\t\t} else {\n\t\t\tvarValue = vars[key]\n\t\t}\n\n\t\tvar varStr string\n\t\tswitch vv := varValue.(type) {\n\t\tcase string:\n\t\t\tvarStr = vv\n\t\tcase fmt.Stringer:\n\t\t\tvarStr = vv.String()\n\t\tcase error:\n\t\t\tvarStr = vv.Error()\n\t\tcase nil:\n\t\t\tvarStr = \"\"\n\t\tdefault:\n\t\t\tvarStr = fmt.Sprintf(\"%v\", vv)\n\t\t}\n\n\t\tvalExpanded := repl.ReplaceAll(varStr, \"\")\n\t\tif match := val.Match(valExpanded, repl); match {\n\t\t\treturn match, nil\n\t\t}\n\t}\n\treturn false, nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression vars_regexp('foo', '{magic_number}', '[0-9]+')\n//\texpression vars_regexp('{magic_number}', '[0-9]+')\nfunc (MatchVarsRE) CELLibrary(ctx caddy.Context) (cel.Library, error) {\n\tunnamedPattern, err := CELMatcherImpl(\n\t\t\"vars_regexp\",\n\t\t\"vars_regexp_request_string_string\",\n\t\t[]*cel.Type{cel.StringType, cel.StringType},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tparams, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tstrParams := params.([]string)\n\t\t\tmatcher := MatchVarsRE{}\n\t\t\tmatcher[strParams[0]] = &MatchRegexp{\n\t\t\t\tPattern: strParams[1],\n\t\t\t\tName:    ctx.Value(MatcherNameCtxKey).(string),\n\t\t\t}\n\t\t\terr = matcher.Provision(ctx)\n\t\t\treturn matcher, err\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnamedPattern, err := CELMatcherImpl(\n\t\t\"vars_regexp\",\n\t\t\"vars_regexp_request_string_string_string\",\n\t\t[]*cel.Type{cel.StringType, cel.StringType, cel.StringType},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tparams, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tstrParams := params.([]string)\n\t\t\tname := strParams[0]\n\t\t\tif name == \"\" {\n\t\t\t\tname = ctx.Value(MatcherNameCtxKey).(string)\n\t\t\t}\n\t\t\tmatcher := MatchVarsRE{}\n\t\t\tmatcher[strParams[1]] = &MatchRegexp{\n\t\t\t\tPattern: strParams[2],\n\t\t\t\tName:    name,\n\t\t\t}\n\t\t\terr = matcher.Provision(ctx)\n\t\t\treturn matcher, err\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tenvOpts := append(unnamedPattern.CompileOptions(), namedPattern.CompileOptions()...)\n\tprgOpts := append(unnamedPattern.ProgramOptions(), namedPattern.ProgramOptions()...)\n\treturn NewMatcherCELLibrary(envOpts, prgOpts), nil\n}\n\n// Validate validates m's regular expressions.\nfunc (m MatchVarsRE) Validate() error {\n\tfor _, rm := range m {\n\t\terr := rm.Validate()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// GetVar gets a value out of the context's variable table by key.\n// If the key does not exist, the return value will be nil.\nfunc GetVar(ctx context.Context, key string) any {\n\tvarMap, ok := ctx.Value(VarsCtxKey).(map[string]any)\n\tif !ok {\n\t\treturn nil\n\t}\n\treturn varMap[key]\n}\n\n// SetVar sets a value in the context's variable table with\n// the given key. It overwrites any previous value with the\n// same key.\n//\n// If the value is nil (note: non-nil interface with nil\n// underlying value does not count) and the key exists in\n// the table, the key+value will be deleted from the table.\nfunc SetVar(ctx context.Context, key string, value any) {\n\tvarMap, ok := ctx.Value(VarsCtxKey).(map[string]any)\n\tif !ok {\n\t\treturn\n\t}\n\tif value == nil {\n\t\tif _, ok := varMap[key]; ok {\n\t\t\tdelete(varMap, key)\n\t\t\treturn\n\t\t}\n\t}\n\tvarMap[key] = value\n}\n\n// Interface guards\nvar (\n\t_ MiddlewareHandler       = (*VarsMiddleware)(nil)\n\t_ caddyfile.Unmarshaler   = (*VarsMiddleware)(nil)\n\t_ RequestMatcherWithError = (*VarsMatcher)(nil)\n\t_ caddyfile.Unmarshaler   = (*VarsMatcher)(nil)\n\t_ RequestMatcherWithError = (*MatchVarsRE)(nil)\n\t_ caddyfile.Unmarshaler   = (*MatchVarsRE)(nil)\n)\n",
    "source_file": "modules/caddyhttp/vars.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/textproto\"\n\t\"os\"\n\t\"slices\"\n\t\"strconv\"\n\t\"strings\"\n\t\"text/template\"\n\t\"time\"\n\n\t\"github.com/spf13/cobra\"\n\t\"go.uber.org/zap\"\n\n\tcaddycmd \"github.com/caddyserver/caddy/v2/cmd\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(StaticResponse{})\n\tcaddycmd.RegisterCommand(caddycmd.Command{\n\t\tName:  \"respond\",\n\t\tUsage: `[--status <code>] [--body <content>] [--listen <addr>] [--access-log] [--debug] [--header \"Field: value\"] <body|status>`,\n\t\tShort: \"Simple, hard-coded HTTP responses for development and testing\",\n\t\tLong: `\nSpins up a quick-and-clean HTTP server for development and testing purposes.\n\nWith no options specified, this command listens on a random available port\nand answers HTTP requests with an empty 200 response. The listen address can\nbe customized with the --listen flag and will always be printed to stdout.\nIf the listen address includes a port range, multiple servers will be started.\n\nIf a final, unnamed argument is given, it will be treated as a status code\n(same as the --status flag) if it is a 3-digit number. Otherwise, it is used\nas the response body (same as the --body flag). The --status and --body flags\nwill always override this argument (for example, to write a body that\nliterally says \"404\" but with a status code of 200, do '--status 200 404').\n\nA body may be given in 3 ways: a flag, a final (and unnamed) argument to\nthe command, or piped to stdin (if flag and argument are unset). Limited\ntemplate evaluation is supported on the body, with the following variables:\n\n\t{{.N}}        The server number (useful if using a port range)\n\t{{.Port}}     The listener port\n\t{{.Address}}  The listener address\n\n(See the docs for the text/template package in the Go standard library for\ninformation about using templates: https://pkg.go.dev/text/template)\n\nAccess/request logging and more verbose debug logging can also be enabled.\n\nResponse headers may be added using the --header flag for each header field.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"listen\", \"l\", \":0\", \"The address to which to bind the listener\")\n\t\t\tcmd.Flags().IntP(\"status\", \"s\", http.StatusOK, \"The response status code\")\n\t\t\tcmd.Flags().StringP(\"body\", \"b\", \"\", \"The body of the HTTP response\")\n\t\t\tcmd.Flags().BoolP(\"access-log\", \"\", false, \"Enable the access log\")\n\t\t\tcmd.Flags().BoolP(\"debug\", \"v\", false, \"Enable more verbose debug-level logging\")\n\t\t\tcmd.Flags().StringSliceP(\"header\", \"H\", []string{}, \"Set a header on the response (format: \\\"Field: value\\\")\")\n\t\t\tcmd.RunE = caddycmd.WrapCommandFuncForCobra(cmdRespond)\n\t\t},\n\t})\n}\n\n// StaticResponse implements a simple responder for static responses.\ntype StaticResponse struct {\n\t// The HTTP status code to respond with. Can be an integer or,\n\t// if needing to use a placeholder, a string.\n\t//\n\t// If the status code is 103 (Early Hints), the response headers\n\t// will be written to the client immediately, the body will be\n\t// ignored, and the next handler will be invoked. This behavior\n\t// is EXPERIMENTAL while RFC 8297 is a draft, and may be changed\n\t// or removed.\n\tStatusCode WeakString `json:\"status_code,omitempty\"`\n\n\t// Header fields to set on the response; overwrites any existing\n\t// header fields of the same names after normalization.\n\tHeaders http.Header `json:\"headers,omitempty\"`\n\n\t// The response body. If non-empty, the Content-Type header may\n\t// be added automatically if it is not explicitly configured nor\n\t// already set on the response; the default value is\n\t// \"text/plain; charset=utf-8\" unless the body is a valid JSON object\n\t// or array, in which case the value will be \"application/json\".\n\t// Other than those common special cases the Content-Type header\n\t// should be set explicitly if it is desired because MIME sniffing\n\t// is disabled for safety.\n\tBody string `json:\"body,omitempty\"`\n\n\t// If true, the server will close the client's connection\n\t// after writing the response.\n\tClose bool `json:\"close,omitempty\"`\n\n\t// Immediately and forcefully closes the connection without\n\t// writing a response. Interrupts any other HTTP streams on\n\t// the same connection.\n\tAbort bool `json:\"abort,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (StaticResponse) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.static_response\",\n\t\tNew: func() caddy.Module { return new(StaticResponse) },\n\t}\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens. Syntax:\n//\n//\trespond [<matcher>] <status>|<body> [<status>] {\n//\t    body <text>\n//\t    close\n//\t}\n//\n// If there is just one argument (other than the matcher), it is considered\n// to be a status code if it's a valid positive integer of 3 digits.\nfunc (s *StaticResponse) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume directive name\n\targs := d.RemainingArgs()\n\tswitch len(args) {\n\tcase 1:\n\t\tif len(args[0]) == 3 {\n\t\t\tif num, err := strconv.Atoi(args[0]); err == nil && num > 0 {\n\t\t\t\ts.StatusCode = WeakString(args[0])\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\ts.Body = args[0]\n\tcase 2:\n\t\ts.Body = args[0]\n\t\ts.StatusCode = WeakString(args[1])\n\tdefault:\n\t\treturn d.ArgErr()\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"body\":\n\t\t\tif s.Body != \"\" {\n\t\t\t\treturn d.Err(\"body already specified\")\n\t\t\t}\n\t\t\tif !d.AllArgs(&s.Body) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\tcase \"close\":\n\t\t\tif s.Close {\n\t\t\t\treturn d.Err(\"close already specified\")\n\t\t\t}\n\t\t\ts.Close = true\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (s StaticResponse) ServeHTTP(w http.ResponseWriter, r *http.Request, next Handler) error {\n\t// close the connection immediately\n\tif s.Abort {\n\t\tpanic(http.ErrAbortHandler)\n\t}\n\n\t// close the connection after responding\n\tif s.Close {\n\t\tr.Close = true\n\t\tw.Header().Set(\"Connection\", \"close\")\n\t}\n\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\t// set all headers\n\tfor field, vals := range s.Headers {\n\t\tfield = textproto.CanonicalMIMEHeaderKey(repl.ReplaceAll(field, \"\"))\n\t\tnewVals := make([]string, len(vals))\n\t\tfor i := range vals {\n\t\t\tnewVals[i] = repl.ReplaceAll(vals[i], \"\")\n\t\t}\n\t\tw.Header()[field] = newVals\n\t}\n\n\t// implicitly set Content-Type header if we can do so safely\n\t// (this allows templates handler to eval templates successfully\n\t// or for clients to render JSON properly which is very common)\n\tbody := repl.ReplaceKnown(s.Body, \"\")\n\tif body != \"\" && w.Header().Get(\"Content-Type\") == \"\" {\n\t\tcontent := strings.TrimSpace(body)\n\t\tif len(content) > 2 &&\n\t\t\t(content[0] == '{' && content[len(content)-1] == '}' ||\n\t\t\t\t(content[0] == '[' && content[len(content)-1] == ']')) &&\n\t\t\tjson.Valid([]byte(content)) {\n\t\t\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t\t} else {\n\t\t\tw.Header().Set(\"Content-Type\", \"text/plain; charset=utf-8\")\n\t\t}\n\t}\n\n\t// do not allow Go to sniff the content-type, for safety\n\tif w.Header().Get(\"Content-Type\") == \"\" {\n\t\tw.Header()[\"Content-Type\"] = nil\n\t}\n\n\t// get the status code; if this handler exists in an error route,\n\t// use the recommended status code as the default; otherwise 200\n\tstatusCode := http.StatusOK\n\tif reqErr, ok := r.Context().Value(ErrorCtxKey).(error); ok {\n\t\tif handlerErr, ok := reqErr.(HandlerError); ok {\n\t\t\tif handlerErr.StatusCode > 0 {\n\t\t\t\tstatusCode = handlerErr.StatusCode\n\t\t\t}\n\t\t}\n\t}\n\tif codeStr := s.StatusCode.String(); codeStr != \"\" {\n\t\tintVal, err := strconv.Atoi(repl.ReplaceAll(codeStr, \"\"))\n\t\tif err != nil {\n\t\t\treturn Error(http.StatusInternalServerError, err)\n\t\t}\n\t\tstatusCode = intVal\n\t}\n\n\t// write headers\n\tw.WriteHeader(statusCode)\n\n\t// write response body\n\tif statusCode != http.StatusEarlyHints && body != \"\" {\n\t\tfmt.Fprint(w, body)\n\t}\n\n\t// continue handling after Early Hints as they are not the final response\n\tif statusCode == http.StatusEarlyHints {\n\t\treturn next.ServeHTTP(w, r)\n\t}\n\n\treturn nil\n}\n\nfunc buildHTTPServer(i int, port uint, addr string, statusCode int, hdr http.Header, body string, accessLog bool) (*Server, error) {\n\tvar handlers []json.RawMessage\n\n\t// response body supports a basic template; evaluate it\n\ttplCtx := struct {\n\t\tN       int    // server number\n\t\tPort    uint   // only the port\n\t\tAddress string // listener address\n\t}{\n\t\tN:       i,\n\t\tPort:    port,\n\t\tAddress: addr,\n\t}\n\ttpl, err := template.New(\"body\").Parse(body)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tbuf := new(bytes.Buffer)\n\terr = tpl.Execute(buf, tplCtx)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// create route with handler\n\thandler := StaticResponse{\n\t\tStatusCode: WeakString(fmt.Sprintf(\"%d\", statusCode)),\n\t\tHeaders:    hdr,\n\t\tBody:       buf.String(),\n\t}\n\thandlers = append(handlers, caddyconfig.JSONModuleObject(handler, \"handler\", \"static_response\", nil))\n\troute := Route{HandlersRaw: handlers}\n\n\tserver := &Server{\n\t\tListen:            []string{addr},\n\t\tReadHeaderTimeout: caddy.Duration(10 * time.Second),\n\t\tIdleTimeout:       caddy.Duration(30 * time.Second),\n\t\tMaxHeaderBytes:    1024 * 10,\n\t\tRoutes:            RouteList{route},\n\t\tAutoHTTPS:         &AutoHTTPSConfig{DisableRedir: true},\n\t}\n\tif accessLog {\n\t\tserver.Logs = new(ServerLogConfig)\n\t}\n\n\treturn server, nil\n}\n\nfunc cmdRespond(fl caddycmd.Flags) (int, error) {\n\tcaddy.TrapSignals()\n\n\t// get flag values\n\tlisten := fl.String(\"listen\")\n\tstatusCodeFl := fl.Int(\"status\")\n\tbodyFl := fl.String(\"body\")\n\taccessLog := fl.Bool(\"access-log\")\n\tdebug := fl.Bool(\"debug\")\n\targ := fl.Arg(0)\n\n\tif fl.NArg() > 1 {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"too many unflagged arguments\")\n\t}\n\n\t// prefer status and body from explicit flags\n\tstatusCode, body := statusCodeFl, bodyFl\n\n\t// figure out if status code was explicitly specified; this lets\n\t// us set a non-zero value as the default but is a little hacky\n\tstatusCodeFlagSpecified := slices.Contains(os.Args, \"--status\")\n\n\t// try to determine what kind of parameter the unnamed argument is\n\tif arg != \"\" {\n\t\t// specifying body and status flags makes the argument redundant/unused\n\t\tif bodyFl != \"\" && statusCodeFlagSpecified {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"unflagged argument \\\"%s\\\" is overridden by flags\", arg)\n\t\t}\n\n\t\t// if a valid 3-digit number, treat as status code; otherwise body\n\t\tif argInt, err := strconv.Atoi(arg); err == nil && !statusCodeFlagSpecified {\n\t\t\tif argInt >= 100 && argInt <= 999 {\n\t\t\t\tstatusCode = argInt\n\t\t\t}\n\t\t} else if body == \"\" {\n\t\t\tbody = arg\n\t\t}\n\t}\n\n\t// if we still need a body, see if stdin is being piped\n\tif body == \"\" {\n\t\tstdinInfo, err := os.Stdin.Stat()\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\t\tif stdinInfo.Mode()&os.ModeNamedPipe != 0 {\n\t\t\tbodyBytes, err := io.ReadAll(os.Stdin)\n\t\t\tif err != nil {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t\t}\n\t\t\tbody = string(bodyBytes)\n\t\t}\n\t}\n\n\t// build headers map\n\theaders, err := fl.GetStringSlice(\"header\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid header flag: %v\", err)\n\t}\n\thdr := make(http.Header)\n\tfor i, h := range headers {\n\t\tkey, val, found := strings.Cut(h, \":\")\n\t\tkey, val = strings.TrimSpace(key), strings.TrimSpace(val)\n\t\tif !found || key == \"\" || val == \"\" {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"header %d: invalid format \\\"%s\\\" (expecting \\\"Field: value\\\")\", i, h)\n\t\t}\n\t\thdr.Set(key, val)\n\t}\n\n\t// build each HTTP server\n\thttpApp := App{Servers: make(map[string]*Server)}\n\n\t// expand listen address, if more than one port\n\tlistenAddr, err := caddy.ParseNetworkAddress(listen)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tif !listenAddr.IsUnixNetwork() && !listenAddr.IsFdNetwork() {\n\t\tlistenAddrs := make([]string, 0, listenAddr.PortRangeSize())\n\t\tfor offset := uint(0); offset < listenAddr.PortRangeSize(); offset++ {\n\t\t\tlistenAddrs = append(listenAddrs, listenAddr.JoinHostPort(offset))\n\t\t}\n\n\t\tfor i, addr := range listenAddrs {\n\t\t\tserver, err := buildHTTPServer(i, listenAddr.StartPort+uint(i), addr, statusCode, hdr, body, accessLog)\n\t\t\tif err != nil {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t\t}\n\n\t\t\t// save server\n\t\t\thttpApp.Servers[fmt.Sprintf(\"static%d\", i)] = server\n\t\t}\n\t} else {\n\t\tserver, err := buildHTTPServer(0, 0, listen, statusCode, hdr, body, accessLog)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\n\t\t// save server\n\t\thttpApp.Servers[fmt.Sprintf(\"static%d\", 0)] = server\n\t}\n\n\t// finish building the config\n\tvar false bool\n\tcfg := &caddy.Config{\n\t\tAdmin: &caddy.AdminConfig{\n\t\t\tDisabled: true,\n\t\t\tConfig: &caddy.ConfigSettings{\n\t\t\t\tPersist: &false,\n\t\t\t},\n\t\t},\n\t\tAppsRaw: caddy.ModuleMap{\n\t\t\t\"http\": caddyconfig.JSON(httpApp, nil),\n\t\t},\n\t}\n\tif debug {\n\t\tcfg.Logging = &caddy.Logging{\n\t\t\tLogs: map[string]*caddy.CustomLog{\n\t\t\t\t\"default\": {BaseLog: caddy.BaseLog{Level: zap.DebugLevel.CapitalString()}},\n\t\t\t},\n\t\t}\n\t}\n\n\t// run it!\n\terr = caddy.Run(cfg)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// to print listener addresses, get the active HTTP app\n\tloadedHTTPApp, err := caddy.ActiveContext().App(\"http\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// print each listener address\n\tfor _, srv := range loadedHTTPApp.(*App).Servers {\n\t\tfor _, ln := range srv.listeners {\n\t\t\tfmt.Printf(\"Server address: %s\\n\", ln.Addr())\n\t\t}\n\t}\n\n\tselect {}\n}\n\n// Interface guards\nvar (\n\t_ MiddlewareHandler     = (*StaticResponse)(nil)\n\t_ caddyfile.Unmarshaler = (*StaticResponse)(nil)\n)\n",
    "source_file": "modules/caddyhttp/staticresp.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/netip\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/internal\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(StaticIPRange{})\n}\n\n// IPRangeSource gets a list of IP ranges.\n//\n// The request is passed as an argument to allow plugin implementations\n// to have more flexibility. But, a plugin MUST NOT modify the request.\n// The caller will have read the `r.RemoteAddr` before getting IP ranges.\n//\n// This should be a very fast function -- instant if possible.\n// The list of IP ranges should be sourced as soon as possible if loaded\n// from an external source (i.e. initially loaded during Provisioning),\n// so that it's ready to be used when requests start getting handled.\n// A read lock should probably be used to get the cached value if the\n// ranges can change at runtime (e.g. periodically refreshed).\n// Using a `caddy.UsagePool` may be a good idea to avoid having refetch\n// the values when a config reload occurs, which would waste time.\n//\n// If the list of IP ranges cannot be sourced, then provisioning SHOULD\n// fail. Getting the IP ranges at runtime MUST NOT fail, because it would\n// cancel incoming requests. If refreshing the list fails, then the\n// previous list of IP ranges should continue to be returned so that the\n// server can continue to operate normally.\ntype IPRangeSource interface {\n\tGetIPRanges(*http.Request) []netip.Prefix\n}\n\n// StaticIPRange provides a static range of IP address prefixes (CIDRs).\ntype StaticIPRange struct {\n\t// A static list of IP ranges (supports CIDR notation).\n\tRanges []string `json:\"ranges,omitempty\"`\n\n\t// Holds the parsed CIDR ranges from Ranges.\n\tranges []netip.Prefix\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (StaticIPRange) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.ip_sources.static\",\n\t\tNew: func() caddy.Module { return new(StaticIPRange) },\n\t}\n}\n\nfunc (s *StaticIPRange) Provision(ctx caddy.Context) error {\n\tfor _, str := range s.Ranges {\n\t\tprefix, err := CIDRExpressionToPrefix(str)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\ts.ranges = append(s.ranges, prefix)\n\t}\n\n\treturn nil\n}\n\nfunc (s *StaticIPRange) GetIPRanges(_ *http.Request) []netip.Prefix {\n\treturn s.ranges\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *StaticIPRange) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tif !d.Next() {\n\t\treturn nil\n\t}\n\tfor d.NextArg() {\n\t\tif d.Val() == \"private_ranges\" {\n\t\t\tm.Ranges = append(m.Ranges, internal.PrivateRangesCIDR()...)\n\t\t\tcontinue\n\t\t}\n\t\tm.Ranges = append(m.Ranges, d.Val())\n\t}\n\treturn nil\n}\n\n// CIDRExpressionToPrefix takes a string which could be either a\n// CIDR expression or a single IP address, and returns a netip.Prefix.\nfunc CIDRExpressionToPrefix(expr string) (netip.Prefix, error) {\n\t// Having a slash means it should be a CIDR expression\n\tif strings.Contains(expr, \"/\") {\n\t\tprefix, err := netip.ParsePrefix(expr)\n\t\tif err != nil {\n\t\t\treturn netip.Prefix{}, fmt.Errorf(\"parsing CIDR expression: '%s': %v\", expr, err)\n\t\t}\n\t\treturn prefix, nil\n\t}\n\n\t// Otherwise it's likely a single IP address\n\tparsed, err := netip.ParseAddr(expr)\n\tif err != nil {\n\t\treturn netip.Prefix{}, fmt.Errorf(\"invalid IP address: '%s': %v\", expr, err)\n\t}\n\tprefix := netip.PrefixFrom(parsed, parsed.BitLen())\n\treturn prefix, nil\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner     = (*StaticIPRange)(nil)\n\t_ caddyfile.Unmarshaler = (*StaticIPRange)(nil)\n\t_ IPRangeSource         = (*StaticIPRange)(nil)\n)\n\n// PrivateRangesCIDR returns a list of private CIDR range\n// strings, which can be used as a configuration shortcut.\n// Note: this function is used at least by mholt/caddy-l4.\nfunc PrivateRangesCIDR() []string {\n\treturn internal.PrivateRangesCIDR()\n}\n",
    "source_file": "modules/caddyhttp/ip_range.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"crypto/x509/pkix\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"reflect\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/google/cel-go/cel\"\n\t\"github.com/google/cel-go/common\"\n\t\"github.com/google/cel-go/common/ast\"\n\t\"github.com/google/cel-go/common/operators\"\n\t\"github.com/google/cel-go/common/types\"\n\t\"github.com/google/cel-go/common/types/ref\"\n\t\"github.com/google/cel-go/common/types/traits\"\n\t\"github.com/google/cel-go/ext\"\n\t\"github.com/google/cel-go/interpreter\"\n\t\"github.com/google/cel-go/interpreter/functions\"\n\t\"github.com/google/cel-go/parser\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(MatchExpression{})\n}\n\n// MatchExpression matches requests by evaluating a\n// [CEL](https://github.com/google/cel-spec) expression.\n// This enables complex logic to be expressed using a comfortable,\n// familiar syntax. Please refer to\n// [the standard definitions of CEL functions and operators](https://github.com/google/cel-spec/blob/master/doc/langdef.md#standard-definitions).\n//\n// This matcher's JSON interface is actually a string, not a struct.\n// The generated docs are not correct because this type has custom\n// marshaling logic.\n//\n// COMPATIBILITY NOTE: This module is still experimental and is not\n// subject to Caddy's compatibility guarantee.\ntype MatchExpression struct {\n\t// The CEL expression to evaluate. Any Caddy placeholders\n\t// will be expanded and situated into proper CEL function\n\t// calls before evaluating.\n\tExpr string `json:\"expr,omitempty\"`\n\n\t// Name is an optional name for this matcher.\n\t// This is used to populate the name for regexp\n\t// matchers that appear in the expression.\n\tName string `json:\"name,omitempty\"`\n\n\texpandedExpr string\n\tprg          cel.Program\n\tta           types.Adapter\n\n\tlog *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchExpression) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.expression\",\n\t\tNew: func() caddy.Module { return new(MatchExpression) },\n\t}\n}\n\n// MarshalJSON marshals m's expression.\nfunc (m MatchExpression) MarshalJSON() ([]byte, error) {\n\t// if the name is empty, then we can marshal just the expression string\n\tif m.Name == \"\" {\n\t\treturn json.Marshal(m.Expr)\n\t}\n\t// otherwise, we need to marshal the full object, using an\n\t// anonymous struct to avoid infinite recursion\n\treturn json.Marshal(struct {\n\t\tExpr string `json:\"expr\"`\n\t\tName string `json:\"name\"`\n\t}{\n\t\tExpr: m.Expr,\n\t\tName: m.Name,\n\t})\n}\n\n// UnmarshalJSON unmarshals m's expression.\nfunc (m *MatchExpression) UnmarshalJSON(data []byte) error {\n\t// if the data is a string, then it's just the expression\n\tif data[0] == '\"' {\n\t\treturn json.Unmarshal(data, &m.Expr)\n\t}\n\t// otherwise, it's a full object, so unmarshal it,\n\t// using an temp map to avoid infinite recursion\n\tvar tmpJson map[string]any\n\terr := json.Unmarshal(data, &tmpJson)\n\t*m = MatchExpression{\n\t\tExpr: tmpJson[\"expr\"].(string),\n\t\tName: tmpJson[\"name\"].(string),\n\t}\n\treturn err\n}\n\n// Provision sets ups m.\nfunc (m *MatchExpression) Provision(ctx caddy.Context) error {\n\tm.log = ctx.Logger()\n\n\t// replace placeholders with a function call - this is just some\n\t// light (and possibly na\u00efve) syntactic sugar\n\tm.expandedExpr = placeholderRegexp.ReplaceAllString(m.Expr, placeholderExpansion)\n\n\t// as a second pass, we'll strip the escape character from an escaped\n\t// placeholder, so that it can be used as an input to other CEL functions\n\tm.expandedExpr = escapedPlaceholderRegexp.ReplaceAllString(m.expandedExpr, escapedPlaceholderExpansion)\n\n\t// our type adapter expands CEL's standard type support\n\tm.ta = celTypeAdapter{}\n\n\t// initialize the CEL libraries from the Matcher implementations which\n\t// have been configured to support CEL.\n\tmatcherLibProducers := []CELLibraryProducer{}\n\tfor _, info := range caddy.GetModules(\"http.matchers\") {\n\t\tp, ok := info.New().(CELLibraryProducer)\n\t\tif ok {\n\t\t\tmatcherLibProducers = append(matcherLibProducers, p)\n\t\t}\n\t}\n\n\t// add the matcher name to the context so that the matcher name\n\t// can be used by regexp matchers being provisioned\n\tctx = ctx.WithValue(MatcherNameCtxKey, m.Name)\n\n\t// Assemble the compilation and program options from the different library\n\t// producers into a single cel.Library implementation.\n\tmatcherEnvOpts := []cel.EnvOption{}\n\tmatcherProgramOpts := []cel.ProgramOption{}\n\tfor _, producer := range matcherLibProducers {\n\t\tl, err := producer.CELLibrary(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error initializing CEL library for %T: %v\", producer, err)\n\t\t}\n\t\tmatcherEnvOpts = append(matcherEnvOpts, l.CompileOptions()...)\n\t\tmatcherProgramOpts = append(matcherProgramOpts, l.ProgramOptions()...)\n\t}\n\tmatcherLib := cel.Lib(NewMatcherCELLibrary(matcherEnvOpts, matcherProgramOpts))\n\n\t// create the CEL environment\n\tenv, err := cel.NewEnv(\n\t\tcel.Function(CELPlaceholderFuncName, cel.SingletonBinaryBinding(m.caddyPlaceholderFunc), cel.Overload(\n\t\t\tCELPlaceholderFuncName+\"_httpRequest_string\",\n\t\t\t[]*cel.Type{httpRequestObjectType, cel.StringType},\n\t\t\tcel.AnyType,\n\t\t)),\n\t\tcel.Variable(CELRequestVarName, httpRequestObjectType),\n\t\tcel.CustomTypeAdapter(m.ta),\n\t\text.Strings(),\n\t\text.Bindings(),\n\t\text.Lists(),\n\t\text.Math(),\n\t\tmatcherLib,\n\t)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"setting up CEL environment: %v\", err)\n\t}\n\n\t// parse and type-check the expression\n\tchecked, issues := env.Compile(m.expandedExpr)\n\tif issues.Err() != nil {\n\t\treturn fmt.Errorf(\"compiling CEL program: %s\", issues.Err())\n\t}\n\n\t// request matching is a boolean operation, so we don't really know\n\t// what to do if the expression returns a non-boolean type\n\tif checked.OutputType() != cel.BoolType {\n\t\treturn fmt.Errorf(\"CEL request matcher expects return type of bool, not %s\", checked.OutputType())\n\t}\n\n\t// compile the \"program\"\n\tm.prg, err = env.Program(checked, cel.EvalOptions(cel.OptOptimize))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"compiling CEL program: %s\", err)\n\t}\n\treturn nil\n}\n\n// Match returns true if r matches m.\nfunc (m MatchExpression) Match(r *http.Request) bool {\n\tmatch, err := m.MatchWithError(r)\n\tif err != nil {\n\t\tSetVar(r.Context(), MatcherErrorVarKey, err)\n\t}\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchExpression) MatchWithError(r *http.Request) (bool, error) {\n\tcelReq := celHTTPRequest{r}\n\tout, _, err := m.prg.Eval(celReq)\n\tif err != nil {\n\t\tm.log.Error(\"evaluating expression\", zap.Error(err))\n\t\treturn false, err\n\t}\n\tif outBool, ok := out.Value().(bool); ok {\n\t\treturn outBool, nil\n\t}\n\treturn false, nil\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchExpression) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume matcher name\n\n\t// if there's multiple args, then we need to keep the raw\n\t// tokens because the user may have used quotes within their\n\t// CEL expression (e.g. strings) and we should retain that\n\tif d.CountRemainingArgs() > 1 {\n\t\tm.Expr = strings.Join(d.RemainingArgsRaw(), \" \")\n\t\treturn nil\n\t}\n\n\t// there should at least be one arg\n\tif !d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\n\t// if there's only one token, then we can safely grab the\n\t// cleaned token (no quotes) and use that as the expression\n\t// because there's no valid CEL expression that is only a\n\t// quoted string; commonly quotes are used in Caddyfile to\n\t// define the expression\n\tm.Expr = d.Val()\n\n\t// use the named matcher's name, to fill regexp\n\t// matchers names by default\n\tm.Name = d.GetContextString(caddyfile.MatcherNameCtxKey)\n\n\treturn nil\n}\n\n// caddyPlaceholderFunc implements the custom CEL function that accesses the\n// Replacer on a request and gets values from it.\nfunc (m MatchExpression) caddyPlaceholderFunc(lhs, rhs ref.Val) ref.Val {\n\tcelReq, ok := lhs.(celHTTPRequest)\n\tif !ok {\n\t\treturn types.NewErr(\n\t\t\t\"invalid request of type '%v' to %s(request, placeholderVarName)\",\n\t\t\tlhs.Type(),\n\t\t\tCELPlaceholderFuncName,\n\t\t)\n\t}\n\tphStr, ok := rhs.(types.String)\n\tif !ok {\n\t\treturn types.NewErr(\n\t\t\t\"invalid placeholder variable name of type '%v' to %s(request, placeholderVarName)\",\n\t\t\trhs.Type(),\n\t\t\tCELPlaceholderFuncName,\n\t\t)\n\t}\n\n\trepl := celReq.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tval, _ := repl.Get(string(phStr))\n\n\treturn m.ta.NativeToValue(val)\n}\n\n// httpRequestCELType is the type representation of a native HTTP request.\nvar httpRequestCELType = cel.ObjectType(\"http.Request\", traits.ReceiverType)\n\n// celHTTPRequest wraps an http.Request with ref.Val interface methods.\n//\n// This type also implements the interpreter.Activation interface which\n// drops allocation costs for CEL expression evaluations by roughly half.\ntype celHTTPRequest struct{ *http.Request }\n\nfunc (cr celHTTPRequest) ResolveName(name string) (any, bool) {\n\tif name == CELRequestVarName {\n\t\treturn cr, true\n\t}\n\treturn nil, false\n}\n\nfunc (cr celHTTPRequest) Parent() interpreter.Activation {\n\treturn nil\n}\n\nfunc (cr celHTTPRequest) ConvertToNative(typeDesc reflect.Type) (any, error) {\n\treturn cr.Request, nil\n}\n\nfunc (celHTTPRequest) ConvertToType(typeVal ref.Type) ref.Val {\n\tpanic(\"not implemented\")\n}\n\nfunc (cr celHTTPRequest) Equal(other ref.Val) ref.Val {\n\tif o, ok := other.Value().(celHTTPRequest); ok {\n\t\treturn types.Bool(o.Request == cr.Request)\n\t}\n\treturn types.ValOrErr(other, \"%v is not comparable type\", other)\n}\nfunc (celHTTPRequest) Type() ref.Type { return httpRequestCELType }\nfunc (cr celHTTPRequest) Value() any  { return cr }\n\nvar pkixNameCELType = cel.ObjectType(\"pkix.Name\", traits.ReceiverType)\n\n// celPkixName wraps an pkix.Name with\n// methods to satisfy the ref.Val interface.\ntype celPkixName struct{ *pkix.Name }\n\nfunc (pn celPkixName) ConvertToNative(typeDesc reflect.Type) (any, error) {\n\treturn pn.Name, nil\n}\n\nfunc (pn celPkixName) ConvertToType(typeVal ref.Type) ref.Val {\n\tif typeVal.TypeName() == \"string\" {\n\t\treturn types.String(pn.Name.String())\n\t}\n\tpanic(\"not implemented\")\n}\n\nfunc (pn celPkixName) Equal(other ref.Val) ref.Val {\n\tif o, ok := other.Value().(string); ok {\n\t\treturn types.Bool(pn.Name.String() == o)\n\t}\n\treturn types.ValOrErr(other, \"%v is not comparable type\", other)\n}\nfunc (celPkixName) Type() ref.Type { return pkixNameCELType }\nfunc (pn celPkixName) Value() any  { return pn }\n\n// celTypeAdapter can adapt our custom types to a CEL value.\ntype celTypeAdapter struct{}\n\nfunc (celTypeAdapter) NativeToValue(value any) ref.Val {\n\tswitch v := value.(type) {\n\tcase celHTTPRequest:\n\t\treturn v\n\tcase pkix.Name:\n\t\treturn celPkixName{&v}\n\tcase time.Time:\n\t\treturn types.Timestamp{Time: v}\n\tcase error:\n\t\treturn types.WrapErr(v)\n\t}\n\treturn types.DefaultTypeAdapter.NativeToValue(value)\n}\n\n// CELLibraryProducer provide CEL libraries that expose a Matcher\n// implementation as a first class function within the CEL expression\n// matcher.\ntype CELLibraryProducer interface {\n\t// CELLibrary creates a cel.Library which makes it possible to use the\n\t// target object within CEL expression matchers.\n\tCELLibrary(caddy.Context) (cel.Library, error)\n}\n\n// CELMatcherImpl creates a new cel.Library based on the following pieces of\n// data:\n//\n//   - macroName: the function name to be used within CEL. This will be a macro\n//     and not a function proper.\n//   - funcName: the function overload name generated by the CEL macro used to\n//     represent the matcher.\n//   - matcherDataTypes: the argument types to the macro.\n//   - fac: a matcherFactory implementation which converts from CEL constant\n//     values to a Matcher instance.\n//\n// Note, macro names and function names must not collide with other macros or\n// functions exposed within CEL expressions, or an error will be produced\n// during the expression matcher plan time.\n//\n// The existing CELMatcherImpl support methods are configured to support a\n// limited set of function signatures. For strong type validation you may need\n// to provide a custom macro which does a more detailed analysis of the CEL\n// literal provided to the macro as an argument.\nfunc CELMatcherImpl(macroName, funcName string, matcherDataTypes []*cel.Type, fac any) (cel.Library, error) {\n\trequestType := cel.ObjectType(\"http.Request\")\n\tvar macro parser.Macro\n\tswitch len(matcherDataTypes) {\n\tcase 1:\n\t\tmatcherDataType := matcherDataTypes[0]\n\t\tswitch matcherDataType.String() {\n\t\tcase \"list(string)\":\n\t\t\tmacro = parser.NewGlobalVarArgMacro(macroName, celMatcherStringListMacroExpander(funcName))\n\t\tcase cel.StringType.String():\n\t\t\tmacro = parser.NewGlobalMacro(macroName, 1, celMatcherStringMacroExpander(funcName))\n\t\tcase CELTypeJSON.String():\n\t\t\tmacro = parser.NewGlobalMacro(macroName, 1, celMatcherJSONMacroExpander(funcName))\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unsupported matcher data type: %s\", matcherDataType)\n\t\t}\n\tcase 2:\n\t\tif matcherDataTypes[0] == cel.StringType && matcherDataTypes[1] == cel.StringType {\n\t\t\tmacro = parser.NewGlobalMacro(macroName, 2, celMatcherStringListMacroExpander(funcName))\n\t\t\tmatcherDataTypes = []*cel.Type{cel.ListType(cel.StringType)}\n\t\t} else {\n\t\t\treturn nil, fmt.Errorf(\"unsupported matcher data type: %s, %s\", matcherDataTypes[0], matcherDataTypes[1])\n\t\t}\n\tcase 3:\n\t\tif matcherDataTypes[0] == cel.StringType && matcherDataTypes[1] == cel.StringType && matcherDataTypes[2] == cel.StringType {\n\t\t\tmacro = parser.NewGlobalMacro(macroName, 3, celMatcherStringListMacroExpander(funcName))\n\t\t\tmatcherDataTypes = []*cel.Type{cel.ListType(cel.StringType)}\n\t\t} else {\n\t\t\treturn nil, fmt.Errorf(\"unsupported matcher data type: %s, %s, %s\", matcherDataTypes[0], matcherDataTypes[1], matcherDataTypes[2])\n\t\t}\n\t}\n\tenvOptions := []cel.EnvOption{\n\t\tcel.Macros(macro),\n\t\tcel.Function(funcName,\n\t\t\tcel.Overload(funcName, append([]*cel.Type{requestType}, matcherDataTypes...), cel.BoolType),\n\t\t\tcel.SingletonBinaryBinding(CELMatcherRuntimeFunction(funcName, fac))),\n\t}\n\tprogramOptions := []cel.ProgramOption{\n\t\tcel.CustomDecorator(CELMatcherDecorator(funcName, fac)),\n\t}\n\treturn NewMatcherCELLibrary(envOptions, programOptions), nil\n}\n\n// CELMatcherFactory converts a constant CEL value into a RequestMatcher.\n// Deprecated: Use CELMatcherWithErrorFactory instead.\ntype CELMatcherFactory = func(data ref.Val) (RequestMatcher, error)\n\n// CELMatcherWithErrorFactory converts a constant CEL value into a RequestMatcherWithError.\ntype CELMatcherWithErrorFactory = func(data ref.Val) (RequestMatcherWithError, error)\n\n// matcherCELLibrary is a simplistic configurable cel.Library implementation.\ntype matcherCELLibrary struct {\n\tenvOptions     []cel.EnvOption\n\tprogramOptions []cel.ProgramOption\n}\n\n// NewMatcherCELLibrary creates a matcherLibrary from option setes.\nfunc NewMatcherCELLibrary(envOptions []cel.EnvOption, programOptions []cel.ProgramOption) cel.Library {\n\treturn &matcherCELLibrary{\n\t\tenvOptions:     envOptions,\n\t\tprogramOptions: programOptions,\n\t}\n}\n\nfunc (lib *matcherCELLibrary) CompileOptions() []cel.EnvOption {\n\treturn lib.envOptions\n}\n\nfunc (lib *matcherCELLibrary) ProgramOptions() []cel.ProgramOption {\n\treturn lib.programOptions\n}\n\n// CELMatcherDecorator matches a call overload generated by a CEL macro\n// that takes a single argument, and optimizes the implementation to precompile\n// the matcher and return a function that references the precompiled and\n// provisioned matcher.\nfunc CELMatcherDecorator(funcName string, fac any) interpreter.InterpretableDecorator {\n\treturn func(i interpreter.Interpretable) (interpreter.Interpretable, error) {\n\t\tcall, ok := i.(interpreter.InterpretableCall)\n\t\tif !ok {\n\t\t\treturn i, nil\n\t\t}\n\t\tif call.OverloadID() != funcName {\n\t\t\treturn i, nil\n\t\t}\n\t\tcallArgs := call.Args()\n\t\treqAttr, ok := callArgs[0].(interpreter.InterpretableAttribute)\n\t\tif !ok {\n\t\t\treturn nil, errors.New(\"missing 'req' argument\")\n\t\t}\n\t\tnsAttr, ok := reqAttr.Attr().(interpreter.NamespacedAttribute)\n\t\tif !ok {\n\t\t\treturn nil, errors.New(\"missing 'req' argument\")\n\t\t}\n\t\tvarNames := nsAttr.CandidateVariableNames()\n\t\tif len(varNames) != 1 || len(varNames) == 1 && varNames[0] != CELRequestVarName {\n\t\t\treturn nil, errors.New(\"missing 'req' argument\")\n\t\t}\n\t\tmatcherData, ok := callArgs[1].(interpreter.InterpretableConst)\n\t\tif !ok {\n\t\t\t// If the matcher arguments are not constant, then this means\n\t\t\t// they contain a Caddy placeholder reference and the evaluation\n\t\t\t// and matcher provisioning should be handled at dynamically.\n\t\t\treturn i, nil\n\t\t}\n\n\t\tif factory, ok := fac.(CELMatcherWithErrorFactory); ok {\n\t\t\tmatcher, err := factory(matcherData.Value())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn interpreter.NewCall(\n\t\t\t\ti.ID(), funcName, funcName+\"_opt\",\n\t\t\t\t[]interpreter.Interpretable{reqAttr},\n\t\t\t\tfunc(args ...ref.Val) ref.Val {\n\t\t\t\t\t// The request value, guaranteed to be of type celHTTPRequest\n\t\t\t\t\tcelReq := args[0]\n\t\t\t\t\t// If needed this call could be changed to convert the value\n\t\t\t\t\t// to a *http.Request using CEL's ConvertToNative method.\n\t\t\t\t\thttpReq := celReq.Value().(celHTTPRequest)\n\t\t\t\t\tmatch, err := matcher.MatchWithError(httpReq.Request)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn types.WrapErr(err)\n\t\t\t\t\t}\n\t\t\t\t\treturn types.Bool(match)\n\t\t\t\t},\n\t\t\t), nil\n\t\t}\n\n\t\tif factory, ok := fac.(CELMatcherFactory); ok {\n\t\t\tmatcher, err := factory(matcherData.Value())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn interpreter.NewCall(\n\t\t\t\ti.ID(), funcName, funcName+\"_opt\",\n\t\t\t\t[]interpreter.Interpretable{reqAttr},\n\t\t\t\tfunc(args ...ref.Val) ref.Val {\n\t\t\t\t\t// The request value, guaranteed to be of type celHTTPRequest\n\t\t\t\t\tcelReq := args[0]\n\t\t\t\t\t// If needed this call could be changed to convert the value\n\t\t\t\t\t// to a *http.Request using CEL's ConvertToNative method.\n\t\t\t\t\thttpReq := celReq.Value().(celHTTPRequest)\n\t\t\t\t\tif m, ok := matcher.(RequestMatcherWithError); ok {\n\t\t\t\t\t\tmatch, err := m.MatchWithError(httpReq.Request)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\treturn types.WrapErr(err)\n\t\t\t\t\t\t}\n\t\t\t\t\t\treturn types.Bool(match)\n\t\t\t\t\t}\n\t\t\t\t\treturn types.Bool(matcher.Match(httpReq.Request))\n\t\t\t\t},\n\t\t\t), nil\n\t\t}\n\n\t\treturn nil, fmt.Errorf(\"invalid matcher factory, must be CELMatcherFactory or CELMatcherWithErrorFactory: %T\", fac)\n\t}\n}\n\n// CELMatcherRuntimeFunction creates a function binding for when the input to the matcher\n// is dynamically resolved rather than a set of static constant values.\nfunc CELMatcherRuntimeFunction(funcName string, fac any) functions.BinaryOp {\n\treturn func(celReq, matcherData ref.Val) ref.Val {\n\t\tif factory, ok := fac.(CELMatcherWithErrorFactory); ok {\n\t\t\tmatcher, err := factory(matcherData)\n\t\t\tif err != nil {\n\t\t\t\treturn types.WrapErr(err)\n\t\t\t}\n\t\t\thttpReq := celReq.Value().(celHTTPRequest)\n\t\t\tmatch, err := matcher.MatchWithError(httpReq.Request)\n\t\t\tif err != nil {\n\t\t\t\treturn types.WrapErr(err)\n\t\t\t}\n\t\t\treturn types.Bool(match)\n\t\t}\n\t\tif factory, ok := fac.(CELMatcherFactory); ok {\n\t\t\tmatcher, err := factory(matcherData)\n\t\t\tif err != nil {\n\t\t\t\treturn types.WrapErr(err)\n\t\t\t}\n\t\t\thttpReq := celReq.Value().(celHTTPRequest)\n\t\t\tif m, ok := matcher.(RequestMatcherWithError); ok {\n\t\t\t\tmatch, err := m.MatchWithError(httpReq.Request)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn types.WrapErr(err)\n\t\t\t\t}\n\t\t\t\treturn types.Bool(match)\n\t\t\t}\n\t\t\treturn types.Bool(matcher.Match(httpReq.Request))\n\t\t}\n\t\treturn types.NewErr(\"CELMatcherRuntimeFunction invalid matcher factory: %T\", fac)\n\t}\n}\n\n// celMatcherStringListMacroExpander validates that the macro is called\n// with a variable number of string arguments (at least one).\n//\n// The arguments are collected into a single list argument the following\n// function call returned: <funcName>(request, [args])\nfunc celMatcherStringListMacroExpander(funcName string) cel.MacroFactory {\n\treturn func(eh cel.MacroExprFactory, target ast.Expr, args []ast.Expr) (ast.Expr, *common.Error) {\n\t\tmatchArgs := []ast.Expr{}\n\t\tif len(args) == 0 {\n\t\t\treturn nil, eh.NewError(0, \"matcher requires at least one argument\")\n\t\t}\n\t\tfor _, arg := range args {\n\t\t\tif isCELStringExpr(arg) {\n\t\t\t\tmatchArgs = append(matchArgs, arg)\n\t\t\t} else {\n\t\t\t\treturn nil, eh.NewError(arg.ID(), \"matcher arguments must be string constants\")\n\t\t\t}\n\t\t}\n\t\treturn eh.NewCall(funcName, eh.NewIdent(CELRequestVarName), eh.NewList(matchArgs...)), nil\n\t}\n}\n\n// celMatcherStringMacroExpander validates that the macro is called a single\n// string argument.\n//\n// The following function call is returned: <funcName>(request, arg)\nfunc celMatcherStringMacroExpander(funcName string) parser.MacroExpander {\n\treturn func(eh cel.MacroExprFactory, target ast.Expr, args []ast.Expr) (ast.Expr, *common.Error) {\n\t\tif len(args) != 1 {\n\t\t\treturn nil, eh.NewError(0, \"matcher requires one argument\")\n\t\t}\n\t\tif isCELStringExpr(args[0]) {\n\t\t\treturn eh.NewCall(funcName, eh.NewIdent(CELRequestVarName), args[0]), nil\n\t\t}\n\t\treturn nil, eh.NewError(args[0].ID(), \"matcher argument must be a string literal\")\n\t}\n}\n\n// celMatcherJSONMacroExpander validates that the macro is called a single\n// map literal argument.\n//\n// The following function call is returned: <funcName>(request, arg)\nfunc celMatcherJSONMacroExpander(funcName string) parser.MacroExpander {\n\treturn func(eh cel.MacroExprFactory, target ast.Expr, args []ast.Expr) (ast.Expr, *common.Error) {\n\t\tif len(args) != 1 {\n\t\t\treturn nil, eh.NewError(0, \"matcher requires a map literal argument\")\n\t\t}\n\t\targ := args[0]\n\n\t\tswitch arg.Kind() {\n\t\tcase ast.StructKind:\n\t\t\treturn nil, eh.NewError(arg.ID(),\n\t\t\t\tfmt.Sprintf(\"matcher input must be a map literal, not a %s\", arg.AsStruct().TypeName()))\n\t\tcase ast.MapKind:\n\t\t\tmapExpr := arg.AsMap()\n\t\t\tfor _, entry := range mapExpr.Entries() {\n\t\t\t\tisStringPlaceholder := isCELStringExpr(entry.AsMapEntry().Key())\n\t\t\t\tif !isStringPlaceholder {\n\t\t\t\t\treturn nil, eh.NewError(entry.ID(), \"matcher map keys must be string literals\")\n\t\t\t\t}\n\t\t\t\tisStringListPlaceholder := isCELStringExpr(entry.AsMapEntry().Value()) ||\n\t\t\t\t\tisCELStringListLiteral(entry.AsMapEntry().Value())\n\t\t\t\tif !isStringListPlaceholder {\n\t\t\t\t\treturn nil, eh.NewError(entry.AsMapEntry().Value().ID(), \"matcher map values must be string or list literals\")\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn eh.NewCall(funcName, eh.NewIdent(CELRequestVarName), arg), nil\n\t\tcase ast.UnspecifiedExprKind, ast.CallKind, ast.ComprehensionKind, ast.IdentKind, ast.ListKind, ast.LiteralKind, ast.SelectKind:\n\t\t\t// appeasing the linter :)\n\t\t}\n\n\t\treturn nil, eh.NewError(arg.ID(), \"matcher requires a map literal argument\")\n\t}\n}\n\n// CELValueToMapStrList converts a CEL value to a map[string][]string\n//\n// Earlier validation stages should guarantee that the value has this type\n// at compile time, and that the runtime value type is map[string]any.\n// The reason for the slight difference in value type is that CEL allows for\n// map literals containing heterogeneous values, in this case string and list\n// of string.\nfunc CELValueToMapStrList(data ref.Val) (map[string][]string, error) {\n\tmapStrType := reflect.TypeOf(map[string]any{})\n\tmapStrRaw, err := data.ConvertToNative(mapStrType)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tmapStrIface := mapStrRaw.(map[string]any)\n\tmapStrListStr := make(map[string][]string, len(mapStrIface))\n\tfor k, v := range mapStrIface {\n\t\tswitch val := v.(type) {\n\t\tcase string:\n\t\t\tmapStrListStr[k] = []string{val}\n\t\tcase types.String:\n\t\t\tmapStrListStr[k] = []string{string(val)}\n\t\tcase []string:\n\t\t\tmapStrListStr[k] = val\n\t\tcase []ref.Val:\n\t\t\tconvVals := make([]string, len(val))\n\t\t\tfor i, elem := range val {\n\t\t\t\tstrVal, ok := elem.(types.String)\n\t\t\t\tif !ok {\n\t\t\t\t\treturn nil, fmt.Errorf(\"unsupported value type in header match: %T\", val)\n\t\t\t\t}\n\t\t\t\tconvVals[i] = string(strVal)\n\t\t\t}\n\t\t\tmapStrListStr[k] = convVals\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unsupported value type in header match: %T\", val)\n\t\t}\n\t}\n\treturn mapStrListStr, nil\n}\n\n// isCELStringExpr indicates whether the expression is a supported string expression\nfunc isCELStringExpr(e ast.Expr) bool {\n\treturn isCELStringLiteral(e) || isCELCaddyPlaceholderCall(e) || isCELConcatCall(e)\n}\n\n// isCELStringLiteral returns whether the expression is a CEL string literal.\nfunc isCELStringLiteral(e ast.Expr) bool {\n\tswitch e.Kind() {\n\tcase ast.LiteralKind:\n\t\tconstant := e.AsLiteral()\n\t\tswitch constant.Type() {\n\t\tcase types.StringType:\n\t\t\treturn true\n\t\t}\n\tcase ast.UnspecifiedExprKind, ast.CallKind, ast.ComprehensionKind, ast.IdentKind, ast.ListKind, ast.MapKind, ast.SelectKind, ast.StructKind:\n\t\t// appeasing the linter :)\n\t}\n\treturn false\n}\n\n// isCELCaddyPlaceholderCall returns whether the expression is a caddy placeholder call.\nfunc isCELCaddyPlaceholderCall(e ast.Expr) bool {\n\tswitch e.Kind() {\n\tcase ast.CallKind:\n\t\tcall := e.AsCall()\n\t\tif call.FunctionName() == CELPlaceholderFuncName {\n\t\t\treturn true\n\t\t}\n\tcase ast.UnspecifiedExprKind, ast.ComprehensionKind, ast.IdentKind, ast.ListKind, ast.LiteralKind, ast.MapKind, ast.SelectKind, ast.StructKind:\n\t\t// appeasing the linter :)\n\t}\n\treturn false\n}\n\n// isCELConcatCall tests whether the expression is a concat function (+) with string, placeholder, or\n// other concat call arguments.\nfunc isCELConcatCall(e ast.Expr) bool {\n\tswitch e.Kind() {\n\tcase ast.CallKind:\n\t\tcall := e.AsCall()\n\t\tif call.Target().Kind() != ast.UnspecifiedExprKind {\n\t\t\treturn false\n\t\t}\n\t\tif call.FunctionName() != operators.Add {\n\t\t\treturn false\n\t\t}\n\t\tfor _, arg := range call.Args() {\n\t\t\tif !isCELStringExpr(arg) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase ast.UnspecifiedExprKind, ast.ComprehensionKind, ast.IdentKind, ast.ListKind, ast.LiteralKind, ast.MapKind, ast.SelectKind, ast.StructKind:\n\t\t// appeasing the linter :)\n\t}\n\treturn false\n}\n\n// isCELStringListLiteral returns whether the expression resolves to a list literal\n// containing only string constants or a placeholder call.\nfunc isCELStringListLiteral(e ast.Expr) bool {\n\tswitch e.Kind() {\n\tcase ast.ListKind:\n\t\tlist := e.AsList()\n\t\tfor _, elem := range list.Elements() {\n\t\t\tif !isCELStringExpr(elem) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase ast.UnspecifiedExprKind, ast.CallKind, ast.ComprehensionKind, ast.IdentKind, ast.LiteralKind, ast.MapKind, ast.SelectKind, ast.StructKind:\n\t\t// appeasing the linter :)\n\t}\n\treturn false\n}\n\n// Variables used for replacing Caddy placeholders in CEL\n// expressions with a proper CEL function call; this is\n// just for syntactic sugar.\nvar (\n\t// The placeholder may not be preceded by a backslash; the expansion\n\t// will include the preceding character if it is not a backslash.\n\tplaceholderRegexp    = regexp.MustCompile(`([^\\\\]|^){([a-zA-Z][\\w.-]+)}`)\n\tplaceholderExpansion = `${1}ph(req, \"${2}\")`\n\n\t// As a second pass, we need to strip the escape character in front of\n\t// the placeholder, if it exists.\n\tescapedPlaceholderRegexp    = regexp.MustCompile(`\\\\{([a-zA-Z][\\w.-]+)}`)\n\tescapedPlaceholderExpansion = `{${1}}`\n\n\tCELTypeJSON = cel.MapType(cel.StringType, cel.DynType)\n)\n\nvar httpRequestObjectType = cel.ObjectType(\"http.Request\")\n\n// The name of the CEL function which accesses Replacer values.\nconst CELPlaceholderFuncName = \"ph\"\n\n// The name of the CEL request variable.\nconst CELRequestVarName = \"req\"\n\nconst MatcherNameCtxKey = \"matcher_name\"\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner       = (*MatchExpression)(nil)\n\t_ RequestMatcherWithError = (*MatchExpression)(nil)\n\t_ caddyfile.Unmarshaler   = (*MatchExpression)(nil)\n\t_ json.Marshaler          = (*MatchExpression)(nil)\n\t_ json.Unmarshaler        = (*MatchExpression)(nil)\n)\n",
    "source_file": "modules/caddyhttp/celmatcher.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"cmp\"\n\t\"context\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"maps\"\n\t\"net\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"sync\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\t\"golang.org/x/net/http2\"\n\t\"golang.org/x/net/http2/h2c\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyevents\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(App{})\n}\n\n// App is a robust, production-ready HTTP server.\n//\n// HTTPS is enabled by default if host matchers with qualifying names are used\n// in any of routes; certificates are automatically provisioned and renewed.\n// Additionally, automatic HTTPS will also enable HTTPS for servers that listen\n// only on the HTTPS port but which do not have any TLS connection policies\n// defined by adding a good, default TLS connection policy.\n//\n// In HTTP routes, additional placeholders are available (replace any `*`):\n//\n// Placeholder | Description\n// ------------|---------------\n// `{http.request.body}` | The request body (\u26a0\ufe0f inefficient; use only for debugging)\n// `{http.request.cookie.*}` | HTTP request cookie\n// `{http.request.duration}` | Time up to now spent handling the request (after decoding headers from client)\n// `{http.request.duration_ms}` | Same as 'duration', but in milliseconds.\n// `{http.request.uuid}` | The request unique identifier\n// `{http.request.header.*}` | Specific request header field\n// `{http.request.host}` | The host part of the request's Host header\n// `{http.request.host.labels.*}` | Request host labels (0-based from right); e.g. for foo.example.com: 0=com, 1=example, 2=foo\n// `{http.request.hostport}` | The host and port from the request's Host header\n// `{http.request.method}` | The request method\n// `{http.request.orig_method}` | The request's original method\n// `{http.request.orig_uri}` | The request's original URI\n// `{http.request.orig_uri.path}` | The request's original path\n// `{http.request.orig_uri.path.*}` | Parts of the original path, split by `/` (0-based from left)\n// `{http.request.orig_uri.path.dir}` | The request's original directory\n// `{http.request.orig_uri.path.file}` | The request's original filename\n// `{http.request.orig_uri.query}` | The request's original query string (without `?`)\n// `{http.request.port}` | The port part of the request's Host header\n// `{http.request.proto}` | The protocol of the request\n// `{http.request.local.host}` | The host (IP) part of the local address the connection arrived on\n// `{http.request.local.port}` | The port part of the local address the connection arrived on\n// `{http.request.local}` | The local address the connection arrived on\n// `{http.request.remote.host}` | The host (IP) part of the remote client's address, if available (not known with HTTP/3 early data)\n// `{http.request.remote.port}` | The port part of the remote client's address\n// `{http.request.remote}` | The address of the remote client\n// `{http.request.scheme}` | The request scheme, typically `http` or `https`\n// `{http.request.tls.version}` | The TLS version name\n// `{http.request.tls.cipher_suite}` | The TLS cipher suite\n// `{http.request.tls.resumed}` | The TLS connection resumed a previous connection\n// `{http.request.tls.proto}` | The negotiated next protocol\n// `{http.request.tls.proto_mutual}` | The negotiated next protocol was advertised by the server\n// `{http.request.tls.server_name}` | The server name requested by the client, if any\n// `{http.request.tls.client.fingerprint}` | The SHA256 checksum of the client certificate\n// `{http.request.tls.client.public_key}` | The public key of the client certificate.\n// `{http.request.tls.client.public_key_sha256}` | The SHA256 checksum of the client's public key.\n// `{http.request.tls.client.certificate_pem}` | The PEM-encoded value of the certificate.\n// `{http.request.tls.client.certificate_der_base64}` | The base64-encoded value of the certificate.\n// `{http.request.tls.client.issuer}` | The issuer DN of the client certificate\n// `{http.request.tls.client.serial}` | The serial number of the client certificate\n// `{http.request.tls.client.subject}` | The subject DN of the client certificate\n// `{http.request.tls.client.san.dns_names.*}` | SAN DNS names(index optional)\n// `{http.request.tls.client.san.emails.*}` | SAN email addresses (index optional)\n// `{http.request.tls.client.san.ips.*}` | SAN IP addresses (index optional)\n// `{http.request.tls.client.san.uris.*}` | SAN URIs (index optional)\n// `{http.request.uri}` | The full request URI\n// `{http.request.uri.path}` | The path component of the request URI\n// `{http.request.uri.path.*}` | Parts of the path, split by `/` (0-based from left)\n// `{http.request.uri.path.dir}` | The directory, excluding leaf filename\n// `{http.request.uri.path.file}` | The filename of the path, excluding directory\n// `{http.request.uri.query}` | The query string (without `?`)\n// `{http.request.uri.query.*}` | Individual query string value\n// `{http.response.header.*}` | Specific response header field\n// `{http.vars.*}` | Custom variables in the HTTP handler chain\n// `{http.shutting_down}` | True if the HTTP app is shutting down\n// `{http.time_until_shutdown}` | Time until HTTP server shutdown, if scheduled\ntype App struct {\n\t// HTTPPort specifies the port to use for HTTP (as opposed to HTTPS),\n\t// which is used when setting up HTTP->HTTPS redirects or ACME HTTP\n\t// challenge solvers. Default: 80.\n\tHTTPPort int `json:\"http_port,omitempty\"`\n\n\t// HTTPSPort specifies the port to use for HTTPS, which is used when\n\t// solving the ACME TLS-ALPN challenges, or whenever HTTPS is needed\n\t// but no specific port number is given. Default: 443.\n\tHTTPSPort int `json:\"https_port,omitempty\"`\n\n\t// GracePeriod is how long to wait for active connections when shutting\n\t// down the servers. During the grace period, no new connections are\n\t// accepted, idle connections are closed, and active connections will\n\t// be given the full length of time to become idle and close.\n\t// Once the grace period is over, connections will be forcefully closed.\n\t// If zero, the grace period is eternal. Default: 0.\n\tGracePeriod caddy.Duration `json:\"grace_period,omitempty\"`\n\n\t// ShutdownDelay is how long to wait before initiating the grace\n\t// period. When this app is stopping (e.g. during a config reload or\n\t// process exit), all servers will be shut down. Normally this immediately\n\t// initiates the grace period. However, if this delay is configured, servers\n\t// will not be shut down until the delay is over. During this time, servers\n\t// continue to function normally and allow new connections. At the end, the\n\t// grace period will begin. This can be useful to allow downstream load\n\t// balancers time to move this instance out of the rotation without hiccups.\n\t//\n\t// When shutdown has been scheduled, placeholders {http.shutting_down} (bool)\n\t// and {http.time_until_shutdown} (duration) may be useful for health checks.\n\tShutdownDelay caddy.Duration `json:\"shutdown_delay,omitempty\"`\n\n\t// Servers is the list of servers, keyed by arbitrary names chosen\n\t// at your discretion for your own convenience; the keys do not\n\t// affect functionality.\n\tServers map[string]*Server `json:\"servers,omitempty\"`\n\n\t// If set, metrics observations will be enabled.\n\t// This setting is EXPERIMENTAL and subject to change.\n\tMetrics *Metrics `json:\"metrics,omitempty\"`\n\n\tctx    caddy.Context\n\tlogger *zap.Logger\n\ttlsApp *caddytls.TLS\n\n\t// used temporarily between phases 1 and 2 of auto HTTPS\n\tallCertDomains map[string]struct{}\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (App) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http\",\n\t\tNew: func() caddy.Module { return new(App) },\n\t}\n}\n\n// Provision sets up the app.\nfunc (app *App) Provision(ctx caddy.Context) error {\n\t// store some references\n\ttlsAppIface, err := ctx.App(\"tls\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting tls app: %v\", err)\n\t}\n\tapp.tlsApp = tlsAppIface.(*caddytls.TLS)\n\tapp.ctx = ctx\n\tapp.logger = ctx.Logger()\n\n\teventsAppIface, err := ctx.App(\"events\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting events app: %v\", err)\n\t}\n\n\trepl := caddy.NewReplacer()\n\n\t// this provisions the matchers for each route,\n\t// and prepares auto HTTP->HTTPS redirects, and\n\t// is required before we provision each server\n\terr = app.automaticHTTPSPhase1(ctx, repl)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif app.Metrics != nil {\n\t\tapp.Metrics.init = sync.Once{}\n\t\tapp.Metrics.httpMetrics = &httpMetrics{}\n\t}\n\t// prepare each server\n\toldContext := ctx.Context\n\tfor srvName, srv := range app.Servers {\n\t\tctx.Context = context.WithValue(oldContext, ServerCtxKey, srv)\n\t\tsrv.name = srvName\n\t\tsrv.tlsApp = app.tlsApp\n\t\tsrv.events = eventsAppIface.(*caddyevents.App)\n\t\tsrv.ctx = ctx\n\t\tsrv.logger = app.logger.Named(\"log\")\n\t\tsrv.errorLogger = app.logger.Named(\"log.error\")\n\t\tsrv.shutdownAtMu = new(sync.RWMutex)\n\n\t\tif srv.Metrics != nil {\n\t\t\tsrv.logger.Warn(\"per-server 'metrics' is deprecated; use 'metrics' in the root 'http' app instead\")\n\t\t\tapp.Metrics = cmp.Or(app.Metrics, &Metrics{\n\t\t\t\tinit:        sync.Once{},\n\t\t\t\thttpMetrics: &httpMetrics{},\n\t\t\t})\n\t\t\tapp.Metrics.PerHost = app.Metrics.PerHost || srv.Metrics.PerHost\n\t\t}\n\n\t\t// only enable access logs if configured\n\t\tif srv.Logs != nil {\n\t\t\tsrv.accessLogger = app.logger.Named(\"log.access\")\n\t\t\tif srv.Logs.Trace {\n\t\t\t\tsrv.traceLogger = app.logger.Named(\"log.trace\")\n\t\t\t}\n\t\t}\n\n\t\t// if no protocols configured explicitly, enable all except h2c\n\t\tif len(srv.Protocols) == 0 {\n\t\t\tsrv.Protocols = []string{\"h1\", \"h2\", \"h3\"}\n\t\t}\n\n\t\tsrvProtocolsUnique := map[string]struct{}{}\n\t\tfor _, srvProtocol := range srv.Protocols {\n\t\t\tsrvProtocolsUnique[srvProtocol] = struct{}{}\n\t\t}\n\t\t_, h1ok := srvProtocolsUnique[\"h1\"]\n\t\t_, h2ok := srvProtocolsUnique[\"h2\"]\n\t\t_, h2cok := srvProtocolsUnique[\"h2c\"]\n\n\t\t// the Go standard library does not let us serve only HTTP/2 using\n\t\t// http.Server; we would probably need to write our own server\n\t\tif !h1ok && (h2ok || h2cok) {\n\t\t\treturn fmt.Errorf(\"server %s: cannot enable HTTP/2 or H2C without enabling HTTP/1.1; add h1 to protocols or remove h2/h2c\", srvName)\n\t\t}\n\n\t\tif srv.ListenProtocols != nil {\n\t\t\tif len(srv.ListenProtocols) != len(srv.Listen) {\n\t\t\t\treturn fmt.Errorf(\"server %s: listener protocols count does not match address count: %d != %d\",\n\t\t\t\t\tsrvName, len(srv.ListenProtocols), len(srv.Listen))\n\t\t\t}\n\n\t\t\tfor i, lnProtocols := range srv.ListenProtocols {\n\t\t\t\tif lnProtocols != nil {\n\t\t\t\t\t// populate empty listen protocols with server protocols\n\t\t\t\t\tlnProtocolsDefault := false\n\t\t\t\t\tvar lnProtocolsInclude []string\n\t\t\t\t\tsrvProtocolsInclude := maps.Clone(srvProtocolsUnique)\n\n\t\t\t\t\t// keep existing listener protocols unless they are empty\n\t\t\t\t\tfor _, lnProtocol := range lnProtocols {\n\t\t\t\t\t\tif lnProtocol == \"\" {\n\t\t\t\t\t\t\tlnProtocolsDefault = true\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlnProtocolsInclude = append(lnProtocolsInclude, lnProtocol)\n\t\t\t\t\t\t\tdelete(srvProtocolsInclude, lnProtocol)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// append server protocols to listener protocols if any listener protocols were empty\n\t\t\t\t\tif lnProtocolsDefault {\n\t\t\t\t\t\tfor _, srvProtocol := range srv.Protocols {\n\t\t\t\t\t\t\tif _, ok := srvProtocolsInclude[srvProtocol]; ok {\n\t\t\t\t\t\t\t\tlnProtocolsInclude = append(lnProtocolsInclude, srvProtocol)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tlnProtocolsIncludeUnique := map[string]struct{}{}\n\t\t\t\t\tfor _, lnProtocol := range lnProtocolsInclude {\n\t\t\t\t\t\tlnProtocolsIncludeUnique[lnProtocol] = struct{}{}\n\t\t\t\t\t}\n\t\t\t\t\t_, h1ok := lnProtocolsIncludeUnique[\"h1\"]\n\t\t\t\t\t_, h2ok := lnProtocolsIncludeUnique[\"h2\"]\n\t\t\t\t\t_, h2cok := lnProtocolsIncludeUnique[\"h2c\"]\n\n\t\t\t\t\t// check if any listener protocols contain h2 or h2c without h1\n\t\t\t\t\tif !h1ok && (h2ok || h2cok) {\n\t\t\t\t\t\treturn fmt.Errorf(\"server %s, listener %d: cannot enable HTTP/2 or H2C without enabling HTTP/1.1; add h1 to protocols or remove h2/h2c\", srvName, i)\n\t\t\t\t\t}\n\n\t\t\t\t\tsrv.ListenProtocols[i] = lnProtocolsInclude\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// if not explicitly configured by the user, disallow TLS\n\t\t// client auth bypass (domain fronting) which could\n\t\t// otherwise be exploited by sending an unprotected SNI\n\t\t// value during a TLS handshake, then putting a protected\n\t\t// domain in the Host header after establishing connection;\n\t\t// this is a safe default, but we allow users to override\n\t\t// it for example in the case of running a proxy where\n\t\t// domain fronting is desired and access is not restricted\n\t\t// based on hostname\n\t\tif srv.StrictSNIHost == nil && srv.hasTLSClientAuth() {\n\t\t\tapp.logger.Warn(\"enabling strict SNI-Host enforcement because TLS client auth is configured\",\n\t\t\t\tzap.String(\"server_id\", srvName))\n\t\t\ttrueBool := true\n\t\t\tsrv.StrictSNIHost = &trueBool\n\t\t}\n\n\t\t// set up the trusted proxies source\n\t\tfor srv.TrustedProxiesRaw != nil {\n\t\t\tval, err := ctx.LoadModule(srv, \"TrustedProxiesRaw\")\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading trusted proxies modules: %v\", err)\n\t\t\t}\n\t\t\tsrv.trustedProxies = val.(IPRangeSource)\n\t\t}\n\n\t\t// set the default client IP header to read from\n\t\tif srv.ClientIPHeaders == nil {\n\t\t\tsrv.ClientIPHeaders = []string{\"X-Forwarded-For\"}\n\t\t}\n\n\t\t// process each listener address\n\t\tfor i := range srv.Listen {\n\t\t\tlnOut, err := repl.ReplaceOrErr(srv.Listen[i], true, true)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"server %s, listener %d: %v\", srvName, i, err)\n\t\t\t}\n\t\t\tsrv.Listen[i] = lnOut\n\t\t}\n\n\t\t// set up each listener modifier\n\t\tif srv.ListenerWrappersRaw != nil {\n\t\t\tvals, err := ctx.LoadModule(srv, \"ListenerWrappersRaw\")\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading listener wrapper modules: %v\", err)\n\t\t\t}\n\t\t\tvar hasTLSPlaceholder bool\n\t\t\tfor i, val := range vals.([]any) {\n\t\t\t\tif _, ok := val.(*tlsPlaceholderWrapper); ok {\n\t\t\t\t\tif i == 0 {\n\t\t\t\t\t\t// putting the tls placeholder wrapper first is nonsensical because\n\t\t\t\t\t\t// that is the default, implicit setting: without it, all wrappers\n\t\t\t\t\t\t// will go after the TLS listener anyway\n\t\t\t\t\t\treturn fmt.Errorf(\"it is unnecessary to specify the TLS listener wrapper in the first position because that is the default\")\n\t\t\t\t\t}\n\t\t\t\t\tif hasTLSPlaceholder {\n\t\t\t\t\t\treturn fmt.Errorf(\"TLS listener wrapper can only be specified once\")\n\t\t\t\t\t}\n\t\t\t\t\thasTLSPlaceholder = true\n\t\t\t\t}\n\t\t\t\tsrv.listenerWrappers = append(srv.listenerWrappers, val.(caddy.ListenerWrapper))\n\t\t\t}\n\t\t\t// if any wrappers were configured but the TLS placeholder wrapper is\n\t\t\t// absent, prepend it so all defined wrappers come after the TLS\n\t\t\t// handshake; this simplifies logic when starting the server, since we\n\t\t\t// can simply assume the TLS placeholder will always be there\n\t\t\tif !hasTLSPlaceholder && len(srv.listenerWrappers) > 0 {\n\t\t\t\tsrv.listenerWrappers = append([]caddy.ListenerWrapper{new(tlsPlaceholderWrapper)}, srv.listenerWrappers...)\n\t\t\t}\n\t\t}\n\t\t// pre-compile the primary handler chain, and be sure to wrap it in our\n\t\t// route handler so that important security checks are done, etc.\n\t\tprimaryRoute := emptyHandler\n\t\tif srv.Routes != nil {\n\t\t\terr := srv.Routes.ProvisionHandlers(ctx, app.Metrics)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"server %s: setting up route handlers: %v\", srvName, err)\n\t\t\t}\n\t\t\tprimaryRoute = srv.Routes.Compile(emptyHandler)\n\t\t}\n\t\tsrv.primaryHandlerChain = srv.wrapPrimaryRoute(primaryRoute)\n\n\t\t// pre-compile the error handler chain\n\t\tif srv.Errors != nil {\n\t\t\terr := srv.Errors.Routes.Provision(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"server %s: setting up error handling routes: %v\", srvName, err)\n\t\t\t}\n\t\t\tsrv.errorHandlerChain = srv.Errors.Routes.Compile(errorEmptyHandler)\n\t\t}\n\n\t\t// provision the named routes (they get compiled at runtime)\n\t\tfor name, route := range srv.NamedRoutes {\n\t\t\terr := route.Provision(ctx, app.Metrics)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"server %s: setting up named route '%s' handlers: %v\", name, srvName, err)\n\t\t\t}\n\t\t}\n\n\t\t// prepare the TLS connection policies\n\t\terr = srv.TLSConnPolicies.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"server %s: setting up TLS connection policies: %v\", srvName, err)\n\t\t}\n\n\t\t// if there is no idle timeout, set a sane default; users have complained\n\t\t// before that aggressive CDNs leave connections open until the server\n\t\t// closes them, so if we don't close them it leads to resource exhaustion\n\t\tif srv.IdleTimeout == 0 {\n\t\t\tsrv.IdleTimeout = defaultIdleTimeout\n\t\t}\n\t\tif srv.ReadHeaderTimeout == 0 {\n\t\t\tsrv.ReadHeaderTimeout = defaultReadHeaderTimeout // see #6663\n\t\t}\n\t}\n\tctx.Context = oldContext\n\treturn nil\n}\n\n// Validate ensures the app's configuration is valid.\nfunc (app *App) Validate() error {\n\tlnAddrs := make(map[string]string)\n\n\tfor srvName, srv := range app.Servers {\n\t\t// each server must use distinct listener addresses\n\t\tfor _, addr := range srv.Listen {\n\t\t\tlistenAddr, err := caddy.ParseNetworkAddress(addr)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"invalid listener address '%s': %v\", addr, err)\n\t\t\t}\n\t\t\t// check that every address in the port range is unique to this server;\n\t\t\t// we do not use <= here because PortRangeSize() adds 1 to EndPort for us\n\t\t\tfor i := uint(0); i < listenAddr.PortRangeSize(); i++ {\n\t\t\t\taddr := caddy.JoinNetworkAddress(listenAddr.Network, listenAddr.Host, strconv.FormatUint(uint64(listenAddr.StartPort+i), 10))\n\t\t\t\tif sn, ok := lnAddrs[addr]; ok {\n\t\t\t\t\treturn fmt.Errorf(\"server %s: listener address repeated: %s (already claimed by server '%s')\", srvName, addr, sn)\n\t\t\t\t}\n\t\t\t\tlnAddrs[addr] = srvName\n\t\t\t}\n\t\t}\n\n\t\t// logger names must not have ports\n\t\tif srv.Logs != nil {\n\t\t\tfor host := range srv.Logs.LoggerNames {\n\t\t\t\tif _, _, err := net.SplitHostPort(host); err == nil {\n\t\t\t\t\treturn fmt.Errorf(\"server %s: logger name must not have a port: %s\", srvName, host)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// Start runs the app. It finishes automatic HTTPS if enabled,\n// including management of certificates.\nfunc (app *App) Start() error {\n\t// get a logger compatible with http.Server\n\tserverLogger, err := zap.NewStdLogAt(app.logger.Named(\"stdlib\"), zap.DebugLevel)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"failed to set up server logger: %v\", err)\n\t}\n\n\tfor srvName, srv := range app.Servers {\n\t\tsrv.server = &http.Server{\n\t\t\tReadTimeout:       time.Duration(srv.ReadTimeout),\n\t\t\tReadHeaderTimeout: time.Duration(srv.ReadHeaderTimeout),\n\t\t\tWriteTimeout:      time.Duration(srv.WriteTimeout),\n\t\t\tIdleTimeout:       time.Duration(srv.IdleTimeout),\n\t\t\tMaxHeaderBytes:    srv.MaxHeaderBytes,\n\t\t\tHandler:           srv,\n\t\t\tErrorLog:          serverLogger,\n\t\t\tConnContext: func(ctx context.Context, c net.Conn) context.Context {\n\t\t\t\treturn context.WithValue(ctx, ConnCtxKey, c)\n\t\t\t},\n\t\t}\n\t\th2server := new(http2.Server)\n\n\t\t// disable HTTP/2, which we enabled by default during provisioning\n\t\tif !srv.protocol(\"h2\") {\n\t\t\tsrv.server.TLSNextProto = make(map[string]func(*http.Server, *tls.Conn, http.Handler))\n\t\t\tfor _, cp := range srv.TLSConnPolicies {\n\t\t\t\t// the TLSConfig was already provisioned, so... manually remove it\n\t\t\t\tfor i, np := range cp.TLSConfig.NextProtos {\n\t\t\t\t\tif np == \"h2\" {\n\t\t\t\t\t\tcp.TLSConfig.NextProtos = append(cp.TLSConfig.NextProtos[:i], cp.TLSConfig.NextProtos[i+1:]...)\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t// remove it from the parent connection policy too, just to keep things tidy\n\t\t\t\tfor i, alpn := range cp.ALPN {\n\t\t\t\t\tif alpn == \"h2\" {\n\t\t\t\t\t\tcp.ALPN = append(cp.ALPN[:i], cp.ALPN[i+1:]...)\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\t//nolint:errcheck\n\t\t\thttp2.ConfigureServer(srv.server, h2server)\n\t\t}\n\n\t\t// this TLS config is used by the std lib to choose the actual TLS config for connections\n\t\t// by looking through the connection policies to find the first one that matches\n\t\ttlsCfg := srv.TLSConnPolicies.TLSConfig(app.ctx)\n\t\tsrv.configureServer(srv.server)\n\n\t\t// enable H2C if configured\n\t\tif srv.protocol(\"h2c\") {\n\t\t\tsrv.server.Handler = h2c.NewHandler(srv, h2server)\n\t\t}\n\n\t\tfor lnIndex, lnAddr := range srv.Listen {\n\t\t\tlistenAddr, err := caddy.ParseNetworkAddress(lnAddr)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"%s: parsing listen address '%s': %v\", srvName, lnAddr, err)\n\t\t\t}\n\n\t\t\tsrv.addresses = append(srv.addresses, listenAddr)\n\n\t\t\tprotocols := srv.Protocols\n\t\t\tif srv.ListenProtocols != nil && srv.ListenProtocols[lnIndex] != nil {\n\t\t\t\tprotocols = srv.ListenProtocols[lnIndex]\n\t\t\t}\n\n\t\t\tprotocolsUnique := map[string]struct{}{}\n\t\t\tfor _, protocol := range protocols {\n\t\t\t\tprotocolsUnique[protocol] = struct{}{}\n\t\t\t}\n\t\t\t_, h1ok := protocolsUnique[\"h1\"]\n\t\t\t_, h2ok := protocolsUnique[\"h2\"]\n\t\t\t_, h2cok := protocolsUnique[\"h2c\"]\n\t\t\t_, h3ok := protocolsUnique[\"h3\"]\n\n\t\t\tfor portOffset := uint(0); portOffset < listenAddr.PortRangeSize(); portOffset++ {\n\t\t\t\thostport := listenAddr.JoinHostPort(portOffset)\n\n\t\t\t\t// enable TLS if there is a policy and if this is not the HTTP port\n\t\t\t\tuseTLS := len(srv.TLSConnPolicies) > 0 && int(listenAddr.StartPort+portOffset) != app.httpPort()\n\n\t\t\t\tif h1ok || h2ok && useTLS || h2cok {\n\t\t\t\t\t// create the listener for this socket\n\t\t\t\t\tlnAny, err := listenAddr.Listen(app.ctx, portOffset, net.ListenConfig{KeepAlive: time.Duration(srv.KeepAliveInterval)})\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"listening on %s: %v\", listenAddr.At(portOffset), err)\n\t\t\t\t\t}\n\t\t\t\t\tln, ok := lnAny.(net.Listener)\n\t\t\t\t\tif !ok {\n\t\t\t\t\t\treturn fmt.Errorf(\"network '%s' cannot handle HTTP/1 or HTTP/2 connections\", listenAddr.Network)\n\t\t\t\t\t}\n\n\t\t\t\t\t// wrap listener before TLS (up to the TLS placeholder wrapper)\n\t\t\t\t\tvar lnWrapperIdx int\n\t\t\t\t\tfor i, lnWrapper := range srv.listenerWrappers {\n\t\t\t\t\t\tif _, ok := lnWrapper.(*tlsPlaceholderWrapper); ok {\n\t\t\t\t\t\t\tlnWrapperIdx = i + 1 // mark the next wrapper's spot\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t\tln = lnWrapper.WrapListener(ln)\n\t\t\t\t\t}\n\n\t\t\t\t\tif useTLS {\n\t\t\t\t\t\t// create TLS listener - this enables and terminates TLS\n\t\t\t\t\t\tln = tls.NewListener(ln, tlsCfg)\n\t\t\t\t\t}\n\n\t\t\t\t\t// finish wrapping listener where we left off before TLS\n\t\t\t\t\tfor i := lnWrapperIdx; i < len(srv.listenerWrappers); i++ {\n\t\t\t\t\t\tln = srv.listenerWrappers[i].WrapListener(ln)\n\t\t\t\t\t}\n\n\t\t\t\t\t// handle http2 if use tls listener wrapper\n\t\t\t\t\tif h2ok {\n\t\t\t\t\t\thttp2lnWrapper := &http2Listener{\n\t\t\t\t\t\t\tListener: ln,\n\t\t\t\t\t\t\tserver:   srv.server,\n\t\t\t\t\t\t\th2server: h2server,\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsrv.h2listeners = append(srv.h2listeners, http2lnWrapper)\n\t\t\t\t\t\tln = http2lnWrapper\n\t\t\t\t\t}\n\n\t\t\t\t\t// if binding to port 0, the OS chooses a port for us;\n\t\t\t\t\t// but the user won't know the port unless we print it\n\t\t\t\t\tif !listenAddr.IsUnixNetwork() && !listenAddr.IsFdNetwork() && listenAddr.StartPort == 0 && listenAddr.EndPort == 0 {\n\t\t\t\t\t\tapp.logger.Info(\"port 0 listener\",\n\t\t\t\t\t\t\tzap.String(\"input_address\", lnAddr),\n\t\t\t\t\t\t\tzap.String(\"actual_address\", ln.Addr().String()))\n\t\t\t\t\t}\n\n\t\t\t\t\tapp.logger.Debug(\"starting server loop\",\n\t\t\t\t\t\tzap.String(\"address\", ln.Addr().String()),\n\t\t\t\t\t\tzap.Bool(\"tls\", useTLS),\n\t\t\t\t\t\tzap.Bool(\"http3\", srv.h3server != nil))\n\n\t\t\t\t\tsrv.listeners = append(srv.listeners, ln)\n\n\t\t\t\t\t// enable HTTP/1 if configured\n\t\t\t\t\tif h1ok {\n\t\t\t\t\t\t//nolint:errcheck\n\t\t\t\t\t\tgo srv.server.Serve(ln)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif h2ok && !useTLS {\n\t\t\t\t\t// Can only serve h2 with TLS enabled\n\t\t\t\t\tapp.logger.Warn(\"HTTP/2 skipped because it requires TLS\",\n\t\t\t\t\t\tzap.String(\"network\", listenAddr.Network),\n\t\t\t\t\t\tzap.String(\"addr\", hostport))\n\t\t\t\t}\n\n\t\t\t\tif h3ok {\n\t\t\t\t\t// Can't serve HTTP/3 on the same socket as HTTP/1 and 2 because it uses\n\t\t\t\t\t// a different transport mechanism... which is fine, but the OS doesn't\n\t\t\t\t\t// differentiate between a SOCK_STREAM file and a SOCK_DGRAM file; they\n\t\t\t\t\t// are still one file on the system. So even though \"unixpacket\" and\n\t\t\t\t\t// \"unixgram\" are different network types just as \"tcp\" and \"udp\" are,\n\t\t\t\t\t// the OS will not let us use the same file as both STREAM and DGRAM.\n\t\t\t\t\tif listenAddr.IsUnixNetwork() {\n\t\t\t\t\t\tapp.logger.Warn(\"HTTP/3 disabled because Unix can't multiplex STREAM and DGRAM on same socket\",\n\t\t\t\t\t\t\tzap.String(\"file\", hostport))\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\tif useTLS {\n\t\t\t\t\t\t// enable HTTP/3 if configured\n\t\t\t\t\t\tapp.logger.Info(\"enabling HTTP/3 listener\", zap.String(\"addr\", hostport))\n\t\t\t\t\t\tif err := srv.serveHTTP3(listenAddr.At(portOffset), tlsCfg); err != nil {\n\t\t\t\t\t\t\treturn err\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\t// Can only serve h3 with TLS enabled\n\t\t\t\t\t\tapp.logger.Warn(\"HTTP/3 skipped because it requires TLS\",\n\t\t\t\t\t\t\tzap.String(\"network\", listenAddr.Network),\n\t\t\t\t\t\t\tzap.String(\"addr\", hostport))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tsrv.logger.Info(\"server running\",\n\t\t\tzap.String(\"name\", srvName),\n\t\t\tzap.Strings(\"protocols\", srv.Protocols))\n\t}\n\n\t// finish automatic HTTPS by finally beginning\n\t// certificate management\n\terr = app.automaticHTTPSPhase2()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"finalizing automatic HTTPS: %v\", err)\n\t}\n\n\treturn nil\n}\n\n// Stop gracefully shuts down the HTTP server.\nfunc (app *App) Stop() error {\n\tctx := context.Background()\n\n\t// see if any listeners in our config will be closing or if they are continuing\n\t// through a reload; because if any are closing, we will enforce shutdown delay\n\tvar delay bool\n\tscheduledTime := time.Now().Add(time.Duration(app.ShutdownDelay))\n\tif app.ShutdownDelay > 0 {\n\t\tfor _, server := range app.Servers {\n\t\t\tfor _, na := range server.addresses {\n\t\t\t\tfor _, addr := range na.Expand() {\n\t\t\t\t\tif caddy.ListenerUsage(addr.Network, addr.JoinHostPort(0)) < 2 {\n\t\t\t\t\t\tapp.logger.Debug(\"listener closing and shutdown delay is configured\", zap.String(\"address\", addr.String()))\n\t\t\t\t\t\tserver.shutdownAtMu.Lock()\n\t\t\t\t\t\tserver.shutdownAt = scheduledTime\n\t\t\t\t\t\tserver.shutdownAtMu.Unlock()\n\t\t\t\t\t\tdelay = true\n\t\t\t\t\t} else {\n\t\t\t\t\t\tapp.logger.Debug(\"shutdown delay configured but listener will remain open\", zap.String(\"address\", addr.String()))\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// honor scheduled/delayed shutdown time\n\tif delay {\n\t\tapp.logger.Info(\"shutdown scheduled\",\n\t\t\tzap.Duration(\"delay_duration\", time.Duration(app.ShutdownDelay)),\n\t\t\tzap.Time(\"time\", scheduledTime))\n\t\ttime.Sleep(time.Duration(app.ShutdownDelay))\n\t}\n\n\t// enforce grace period if configured\n\tif app.GracePeriod > 0 {\n\t\tvar cancel context.CancelFunc\n\t\tctx, cancel = context.WithTimeout(ctx, time.Duration(app.GracePeriod))\n\t\tdefer cancel()\n\t\tapp.logger.Info(\"servers shutting down; grace period initiated\", zap.Duration(\"duration\", time.Duration(app.GracePeriod)))\n\t} else {\n\t\tapp.logger.Info(\"servers shutting down with eternal grace period\")\n\t}\n\n\t// goroutines aren't guaranteed to be scheduled right away,\n\t// so we'll use one WaitGroup to wait for all the goroutines\n\t// to start their server shutdowns, and another to wait for\n\t// them to finish; we'll always block for them to start so\n\t// that when we return the caller can be confident* that the\n\t// old servers are no longer accepting new connections\n\t// (* the scheduler might still pause them right before\n\t// calling Shutdown(), but it's unlikely)\n\tvar startedShutdown, finishedShutdown sync.WaitGroup\n\n\t// these will run in goroutines\n\tstopServer := func(server *Server) {\n\t\tdefer finishedShutdown.Done()\n\t\tstartedShutdown.Done()\n\n\t\tif err := server.server.Shutdown(ctx); err != nil {\n\t\t\tapp.logger.Error(\"server shutdown\",\n\t\t\t\tzap.Error(err),\n\t\t\t\tzap.Strings(\"addresses\", server.Listen))\n\t\t}\n\t}\n\tstopH3Server := func(server *Server) {\n\t\tdefer finishedShutdown.Done()\n\t\tstartedShutdown.Done()\n\n\t\tif server.h3server == nil {\n\t\t\treturn\n\t\t}\n\n\t\tif err := server.h3server.Shutdown(ctx); err != nil {\n\t\t\tapp.logger.Error(\"HTTP/3 server shutdown\",\n\t\t\t\tzap.Error(err),\n\t\t\t\tzap.Strings(\"addresses\", server.Listen))\n\t\t}\n\t}\n\tstopH2Listener := func(server *Server) {\n\t\tdefer finishedShutdown.Done()\n\t\tstartedShutdown.Done()\n\n\t\tfor i, s := range server.h2listeners {\n\t\t\tif err := s.Shutdown(ctx); err != nil {\n\t\t\t\tapp.logger.Error(\"http2 listener shutdown\",\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t\tzap.Int(\"index\", i))\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, server := range app.Servers {\n\t\tstartedShutdown.Add(3)\n\t\tfinishedShutdown.Add(3)\n\t\tgo stopServer(server)\n\t\tgo stopH3Server(server)\n\t\tgo stopH2Listener(server)\n\t}\n\n\t// block until all the goroutines have been run by the scheduler;\n\t// this means that they have likely called Shutdown() by now\n\tstartedShutdown.Wait()\n\n\t// if the process is exiting, we need to block here and wait\n\t// for the grace periods to complete, otherwise the process will\n\t// terminate before the servers are finished shutting down; but\n\t// we don't really need to wait for the grace period to finish\n\t// if the process isn't exiting (but note that frequent config\n\t// reloads with long grace periods for a sustained length of time\n\t// may deplete resources)\n\tif caddy.Exiting() {\n\t\tfinishedShutdown.Wait()\n\t}\n\n\t// run stop callbacks now that the server shutdowns are complete\n\tfor name, s := range app.Servers {\n\t\tfor _, stopHook := range s.onStopFuncs {\n\t\t\tif err := stopHook(ctx); err != nil {\n\t\t\t\tapp.logger.Error(\"server stop hook\", zap.String(\"server\", name), zap.Error(err))\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (app *App) httpPort() int {\n\tif app.HTTPPort == 0 {\n\t\treturn DefaultHTTPPort\n\t}\n\treturn app.HTTPPort\n}\n\nfunc (app *App) httpsPort() int {\n\tif app.HTTPSPort == 0 {\n\t\treturn DefaultHTTPSPort\n\t}\n\treturn app.HTTPSPort\n}\n\nconst (\n\t// defaultIdleTimeout is the default HTTP server timeout\n\t// for closing idle connections; useful to avoid resource\n\t// exhaustion behind hungry CDNs, for example (we've had\n\t// several complaints without this).\n\tdefaultIdleTimeout = caddy.Duration(5 * time.Minute)\n\n\t// defaultReadHeaderTimeout is the default timeout for\n\t// reading HTTP headers from clients. Headers are generally\n\t// small, often less than 1 KB, so it shouldn't take a\n\t// long time even on legitimately slow connections or\n\t// busy servers to read it.\n\tdefaultReadHeaderTimeout = caddy.Duration(time.Minute)\n)\n\n// Interface guards\nvar (\n\t_ caddy.App         = (*App)(nil)\n\t_ caddy.Provisioner = (*App)(nil)\n\t_ caddy.Validator   = (*App)(nil)\n)\n",
    "source_file": "modules/caddyhttp/app.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"strconv\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(StaticError{})\n}\n\n// StaticError implements a simple handler that returns an error.\n// This handler returns an error value, but does not write a response.\n// This is useful when you want the server to act as if an error\n// occurred; for example, to invoke your custom error handling logic.\n//\n// Since this handler does not write a response, the error information\n// is for use by the server to know how to handle the error.\ntype StaticError struct {\n\t// The error message. Optional. Default is no error message.\n\tError string `json:\"error,omitempty\"`\n\n\t// The recommended HTTP status code. Can be either an integer or a\n\t// string if placeholders are needed. Optional. Default is 500.\n\tStatusCode WeakString `json:\"status_code,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (StaticError) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.error\",\n\t\tNew: func() caddy.Module { return new(StaticError) },\n\t}\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens. Syntax:\n//\n//\terror [<matcher>] <status>|<message> [<status>] {\n//\t    message <text>\n//\t}\n//\n// If there is just one argument (other than the matcher), it is considered\n// to be a status code if it's a valid positive integer of 3 digits.\nfunc (e *StaticError) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume directive name\n\targs := d.RemainingArgs()\n\tswitch len(args) {\n\tcase 1:\n\t\tif len(args[0]) == 3 {\n\t\t\tif num, err := strconv.Atoi(args[0]); err == nil && num > 0 {\n\t\t\t\te.StatusCode = WeakString(args[0])\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\te.Error = args[0]\n\tcase 2:\n\t\te.Error = args[0]\n\t\te.StatusCode = WeakString(args[1])\n\tdefault:\n\t\treturn d.ArgErr()\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"message\":\n\t\t\tif e.Error != \"\" {\n\t\t\t\treturn d.Err(\"message already specified\")\n\t\t\t}\n\t\t\tif !d.AllArgs(&e.Error) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (e StaticError) ServeHTTP(w http.ResponseWriter, r *http.Request, _ Handler) error {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\tstatusCode := http.StatusInternalServerError\n\tif codeStr := e.StatusCode.String(); codeStr != \"\" {\n\t\tintVal, err := strconv.Atoi(repl.ReplaceAll(codeStr, \"\"))\n\t\tif err != nil {\n\t\t\treturn Error(http.StatusInternalServerError, err)\n\t\t}\n\t\tstatusCode = intVal\n\t}\n\treturn Error(statusCode, fmt.Errorf(\"%s\", repl.ReplaceKnown(e.Error, \"\")))\n}\n\n// Interface guard\nvar (\n\t_ MiddlewareHandler     = (*StaticError)(nil)\n\t_ caddyfile.Unmarshaler = (*StaticError)(nil)\n)\n",
    "source_file": "modules/caddyhttp/staticerror.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(HTTPRedirectListenerWrapper{})\n}\n\n// HTTPRedirectListenerWrapper provides HTTP->HTTPS redirects for\n// connections that come on the TLS port as an HTTP request,\n// by detecting using the first few bytes that it's not a TLS\n// handshake, but instead an HTTP request.\n//\n// This is especially useful when using a non-standard HTTPS port.\n// A user may simply type the address in their browser without the\n// https:// scheme, which would cause the browser to attempt the\n// connection over HTTP, but this would cause a \"Client sent an\n// HTTP request to an HTTPS server\" error response.\n//\n// This listener wrapper must be placed BEFORE the \"tls\" listener\n// wrapper, for it to work properly.\ntype HTTPRedirectListenerWrapper struct {\n\t// MaxHeaderBytes is the maximum size to parse from a client's\n\t// HTTP request headers. Default: 1 MB\n\tMaxHeaderBytes int64 `json:\"max_header_bytes,omitempty\"`\n}\n\nfunc (HTTPRedirectListenerWrapper) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"caddy.listeners.http_redirect\",\n\t\tNew: func() caddy.Module { return new(HTTPRedirectListenerWrapper) },\n\t}\n}\n\nfunc (h *HTTPRedirectListenerWrapper) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\treturn nil\n}\n\nfunc (h *HTTPRedirectListenerWrapper) WrapListener(l net.Listener) net.Listener {\n\treturn &httpRedirectListener{l, h.MaxHeaderBytes}\n}\n\n// httpRedirectListener is listener that checks the first few bytes\n// of the request when the server is intended to accept HTTPS requests,\n// to respond to an HTTP request with a redirect.\ntype httpRedirectListener struct {\n\tnet.Listener\n\tmaxHeaderBytes int64\n}\n\n// Accept waits for and returns the next connection to the listener,\n// wrapping it with a httpRedirectConn.\nfunc (l *httpRedirectListener) Accept() (net.Conn, error) {\n\tc, err := l.Listener.Accept()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tmaxHeaderBytes := l.maxHeaderBytes\n\tif maxHeaderBytes == 0 {\n\t\tmaxHeaderBytes = 1024 * 1024\n\t}\n\n\treturn &httpRedirectConn{\n\t\tConn:  c,\n\t\tlimit: maxHeaderBytes,\n\t\tr:     bufio.NewReader(c),\n\t}, nil\n}\n\ntype httpRedirectConn struct {\n\tnet.Conn\n\tonce  bool\n\tlimit int64\n\tr     *bufio.Reader\n}\n\n// Read tries to peek at the first few bytes of the request, and if we get\n// an error reading the headers, and that error was due to the bytes looking\n// like an HTTP request, then we perform a HTTP->HTTPS redirect on the same\n// port as the original connection.\nfunc (c *httpRedirectConn) Read(p []byte) (int, error) {\n\tif c.once {\n\t\treturn c.r.Read(p)\n\t}\n\t// no need to use sync.Once - net.Conn is not read from concurrently.\n\tc.once = true\n\n\tfirstBytes, err := c.r.Peek(5)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t// If the request doesn't look like HTTP, then it's probably\n\t// TLS bytes, and we don't need to do anything.\n\tif !firstBytesLookLikeHTTP(firstBytes) {\n\t\treturn c.r.Read(p)\n\t}\n\n\t// From now on, we can be almost certain the request is HTTP.\n\t// The returned error will be non nil and caller are expected to\n\t// close the connection.\n\n\t// Set the read limit, io.MultiReader is needed because\n\t// when resetting, *bufio.Reader discards buffered data.\n\tbuffered, _ := c.r.Peek(c.r.Buffered())\n\tmr := io.MultiReader(bytes.NewReader(buffered), c.Conn)\n\tc.r.Reset(io.LimitReader(mr, c.limit))\n\n\t// Parse the HTTP request, so we can get the Host and URL to redirect to.\n\treq, err := http.ReadRequest(c.r)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"couldn't read HTTP request\")\n\t}\n\n\t// Build the redirect response, using the same Host and URL,\n\t// but replacing the scheme with https.\n\theaders := make(http.Header)\n\theaders.Add(\"Location\", \"https://\"+req.Host+req.URL.String())\n\tresp := &http.Response{\n\t\tProto:      \"HTTP/1.0\",\n\t\tStatus:     \"308 Permanent Redirect\",\n\t\tStatusCode: 308,\n\t\tProtoMajor: 1,\n\t\tProtoMinor: 0,\n\t\tHeader:     headers,\n\t}\n\n\terr = resp.Write(c.Conn)\n\tif err != nil {\n\t\treturn 0, fmt.Errorf(\"couldn't write HTTP->HTTPS redirect\")\n\t}\n\n\treturn 0, fmt.Errorf(\"redirected HTTP request on HTTPS port\")\n}\n\n// firstBytesLookLikeHTTP reports whether a TLS record header\n// looks like it might've been a misdirected plaintext HTTP request.\nfunc firstBytesLookLikeHTTP(hdr []byte) bool {\n\tswitch string(hdr[:5]) {\n\tcase \"GET /\", \"HEAD \", \"POST \", \"PUT /\", \"OPTIO\":\n\t\treturn true\n\t}\n\treturn false\n}\n\nvar (\n\t_ caddy.ListenerWrapper = (*HTTPRedirectListenerWrapper)(nil)\n\t_ caddyfile.Unmarshaler = (*HTTPRedirectListenerWrapper)(nil)\n)\n",
    "source_file": "modules/caddyhttp/httpredirectlistener.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n)\n\n// ResponseWriterWrapper wraps an underlying ResponseWriter and\n// promotes its Pusher method as well. To use this type, embed\n// a pointer to it within your own struct type that implements\n// the http.ResponseWriter interface, then call methods on the\n// embedded value.\ntype ResponseWriterWrapper struct {\n\thttp.ResponseWriter\n}\n\n// Push implements http.Pusher. It simply calls the underlying\n// ResponseWriter's Push method if there is one, or returns\n// ErrNotImplemented otherwise.\nfunc (rww *ResponseWriterWrapper) Push(target string, opts *http.PushOptions) error {\n\tif pusher, ok := rww.ResponseWriter.(http.Pusher); ok {\n\t\treturn pusher.Push(target, opts)\n\t}\n\treturn ErrNotImplemented\n}\n\n// ReadFrom implements io.ReaderFrom. It retries to use io.ReaderFrom if available,\n// then fallback to io.Copy.\n// see: https://github.com/caddyserver/caddy/issues/6546\nfunc (rww *ResponseWriterWrapper) ReadFrom(r io.Reader) (n int64, err error) {\n\tif rf, ok := rww.ResponseWriter.(io.ReaderFrom); ok {\n\t\treturn rf.ReadFrom(r)\n\t}\n\treturn io.Copy(rww.ResponseWriter, r)\n}\n\n// Unwrap returns the underlying ResponseWriter, necessary for\n// http.ResponseController to work correctly.\nfunc (rww *ResponseWriterWrapper) Unwrap() http.ResponseWriter {\n\treturn rww.ResponseWriter\n}\n\n// ErrNotImplemented is returned when an underlying\n// ResponseWriter does not implement the required method.\nvar ErrNotImplemented = fmt.Errorf(\"method not implemented\")\n\ntype responseRecorder struct {\n\t*ResponseWriterWrapper\n\tstatusCode   int\n\tbuf          *bytes.Buffer\n\tshouldBuffer ShouldBufferFunc\n\tsize         int\n\twroteHeader  bool\n\tstream       bool\n\n\treadSize *int\n}\n\n// NewResponseRecorder returns a new ResponseRecorder that can be\n// used instead of a standard http.ResponseWriter. The recorder is\n// useful for middlewares which need to buffer a response and\n// potentially process its entire body before actually writing the\n// response to the underlying writer. Of course, buffering the entire\n// body has a memory overhead, but sometimes there is no way to avoid\n// buffering the whole response, hence the existence of this type.\n// Still, if at all practical, handlers should strive to stream\n// responses by wrapping Write and WriteHeader methods instead of\n// buffering whole response bodies.\n//\n// Buffering is actually optional. The shouldBuffer function will\n// be called just before the headers are written. If it returns\n// true, the headers and body will be buffered by this recorder\n// and not written to the underlying writer; if false, the headers\n// will be written immediately and the body will be streamed out\n// directly to the underlying writer. If shouldBuffer is nil,\n// the response will never be buffered and will always be streamed\n// directly to the writer.\n//\n// You can know if shouldBuffer returned true by calling Buffered().\n//\n// The provided buffer buf should be obtained from a pool for best\n// performance (see the sync.Pool type).\n//\n// Proper usage of a recorder looks like this:\n//\n//\trec := caddyhttp.NewResponseRecorder(w, buf, shouldBuffer)\n//\terr := next.ServeHTTP(rec, req)\n//\tif err != nil {\n//\t    return err\n//\t}\n//\tif !rec.Buffered() {\n//\t    return nil\n//\t}\n//\t// process the buffered response here\n//\n// The header map is not buffered; i.e. the ResponseRecorder's Header()\n// method returns the same header map of the underlying ResponseWriter.\n// This is a crucial design decision to allow HTTP trailers to be\n// flushed properly (https://github.com/caddyserver/caddy/issues/3236).\n//\n// Once you are ready to write the response, there are two ways you can\n// do it. The easier way is to have the recorder do it:\n//\n//\trec.WriteResponse()\n//\n// This writes the recorded response headers as well as the buffered body.\n// Or, you may wish to do it yourself, especially if you manipulated the\n// buffered body. First you will need to write the headers with the\n// recorded status code, then write the body (this example writes the\n// recorder's body buffer, but you might have your own body to write\n// instead):\n//\n//\tw.WriteHeader(rec.Status())\n//\tio.Copy(w, rec.Buffer())\n//\n// As a special case, 1xx responses are not buffered nor recorded\n// because they are not the final response; they are passed through\n// directly to the underlying ResponseWriter.\nfunc NewResponseRecorder(w http.ResponseWriter, buf *bytes.Buffer, shouldBuffer ShouldBufferFunc) ResponseRecorder {\n\treturn &responseRecorder{\n\t\tResponseWriterWrapper: &ResponseWriterWrapper{ResponseWriter: w},\n\t\tbuf:                   buf,\n\t\tshouldBuffer:          shouldBuffer,\n\t}\n}\n\n// WriteHeader writes the headers with statusCode to the wrapped\n// ResponseWriter unless the response is to be buffered instead.\n// 1xx responses are never buffered.\nfunc (rr *responseRecorder) WriteHeader(statusCode int) {\n\tif rr.wroteHeader {\n\t\treturn\n\t}\n\n\t// save statusCode always, in case HTTP middleware upgrades websocket\n\t// connections by manually setting headers and writing status 101\n\trr.statusCode = statusCode\n\n\t// decide whether we should buffer the response\n\tif rr.shouldBuffer == nil {\n\t\trr.stream = true\n\t} else {\n\t\trr.stream = !rr.shouldBuffer(rr.statusCode, rr.ResponseWriterWrapper.Header())\n\t}\n\n\t// 1xx responses aren't final; just informational\n\tif statusCode < 100 || statusCode > 199 {\n\t\trr.wroteHeader = true\n\t}\n\n\t// if informational or not buffered, immediately write header\n\tif rr.stream || (100 <= statusCode && statusCode <= 199) {\n\t\trr.ResponseWriterWrapper.WriteHeader(statusCode)\n\t}\n}\n\nfunc (rr *responseRecorder) Write(data []byte) (int, error) {\n\trr.WriteHeader(http.StatusOK)\n\tvar n int\n\tvar err error\n\tif rr.stream {\n\t\tn, err = rr.ResponseWriterWrapper.Write(data)\n\t} else {\n\t\tn, err = rr.buf.Write(data)\n\t}\n\n\trr.size += n\n\treturn n, err\n}\n\nfunc (rr *responseRecorder) ReadFrom(r io.Reader) (int64, error) {\n\trr.WriteHeader(http.StatusOK)\n\tvar n int64\n\tvar err error\n\tif rr.stream {\n\t\tn, err = rr.ResponseWriterWrapper.ReadFrom(r)\n\t} else {\n\t\tn, err = rr.buf.ReadFrom(r)\n\t}\n\n\trr.size += int(n)\n\treturn n, err\n}\n\n// Status returns the status code that was written, if any.\nfunc (rr *responseRecorder) Status() int {\n\treturn rr.statusCode\n}\n\n// Size returns the number of bytes written,\n// not including the response headers.\nfunc (rr *responseRecorder) Size() int {\n\treturn rr.size\n}\n\n// Buffer returns the body buffer that rr was created with.\n// You should still have your original pointer, though.\nfunc (rr *responseRecorder) Buffer() *bytes.Buffer {\n\treturn rr.buf\n}\n\n// Buffered returns whether rr has decided to buffer the response.\nfunc (rr *responseRecorder) Buffered() bool {\n\treturn !rr.stream\n}\n\nfunc (rr *responseRecorder) WriteResponse() error {\n\tif rr.statusCode == 0 {\n\t\t// could happen if no handlers actually wrote anything,\n\t\t// and this prevents a panic; status must be > 0\n\t\trr.WriteHeader(http.StatusOK)\n\t}\n\tif rr.stream {\n\t\treturn nil\n\t}\n\trr.ResponseWriterWrapper.WriteHeader(rr.statusCode)\n\t_, err := io.Copy(rr.ResponseWriterWrapper, rr.buf)\n\treturn err\n}\n\n// FlushError will suppress actual flushing if the response is buffered. See:\n// https://github.com/caddyserver/caddy/issues/6144\nfunc (rr *responseRecorder) FlushError() error {\n\tif rr.stream {\n\t\t//nolint:bodyclose\n\t\treturn http.NewResponseController(rr.ResponseWriterWrapper).Flush()\n\t}\n\treturn nil\n}\n\n// Private interface so it can only be used in this package\n// #TODO: maybe export it later\nfunc (rr *responseRecorder) setReadSize(size *int) {\n\trr.readSize = size\n}\n\nfunc (rr *responseRecorder) Hijack() (net.Conn, *bufio.ReadWriter, error) {\n\t//nolint:bodyclose\n\tconn, brw, err := http.NewResponseController(rr.ResponseWriterWrapper).Hijack()\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\t// Per http documentation, returned bufio.Writer is empty, but bufio.Read maybe not\n\tconn = &hijackedConn{conn, rr}\n\tbrw.Writer.Reset(conn)\n\n\tbuffered := brw.Reader.Buffered()\n\tif buffered != 0 {\n\t\tconn.(*hijackedConn).updateReadSize(buffered)\n\t\tdata, _ := brw.Peek(buffered)\n\t\tbrw.Reader.Reset(io.MultiReader(bytes.NewReader(data), conn))\n\t\t// peek to make buffered data appear, as Reset will make it 0\n\t\t_, _ = brw.Peek(buffered)\n\t} else {\n\t\tbrw.Reader.Reset(conn)\n\t}\n\treturn conn, brw, nil\n}\n\n// used to track the size of hijacked response writers\ntype hijackedConn struct {\n\tnet.Conn\n\trr *responseRecorder\n}\n\nfunc (hc *hijackedConn) updateReadSize(n int) {\n\tif hc.rr.readSize != nil {\n\t\t*hc.rr.readSize += n\n\t}\n}\n\nfunc (hc *hijackedConn) Read(p []byte) (int, error) {\n\tn, err := hc.Conn.Read(p)\n\thc.updateReadSize(n)\n\treturn n, err\n}\n\nfunc (hc *hijackedConn) WriteTo(w io.Writer) (int64, error) {\n\tn, err := io.Copy(w, hc.Conn)\n\thc.updateReadSize(int(n))\n\treturn n, err\n}\n\nfunc (hc *hijackedConn) Write(p []byte) (int, error) {\n\tn, err := hc.Conn.Write(p)\n\thc.rr.size += n\n\treturn n, err\n}\n\nfunc (hc *hijackedConn) ReadFrom(r io.Reader) (int64, error) {\n\tn, err := io.Copy(hc.Conn, r)\n\thc.rr.size += int(n)\n\treturn n, err\n}\n\n// ResponseRecorder is a http.ResponseWriter that records\n// responses instead of writing them to the client. See\n// docs for NewResponseRecorder for proper usage.\ntype ResponseRecorder interface {\n\thttp.ResponseWriter\n\tStatus() int\n\tBuffer() *bytes.Buffer\n\tBuffered() bool\n\tSize() int\n\tWriteResponse() error\n}\n\n// ShouldBufferFunc is a function that returns true if the\n// response should be buffered, given the pending HTTP status\n// code and response headers.\ntype ShouldBufferFunc func(status int, header http.Header) bool\n\n// Interface guards\nvar (\n\t_ http.ResponseWriter = (*ResponseWriterWrapper)(nil)\n\t_ ResponseRecorder    = (*responseRecorder)(nil)\n\n\t// Implementing ReaderFrom can be such a significant\n\t// optimization that it should probably be required!\n\t// see PR #5022 (25%-50% speedup)\n\t_ io.ReaderFrom = (*ResponseWriterWrapper)(nil)\n\t_ io.ReaderFrom = (*responseRecorder)(nil)\n\t_ io.ReaderFrom = (*hijackedConn)(nil)\n\n\t_ io.WriterTo = (*hijackedConn)(nil)\n)\n",
    "source_file": "modules/caddyhttp/responsewriter.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddyhttp\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\tweakrand \"math/rand\"\n\t\"net\"\n\t\"net/http\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"golang.org/x/net/http2\"\n)\n\n// http2Listener wraps the listener to solve the following problems:\n// 1. server h2 natively without using h2c hack when listener handles tls connection but\n// don't return *tls.Conn\n// 2. graceful shutdown. the shutdown logic is copied from stdlib http.Server, it's an extra maintenance burden but\n// whatever, the shutdown logic maybe extracted to be used with h2c graceful shutdown. http2.Server supports graceful shutdown\n// sending GO_AWAY frame to connected clients, but doesn't track connection status. It requires explicit call of http2.ConfigureServer\ntype http2Listener struct {\n\tcnt uint64\n\tnet.Listener\n\tserver   *http.Server\n\th2server *http2.Server\n}\n\ntype connectionStateConn interface {\n\tnet.Conn\n\tConnectionState() tls.ConnectionState\n}\n\nfunc (h *http2Listener) Accept() (net.Conn, error) {\n\tfor {\n\t\tconn, err := h.Listener.Accept()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tif csc, ok := conn.(connectionStateConn); ok {\n\t\t\t// *tls.Conn will return empty string because it's only populated after handshake is complete\n\t\t\tif csc.ConnectionState().NegotiatedProtocol == http2.NextProtoTLS {\n\t\t\t\tgo h.serveHttp2(csc)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\treturn conn, nil\n\t}\n}\n\nfunc (h *http2Listener) serveHttp2(csc connectionStateConn) {\n\tatomic.AddUint64(&h.cnt, 1)\n\th.runHook(csc, http.StateNew)\n\tdefer func() {\n\t\tcsc.Close()\n\t\tatomic.AddUint64(&h.cnt, ^uint64(0))\n\t\th.runHook(csc, http.StateClosed)\n\t}()\n\th.h2server.ServeConn(csc, &http2.ServeConnOpts{\n\t\tContext:    h.server.ConnContext(context.Background(), csc),\n\t\tBaseConfig: h.server,\n\t\tHandler:    h.server.Handler,\n\t})\n}\n\nconst shutdownPollIntervalMax = 500 * time.Millisecond\n\nfunc (h *http2Listener) Shutdown(ctx context.Context) error {\n\tpollIntervalBase := time.Millisecond\n\tnextPollInterval := func() time.Duration {\n\t\t// Add 10% jitter.\n\t\t//nolint:gosec\n\t\tinterval := pollIntervalBase + time.Duration(weakrand.Intn(int(pollIntervalBase/10)))\n\t\t// Double and clamp for next time.\n\t\tpollIntervalBase *= 2\n\t\tif pollIntervalBase > shutdownPollIntervalMax {\n\t\t\tpollIntervalBase = shutdownPollIntervalMax\n\t\t}\n\t\treturn interval\n\t}\n\n\ttimer := time.NewTimer(nextPollInterval())\n\tdefer timer.Stop()\n\tfor {\n\t\tif atomic.LoadUint64(&h.cnt) == 0 {\n\t\t\treturn nil\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-timer.C:\n\t\t\ttimer.Reset(nextPollInterval())\n\t\t}\n\t}\n}\n\nfunc (h *http2Listener) runHook(conn net.Conn, state http.ConnState) {\n\tif h.server.ConnState != nil {\n\t\th.server.ConnState(conn, state)\n\t}\n}\n",
    "source_file": "modules/caddyhttp/http2listener.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// Route consists of a set of rules for matching HTTP requests,\n// a list of handlers to execute, and optional flow control\n// parameters which customize the handling of HTTP requests\n// in a highly flexible and performant manner.\ntype Route struct {\n\t// Group is an optional name for a group to which this\n\t// route belongs. Grouping a route makes it mutually\n\t// exclusive with others in its group; if a route belongs\n\t// to a group, only the first matching route in that group\n\t// will be executed.\n\tGroup string `json:\"group,omitempty\"`\n\n\t// The matcher sets which will be used to qualify this\n\t// route for a request (essentially the \"if\" statement\n\t// of this route). Each matcher set is OR'ed, but matchers\n\t// within a set are AND'ed together.\n\tMatcherSetsRaw RawMatcherSets `json:\"match,omitempty\" caddy:\"namespace=http.matchers\"`\n\n\t// The list of handlers for this route. Upon matching a request, they are chained\n\t// together in a middleware fashion: requests flow from the first handler to the last\n\t// (top of the list to the bottom), with the possibility that any handler could stop\n\t// the chain and/or return an error. Responses flow back through the chain (bottom of\n\t// the list to the top) as they are written out to the client.\n\t//\n\t// Not all handlers call the next handler in the chain. For example, the reverse_proxy\n\t// handler always sends a request upstream or returns an error. Thus, configuring\n\t// handlers after reverse_proxy in the same route is illogical, since they would never\n\t// be executed. You will want to put handlers which originate the response at the very\n\t// end of your route(s). The documentation for a module should state whether it invokes\n\t// the next handler, but sometimes it is common sense.\n\t//\n\t// Some handlers manipulate the response. Remember that requests flow down the list, and\n\t// responses flow up the list.\n\t//\n\t// For example, if you wanted to use both `templates` and `encode` handlers, you would\n\t// need to put `templates` after `encode` in your route, because responses flow up.\n\t// Thus, `templates` will be able to parse and execute the plain-text response as a\n\t// template, and then return it up to the `encode` handler which will then compress it\n\t// into a binary format.\n\t//\n\t// If `templates` came before `encode`, then `encode` would write a compressed,\n\t// binary-encoded response to `templates` which would not be able to parse the response\n\t// properly.\n\t//\n\t// The correct order, then, is this:\n\t//\n\t//     [\n\t//         {\"handler\": \"encode\"},\n\t//         {\"handler\": \"templates\"},\n\t//         {\"handler\": \"file_server\"}\n\t//     ]\n\t//\n\t// The request flows \u2b07\ufe0f DOWN (`encode` -> `templates` -> `file_server`).\n\t//\n\t// 1. First, `encode` will choose how to `encode` the response and wrap the response.\n\t// 2. Then, `templates` will wrap the response with a buffer.\n\t// 3. Finally, `file_server` will originate the content from a file.\n\t//\n\t// The response flows \u2b06\ufe0f UP (`file_server` -> `templates` -> `encode`):\n\t//\n\t// 1. First, `file_server` will write the file to the response.\n\t// 2. That write will be buffered and then executed by `templates`.\n\t// 3. Lastly, the write from `templates` will flow into `encode` which will compress the stream.\n\t//\n\t// If you think of routes in this way, it will be easy and even fun to solve the puzzle of writing correct routes.\n\tHandlersRaw []json.RawMessage `json:\"handle,omitempty\" caddy:\"namespace=http.handlers inline_key=handler\"`\n\n\t// If true, no more routes will be executed after this one.\n\tTerminal bool `json:\"terminal,omitempty\"`\n\n\t// decoded values\n\tMatcherSets MatcherSets         `json:\"-\"`\n\tHandlers    []MiddlewareHandler `json:\"-\"`\n\n\tmiddleware []Middleware\n}\n\n// Empty returns true if the route has all zero/default values.\nfunc (r Route) Empty() bool {\n\treturn len(r.MatcherSetsRaw) == 0 &&\n\t\tlen(r.MatcherSets) == 0 &&\n\t\tlen(r.HandlersRaw) == 0 &&\n\t\tlen(r.Handlers) == 0 &&\n\t\t!r.Terminal &&\n\t\tr.Group == \"\"\n}\n\nfunc (r Route) String() string {\n\thandlersRaw := \"[\"\n\tfor _, hr := range r.HandlersRaw {\n\t\thandlersRaw += \" \" + string(hr)\n\t}\n\thandlersRaw += \"]\"\n\n\treturn fmt.Sprintf(`{Group:\"%s\" MatcherSetsRaw:%s HandlersRaw:%s Terminal:%t}`,\n\t\tr.Group, r.MatcherSetsRaw, handlersRaw, r.Terminal)\n}\n\n// Provision sets up both the matchers and handlers in the route.\nfunc (r *Route) Provision(ctx caddy.Context, metrics *Metrics) error {\n\terr := r.ProvisionMatchers(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn r.ProvisionHandlers(ctx, metrics)\n}\n\n// ProvisionMatchers sets up all the matchers by loading the\n// matcher modules. Only call this method directly if you need\n// to set up matchers and handlers separately without having\n// to provision a second time; otherwise use Provision instead.\nfunc (r *Route) ProvisionMatchers(ctx caddy.Context) error {\n\t// matchers\n\tmatchersIface, err := ctx.LoadModule(r, \"MatcherSetsRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading matcher modules: %v\", err)\n\t}\n\terr = r.MatcherSets.FromInterface(matchersIface)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// ProvisionHandlers sets up all the handlers by loading the\n// handler modules. Only call this method directly if you need\n// to set up matchers and handlers separately without having\n// to provision a second time; otherwise use Provision instead.\nfunc (r *Route) ProvisionHandlers(ctx caddy.Context, metrics *Metrics) error {\n\thandlersIface, err := ctx.LoadModule(r, \"HandlersRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading handler modules: %v\", err)\n\t}\n\tfor _, handler := range handlersIface.([]any) {\n\t\tr.Handlers = append(r.Handlers, handler.(MiddlewareHandler))\n\t}\n\n\t// Make ProvisionHandlers idempotent by clearing the middleware field\n\tr.middleware = []Middleware{}\n\n\t// pre-compile the middleware handler chain\n\tfor _, midhandler := range r.Handlers {\n\t\tr.middleware = append(r.middleware, wrapMiddleware(ctx, midhandler, metrics))\n\t}\n\treturn nil\n}\n\n// Compile prepares a middleware chain from the route list.\n// This should only be done once during the request, just\n// before the middleware chain is executed.\nfunc (r Route) Compile(next Handler) Handler {\n\treturn wrapRoute(r)(next)\n}\n\n// RouteList is a list of server routes that can\n// create a middleware chain.\ntype RouteList []Route\n\n// Provision sets up both the matchers and handlers in the routes.\nfunc (routes RouteList) Provision(ctx caddy.Context) error {\n\terr := routes.ProvisionMatchers(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\treturn routes.ProvisionHandlers(ctx, nil)\n}\n\n// ProvisionMatchers sets up all the matchers by loading the\n// matcher modules. Only call this method directly if you need\n// to set up matchers and handlers separately without having\n// to provision a second time; otherwise use Provision instead.\nfunc (routes RouteList) ProvisionMatchers(ctx caddy.Context) error {\n\tfor i := range routes {\n\t\terr := routes[i].ProvisionMatchers(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"route %d: %v\", i, err)\n\t\t}\n\t}\n\treturn nil\n}\n\n// ProvisionHandlers sets up all the handlers by loading the\n// handler modules. Only call this method directly if you need\n// to set up matchers and handlers separately without having\n// to provision a second time; otherwise use Provision instead.\nfunc (routes RouteList) ProvisionHandlers(ctx caddy.Context, metrics *Metrics) error {\n\tfor i := range routes {\n\t\terr := routes[i].ProvisionHandlers(ctx, metrics)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"route %d: %v\", i, err)\n\t\t}\n\t}\n\treturn nil\n}\n\n// Compile prepares a middleware chain from the route list.\n// This should only be done either once during provisioning\n// for top-level routes, or on each request just before the\n// middleware chain is executed for subroutes.\nfunc (routes RouteList) Compile(next Handler) Handler {\n\tmid := make([]Middleware, 0, len(routes))\n\tfor _, route := range routes {\n\t\tmid = append(mid, wrapRoute(route))\n\t}\n\tstack := next\n\tfor i := len(mid) - 1; i >= 0; i-- {\n\t\tstack = mid[i](stack)\n\t}\n\treturn stack\n}\n\n// wrapRoute wraps route with a middleware and handler so that it can\n// be chained in and defer evaluation of its matchers to request-time.\n// Like wrapMiddleware, it is vital that this wrapping takes place in\n// its own stack frame so as to not overwrite the reference to the\n// intended route by looping and changing the reference each time.\nfunc wrapRoute(route Route) Middleware {\n\treturn func(next Handler) Handler {\n\t\treturn HandlerFunc(func(rw http.ResponseWriter, req *http.Request) error {\n\t\t\t// TODO: Update this comment, it seems we've moved the copy into the handler?\n\t\t\t// copy the next handler (it's an interface, so it's just\n\t\t\t// a very lightweight copy of a pointer); this is important\n\t\t\t// because this is a closure to the func below, which\n\t\t\t// re-assigns the value as it compiles the middleware stack;\n\t\t\t// if we don't make this copy, we'd affect the underlying\n\t\t\t// pointer for all future request (yikes); we could\n\t\t\t// alternatively solve this by moving the func below out of\n\t\t\t// this closure and into a standalone package-level func,\n\t\t\t// but I just thought this made more sense\n\t\t\tnextCopy := next\n\n\t\t\t// route must match at least one of the matcher sets\n\t\t\tmatches, err := route.MatcherSets.AnyMatchWithError(req)\n\t\t\tif err != nil {\n\t\t\t\t// allow matchers the opportunity to short circuit\n\t\t\t\t// the request and trigger the error handling chain\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tif !matches {\n\t\t\t\t// call the next handler, and skip this one,\n\t\t\t\t// since the matcher didn't match\n\t\t\t\treturn nextCopy.ServeHTTP(rw, req)\n\t\t\t}\n\n\t\t\t// if route is part of a group, ensure only the\n\t\t\t// first matching route in the group is applied\n\t\t\tif route.Group != \"\" {\n\t\t\t\tgroups := req.Context().Value(routeGroupCtxKey).(map[string]struct{})\n\n\t\t\t\tif _, ok := groups[route.Group]; ok {\n\t\t\t\t\t// this group has already been\n\t\t\t\t\t// satisfied by a matching route\n\t\t\t\t\treturn nextCopy.ServeHTTP(rw, req)\n\t\t\t\t}\n\n\t\t\t\t// this matching route satisfies the group\n\t\t\t\tgroups[route.Group] = struct{}{}\n\t\t\t}\n\n\t\t\t// make terminal routes terminate\n\t\t\tif route.Terminal {\n\t\t\t\tif _, ok := req.Context().Value(ErrorCtxKey).(error); ok {\n\t\t\t\t\tnextCopy = errorEmptyHandler\n\t\t\t\t} else {\n\t\t\t\t\tnextCopy = emptyHandler\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// compile this route's handler stack\n\t\t\tfor i := len(route.middleware) - 1; i >= 0; i-- {\n\t\t\t\tnextCopy = route.middleware[i](nextCopy)\n\t\t\t}\n\n\t\t\treturn nextCopy.ServeHTTP(rw, req)\n\t\t})\n\t}\n}\n\n// wrapMiddleware wraps mh such that it can be correctly\n// appended to a list of middleware in preparation for\n// compiling into a handler chain. We can't do this inline\n// inside a loop, because it relies on a reference to mh\n// not changing until the execution of its handler (which\n// is deferred by multiple func closures). In other words,\n// we need to pull this particular MiddlewareHandler\n// pointer into its own stack frame to preserve it so it\n// won't be overwritten in future loop iterations.\nfunc wrapMiddleware(ctx caddy.Context, mh MiddlewareHandler, metrics *Metrics) Middleware {\n\thandlerToUse := mh\n\tif metrics != nil {\n\t\t// wrap the middleware with metrics instrumentation\n\t\thandlerToUse = newMetricsInstrumentedHandler(ctx, caddy.GetModuleName(mh), mh, metrics)\n\t}\n\n\treturn func(next Handler) Handler {\n\t\t// copy the next handler (it's an interface, so it's\n\t\t// just a very lightweight copy of a pointer); this\n\t\t// is a safeguard against the handler changing the\n\t\t// value, which could affect future requests (yikes)\n\t\tnextCopy := next\n\n\t\treturn HandlerFunc(func(w http.ResponseWriter, r *http.Request) error {\n\t\t\t// EXPERIMENTAL: Trace each module that gets invoked\n\t\t\tif server, ok := r.Context().Value(ServerCtxKey).(*Server); ok && server != nil {\n\t\t\t\tserver.logTrace(handlerToUse)\n\t\t\t}\n\t\t\treturn handlerToUse.ServeHTTP(w, r, nextCopy)\n\t\t})\n\t}\n}\n\n// MatcherSet is a set of matchers which\n// must all match in order for the request\n// to be matched successfully.\ntype MatcherSet []any\n\n// Match returns true if the request matches all\n// matchers in mset or if there are no matchers.\nfunc (mset MatcherSet) Match(r *http.Request) bool {\n\tfor _, m := range mset {\n\t\tif me, ok := m.(RequestMatcherWithError); ok {\n\t\t\tmatch, _ := me.MatchWithError(r)\n\t\t\tif !match {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif me, ok := m.(RequestMatcher); ok {\n\t\t\tif !me.Match(r) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn false\n\t}\n\treturn true\n}\n\n// MatchWithError returns true if r matches m.\nfunc (mset MatcherSet) MatchWithError(r *http.Request) (bool, error) {\n\tfor _, m := range mset {\n\t\tif me, ok := m.(RequestMatcherWithError); ok {\n\t\t\tmatch, err := me.MatchWithError(r)\n\t\t\tif err != nil || !match {\n\t\t\t\treturn match, err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif me, ok := m.(RequestMatcher); ok {\n\t\t\tif !me.Match(r) {\n\t\t\t\t// for backwards compatibility\n\t\t\t\terr, ok := GetVar(r.Context(), MatcherErrorVarKey).(error)\n\t\t\t\tif ok {\n\t\t\t\t\t// clear out the error from context since we've consumed it\n\t\t\t\t\tSetVar(r.Context(), MatcherErrorVarKey, nil)\n\t\t\t\t\treturn false, err\n\t\t\t\t}\n\t\t\t\treturn false, nil\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\treturn false, fmt.Errorf(\"matcher is not a RequestMatcher or RequestMatcherWithError: %#v\", m)\n\t}\n\treturn true, nil\n}\n\n// RawMatcherSets is a group of matcher sets\n// in their raw, JSON form.\ntype RawMatcherSets []caddy.ModuleMap\n\n// MatcherSets is a group of matcher sets capable\n// of checking whether a request matches any of\n// the sets.\ntype MatcherSets []MatcherSet\n\n// AnyMatch returns true if req matches any of the\n// matcher sets in ms or if there are no matchers,\n// in which case the request always matches.\n//\n// Deprecated: Use AnyMatchWithError instead.\nfunc (ms MatcherSets) AnyMatch(req *http.Request) bool {\n\tfor _, m := range ms {\n\t\tmatch, err := m.MatchWithError(req)\n\t\tif err != nil {\n\t\t\tSetVar(req.Context(), MatcherErrorVarKey, err)\n\t\t\treturn false\n\t\t}\n\t\tif match {\n\t\t\treturn match\n\t\t}\n\t}\n\treturn len(ms) == 0\n}\n\n// AnyMatchWithError returns true if req matches any of the\n// matcher sets in ms or if there are no matchers, in which\n// case the request always matches. If any matcher returns\n// an error, we cut short and return the error.\nfunc (ms MatcherSets) AnyMatchWithError(req *http.Request) (bool, error) {\n\tfor _, m := range ms {\n\t\tmatch, err := m.MatchWithError(req)\n\t\tif err != nil || match {\n\t\t\treturn match, err\n\t\t}\n\t}\n\treturn len(ms) == 0, nil\n}\n\n// FromInterface fills ms from an 'any' value obtained from LoadModule.\nfunc (ms *MatcherSets) FromInterface(matcherSets any) error {\n\tfor _, matcherSetIfaces := range matcherSets.([]map[string]any) {\n\t\tvar matcherSet MatcherSet\n\t\tfor _, matcher := range matcherSetIfaces {\n\t\t\tif m, ok := matcher.(RequestMatcherWithError); ok {\n\t\t\t\tmatcherSet = append(matcherSet, m)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif m, ok := matcher.(RequestMatcher); ok {\n\t\t\t\tmatcherSet = append(matcherSet, m)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"decoded module is not a RequestMatcher or RequestMatcherWithError: %#v\", matcher)\n\t\t}\n\t\t*ms = append(*ms, matcherSet)\n\t}\n\treturn nil\n}\n\n// TODO: Is this used?\nfunc (ms MatcherSets) String() string {\n\tresult := \"[\"\n\tfor _, matcherSet := range ms {\n\t\tfor _, matcher := range matcherSet {\n\t\t\tresult += fmt.Sprintf(\" %#v\", matcher)\n\t\t}\n\t}\n\treturn result + \" ]\"\n}\n\nvar routeGroupCtxKey = caddy.CtxKey(\"route_group\")\n",
    "source_file": "modules/caddyhttp/routes.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(tlsPlaceholderWrapper{})\n}\n\n// RequestMatcher is a type that can match to a request.\n// A route matcher MUST NOT modify the request, with the\n// only exception being its context.\n//\n// Deprecated: Matchers should now implement RequestMatcherWithError.\n// You may remove any interface guards for RequestMatcher\n// but keep your Match() methods for backwards compatibility.\ntype RequestMatcher interface {\n\tMatch(*http.Request) bool\n}\n\n// RequestMatcherWithError is like RequestMatcher but can return an error.\n// An error during matching will abort the request middleware chain and\n// invoke the error middleware chain.\n//\n// This will eventually replace RequestMatcher. Matcher modules\n// should implement both interfaces, and once all modules have\n// been updated to use RequestMatcherWithError, the RequestMatcher\n// interface may eventually be dropped.\ntype RequestMatcherWithError interface {\n\tMatchWithError(*http.Request) (bool, error)\n}\n\n// Handler is like http.Handler except ServeHTTP may return an error.\n//\n// If any handler encounters an error, it should be returned for proper\n// handling. Return values should be propagated down the middleware chain\n// by returning it unchanged. Returned errors should not be re-wrapped\n// if they are already HandlerError values.\ntype Handler interface {\n\tServeHTTP(http.ResponseWriter, *http.Request) error\n}\n\n// HandlerFunc is a convenience type like http.HandlerFunc.\ntype HandlerFunc func(http.ResponseWriter, *http.Request) error\n\n// ServeHTTP implements the Handler interface.\nfunc (f HandlerFunc) ServeHTTP(w http.ResponseWriter, r *http.Request) error {\n\treturn f(w, r)\n}\n\n// Middleware chains one Handler to the next by being passed\n// the next Handler in the chain.\ntype Middleware func(Handler) Handler\n\n// MiddlewareHandler is like Handler except it takes as a third\n// argument the next handler in the chain. The next handler will\n// never be nil, but may be a no-op handler if this is the last\n// handler in the chain. Handlers which act as middleware should\n// call the next handler's ServeHTTP method so as to propagate\n// the request down the chain properly. Handlers which act as\n// responders (content origins) need not invoke the next handler,\n// since the last handler in the chain should be the first to\n// write the response.\ntype MiddlewareHandler interface {\n\tServeHTTP(http.ResponseWriter, *http.Request, Handler) error\n}\n\n// emptyHandler is used as a no-op handler.\nvar emptyHandler Handler = HandlerFunc(func(_ http.ResponseWriter, req *http.Request) error {\n\tSetVar(req.Context(), \"unhandled\", true)\n\treturn nil\n})\n\n// An implicit suffix middleware that, if reached, sets the StatusCode to the\n// error stored in the ErrorCtxKey. This is to prevent situations where the\n// Error chain does not actually handle the error (for instance, it matches only\n// on some errors). See #3053\nvar errorEmptyHandler Handler = HandlerFunc(func(w http.ResponseWriter, r *http.Request) error {\n\thttpError := r.Context().Value(ErrorCtxKey)\n\tif handlerError, ok := httpError.(HandlerError); ok {\n\t\tw.WriteHeader(handlerError.StatusCode)\n\t} else {\n\t\tw.WriteHeader(http.StatusInternalServerError)\n\t}\n\treturn nil\n})\n\n// ResponseHandler pairs a response matcher with custom handling\n// logic. Either the status code can be changed to something else\n// while using the original response body, or, if a status code\n// is not set, it can execute a custom route list; this is useful\n// for executing handler routes based on the properties of an HTTP\n// response that has not been written out to the client yet.\n//\n// To use this type, provision it at module load time, then when\n// ready to use, match the response against its matcher; if it\n// matches (or doesn't have a matcher), change the status code on\n// the response if configured; otherwise invoke the routes by\n// calling `rh.Routes.Compile(next).ServeHTTP(rw, req)` (or similar).\ntype ResponseHandler struct {\n\t// The response matcher for this handler. If empty/nil,\n\t// it always matches.\n\tMatch *ResponseMatcher `json:\"match,omitempty\"`\n\n\t// To write the original response body but with a different\n\t// status code, set this field to the desired status code.\n\t// If set, this takes priority over routes.\n\tStatusCode WeakString `json:\"status_code,omitempty\"`\n\n\t// The list of HTTP routes to execute if no status code is\n\t// specified. If evaluated, the original response body\n\t// will not be written.\n\tRoutes RouteList `json:\"routes,omitempty\"`\n}\n\n// Provision sets up the routes in rh.\nfunc (rh *ResponseHandler) Provision(ctx caddy.Context) error {\n\tif rh.Routes != nil {\n\t\terr := rh.Routes.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// WeakString is a type that unmarshals any JSON value\n// as a string literal, with the following exceptions:\n//\n// 1. actual string values are decoded as strings; and\n// 2. null is decoded as empty string;\n//\n// and provides methods for getting the value as various\n// primitive types. However, using this type removes any\n// type safety as far as deserializing JSON is concerned.\ntype WeakString string\n\n// UnmarshalJSON satisfies json.Unmarshaler according to\n// this type's documentation.\nfunc (ws *WeakString) UnmarshalJSON(b []byte) error {\n\tif len(b) == 0 {\n\t\treturn io.EOF\n\t}\n\tif b[0] == byte('\"') && b[len(b)-1] == byte('\"') {\n\t\tvar s string\n\t\terr := json.Unmarshal(b, &s)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t*ws = WeakString(s)\n\t\treturn nil\n\t}\n\tif bytes.Equal(b, []byte(\"null\")) {\n\t\treturn nil\n\t}\n\t*ws = WeakString(b)\n\treturn nil\n}\n\n// MarshalJSON marshals was a boolean if true or false,\n// a number if an integer, or a string otherwise.\nfunc (ws WeakString) MarshalJSON() ([]byte, error) {\n\tif ws == \"true\" {\n\t\treturn []byte(\"true\"), nil\n\t}\n\tif ws == \"false\" {\n\t\treturn []byte(\"false\"), nil\n\t}\n\tif num, err := strconv.Atoi(string(ws)); err == nil {\n\t\treturn json.Marshal(num)\n\t}\n\treturn json.Marshal(string(ws))\n}\n\n// Int returns ws as an integer. If ws is not an\n// integer, 0 is returned.\nfunc (ws WeakString) Int() int {\n\tnum, _ := strconv.Atoi(string(ws))\n\treturn num\n}\n\n// Float64 returns ws as a float64. If ws is not a\n// float value, the zero value is returned.\nfunc (ws WeakString) Float64() float64 {\n\tnum, _ := strconv.ParseFloat(string(ws), 64)\n\treturn num\n}\n\n// Bool returns ws as a boolean. If ws is not a\n// boolean, false is returned.\nfunc (ws WeakString) Bool() bool {\n\treturn string(ws) == \"true\"\n}\n\n// String returns ws as a string.\nfunc (ws WeakString) String() string {\n\treturn string(ws)\n}\n\n// StatusCodeMatches returns true if a real HTTP status code matches\n// the configured status code, which may be either a real HTTP status\n// code or an integer representing a class of codes (e.g. 4 for all\n// 4xx statuses).\nfunc StatusCodeMatches(actual, configured int) bool {\n\tif actual == configured {\n\t\treturn true\n\t}\n\tif configured < 100 &&\n\t\tactual >= configured*100 &&\n\t\tactual < (configured+1)*100 {\n\t\treturn true\n\t}\n\treturn false\n}\n\n// SanitizedPathJoin performs filepath.Join(root, reqPath) that\n// is safe against directory traversal attacks. It uses logic\n// similar to that in the Go standard library, specifically\n// in the implementation of http.Dir. The root is assumed to\n// be a trusted path, but reqPath is not; and the output will\n// never be outside of root. The resulting path can be used\n// with the local file system. If root is empty, the current\n// directory is assumed. If the cleaned request path is deemed\n// not local according to lexical processing (i.e. ignoring links),\n// it will be rejected as unsafe and only the root will be returned.\nfunc SanitizedPathJoin(root, reqPath string) string {\n\tif root == \"\" {\n\t\troot = \".\"\n\t}\n\n\trelPath := path.Clean(\"/\" + reqPath)[1:] // clean path and trim the leading /\n\tif relPath != \"\" && !filepath.IsLocal(relPath) {\n\t\t// path is unsafe (see https://github.com/golang/go/issues/56336#issuecomment-1416214885)\n\t\treturn root\n\t}\n\n\tpath := filepath.Join(root, filepath.FromSlash(relPath))\n\n\t// filepath.Join also cleans the path, and cleaning strips\n\t// the trailing slash, so we need to re-add it afterwards.\n\t// if the length is 1, then it's a path to the root,\n\t// and that should return \".\", so we don't append the separator.\n\tif strings.HasSuffix(reqPath, \"/\") && len(reqPath) > 1 {\n\t\tpath += separator\n\t}\n\n\treturn path\n}\n\n// CleanPath cleans path p according to path.Clean(), but only\n// merges repeated slashes if collapseSlashes is true, and always\n// preserves trailing slashes.\nfunc CleanPath(p string, collapseSlashes bool) string {\n\tif collapseSlashes {\n\t\treturn cleanPath(p)\n\t}\n\n\t// insert an invalid/impossible URI character into each two consecutive\n\t// slashes to expand empty path segments; then clean the path as usual,\n\t// and then remove the remaining temporary characters.\n\tconst tmpCh = 0xff\n\tvar sb strings.Builder\n\tfor i, ch := range p {\n\t\tif ch == '/' && i > 0 && p[i-1] == '/' {\n\t\t\tsb.WriteByte(tmpCh)\n\t\t}\n\t\tsb.WriteRune(ch)\n\t}\n\thalfCleaned := cleanPath(sb.String())\n\thalfCleaned = strings.ReplaceAll(halfCleaned, string([]byte{tmpCh}), \"\")\n\n\treturn halfCleaned\n}\n\n// cleanPath does path.Clean(p) but preserves any trailing slash.\nfunc cleanPath(p string) string {\n\tcleaned := path.Clean(p)\n\tif cleaned != \"/\" && strings.HasSuffix(p, \"/\") {\n\t\tcleaned = cleaned + \"/\"\n\t}\n\treturn cleaned\n}\n\n// tlsPlaceholderWrapper is a no-op listener wrapper that marks\n// where the TLS listener should be in a chain of listener wrappers.\n// It should only be used if another listener wrapper must be placed\n// in front of the TLS handshake.\ntype tlsPlaceholderWrapper struct{}\n\nfunc (tlsPlaceholderWrapper) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"caddy.listeners.tls\",\n\t\tNew: func() caddy.Module { return new(tlsPlaceholderWrapper) },\n\t}\n}\n\nfunc (tlsPlaceholderWrapper) WrapListener(ln net.Listener) net.Listener { return ln }\n\nfunc (tlsPlaceholderWrapper) UnmarshalCaddyfile(d *caddyfile.Dispenser) error { return nil }\n\nconst (\n\t// DefaultHTTPPort is the default port for HTTP.\n\tDefaultHTTPPort = 80\n\n\t// DefaultHTTPSPort is the default port for HTTPS.\n\tDefaultHTTPSPort = 443\n)\n\nconst separator = string(filepath.Separator)\n\n// Interface guard\nvar (\n\t_ caddy.ListenerWrapper = (*tlsPlaceholderWrapper)(nil)\n\t_ caddyfile.Unmarshaler = (*tlsPlaceholderWrapper)(nil)\n)\n",
    "source_file": "modules/caddyhttp/caddyhttp.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/ecdsa\"\n\t\"crypto/ed25519\"\n\t\"crypto/rsa\"\n\t\"crypto/sha256\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/asn1\"\n\t\"encoding/base64\"\n\t\"encoding/pem\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/netip\"\n\t\"net/textproto\"\n\t\"net/url\"\n\t\"path\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/google/uuid\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\n// NewTestReplacer creates a replacer for an http.Request\n// for use in tests that are not in this package\nfunc NewTestReplacer(req *http.Request) *caddy.Replacer {\n\trepl := caddy.NewReplacer()\n\tctx := context.WithValue(req.Context(), caddy.ReplacerCtxKey, repl)\n\t*req = *req.WithContext(ctx)\n\taddHTTPVarsToReplacer(repl, req, nil)\n\treturn repl\n}\n\nfunc addHTTPVarsToReplacer(repl *caddy.Replacer, req *http.Request, w http.ResponseWriter) {\n\tSetVar(req.Context(), \"start_time\", time.Now())\n\tSetVar(req.Context(), \"uuid\", new(requestID))\n\n\thttpVars := func(key string) (any, bool) {\n\t\tif req != nil {\n\t\t\t// query string parameters\n\t\t\tif strings.HasPrefix(key, reqURIQueryReplPrefix) {\n\t\t\t\tvals := req.URL.Query()[key[len(reqURIQueryReplPrefix):]]\n\t\t\t\t// always return true, since the query param might\n\t\t\t\t// be present only in some requests\n\t\t\t\treturn strings.Join(vals, \",\"), true\n\t\t\t}\n\n\t\t\t// request header fields\n\t\t\tif strings.HasPrefix(key, reqHeaderReplPrefix) {\n\t\t\t\tfield := key[len(reqHeaderReplPrefix):]\n\t\t\t\tvals := req.Header[textproto.CanonicalMIMEHeaderKey(field)]\n\t\t\t\t// always return true, since the header field might\n\t\t\t\t// be present only in some requests\n\t\t\t\treturn strings.Join(vals, \",\"), true\n\t\t\t}\n\n\t\t\t// cookies\n\t\t\tif strings.HasPrefix(key, reqCookieReplPrefix) {\n\t\t\t\tname := key[len(reqCookieReplPrefix):]\n\t\t\t\tfor _, cookie := range req.Cookies() {\n\t\t\t\t\tif strings.EqualFold(name, cookie.Name) {\n\t\t\t\t\t\t// always return true, since the cookie might\n\t\t\t\t\t\t// be present only in some requests\n\t\t\t\t\t\treturn cookie.Value, true\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// http.request.tls.*\n\t\t\tif strings.HasPrefix(key, reqTLSReplPrefix) {\n\t\t\t\treturn getReqTLSReplacement(req, key)\n\t\t\t}\n\n\t\t\tswitch key {\n\t\t\tcase \"http.request.method\":\n\t\t\t\treturn req.Method, true\n\t\t\tcase \"http.request.scheme\":\n\t\t\t\tif req.TLS != nil {\n\t\t\t\t\treturn \"https\", true\n\t\t\t\t}\n\t\t\t\treturn \"http\", true\n\t\t\tcase \"http.request.proto\":\n\t\t\t\treturn req.Proto, true\n\t\t\tcase \"http.request.host\":\n\t\t\t\thost, _, err := net.SplitHostPort(req.Host)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn req.Host, true // OK; there probably was no port\n\t\t\t\t}\n\t\t\t\treturn host, true\n\t\t\tcase \"http.request.port\":\n\t\t\t\t_, port, _ := net.SplitHostPort(req.Host)\n\t\t\t\tif portNum, err := strconv.Atoi(port); err == nil {\n\t\t\t\t\treturn portNum, true\n\t\t\t\t}\n\t\t\t\treturn port, true\n\t\t\tcase \"http.request.hostport\":\n\t\t\t\treturn req.Host, true\n\t\t\tcase \"http.request.local\":\n\t\t\t\tlocalAddr, _ := req.Context().Value(http.LocalAddrContextKey).(net.Addr)\n\t\t\t\treturn localAddr.String(), true\n\t\t\tcase \"http.request.local.host\":\n\t\t\t\tlocalAddr, _ := req.Context().Value(http.LocalAddrContextKey).(net.Addr)\n\t\t\t\thost, _, err := net.SplitHostPort(localAddr.String())\n\t\t\t\tif err != nil {\n\t\t\t\t\t// localAddr is host:port for tcp and udp sockets and /unix/socket.path\n\t\t\t\t\t// for unix sockets. net.SplitHostPort only operates on tcp and udp sockets,\n\t\t\t\t\t// not unix sockets and will fail with the latter.\n\t\t\t\t\t// We assume when net.SplitHostPort fails, localAddr is a unix socket and thus\n\t\t\t\t\t// already \"split\" and save to return.\n\t\t\t\t\treturn localAddr, true\n\t\t\t\t}\n\t\t\t\treturn host, true\n\t\t\tcase \"http.request.local.port\":\n\t\t\t\tlocalAddr, _ := req.Context().Value(http.LocalAddrContextKey).(net.Addr)\n\t\t\t\t_, port, _ := net.SplitHostPort(localAddr.String())\n\t\t\t\tif portNum, err := strconv.Atoi(port); err == nil {\n\t\t\t\t\treturn portNum, true\n\t\t\t\t}\n\t\t\t\treturn port, true\n\t\t\tcase \"http.request.remote\":\n\t\t\t\tif req.TLS != nil && !req.TLS.HandshakeComplete {\n\t\t\t\t\t// without a complete handshake (QUIC \"early data\") we can't trust the remote IP address to not be spoofed\n\t\t\t\t\treturn nil, true\n\t\t\t\t}\n\t\t\t\treturn req.RemoteAddr, true\n\t\t\tcase \"http.request.remote.host\":\n\t\t\t\tif req.TLS != nil && !req.TLS.HandshakeComplete {\n\t\t\t\t\t// without a complete handshake (QUIC \"early data\") we can't trust the remote IP address to not be spoofed\n\t\t\t\t\treturn nil, true\n\t\t\t\t}\n\t\t\t\thost, _, err := net.SplitHostPort(req.RemoteAddr)\n\t\t\t\tif err != nil {\n\t\t\t\t\t// req.RemoteAddr is host:port for tcp and udp sockets and /unix/socket.path\n\t\t\t\t\t// for unix sockets. net.SplitHostPort only operates on tcp and udp sockets,\n\t\t\t\t\t// not unix sockets and will fail with the latter.\n\t\t\t\t\t// We assume when net.SplitHostPort fails, req.RemoteAddr is a unix socket\n\t\t\t\t\t// and thus already \"split\" and save to return.\n\t\t\t\t\treturn req.RemoteAddr, true\n\t\t\t\t}\n\t\t\t\treturn host, true\n\t\t\tcase \"http.request.remote.port\":\n\t\t\t\t_, port, _ := net.SplitHostPort(req.RemoteAddr)\n\t\t\t\tif portNum, err := strconv.Atoi(port); err == nil {\n\t\t\t\t\treturn portNum, true\n\t\t\t\t}\n\t\t\t\treturn port, true\n\n\t\t\t// current URI, including any internal rewrites\n\t\t\tcase \"http.request.uri\":\n\t\t\t\treturn req.URL.RequestURI(), true\n\t\t\tcase \"http.request.uri.path\":\n\t\t\t\treturn req.URL.Path, true\n\t\t\tcase \"http.request.uri.path.file\":\n\t\t\t\t_, file := path.Split(req.URL.Path)\n\t\t\t\treturn file, true\n\t\t\tcase \"http.request.uri.path.dir\":\n\t\t\t\tdir, _ := path.Split(req.URL.Path)\n\t\t\t\treturn dir, true\n\t\t\tcase \"http.request.uri.path.file.base\":\n\t\t\t\treturn strings.TrimSuffix(path.Base(req.URL.Path), path.Ext(req.URL.Path)), true\n\t\t\tcase \"http.request.uri.path.file.ext\":\n\t\t\t\treturn path.Ext(req.URL.Path), true\n\t\t\tcase \"http.request.uri.query\":\n\t\t\t\treturn req.URL.RawQuery, true\n\t\t\tcase \"http.request.uri.prefixed_query\":\n\t\t\t\tif req.URL.RawQuery == \"\" {\n\t\t\t\t\treturn \"\", true\n\t\t\t\t}\n\t\t\t\treturn \"?\" + req.URL.RawQuery, true\n\t\t\tcase \"http.request.duration\":\n\t\t\t\tstart := GetVar(req.Context(), \"start_time\").(time.Time)\n\t\t\t\treturn time.Since(start), true\n\t\t\tcase \"http.request.duration_ms\":\n\t\t\t\tstart := GetVar(req.Context(), \"start_time\").(time.Time)\n\t\t\t\treturn time.Since(start).Seconds() * 1e3, true // multiply seconds to preserve decimal (see #4666)\n\n\t\t\tcase \"http.request.uuid\":\n\t\t\t\t// fetch the UUID for this request\n\t\t\t\tid := GetVar(req.Context(), \"uuid\").(*requestID)\n\n\t\t\t\t// set it to this request's access log\n\t\t\t\textra := req.Context().Value(ExtraLogFieldsCtxKey).(*ExtraLogFields)\n\t\t\t\textra.Set(zap.String(\"uuid\", id.String()))\n\n\t\t\t\treturn id.String(), true\n\n\t\t\tcase \"http.request.body\":\n\t\t\t\tif req.Body == nil {\n\t\t\t\t\treturn \"\", true\n\t\t\t\t}\n\t\t\t\t// normally net/http will close the body for us, but since we\n\t\t\t\t// are replacing it with a fake one, we have to ensure we close\n\t\t\t\t// the real body ourselves when we're done\n\t\t\t\tdefer req.Body.Close()\n\t\t\t\t// read the request body into a buffer (can't pool because we\n\t\t\t\t// don't know its lifetime and would have to make a copy anyway)\n\t\t\t\tbuf := new(bytes.Buffer)\n\t\t\t\t_, _ = io.Copy(buf, req.Body) // can't handle error, so just ignore it\n\t\t\t\treq.Body = io.NopCloser(buf)  // replace real body with buffered data\n\t\t\t\treturn buf.String(), true\n\n\t\t\t// original request, before any internal changes\n\t\t\tcase \"http.request.orig_method\":\n\t\t\t\tor, _ := req.Context().Value(OriginalRequestCtxKey).(http.Request)\n\t\t\t\treturn or.Method, true\n\t\t\tcase \"http.request.orig_uri\":\n\t\t\t\tor, _ := req.Context().Value(OriginalRequestCtxKey).(http.Request)\n\t\t\t\treturn or.RequestURI, true\n\t\t\tcase \"http.request.orig_uri.path\":\n\t\t\t\tor, _ := req.Context().Value(OriginalRequestCtxKey).(http.Request)\n\t\t\t\treturn or.URL.Path, true\n\t\t\tcase \"http.request.orig_uri.path.file\":\n\t\t\t\tor, _ := req.Context().Value(OriginalRequestCtxKey).(http.Request)\n\t\t\t\t_, file := path.Split(or.URL.Path)\n\t\t\t\treturn file, true\n\t\t\tcase \"http.request.orig_uri.path.dir\":\n\t\t\t\tor, _ := req.Context().Value(OriginalRequestCtxKey).(http.Request)\n\t\t\t\tdir, _ := path.Split(or.URL.Path)\n\t\t\t\treturn dir, true\n\t\t\tcase \"http.request.orig_uri.query\":\n\t\t\t\tor, _ := req.Context().Value(OriginalRequestCtxKey).(http.Request)\n\t\t\t\treturn or.URL.RawQuery, true\n\t\t\tcase \"http.request.orig_uri.prefixed_query\":\n\t\t\t\tor, _ := req.Context().Value(OriginalRequestCtxKey).(http.Request)\n\t\t\t\tif or.URL.RawQuery == \"\" {\n\t\t\t\t\treturn \"\", true\n\t\t\t\t}\n\t\t\t\treturn \"?\" + or.URL.RawQuery, true\n\t\t\t}\n\n\t\t\t// remote IP range/prefix (e.g. keep top 24 bits of 1.2.3.4  => \"1.2.3.0/24\")\n\t\t\t// syntax: \"/V4,V6\" where V4 = IPv4 bits, and V6 = IPv6 bits; if no comma, then same bit length used for both\n\t\t\t// (EXPERIMENTAL)\n\t\t\tif strings.HasPrefix(key, \"http.request.remote.host/\") {\n\t\t\t\thost, _, err := net.SplitHostPort(req.RemoteAddr)\n\t\t\t\tif err != nil {\n\t\t\t\t\thost = req.RemoteAddr // assume no port, I guess?\n\t\t\t\t}\n\t\t\t\taddr, err := netip.ParseAddr(host)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn host, true // not an IP address\n\t\t\t\t}\n\t\t\t\t// extract the bits from the end of the placeholder (start after \"/\") then split on \",\"\n\t\t\t\tbitsBoth := key[strings.Index(key, \"/\")+1:]\n\t\t\t\tipv4BitsStr, ipv6BitsStr, cutOK := strings.Cut(bitsBoth, \",\")\n\t\t\t\tbitsStr := ipv4BitsStr\n\t\t\t\tif addr.Is6() && cutOK {\n\t\t\t\t\tbitsStr = ipv6BitsStr\n\t\t\t\t}\n\t\t\t\t// convert to integer then compute prefix\n\t\t\t\tbits, err := strconv.Atoi(bitsStr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn \"\", true\n\t\t\t\t}\n\t\t\t\tprefix, err := addr.Prefix(bits)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn \"\", true\n\t\t\t\t}\n\t\t\t\treturn prefix.String(), true\n\t\t\t}\n\n\t\t\t// hostname labels\n\t\t\tif strings.HasPrefix(key, reqHostLabelsReplPrefix) {\n\t\t\t\tidxStr := key[len(reqHostLabelsReplPrefix):]\n\t\t\t\tidx, err := strconv.Atoi(idxStr)\n\t\t\t\tif err != nil || idx < 0 {\n\t\t\t\t\treturn \"\", false\n\t\t\t\t}\n\t\t\t\treqHost, _, err := net.SplitHostPort(req.Host)\n\t\t\t\tif err != nil {\n\t\t\t\t\treqHost = req.Host // OK; assume there was no port\n\t\t\t\t}\n\t\t\t\thostLabels := strings.Split(reqHost, \".\")\n\t\t\t\tif idx >= len(hostLabels) {\n\t\t\t\t\treturn \"\", true\n\t\t\t\t}\n\t\t\t\treturn hostLabels[len(hostLabels)-idx-1], true\n\t\t\t}\n\n\t\t\t// path parts\n\t\t\tif strings.HasPrefix(key, reqURIPathReplPrefix) {\n\t\t\t\tidxStr := key[len(reqURIPathReplPrefix):]\n\t\t\t\tidx, err := strconv.Atoi(idxStr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn \"\", false\n\t\t\t\t}\n\t\t\t\tpathParts := strings.Split(req.URL.Path, \"/\")\n\t\t\t\tif len(pathParts) > 0 && pathParts[0] == \"\" {\n\t\t\t\t\tpathParts = pathParts[1:]\n\t\t\t\t}\n\t\t\t\tif idx < 0 {\n\t\t\t\t\treturn \"\", false\n\t\t\t\t}\n\t\t\t\tif idx >= len(pathParts) {\n\t\t\t\t\treturn \"\", true\n\t\t\t\t}\n\t\t\t\treturn pathParts[idx], true\n\t\t\t}\n\n\t\t\t// orig uri path parts\n\t\t\tif strings.HasPrefix(key, reqOrigURIPathReplPrefix) {\n\t\t\t\tidxStr := key[len(reqOrigURIPathReplPrefix):]\n\t\t\t\tidx, err := strconv.Atoi(idxStr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn \"\", false\n\t\t\t\t}\n\t\t\t\tor, _ := req.Context().Value(OriginalRequestCtxKey).(http.Request)\n\t\t\t\tpathParts := strings.Split(or.URL.Path, \"/\")\n\t\t\t\tif len(pathParts) > 0 && pathParts[0] == \"\" {\n\t\t\t\t\tpathParts = pathParts[1:]\n\t\t\t\t}\n\t\t\t\tif idx < 0 {\n\t\t\t\t\treturn \"\", false\n\t\t\t\t}\n\t\t\t\tif idx >= len(pathParts) {\n\t\t\t\t\treturn \"\", true\n\t\t\t\t}\n\t\t\t\treturn pathParts[idx], true\n\t\t\t}\n\n\t\t\t// middleware variables\n\t\t\tif strings.HasPrefix(key, varsReplPrefix) {\n\t\t\t\tvarName := key[len(varsReplPrefix):]\n\t\t\t\traw := GetVar(req.Context(), varName)\n\t\t\t\t// variables can be dynamic, so always return true\n\t\t\t\t// even when it may not be set; treat as empty then\n\t\t\t\treturn raw, true\n\t\t\t}\n\t\t}\n\n\t\tif w != nil {\n\t\t\t// response header fields\n\t\t\tif strings.HasPrefix(key, respHeaderReplPrefix) {\n\t\t\t\tfield := key[len(respHeaderReplPrefix):]\n\t\t\t\tvals := w.Header()[textproto.CanonicalMIMEHeaderKey(field)]\n\t\t\t\t// always return true, since the header field might\n\t\t\t\t// be present only in some responses\n\t\t\t\treturn strings.Join(vals, \",\"), true\n\t\t\t}\n\t\t}\n\n\t\tswitch key {\n\t\tcase \"http.shutting_down\":\n\t\t\tserver := req.Context().Value(ServerCtxKey).(*Server)\n\t\t\tserver.shutdownAtMu.RLock()\n\t\t\tdefer server.shutdownAtMu.RUnlock()\n\t\t\treturn !server.shutdownAt.IsZero(), true\n\t\tcase \"http.time_until_shutdown\":\n\t\t\tserver := req.Context().Value(ServerCtxKey).(*Server)\n\t\t\tserver.shutdownAtMu.RLock()\n\t\t\tdefer server.shutdownAtMu.RUnlock()\n\t\t\tif server.shutdownAt.IsZero() {\n\t\t\t\treturn nil, true\n\t\t\t}\n\t\t\treturn time.Until(server.shutdownAt), true\n\t\t}\n\n\t\treturn nil, false\n\t}\n\n\trepl.Map(httpVars)\n}\n\nfunc getReqTLSReplacement(req *http.Request, key string) (any, bool) {\n\tif req == nil || req.TLS == nil {\n\t\treturn nil, false\n\t}\n\n\tif len(key) < len(reqTLSReplPrefix) {\n\t\treturn nil, false\n\t}\n\n\tfield := strings.ToLower(key[len(reqTLSReplPrefix):])\n\n\tif strings.HasPrefix(field, \"client.\") {\n\t\tcert := getTLSPeerCert(req.TLS)\n\t\tif cert == nil {\n\t\t\treturn nil, false\n\t\t}\n\n\t\t// subject alternate names (SANs)\n\t\tif strings.HasPrefix(field, \"client.san.\") {\n\t\t\tfield = field[len(\"client.san.\"):]\n\t\t\tvar fieldName string\n\t\t\tvar fieldValue any\n\t\t\tswitch {\n\t\t\tcase strings.HasPrefix(field, \"dns_names\"):\n\t\t\t\tfieldName = \"dns_names\"\n\t\t\t\tfieldValue = cert.DNSNames\n\t\t\tcase strings.HasPrefix(field, \"emails\"):\n\t\t\t\tfieldName = \"emails\"\n\t\t\t\tfieldValue = cert.EmailAddresses\n\t\t\tcase strings.HasPrefix(field, \"ips\"):\n\t\t\t\tfieldName = \"ips\"\n\t\t\t\tfieldValue = cert.IPAddresses\n\t\t\tcase strings.HasPrefix(field, \"uris\"):\n\t\t\t\tfieldName = \"uris\"\n\t\t\t\tfieldValue = cert.URIs\n\t\t\tdefault:\n\t\t\t\treturn nil, false\n\t\t\t}\n\t\t\tfield = field[len(fieldName):]\n\n\t\t\t// if no index was specified, return the whole list\n\t\t\tif field == \"\" {\n\t\t\t\treturn fieldValue, true\n\t\t\t}\n\t\t\tif len(field) < 2 || field[0] != '.' {\n\t\t\t\treturn nil, false\n\t\t\t}\n\t\t\tfield = field[1:] // trim '.' between field name and index\n\n\t\t\t// get the numeric index\n\t\t\tidx, err := strconv.Atoi(field)\n\t\t\tif err != nil || idx < 0 {\n\t\t\t\treturn nil, false\n\t\t\t}\n\n\t\t\t// access the indexed element and return it\n\t\t\tswitch v := fieldValue.(type) {\n\t\t\tcase []string:\n\t\t\t\tif idx >= len(v) {\n\t\t\t\t\treturn nil, true\n\t\t\t\t}\n\t\t\t\treturn v[idx], true\n\t\t\tcase []net.IP:\n\t\t\t\tif idx >= len(v) {\n\t\t\t\t\treturn nil, true\n\t\t\t\t}\n\t\t\t\treturn v[idx], true\n\t\t\tcase []*url.URL:\n\t\t\t\tif idx >= len(v) {\n\t\t\t\t\treturn nil, true\n\t\t\t\t}\n\t\t\t\treturn v[idx], true\n\t\t\t}\n\t\t}\n\n\t\tswitch field {\n\t\tcase \"client.fingerprint\":\n\t\t\treturn fmt.Sprintf(\"%x\", sha256.Sum256(cert.Raw)), true\n\t\tcase \"client.public_key\", \"client.public_key_sha256\":\n\t\t\tif cert.PublicKey == nil {\n\t\t\t\treturn nil, true\n\t\t\t}\n\t\t\tpubKeyBytes, err := marshalPublicKey(cert.PublicKey)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, true\n\t\t\t}\n\t\t\tif strings.HasSuffix(field, \"_sha256\") {\n\t\t\t\treturn fmt.Sprintf(\"%x\", sha256.Sum256(pubKeyBytes)), true\n\t\t\t}\n\t\t\treturn fmt.Sprintf(\"%x\", pubKeyBytes), true\n\t\tcase \"client.issuer\":\n\t\t\treturn cert.Issuer, true\n\t\tcase \"client.serial\":\n\t\t\treturn cert.SerialNumber, true\n\t\tcase \"client.subject\":\n\t\t\treturn cert.Subject, true\n\t\tcase \"client.certificate_pem\":\n\t\t\tblock := pem.Block{Type: \"CERTIFICATE\", Bytes: cert.Raw}\n\t\t\treturn pem.EncodeToMemory(&block), true\n\t\tcase \"client.certificate_der_base64\":\n\t\t\treturn base64.StdEncoding.EncodeToString(cert.Raw), true\n\t\tdefault:\n\t\t\treturn nil, false\n\t\t}\n\t}\n\n\tswitch field {\n\tcase \"version\":\n\t\treturn caddytls.ProtocolName(req.TLS.Version), true\n\tcase \"cipher_suite\":\n\t\treturn tls.CipherSuiteName(req.TLS.CipherSuite), true\n\tcase \"resumed\":\n\t\treturn req.TLS.DidResume, true\n\tcase \"proto\":\n\t\treturn req.TLS.NegotiatedProtocol, true\n\tcase \"proto_mutual\":\n\t\t// req.TLS.NegotiatedProtocolIsMutual is deprecated - it's always true.\n\t\treturn true, true\n\tcase \"server_name\":\n\t\treturn req.TLS.ServerName, true\n\t}\n\treturn nil, false\n}\n\n// marshalPublicKey returns the byte encoding of pubKey.\nfunc marshalPublicKey(pubKey any) ([]byte, error) {\n\tswitch key := pubKey.(type) {\n\tcase *rsa.PublicKey:\n\t\treturn asn1.Marshal(key)\n\tcase *ecdsa.PublicKey:\n\t\te, err := key.ECDH()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\treturn e.Bytes(), nil\n\tcase ed25519.PublicKey:\n\t\treturn key, nil\n\t}\n\treturn nil, fmt.Errorf(\"unrecognized public key type: %T\", pubKey)\n}\n\n// getTLSPeerCert retrieves the first peer certificate from a TLS session.\n// Returns nil if no peer cert is in use.\nfunc getTLSPeerCert(cs *tls.ConnectionState) *x509.Certificate {\n\tif len(cs.PeerCertificates) == 0 {\n\t\treturn nil\n\t}\n\treturn cs.PeerCertificates[0]\n}\n\ntype requestID struct {\n\tvalue string\n}\n\n// Lazy generates UUID string or return cached value if present\nfunc (rid *requestID) String() string {\n\tif rid.value == \"\" {\n\t\tif id, err := uuid.NewRandom(); err == nil {\n\t\t\trid.value = id.String()\n\t\t}\n\t}\n\treturn rid.value\n}\n\nconst (\n\treqCookieReplPrefix      = \"http.request.cookie.\"\n\treqHeaderReplPrefix      = \"http.request.header.\"\n\treqHostLabelsReplPrefix  = \"http.request.host.labels.\"\n\treqTLSReplPrefix         = \"http.request.tls.\"\n\treqURIPathReplPrefix     = \"http.request.uri.path.\"\n\treqURIQueryReplPrefix    = \"http.request.uri.query.\"\n\trespHeaderReplPrefix     = \"http.response.header.\"\n\tvarsReplPrefix           = \"http.vars.\"\n\treqOrigURIPathReplPrefix = \"http.request.orig_uri.path.\"\n)\n",
    "source_file": "modules/caddyhttp/replacer.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"crypto/tls\"\n\t\"net\"\n\t\"net/http\"\n\t\"strings\"\n\n\t\"go.uber.org/zap/zapcore\"\n)\n\n// LoggableHTTPRequest makes an HTTP request loggable with zap.Object().\ntype LoggableHTTPRequest struct {\n\t*http.Request\n\n\tShouldLogCredentials bool\n}\n\n// MarshalLogObject satisfies the zapcore.ObjectMarshaler interface.\nfunc (r LoggableHTTPRequest) MarshalLogObject(enc zapcore.ObjectEncoder) error {\n\tip, port, err := net.SplitHostPort(r.RemoteAddr)\n\tif err != nil {\n\t\tip = r.RemoteAddr\n\t\tport = \"\"\n\t}\n\n\tenc.AddString(\"remote_ip\", ip)\n\tenc.AddString(\"remote_port\", port)\n\tif ip, ok := GetVar(r.Context(), ClientIPVarKey).(string); ok {\n\t\tenc.AddString(\"client_ip\", ip)\n\t}\n\tenc.AddString(\"proto\", r.Proto)\n\tenc.AddString(\"method\", r.Method)\n\tenc.AddString(\"host\", r.Host)\n\tenc.AddString(\"uri\", r.RequestURI)\n\tenc.AddObject(\"headers\", LoggableHTTPHeader{\n\t\tHeader:               r.Header,\n\t\tShouldLogCredentials: r.ShouldLogCredentials,\n\t})\n\tif r.TransferEncoding != nil {\n\t\tenc.AddArray(\"transfer_encoding\", LoggableStringArray(r.TransferEncoding))\n\t}\n\tif r.TLS != nil {\n\t\tenc.AddObject(\"tls\", LoggableTLSConnState(*r.TLS))\n\t}\n\treturn nil\n}\n\n// LoggableHTTPHeader makes an HTTP header loggable with zap.Object().\n// Headers with potentially sensitive information (Cookie, Set-Cookie,\n// Authorization, and Proxy-Authorization) are logged with empty values.\ntype LoggableHTTPHeader struct {\n\thttp.Header\n\n\tShouldLogCredentials bool\n}\n\n// MarshalLogObject satisfies the zapcore.ObjectMarshaler interface.\nfunc (h LoggableHTTPHeader) MarshalLogObject(enc zapcore.ObjectEncoder) error {\n\tif h.Header == nil {\n\t\treturn nil\n\t}\n\tfor key, val := range h.Header {\n\t\tif !h.ShouldLogCredentials {\n\t\t\tswitch strings.ToLower(key) {\n\t\t\tcase \"cookie\", \"set-cookie\", \"authorization\", \"proxy-authorization\":\n\t\t\t\tval = []string{\"REDACTED\"} // see #5669. I still think \u2592\u2592\u2592\u2592 would be cool.\n\t\t\t}\n\t\t}\n\t\tenc.AddArray(key, LoggableStringArray(val))\n\t}\n\treturn nil\n}\n\n// LoggableStringArray makes a slice of strings marshalable for logging.\ntype LoggableStringArray []string\n\n// MarshalLogArray satisfies the zapcore.ArrayMarshaler interface.\nfunc (sa LoggableStringArray) MarshalLogArray(enc zapcore.ArrayEncoder) error {\n\tif sa == nil {\n\t\treturn nil\n\t}\n\tfor _, s := range sa {\n\t\tenc.AppendString(s)\n\t}\n\treturn nil\n}\n\n// LoggableTLSConnState makes a TLS connection state loggable with zap.Object().\ntype LoggableTLSConnState tls.ConnectionState\n\n// MarshalLogObject satisfies the zapcore.ObjectMarshaler interface.\nfunc (t LoggableTLSConnState) MarshalLogObject(enc zapcore.ObjectEncoder) error {\n\tenc.AddBool(\"resumed\", t.DidResume)\n\tenc.AddUint16(\"version\", t.Version)\n\tenc.AddUint16(\"cipher_suite\", t.CipherSuite)\n\tenc.AddString(\"proto\", t.NegotiatedProtocol)\n\tenc.AddString(\"server_name\", t.ServerName)\n\tif len(t.PeerCertificates) > 0 {\n\t\tenc.AddString(\"client_common_name\", t.PeerCertificates[0].Subject.CommonName)\n\t\tenc.AddString(\"client_serial\", t.PeerCertificates[0].SerialNumber.String())\n\t}\n\treturn nil\n}\n\n// Interface guards\nvar (\n\t_ zapcore.ObjectMarshaler = (*LoggableHTTPRequest)(nil)\n\t_ zapcore.ObjectMarshaler = (*LoggableHTTPHeader)(nil)\n\t_ zapcore.ArrayMarshaler  = (*LoggableStringArray)(nil)\n\t_ zapcore.ObjectMarshaler = (*LoggableTLSConnState)(nil)\n)\n",
    "source_file": "modules/caddyhttp/marshalers.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\n// ResponseMatcher is a type which can determine if an\n// HTTP response matches some criteria.\ntype ResponseMatcher struct {\n\t// If set, one of these status codes would be required.\n\t// A one-digit status can be used to represent all codes\n\t// in that class (e.g. 3 for all 3xx codes).\n\tStatusCode []int `json:\"status_code,omitempty\"`\n\n\t// If set, each header specified must be one of the\n\t// specified values, with the same logic used by the\n\t// [request header matcher](/docs/json/apps/http/servers/routes/match/header/).\n\tHeaders http.Header `json:\"headers,omitempty\"`\n}\n\n// Match returns true if the given statusCode and hdr match rm.\nfunc (rm ResponseMatcher) Match(statusCode int, hdr http.Header) bool {\n\tif !rm.matchStatusCode(statusCode) {\n\t\treturn false\n\t}\n\treturn matchHeaders(hdr, rm.Headers, \"\", []string{}, nil)\n}\n\nfunc (rm ResponseMatcher) matchStatusCode(statusCode int) bool {\n\tif rm.StatusCode == nil {\n\t\treturn true\n\t}\n\tfor _, code := range rm.StatusCode {\n\t\tif StatusCodeMatches(statusCode, code) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// ParseNamedResponseMatcher parses the tokens of a named response matcher.\n//\n//\t@name {\n//\t    header <field> [<value>]\n//\t    status <code...>\n//\t}\n//\n// Or, single line syntax:\n//\n//\t@name [header <field> [<value>]] | [status <code...>]\nfunc ParseNamedResponseMatcher(d *caddyfile.Dispenser, matchers map[string]ResponseMatcher) error {\n\td.Next() // consume matcher name\n\tdefinitionName := d.Val()\n\n\tif _, ok := matchers[definitionName]; ok {\n\t\treturn d.Errf(\"matcher is defined more than once: %s\", definitionName)\n\t}\n\n\tmatcher := ResponseMatcher{}\n\tfor nesting := d.Nesting(); d.NextArg() || d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"header\":\n\t\t\tif matcher.Headers == nil {\n\t\t\t\tmatcher.Headers = http.Header{}\n\t\t\t}\n\n\t\t\t// reuse the header request matcher's unmarshaler\n\t\t\theaderMatcher := MatchHeader(matcher.Headers)\n\t\t\terr := headerMatcher.UnmarshalCaddyfile(d.NewFromNextSegment())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tmatcher.Headers = http.Header(headerMatcher)\n\t\tcase \"status\":\n\t\t\tif matcher.StatusCode == nil {\n\t\t\t\tmatcher.StatusCode = []int{}\n\t\t\t}\n\n\t\t\targs := d.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\t\tfor _, arg := range args {\n\t\t\t\tif len(arg) == 3 && strings.HasSuffix(arg, \"xx\") {\n\t\t\t\t\targ = arg[:1]\n\t\t\t\t}\n\t\t\t\tstatusNum, err := strconv.Atoi(arg)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn d.Errf(\"bad status value '%s': %v\", arg, err)\n\t\t\t\t}\n\t\t\t\tmatcher.StatusCode = append(matcher.StatusCode, statusNum)\n\t\t\t}\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized response matcher %s\", d.Val())\n\t\t}\n\t}\n\tmatchers[definitionName] = matcher\n\treturn nil\n}\n",
    "source_file": "modules/caddyhttp/responsematchers.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Subroute{})\n}\n\n// Subroute implements a handler that compiles and executes routes.\n// This is useful for a batch of routes that all inherit the same\n// matchers, or for multiple routes that should be treated as a\n// single route.\n//\n// You can also use subroutes to handle errors from its handlers.\n// First the primary routes will be executed, and if they return an\n// error, the errors routes will be executed; in that case, an error\n// is only returned to the entry point at the server if there is an\n// additional error returned from the errors routes.\ntype Subroute struct {\n\t// The primary list of routes to compile and execute.\n\tRoutes RouteList `json:\"routes,omitempty\"`\n\n\t// If the primary routes return an error, error handling\n\t// can be promoted to this configuration instead.\n\tErrors *HTTPErrorConfig `json:\"errors,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Subroute) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.subroute\",\n\t\tNew: func() caddy.Module { return new(Subroute) },\n\t}\n}\n\n// Provision sets up subrouting.\nfunc (sr *Subroute) Provision(ctx caddy.Context) error {\n\tif sr.Routes != nil {\n\t\terr := sr.Routes.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"setting up subroutes: %v\", err)\n\t\t}\n\t\tif sr.Errors != nil {\n\t\t\terr := sr.Errors.Routes.Provision(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"setting up error subroutes: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (sr *Subroute) ServeHTTP(w http.ResponseWriter, r *http.Request, next Handler) error {\n\tsubroute := sr.Routes.Compile(next)\n\terr := subroute.ServeHTTP(w, r)\n\tif err != nil && sr.Errors != nil {\n\t\tr = sr.Errors.WithError(r, err)\n\t\terrRoute := sr.Errors.Routes.Compile(next)\n\t\treturn errRoute.ServeHTTP(w, r)\n\t}\n\treturn err\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner = (*Subroute)(nil)\n\t_ MiddlewareHandler = (*Subroute)(nil)\n)\n",
    "source_file": "modules/caddyhttp/subroute.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/textproto\"\n\t\"net/url\"\n\t\"path\"\n\t\"reflect\"\n\t\"regexp\"\n\t\"runtime\"\n\t\"slices\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/google/cel-go/cel\"\n\t\"github.com/google/cel-go/common/types\"\n\t\"github.com/google/cel-go/common/types/ref\"\n\t\"golang.org/x/net/idna\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\ntype (\n\t// MatchHost matches requests by the Host value (case-insensitive).\n\t//\n\t// When used in a top-level HTTP route,\n\t// [qualifying domain names](/docs/automatic-https#hostname-requirements)\n\t// may trigger [automatic HTTPS](/docs/automatic-https), which automatically\n\t// provisions and renews certificates for you. Before doing this, you\n\t// should ensure that DNS records for these domains are properly configured,\n\t// especially A/AAAA pointed at your server.\n\t//\n\t// Automatic HTTPS can be\n\t// [customized or disabled](/docs/modules/http#servers/automatic_https).\n\t//\n\t// Wildcards (`*`) may be used to represent exactly one label of the\n\t// hostname, in accordance with RFC 1034 (because host matchers are also\n\t// used for automatic HTTPS which influences TLS certificates). Thus,\n\t// a host of `*` matches hosts like `localhost` or `internal` but not\n\t// `example.com`. To catch all hosts, omit the host matcher entirely.\n\t//\n\t// The wildcard can be useful for matching all subdomains, for example:\n\t// `*.example.com` matches `foo.example.com` but not `foo.bar.example.com`.\n\t//\n\t// Duplicate entries will return an error.\n\tMatchHost []string\n\n\t// MatchPath case-insensitively matches requests by the URI's path. Path\n\t// matching is exact, not prefix-based, giving you more control and clarity\n\t// over matching. Wildcards (`*`) may be used:\n\t//\n\t// - At the end only, for a prefix match (`/prefix/*`)\n\t// - At the beginning only, for a suffix match (`*.suffix`)\n\t// - On both sides only, for a substring match (`*/contains/*`)\n\t// - In the middle, for a globular match (`/accounts/*/info`)\n\t//\n\t// Slashes are significant; i.e. `/foo*` matches `/foo`, `/foo/`, `/foo/bar`,\n\t// and `/foobar`; but `/foo/*` does not match `/foo` or `/foobar`. Valid\n\t// paths start with a slash `/`.\n\t//\n\t// Because there are, in general, multiple possible escaped forms of any\n\t// path, path matchers operate in unescaped space; that is, path matchers\n\t// should be written in their unescaped form to prevent ambiguities and\n\t// possible security issues, as all request paths will be normalized to\n\t// their unescaped forms before matcher evaluation.\n\t//\n\t// However, escape sequences in a match pattern are supported; they are\n\t// compared with the request's raw/escaped path for those bytes only.\n\t// In other words, a matcher of `/foo%2Fbar` will match a request path\n\t// of precisely `/foo%2Fbar`, but not `/foo/bar`. It follows that matching\n\t// the literal percent sign (%) in normalized space can be done using the\n\t// escaped form, `%25`.\n\t//\n\t// Even though wildcards (`*`) operate in the normalized space, the special\n\t// escaped wildcard (`%*`), which is not a valid escape sequence, may be\n\t// used in place of a span that should NOT be decoded; that is, `/bands/%*`\n\t// will match `/bands/AC%2fDC` whereas `/bands/*` will not.\n\t//\n\t// Even though path matching is done in normalized space, the special\n\t// wildcard `%*` may be used in place of a span that should NOT be decoded;\n\t// that is, `/bands/%*/` will match `/bands/AC%2fDC/` whereas `/bands/*/`\n\t// will not.\n\t//\n\t// This matcher is fast, so it does not support regular expressions or\n\t// capture groups. For slower but more powerful matching, use the\n\t// path_regexp matcher. (Note that due to the special treatment of\n\t// escape sequences in matcher patterns, they may perform slightly slower\n\t// in high-traffic environments.)\n\tMatchPath []string\n\n\t// MatchPathRE matches requests by a regular expression on the URI's path.\n\t// Path matching is performed in the unescaped (decoded) form of the path.\n\t//\n\t// Upon a match, it adds placeholders to the request: `{http.regexp.name.capture_group}`\n\t// where `name` is the regular expression's name, and `capture_group` is either\n\t// the named or positional capture group from the expression itself. If no name\n\t// is given, then the placeholder omits the name: `{http.regexp.capture_group}`\n\t// (potentially leading to collisions).\n\tMatchPathRE struct{ MatchRegexp }\n\n\t// MatchMethod matches requests by the method.\n\tMatchMethod []string\n\n\t// MatchQuery matches requests by the URI's query string. It takes a JSON object\n\t// keyed by the query keys, with an array of string values to match for that key.\n\t// Query key matches are exact, but wildcards may be used for value matches. Both\n\t// keys and values may be placeholders.\n\t//\n\t// An example of the structure to match `?key=value&topic=api&query=something` is:\n\t//\n\t// ```json\n\t// {\n\t// \t\"key\": [\"value\"],\n\t//\t\"topic\": [\"api\"],\n\t//\t\"query\": [\"*\"]\n\t// }\n\t// ```\n\t//\n\t// Invalid query strings, including those with bad escapings or illegal characters\n\t// like semicolons, will fail to parse and thus fail to match.\n\t//\n\t// **NOTE:** Notice that query string values are arrays, not singular values. This is\n\t// because repeated keys are valid in query strings, and each one may have a\n\t// different value. This matcher will match for a key if any one of its configured\n\t// values is assigned in the query string. Backend applications relying on query\n\t// strings MUST take into consideration that query string values are arrays and can\n\t// have multiple values.\n\tMatchQuery url.Values\n\n\t// MatchHeader matches requests by header fields. The key is the field\n\t// name and the array is the list of field values. It performs fast,\n\t// exact string comparisons of the field values. Fast prefix, suffix,\n\t// and substring matches can also be done by suffixing, prefixing, or\n\t// surrounding the value with the wildcard `*` character, respectively.\n\t// If a list is null, the header must not exist. If the list is empty,\n\t// the field must simply exist, regardless of its value.\n\t//\n\t// **NOTE:** Notice that header values are arrays, not singular values. This is\n\t// because repeated fields are valid in headers, and each one may have a\n\t// different value. This matcher will match for a field if any one of its configured\n\t// values matches in the header. Backend applications relying on headers MUST take\n\t// into consideration that header field values are arrays and can have multiple\n\t// values.\n\tMatchHeader http.Header\n\n\t// MatchHeaderRE matches requests by a regular expression on header fields.\n\t//\n\t// Upon a match, it adds placeholders to the request: `{http.regexp.name.capture_group}`\n\t// where `name` is the regular expression's name, and `capture_group` is either\n\t// the named or positional capture group from the expression itself. If no name\n\t// is given, then the placeholder omits the name: `{http.regexp.capture_group}`\n\t// (potentially leading to collisions).\n\tMatchHeaderRE map[string]*MatchRegexp\n\n\t// MatchProtocol matches requests by protocol. Recognized values are\n\t// \"http\", \"https\", and \"grpc\" for broad protocol matches, or specific\n\t// HTTP versions can be specified like so: \"http/1\", \"http/1.1\",\n\t// \"http/2\", \"http/3\", or minimum versions: \"http/2+\", etc.\n\tMatchProtocol string\n\n\t// MatchTLS matches HTTP requests based on the underlying\n\t// TLS connection state. If this matcher is specified but\n\t// the request did not come over TLS, it will never match.\n\t// If this matcher is specified but is empty and the request\n\t// did come in over TLS, it will always match.\n\tMatchTLS struct {\n\t\t// Matches if the TLS handshake has completed. QUIC 0-RTT early\n\t\t// data may arrive before the handshake completes. Generally, it\n\t\t// is unsafe to replay these requests if they are not idempotent;\n\t\t// additionally, the remote IP of early data packets can more\n\t\t// easily be spoofed. It is conventional to respond with HTTP 425\n\t\t// Too Early if the request cannot risk being processed in this\n\t\t// state.\n\t\tHandshakeComplete *bool `json:\"handshake_complete,omitempty\"`\n\t}\n\n\t// MatchNot matches requests by negating the results of its matcher\n\t// sets. A single \"not\" matcher takes one or more matcher sets. Each\n\t// matcher set is OR'ed; in other words, if any matcher set returns\n\t// true, the final result of the \"not\" matcher is false. Individual\n\t// matchers within a set work the same (i.e. different matchers in\n\t// the same set are AND'ed).\n\t//\n\t// NOTE: The generated docs which describe the structure of this\n\t// module are wrong because of how this type unmarshals JSON in a\n\t// custom way. The correct structure is:\n\t//\n\t// ```json\n\t// [\n\t// \t{},\n\t// \t{}\n\t// ]\n\t// ```\n\t//\n\t// where each of the array elements is a matcher set, i.e. an\n\t// object keyed by matcher name.\n\tMatchNot struct {\n\t\tMatcherSetsRaw []caddy.ModuleMap `json:\"-\" caddy:\"namespace=http.matchers\"`\n\t\tMatcherSets    []MatcherSet      `json:\"-\"`\n\t}\n)\n\nfunc init() {\n\tcaddy.RegisterModule(MatchHost{})\n\tcaddy.RegisterModule(MatchPath{})\n\tcaddy.RegisterModule(MatchPathRE{})\n\tcaddy.RegisterModule(MatchMethod{})\n\tcaddy.RegisterModule(MatchQuery{})\n\tcaddy.RegisterModule(MatchHeader{})\n\tcaddy.RegisterModule(MatchHeaderRE{})\n\tcaddy.RegisterModule(new(MatchProtocol))\n\tcaddy.RegisterModule(MatchTLS{})\n\tcaddy.RegisterModule(MatchNot{})\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchHost) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.host\",\n\t\tNew: func() caddy.Module { return new(MatchHost) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchHost) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\t*m = append(*m, d.RemainingArgs()...)\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed host matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Provision sets up and validates m, including making it more efficient for large lists.\nfunc (m MatchHost) Provision(_ caddy.Context) error {\n\t// check for duplicates; they are nonsensical and reduce efficiency\n\t// (we could just remove them, but the user should know their config is erroneous)\n\tseen := make(map[string]int, len(m))\n\tfor i, host := range m {\n\t\tasciiHost, err := idna.ToASCII(host)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"converting hostname '%s' to ASCII: %v\", host, err)\n\t\t}\n\t\tif asciiHost != host {\n\t\t\tm[i] = asciiHost\n\t\t}\n\t\tnormalizedHost := strings.ToLower(asciiHost)\n\t\tif firstI, ok := seen[normalizedHost]; ok {\n\t\t\treturn fmt.Errorf(\"host at index %d is repeated at index %d: %s\", firstI, i, host)\n\t\t}\n\t\tseen[normalizedHost] = i\n\t}\n\n\tif m.large() {\n\t\t// sort the slice lexicographically, grouping \"fuzzy\" entries (wildcards and placeholders)\n\t\t// at the front of the list; this allows us to use binary search for exact matches, which\n\t\t// we have seen from experience is the most common kind of value in large lists; and any\n\t\t// other kinds of values (wildcards and placeholders) are grouped in front so the linear\n\t\t// search should find a match fairly quickly\n\t\tsort.Slice(m, func(i, j int) bool {\n\t\t\tiInexact, jInexact := m.fuzzy(m[i]), m.fuzzy(m[j])\n\t\t\tif iInexact && !jInexact {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tif !iInexact && jInexact {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\treturn m[i] < m[j]\n\t\t})\n\t}\n\n\treturn nil\n}\n\n// Match returns true if r matches m.\nfunc (m MatchHost) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchHost) MatchWithError(r *http.Request) (bool, error) {\n\treqHost, _, err := net.SplitHostPort(r.Host)\n\tif err != nil {\n\t\t// OK; probably didn't have a port\n\t\treqHost = r.Host\n\n\t\t// make sure we strip the brackets from IPv6 addresses\n\t\treqHost = strings.TrimPrefix(reqHost, \"[\")\n\t\treqHost = strings.TrimSuffix(reqHost, \"]\")\n\t}\n\n\tif m.large() {\n\t\t// fast path: locate exact match using binary search (about 100-1000x faster for large lists)\n\t\tpos := sort.Search(len(m), func(i int) bool {\n\t\t\tif m.fuzzy(m[i]) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\treturn m[i] >= reqHost\n\t\t})\n\t\tif pos < len(m) && m[pos] == reqHost {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\nouter:\n\tfor _, host := range m {\n\t\t// fast path: if matcher is large, we already know we don't have an exact\n\t\t// match, so we're only looking for fuzzy match now, which should be at the\n\t\t// front of the list; if we have reached a value that is not fuzzy, there\n\t\t// will be no match and we can short-circuit for efficiency\n\t\tif m.large() && !m.fuzzy(host) {\n\t\t\tbreak\n\t\t}\n\n\t\thost = repl.ReplaceAll(host, \"\")\n\t\tif strings.Contains(host, \"*\") {\n\t\t\tpatternParts := strings.Split(host, \".\")\n\t\t\tincomingParts := strings.Split(reqHost, \".\")\n\t\t\tif len(patternParts) != len(incomingParts) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor i := range patternParts {\n\t\t\t\tif patternParts[i] == \"*\" {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tif !strings.EqualFold(patternParts[i], incomingParts[i]) {\n\t\t\t\t\tcontinue outer\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn true, nil\n\t\t} else if strings.EqualFold(reqHost, host) {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\n\treturn false, nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression host('localhost')\nfunc (MatchHost) CELLibrary(ctx caddy.Context) (cel.Library, error) {\n\treturn CELMatcherImpl(\n\t\t\"host\",\n\t\t\"host_match_request_list\",\n\t\t[]*cel.Type{cel.ListType(cel.StringType)},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tstrList, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tmatcher := MatchHost(strList.([]string))\n\t\t\terr = matcher.Provision(ctx)\n\t\t\treturn matcher, err\n\t\t},\n\t)\n}\n\n// fuzzy returns true if the given hostname h is not a specific\n// hostname, e.g. has placeholders or wildcards.\nfunc (MatchHost) fuzzy(h string) bool { return strings.ContainsAny(h, \"{*\") }\n\n// large returns true if m is considered to be large. Optimizing\n// the matcher for smaller lists has diminishing returns.\n// See related benchmark function in test file to conduct experiments.\nfunc (m MatchHost) large() bool { return len(m) > 100 }\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchPath) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.path\",\n\t\tNew: func() caddy.Module { return new(MatchPath) },\n\t}\n}\n\n// Provision lower-cases the paths in m to ensure case-insensitive matching.\nfunc (m MatchPath) Provision(_ caddy.Context) error {\n\tfor i := range m {\n\t\tif m[i] == \"*\" && i > 0 {\n\t\t\t// will always match, so just put it first\n\t\t\tm[0] = m[i]\n\t\t\tbreak\n\t\t}\n\t\tm[i] = strings.ToLower(m[i])\n\t}\n\treturn nil\n}\n\n// Match returns true if r matches m.\nfunc (m MatchPath) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchPath) MatchWithError(r *http.Request) (bool, error) {\n\t// Even though RFC 9110 says that path matching is case-sensitive\n\t// (https://www.rfc-editor.org/rfc/rfc9110.html#section-4.2.3),\n\t// we do case-insensitive matching to mitigate security issues\n\t// related to differences between operating systems, applications,\n\t// etc; if case-sensitive matching is needed, the regex matcher\n\t// can be used instead.\n\treqPath := strings.ToLower(r.URL.Path)\n\n\t// See #2917; Windows ignores trailing dots and spaces\n\t// when accessing files (sigh), potentially causing a\n\t// security risk (cry) if PHP files end up being served\n\t// as static files, exposing the source code, instead of\n\t// being matched by *.php to be treated as PHP scripts.\n\tif runtime.GOOS == \"windows\" { // issue #5613\n\t\treqPath = strings.TrimRight(reqPath, \". \")\n\t}\n\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\tfor _, matchPattern := range m {\n\t\tmatchPattern = repl.ReplaceAll(matchPattern, \"\")\n\n\t\t// special case: whole path is wildcard; this is unnecessary\n\t\t// as it matches all requests, which is the same as no matcher\n\t\tif matchPattern == \"*\" {\n\t\t\treturn true, nil\n\t\t}\n\n\t\t// Clean the path, merge doubled slashes, etc.\n\t\t// This ensures maliciously crafted requests can't bypass\n\t\t// the path matcher. See #4407. Good security posture\n\t\t// requires that we should do all we can to reduce any\n\t\t// funny-looking paths into \"normalized\" forms such that\n\t\t// weird variants can't sneak by.\n\t\t//\n\t\t// How we clean the path depends on the kind of pattern:\n\t\t// we either merge slashes or we don't. If the pattern\n\t\t// has double slashes, we preserve them in the path.\n\t\t//\n\t\t// TODO: Despite the fact that the *vast* majority of path\n\t\t// matchers have only 1 pattern, a possible optimization is\n\t\t// to remember the cleaned form of the path for future\n\t\t// iterations; it's just that the way we clean depends on\n\t\t// the kind of pattern.\n\n\t\tmergeSlashes := !strings.Contains(matchPattern, \"//\")\n\n\t\t// if '%' appears in the match pattern, we interpret that to mean\n\t\t// the intent is to compare that part of the path in raw/escaped\n\t\t// space; i.e. \"%40\"==\"%40\", not \"@\", and \"%2F\"==\"%2F\", not \"/\"\n\t\tif strings.Contains(matchPattern, \"%\") {\n\t\t\treqPathForPattern := CleanPath(r.URL.EscapedPath(), mergeSlashes)\n\t\t\tif m.matchPatternWithEscapeSequence(reqPathForPattern, matchPattern) {\n\t\t\t\treturn true, nil\n\t\t\t}\n\n\t\t\t// doing prefix/suffix/substring matches doesn't make sense\n\t\t\tcontinue\n\t\t}\n\n\t\treqPathForPattern := CleanPath(reqPath, mergeSlashes)\n\n\t\t// for substring, prefix, and suffix matching, only perform those\n\t\t// special, fast matches if they are the only wildcards in the pattern;\n\t\t// otherwise we assume a globular match if any * appears in the middle\n\n\t\t// special case: first and last characters are wildcard,\n\t\t// treat it as a fast substring match\n\t\tif strings.Count(matchPattern, \"*\") == 2 &&\n\t\t\tstrings.HasPrefix(matchPattern, \"*\") &&\n\t\t\tstrings.HasSuffix(matchPattern, \"*\") {\n\t\t\tif strings.Contains(reqPathForPattern, matchPattern[1:len(matchPattern)-1]) {\n\t\t\t\treturn true, nil\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// only perform prefix/suffix match if it is the only wildcard...\n\t\t// I think that is more correct most of the time\n\t\tif strings.Count(matchPattern, \"*\") == 1 {\n\t\t\t// special case: first character is a wildcard,\n\t\t\t// treat it as a fast suffix match\n\t\t\tif strings.HasPrefix(matchPattern, \"*\") {\n\t\t\t\tif strings.HasSuffix(reqPathForPattern, matchPattern[1:]) {\n\t\t\t\t\treturn true, nil\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// special case: last character is a wildcard,\n\t\t\t// treat it as a fast prefix match\n\t\t\tif strings.HasSuffix(matchPattern, \"*\") {\n\t\t\t\tif strings.HasPrefix(reqPathForPattern, matchPattern[:len(matchPattern)-1]) {\n\t\t\t\t\treturn true, nil\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// at last, use globular matching, which also is exact matching\n\t\t// if there are no glob/wildcard chars; we ignore the error here\n\t\t// because we can't handle it anyway\n\t\tmatches, _ := path.Match(matchPattern, reqPathForPattern)\n\t\tif matches {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\treturn false, nil\n}\n\nfunc (MatchPath) matchPatternWithEscapeSequence(escapedPath, matchPath string) bool {\n\t// We would just compare the pattern against r.URL.Path,\n\t// but the pattern contains %, indicating that we should\n\t// compare at least some part of the path in raw/escaped\n\t// space, not normalized space; so we build the string we\n\t// will compare against by adding the normalized parts\n\t// of the path, then switching to the escaped parts where\n\t// the pattern hints to us wherever % is present.\n\tvar sb strings.Builder\n\n\t// iterate the pattern and escaped path in lock-step;\n\t// increment iPattern every time we consume a char from the pattern,\n\t// increment iPath every time we consume a char from the path;\n\t// iPattern and iPath are our cursors/iterator positions for each string\n\tvar iPattern, iPath int\n\tfor {\n\t\tif iPattern >= len(matchPath) || iPath >= len(escapedPath) {\n\t\t\tbreak\n\t\t}\n\t\t// get the next character from the request path\n\n\t\tpathCh := string(escapedPath[iPath])\n\t\tvar escapedPathCh string\n\n\t\t// normalize (decode) escape sequences\n\t\tif pathCh == \"%\" && len(escapedPath) >= iPath+3 {\n\t\t\t// hold onto this in case we find out the intent is to match in escaped space here;\n\t\t\t// we lowercase it even though technically the spec says: \"For consistency, URI\n\t\t\t// producers and normalizers should use uppercase hexadecimal digits for all percent-\n\t\t\t// encodings\" (RFC 3986 section 2.1) - we lowercased the matcher pattern earlier in\n\t\t\t// provisioning so we do the same here to gain case-insensitivity in equivalence;\n\t\t\t// besides, this string is never shown visibly\n\t\t\tescapedPathCh = strings.ToLower(escapedPath[iPath : iPath+3])\n\n\t\t\tvar err error\n\t\t\tpathCh, err = url.PathUnescape(escapedPathCh)\n\t\t\tif err != nil {\n\t\t\t\t// should be impossible unless EscapedPath() is giving us an invalid sequence!\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tiPath += 2 // escape sequence is 2 bytes longer than normal char\n\t\t}\n\n\t\t// now get the next character from the pattern\n\n\t\tnormalize := true\n\t\tswitch matchPath[iPattern] {\n\t\tcase '%':\n\t\t\t// escape sequence\n\n\t\t\t// if not a wildcard (\"%*\"), compare literally; consume next two bytes of pattern\n\t\t\tif len(matchPath) >= iPattern+3 && matchPath[iPattern+1] != '*' {\n\t\t\t\tsb.WriteString(escapedPathCh)\n\t\t\t\tiPath++\n\t\t\t\tiPattern += 2\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// escaped wildcard sequence; consume next byte only ('*')\n\t\t\tiPattern++\n\t\t\tnormalize = false\n\n\t\t\tfallthrough\n\t\tcase '*':\n\t\t\t// wildcard, so consume until next matching character\n\t\t\tremaining := escapedPath[iPath:]\n\t\t\tuntil := len(escapedPath) - iPath // go until end of string...\n\t\t\tif iPattern < len(matchPath)-1 {  // ...unless the * is not at the end\n\t\t\t\tnextCh := matchPath[iPattern+1]\n\t\t\t\tuntil = strings.IndexByte(remaining, nextCh)\n\t\t\t\tif until == -1 {\n\t\t\t\t\t// terminating char of wildcard span not found, so definitely no match\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\t}\n\t\t\tif until == 0 {\n\t\t\t\t// empty span; nothing to add on this iteration\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tnext := remaining[:until]\n\t\t\tif normalize {\n\t\t\t\tvar err error\n\t\t\t\tnext, err = url.PathUnescape(next)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn false // should be impossible anyway\n\t\t\t\t}\n\t\t\t}\n\t\t\tsb.WriteString(next)\n\t\t\tiPath += until\n\t\tdefault:\n\t\t\tsb.WriteString(pathCh)\n\t\t\tiPath++\n\t\t}\n\n\t\tiPattern++\n\t}\n\n\t// we can now treat rawpath globs (%*) as regular globs (*)\n\tmatchPath = strings.ReplaceAll(matchPath, \"%*\", \"*\")\n\n\t// ignore error here because we can't handle it anyway=\n\tmatches, _ := path.Match(matchPath, sb.String())\n\treturn matches\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression path('*substring*', '*suffix')\nfunc (MatchPath) CELLibrary(ctx caddy.Context) (cel.Library, error) {\n\treturn CELMatcherImpl(\n\t\t// name of the macro, this is the function name that users see when writing expressions.\n\t\t\"path\",\n\t\t// name of the function that the macro will be rewritten to call.\n\t\t\"path_match_request_list\",\n\t\t// internal data type of the MatchPath value.\n\t\t[]*cel.Type{cel.ListType(cel.StringType)},\n\t\t// function to convert a constant list of strings to a MatchPath instance.\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tstrList, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tmatcher := MatchPath(strList.([]string))\n\t\t\terr = matcher.Provision(ctx)\n\t\t\treturn matcher, err\n\t\t},\n\t)\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchPath) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\t*m = append(*m, d.RemainingArgs()...)\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed path matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchPathRE) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.path_regexp\",\n\t\tNew: func() caddy.Module { return new(MatchPathRE) },\n\t}\n}\n\n// Match returns true if r matches m.\nfunc (m MatchPathRE) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchPathRE) MatchWithError(r *http.Request) (bool, error) {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\t// Clean the path, merges doubled slashes, etc.\n\t// This ensures maliciously crafted requests can't bypass\n\t// the path matcher. See #4407\n\tcleanedPath := cleanPath(r.URL.Path)\n\n\treturn m.MatchRegexp.Match(cleanedPath, repl), nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression path_regexp('^/bar')\nfunc (MatchPathRE) CELLibrary(ctx caddy.Context) (cel.Library, error) {\n\tunnamedPattern, err := CELMatcherImpl(\n\t\t\"path_regexp\",\n\t\t\"path_regexp_request_string\",\n\t\t[]*cel.Type{cel.StringType},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\tpattern := data.(types.String)\n\t\t\tmatcher := MatchPathRE{MatchRegexp{\n\t\t\t\tName:    ctx.Value(MatcherNameCtxKey).(string),\n\t\t\t\tPattern: string(pattern),\n\t\t\t}}\n\t\t\terr := matcher.Provision(ctx)\n\t\t\treturn matcher, err\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnamedPattern, err := CELMatcherImpl(\n\t\t\"path_regexp\",\n\t\t\"path_regexp_request_string_string\",\n\t\t[]*cel.Type{cel.StringType, cel.StringType},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tparams, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tstrParams := params.([]string)\n\t\t\tname := strParams[0]\n\t\t\tif name == \"\" {\n\t\t\t\tname = ctx.Value(MatcherNameCtxKey).(string)\n\t\t\t}\n\t\t\tmatcher := MatchPathRE{MatchRegexp{\n\t\t\t\tName:    name,\n\t\t\t\tPattern: strParams[1],\n\t\t\t}}\n\t\t\terr = matcher.Provision(ctx)\n\t\t\treturn matcher, err\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tenvOpts := append(unnamedPattern.CompileOptions(), namedPattern.CompileOptions()...)\n\tprgOpts := append(unnamedPattern.ProgramOptions(), namedPattern.ProgramOptions()...)\n\treturn NewMatcherCELLibrary(envOpts, prgOpts), nil\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchMethod) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.method\",\n\t\tNew: func() caddy.Module { return new(MatchMethod) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchMethod) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\t*m = append(*m, d.RemainingArgs()...)\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed method matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Match returns true if r matches m.\nfunc (m MatchMethod) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchMethod) MatchWithError(r *http.Request) (bool, error) {\n\treturn slices.Contains(m, r.Method), nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression method('PUT', 'POST')\nfunc (MatchMethod) CELLibrary(_ caddy.Context) (cel.Library, error) {\n\treturn CELMatcherImpl(\n\t\t\"method\",\n\t\t\"method_request_list\",\n\t\t[]*cel.Type{cel.ListType(cel.StringType)},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tstrList, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn MatchMethod(strList.([]string)), nil\n\t\t},\n\t)\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchQuery) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.query\",\n\t\tNew: func() caddy.Module { return new(MatchQuery) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchQuery) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tif *m == nil {\n\t\t*m = make(map[string][]string)\n\t}\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tfor _, query := range d.RemainingArgs() {\n\t\t\tif query == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tbefore, after, found := strings.Cut(query, \"=\")\n\t\t\tif !found {\n\t\t\t\treturn d.Errf(\"malformed query matcher token: %s; must be in param=val format\", d.Val())\n\t\t\t}\n\t\t\turl.Values(*m).Add(before, after)\n\t\t}\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed query matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Match returns true if r matches m. An empty m matches an empty query string.\nfunc (m MatchQuery) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\n// An empty m matches an empty query string.\nfunc (m MatchQuery) MatchWithError(r *http.Request) (bool, error) {\n\t// If no query keys are configured, this only\n\t// matches an empty query string.\n\tif len(m) == 0 {\n\t\treturn len(r.URL.Query()) == 0, nil\n\t}\n\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\t// parse query string just once, for efficiency\n\tparsed, err := url.ParseQuery(r.URL.RawQuery)\n\tif err != nil {\n\t\t// Illegal query string. Likely bad escape sequence or unescaped literals.\n\t\t// Note that semicolons in query string have a controversial history. Summaries:\n\t\t// - https://github.com/golang/go/issues/50034\n\t\t// - https://github.com/golang/go/issues/25192\n\t\t// Despite the URL WHATWG spec mandating the use of & separators for query strings,\n\t\t// every URL parser implementation is different, and Filippo Valsorda rightly wrote:\n\t\t// \"Relying on parser alignment for security is doomed.\" Overall conclusion is that\n\t\t// splitting on & and rejecting ; in key=value pairs is safer than accepting raw ;.\n\t\t// We regard the Go team's decision as sound and thus reject malformed query strings.\n\t\treturn false, nil\n\t}\n\n\t// Count the amount of matched keys, to ensure we AND\n\t// between all configured query keys; all keys must\n\t// match at least one value.\n\tmatchedKeys := 0\n\tfor param, vals := range m {\n\t\tparam = repl.ReplaceAll(param, \"\")\n\t\tparamVal, found := parsed[param]\n\t\tif !found {\n\t\t\treturn false, nil\n\t\t}\n\t\tfor _, v := range vals {\n\t\t\tv = repl.ReplaceAll(v, \"\")\n\t\t\tif slices.Contains(paramVal, v) || v == \"*\" {\n\t\t\t\tmatchedKeys++\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\treturn matchedKeys == len(m), nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression query({'sort': 'asc'}) || query({'foo': ['*bar*', 'baz']})\nfunc (MatchQuery) CELLibrary(_ caddy.Context) (cel.Library, error) {\n\treturn CELMatcherImpl(\n\t\t\"query\",\n\t\t\"query_matcher_request_map\",\n\t\t[]*cel.Type{CELTypeJSON},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\tmapStrListStr, err := CELValueToMapStrList(data)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn MatchQuery(url.Values(mapStrListStr)), nil\n\t\t},\n\t)\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchHeader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.header\",\n\t\tNew: func() caddy.Module { return new(MatchHeader) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchHeader) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tif *m == nil {\n\t\t*m = make(map[string][]string)\n\t}\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tvar field, val string\n\t\tif !d.Args(&field) {\n\t\t\treturn d.Errf(\"malformed header matcher: expected field\")\n\t\t}\n\n\t\tif strings.HasPrefix(field, \"!\") {\n\t\t\tif len(field) == 1 {\n\t\t\t\treturn d.Errf(\"malformed header matcher: must have field name following ! character\")\n\t\t\t}\n\n\t\t\tfield = field[1:]\n\t\t\theaders := *m\n\t\t\theaders[field] = nil\n\t\t\tm = &headers\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.Errf(\"malformed header matcher: null matching headers cannot have a field value\")\n\t\t\t}\n\t\t} else {\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.Errf(\"malformed header matcher: expected both field and value\")\n\t\t\t}\n\n\t\t\t// If multiple header matchers with the same header field are defined,\n\t\t\t// we want to add the existing to the list of headers (will be OR'ed)\n\t\t\tval = d.Val()\n\t\t\thttp.Header(*m).Add(field, val)\n\t\t}\n\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed header matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Match returns true if r matches m.\nfunc (m MatchHeader) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchHeader) MatchWithError(r *http.Request) (bool, error) {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\treturn matchHeaders(r.Header, http.Header(m), r.Host, r.TransferEncoding, repl), nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression header({'content-type': 'image/png'})\n//\texpression header({'foo': ['bar', 'baz']}) // match bar or baz\nfunc (MatchHeader) CELLibrary(_ caddy.Context) (cel.Library, error) {\n\treturn CELMatcherImpl(\n\t\t\"header\",\n\t\t\"header_matcher_request_map\",\n\t\t[]*cel.Type{CELTypeJSON},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\tmapStrListStr, err := CELValueToMapStrList(data)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn MatchHeader(http.Header(mapStrListStr)), nil\n\t\t},\n\t)\n}\n\n// getHeaderFieldVals returns the field values for the given fieldName from input.\n// The host parameter should be obtained from the http.Request.Host field, and the\n// transferEncoding from http.Request.TransferEncoding, since net/http removes them\n// from the header map.\nfunc getHeaderFieldVals(input http.Header, fieldName, host string, transferEncoding []string) []string {\n\tfieldName = textproto.CanonicalMIMEHeaderKey(fieldName)\n\tif fieldName == \"Host\" && host != \"\" {\n\t\treturn []string{host}\n\t}\n\tif fieldName == \"Transfer-Encoding\" && input[fieldName] == nil {\n\t\treturn transferEncoding\n\t}\n\treturn input[fieldName]\n}\n\n// matchHeaders returns true if input matches the criteria in against without regex.\n// The host parameter should be obtained from the http.Request.Host field since\n// net/http removes it from the header map.\nfunc matchHeaders(input, against http.Header, host string, transferEncoding []string, repl *caddy.Replacer) bool {\n\tfor field, allowedFieldVals := range against {\n\t\tactualFieldVals := getHeaderFieldVals(input, field, host, transferEncoding)\n\t\tif allowedFieldVals != nil && len(allowedFieldVals) == 0 && actualFieldVals != nil {\n\t\t\t// a non-nil but empty list of allowed values means\n\t\t\t// match if the header field exists at all\n\t\t\tcontinue\n\t\t}\n\t\tif allowedFieldVals == nil && actualFieldVals == nil {\n\t\t\t// a nil list means match if the header does not exist at all\n\t\t\tcontinue\n\t\t}\n\t\tvar match bool\n\tfieldVals:\n\t\tfor _, actualFieldVal := range actualFieldVals {\n\t\t\tfor _, allowedFieldVal := range allowedFieldVals {\n\t\t\t\tif repl != nil {\n\t\t\t\t\tallowedFieldVal = repl.ReplaceAll(allowedFieldVal, \"\")\n\t\t\t\t}\n\t\t\t\tswitch {\n\t\t\t\tcase allowedFieldVal == \"*\":\n\t\t\t\t\tmatch = true\n\t\t\t\tcase strings.HasPrefix(allowedFieldVal, \"*\") && strings.HasSuffix(allowedFieldVal, \"*\"):\n\t\t\t\t\tmatch = strings.Contains(actualFieldVal, allowedFieldVal[1:len(allowedFieldVal)-1])\n\t\t\t\tcase strings.HasPrefix(allowedFieldVal, \"*\"):\n\t\t\t\t\tmatch = strings.HasSuffix(actualFieldVal, allowedFieldVal[1:])\n\t\t\t\tcase strings.HasSuffix(allowedFieldVal, \"*\"):\n\t\t\t\t\tmatch = strings.HasPrefix(actualFieldVal, allowedFieldVal[:len(allowedFieldVal)-1])\n\t\t\t\tdefault:\n\t\t\t\t\tmatch = actualFieldVal == allowedFieldVal\n\t\t\t\t}\n\t\t\t\tif match {\n\t\t\t\t\tbreak fieldVals\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif !match {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchHeaderRE) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.header_regexp\",\n\t\tNew: func() caddy.Module { return new(MatchHeaderRE) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchHeaderRE) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tif *m == nil {\n\t\t*m = make(map[string]*MatchRegexp)\n\t}\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tvar first, second, third string\n\t\tif !d.Args(&first, &second) {\n\t\t\treturn d.ArgErr()\n\t\t}\n\n\t\tvar name, field, val string\n\t\tif d.Args(&third) {\n\t\t\tname = first\n\t\t\tfield = second\n\t\t\tval = third\n\t\t} else {\n\t\t\tfield = first\n\t\t\tval = second\n\t\t}\n\n\t\t// Default to the named matcher's name, if no regexp name is provided\n\t\tif name == \"\" {\n\t\t\tname = d.GetContextString(caddyfile.MatcherNameCtxKey)\n\t\t}\n\n\t\t// If there's already a pattern for this field\n\t\t// then we would end up overwriting the old one\n\t\tif (*m)[field] != nil {\n\t\t\treturn d.Errf(\"header_regexp matcher can only be used once per named matcher, per header field: %s\", field)\n\t\t}\n\n\t\t(*m)[field] = &MatchRegexp{Pattern: val, Name: name}\n\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed header_regexp matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Match returns true if r matches m.\nfunc (m MatchHeaderRE) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchHeaderRE) MatchWithError(r *http.Request) (bool, error) {\n\tfor field, rm := range m {\n\t\tactualFieldVals := getHeaderFieldVals(r.Header, field, r.Host, r.TransferEncoding)\n\t\tmatch := false\n\tfieldVal:\n\t\tfor _, actualFieldVal := range actualFieldVals {\n\t\t\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\t\t\tif rm.Match(actualFieldVal, repl) {\n\t\t\t\tmatch = true\n\t\t\t\tbreak fieldVal\n\t\t\t}\n\t\t}\n\t\tif !match {\n\t\t\treturn false, nil\n\t\t}\n\t}\n\treturn true, nil\n}\n\n// Provision compiles m's regular expressions.\nfunc (m MatchHeaderRE) Provision(ctx caddy.Context) error {\n\tfor _, rm := range m {\n\t\terr := rm.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Validate validates m's regular expressions.\nfunc (m MatchHeaderRE) Validate() error {\n\tfor _, rm := range m {\n\t\terr := rm.Validate()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression header_regexp('foo', 'Field', 'fo+')\nfunc (MatchHeaderRE) CELLibrary(ctx caddy.Context) (cel.Library, error) {\n\tunnamedPattern, err := CELMatcherImpl(\n\t\t\"header_regexp\",\n\t\t\"header_regexp_request_string_string\",\n\t\t[]*cel.Type{cel.StringType, cel.StringType},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tparams, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tstrParams := params.([]string)\n\t\t\tmatcher := MatchHeaderRE{}\n\t\t\tmatcher[strParams[0]] = &MatchRegexp{\n\t\t\t\tPattern: strParams[1],\n\t\t\t\tName:    ctx.Value(MatcherNameCtxKey).(string),\n\t\t\t}\n\t\t\terr = matcher.Provision(ctx)\n\t\t\treturn matcher, err\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnamedPattern, err := CELMatcherImpl(\n\t\t\"header_regexp\",\n\t\t\"header_regexp_request_string_string_string\",\n\t\t[]*cel.Type{cel.StringType, cel.StringType, cel.StringType},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\trefStringList := reflect.TypeOf([]string{})\n\t\t\tparams, err := data.ConvertToNative(refStringList)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tstrParams := params.([]string)\n\t\t\tname := strParams[0]\n\t\t\tif name == \"\" {\n\t\t\t\tname = ctx.Value(MatcherNameCtxKey).(string)\n\t\t\t}\n\t\t\tmatcher := MatchHeaderRE{}\n\t\t\tmatcher[strParams[1]] = &MatchRegexp{\n\t\t\t\tPattern: strParams[2],\n\t\t\t\tName:    name,\n\t\t\t}\n\t\t\terr = matcher.Provision(ctx)\n\t\t\treturn matcher, err\n\t\t},\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tenvOpts := append(unnamedPattern.CompileOptions(), namedPattern.CompileOptions()...)\n\tprgOpts := append(unnamedPattern.ProgramOptions(), namedPattern.ProgramOptions()...)\n\treturn NewMatcherCELLibrary(envOpts, prgOpts), nil\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchProtocol) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.protocol\",\n\t\tNew: func() caddy.Module { return new(MatchProtocol) },\n\t}\n}\n\n// Match returns true if r matches m.\nfunc (m MatchProtocol) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchProtocol) MatchWithError(r *http.Request) (bool, error) {\n\tswitch string(m) {\n\tcase \"grpc\":\n\t\treturn strings.HasPrefix(r.Header.Get(\"content-type\"), \"application/grpc\"), nil\n\tcase \"https\":\n\t\treturn r.TLS != nil, nil\n\tcase \"http\":\n\t\treturn r.TLS == nil, nil\n\tcase \"http/1.0\":\n\t\treturn r.ProtoMajor == 1 && r.ProtoMinor == 0, nil\n\tcase \"http/1.0+\":\n\t\treturn r.ProtoAtLeast(1, 0), nil\n\tcase \"http/1.1\":\n\t\treturn r.ProtoMajor == 1 && r.ProtoMinor == 1, nil\n\tcase \"http/1.1+\":\n\t\treturn r.ProtoAtLeast(1, 1), nil\n\tcase \"http/2\":\n\t\treturn r.ProtoMajor == 2, nil\n\tcase \"http/2+\":\n\t\treturn r.ProtoAtLeast(2, 0), nil\n\tcase \"http/3\":\n\t\treturn r.ProtoMajor == 3, nil\n\tcase \"http/3+\":\n\t\treturn r.ProtoAtLeast(3, 0), nil\n\t}\n\treturn false, nil\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchProtocol) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tvar proto string\n\t\tif !d.Args(&proto) {\n\t\t\treturn d.Err(\"expected exactly one protocol\")\n\t\t}\n\t\t*m = MatchProtocol(proto)\n\t}\n\treturn nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression protocol('https')\nfunc (MatchProtocol) CELLibrary(_ caddy.Context) (cel.Library, error) {\n\treturn CELMatcherImpl(\n\t\t\"protocol\",\n\t\t\"protocol_request_string\",\n\t\t[]*cel.Type{cel.StringType},\n\t\tfunc(data ref.Val) (RequestMatcherWithError, error) {\n\t\t\tprotocolStr, ok := data.(types.String)\n\t\t\tif !ok {\n\t\t\t\treturn nil, errors.New(\"protocol argument was not a string\")\n\t\t\t}\n\t\t\treturn MatchProtocol(strings.ToLower(string(protocolStr))), nil\n\t\t},\n\t)\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchTLS) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.tls\",\n\t\tNew: func() caddy.Module { return new(MatchTLS) },\n\t}\n}\n\n// Match returns true if r matches m.\nfunc (m MatchTLS) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchTLS) MatchWithError(r *http.Request) (bool, error) {\n\tif r.TLS == nil {\n\t\treturn false, nil\n\t}\n\tif m.HandshakeComplete != nil {\n\t\tif (!*m.HandshakeComplete && r.TLS.HandshakeComplete) ||\n\t\t\t(*m.HandshakeComplete && !r.TLS.HandshakeComplete) {\n\t\t\treturn false, nil\n\t\t}\n\t}\n\treturn true, nil\n}\n\n// UnmarshalCaddyfile parses Caddyfile tokens for this matcher. Syntax:\n//\n// ... tls [early_data]\n//\n// EXPERIMENTAL SYNTAX: Subject to change.\nfunc (m *MatchTLS) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tif d.NextArg() {\n\t\t\tswitch d.Val() {\n\t\t\tcase \"early_data\":\n\t\t\t\tvar false bool\n\t\t\t\tm.HandshakeComplete = &false\n\t\t\tdefault:\n\t\t\t\treturn d.Errf(\"unrecognized option '%s'\", d.Val())\n\t\t\t}\n\t\t}\n\t\tif d.NextArg() {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed tls matcher: blocks are not supported yet\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchNot) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.not\",\n\t\tNew: func() caddy.Module { return new(MatchNot) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (m *MatchNot) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tmatcherSet, err := ParseCaddyfileNestedMatcherSet(d)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tm.MatcherSetsRaw = append(m.MatcherSetsRaw, matcherSet)\n\t}\n\treturn nil\n}\n\n// UnmarshalJSON satisfies json.Unmarshaler. It puts the JSON\n// bytes directly into m's MatcherSetsRaw field.\nfunc (m *MatchNot) UnmarshalJSON(data []byte) error {\n\treturn json.Unmarshal(data, &m.MatcherSetsRaw)\n}\n\n// MarshalJSON satisfies json.Marshaler by marshaling\n// m's raw matcher sets.\nfunc (m MatchNot) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(m.MatcherSetsRaw)\n}\n\n// Provision loads the matcher modules to be negated.\nfunc (m *MatchNot) Provision(ctx caddy.Context) error {\n\tmatcherSets, err := ctx.LoadModule(m, \"MatcherSetsRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading matcher sets: %v\", err)\n\t}\n\tfor _, modMap := range matcherSets.([]map[string]any) {\n\t\tvar ms MatcherSet\n\t\tfor _, modIface := range modMap {\n\t\t\tif mod, ok := modIface.(RequestMatcherWithError); ok {\n\t\t\t\tms = append(ms, mod)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif mod, ok := modIface.(RequestMatcher); ok {\n\t\t\t\tms = append(ms, mod)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"module is not a request matcher: %T\", modIface)\n\t\t}\n\t\tm.MatcherSets = append(m.MatcherSets, ms)\n\t}\n\treturn nil\n}\n\n// Match returns true if r matches m. Since this matcher negates\n// the embedded matchers, false is returned if any of its matcher\n// sets return true.\nfunc (m MatchNot) Match(r *http.Request) bool {\n\tmatch, _ := m.MatchWithError(r)\n\treturn match\n}\n\n// MatchWithError returns true if r matches m. Since this matcher\n// negates the embedded matchers, false is returned if any of its\n// matcher sets return true.\nfunc (m MatchNot) MatchWithError(r *http.Request) (bool, error) {\n\tfor _, ms := range m.MatcherSets {\n\t\tmatches, err := ms.MatchWithError(r)\n\t\tif err != nil {\n\t\t\treturn false, err\n\t\t}\n\t\tif matches {\n\t\t\treturn false, nil\n\t\t}\n\t}\n\treturn true, nil\n}\n\n// MatchRegexp is an embedable type for matching\n// using regular expressions. It adds placeholders\n// to the request's replacer.\ntype MatchRegexp struct {\n\t// A unique name for this regular expression. Optional,\n\t// but useful to prevent overwriting captures from other\n\t// regexp matchers.\n\tName string `json:\"name,omitempty\"`\n\n\t// The regular expression to evaluate, in RE2 syntax,\n\t// which is the same general syntax used by Go, Perl,\n\t// and Python. For details, see\n\t// [Go's regexp package](https://golang.org/pkg/regexp/).\n\t// Captures are accessible via placeholders. Unnamed\n\t// capture groups are exposed as their numeric, 1-based\n\t// index, while named capture groups are available by\n\t// the capture group name.\n\tPattern string `json:\"pattern\"`\n\n\tcompiled *regexp.Regexp\n}\n\n// Provision compiles the regular expression.\nfunc (mre *MatchRegexp) Provision(caddy.Context) error {\n\tre, err := regexp.Compile(mre.Pattern)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"compiling matcher regexp %s: %v\", mre.Pattern, err)\n\t}\n\tmre.compiled = re\n\treturn nil\n}\n\n// Validate ensures mre is set up correctly.\nfunc (mre *MatchRegexp) Validate() error {\n\tif mre.Name != \"\" && !wordRE.MatchString(mre.Name) {\n\t\treturn fmt.Errorf(\"invalid regexp name (must contain only word characters): %s\", mre.Name)\n\t}\n\treturn nil\n}\n\n// Match returns true if input matches the compiled regular\n// expression in mre. It sets values on the replacer repl\n// associated with capture groups, using the given scope\n// (namespace).\nfunc (mre *MatchRegexp) Match(input string, repl *caddy.Replacer) bool {\n\tmatches := mre.compiled.FindStringSubmatch(input)\n\tif matches == nil {\n\t\treturn false\n\t}\n\n\t// save all capture groups, first by index\n\tfor i, match := range matches {\n\t\tkeySuffix := \".\" + strconv.Itoa(i)\n\t\tif mre.Name != \"\" {\n\t\t\trepl.Set(regexpPlaceholderPrefix+\".\"+mre.Name+keySuffix, match)\n\t\t}\n\t\trepl.Set(regexpPlaceholderPrefix+keySuffix, match)\n\t}\n\n\t// then by name\n\tfor i, name := range mre.compiled.SubexpNames() {\n\t\t// skip the first element (the full match), and empty names\n\t\tif i == 0 || name == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tkeySuffix := \".\" + name\n\t\tif mre.Name != \"\" {\n\t\t\trepl.Set(regexpPlaceholderPrefix+\".\"+mre.Name+keySuffix, matches[i])\n\t\t}\n\t\trepl.Set(regexpPlaceholderPrefix+keySuffix, matches[i])\n\t}\n\n\treturn true\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (mre *MatchRegexp) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\t// If this is the second iteration of the loop\n\t\t// then there's more than one path_regexp matcher\n\t\t// and we would end up overwriting the old one\n\t\tif mre.Pattern != \"\" {\n\t\t\treturn d.Err(\"regular expression can only be used once per named matcher\")\n\t\t}\n\n\t\targs := d.RemainingArgs()\n\t\tswitch len(args) {\n\t\tcase 1:\n\t\t\tmre.Pattern = args[0]\n\t\tcase 2:\n\t\t\tmre.Name = args[0]\n\t\t\tmre.Pattern = args[1]\n\t\tdefault:\n\t\t\treturn d.ArgErr()\n\t\t}\n\n\t\t// Default to the named matcher's name, if no regexp name is provided\n\t\tif mre.Name == \"\" {\n\t\t\tmre.Name = d.GetContextString(caddyfile.MatcherNameCtxKey)\n\t\t}\n\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed path_regexp matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// ParseCaddyfileNestedMatcher parses the Caddyfile tokens for a nested\n// matcher set, and returns its raw module map value.\nfunc ParseCaddyfileNestedMatcherSet(d *caddyfile.Dispenser) (caddy.ModuleMap, error) {\n\tmatcherMap := make(map[string]any)\n\n\t// in case there are multiple instances of the same matcher, concatenate\n\t// their tokens (we expect that UnmarshalCaddyfile should be able to\n\t// handle more than one segment); otherwise, we'd overwrite other\n\t// instances of the matcher in this set\n\ttokensByMatcherName := make(map[string][]caddyfile.Token)\n\tfor nesting := d.Nesting(); d.NextArg() || d.NextBlock(nesting); {\n\t\tmatcherName := d.Val()\n\t\ttokensByMatcherName[matcherName] = append(tokensByMatcherName[matcherName], d.NextSegment()...)\n\t}\n\n\tfor matcherName, tokens := range tokensByMatcherName {\n\t\tmod, err := caddy.GetModule(\"http.matchers.\" + matcherName)\n\t\tif err != nil {\n\t\t\treturn nil, d.Errf(\"getting matcher module '%s': %v\", matcherName, err)\n\t\t}\n\t\tunm, ok := mod.New().(caddyfile.Unmarshaler)\n\t\tif !ok {\n\t\t\treturn nil, d.Errf(\"matcher module '%s' is not a Caddyfile unmarshaler\", matcherName)\n\t\t}\n\t\terr = unm.UnmarshalCaddyfile(caddyfile.NewDispenser(tokens))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif rm, ok := unm.(RequestMatcherWithError); ok {\n\t\t\tmatcherMap[matcherName] = rm\n\t\t\tcontinue\n\t\t}\n\t\tif rm, ok := unm.(RequestMatcher); ok {\n\t\t\tmatcherMap[matcherName] = rm\n\t\t\tcontinue\n\t\t}\n\t\treturn nil, fmt.Errorf(\"matcher module '%s' is not a request matcher\", matcherName)\n\t}\n\n\t// we should now have a functional matcher, but we also\n\t// need to be able to marshal as JSON, otherwise config\n\t// adaptation will be missing the matchers!\n\tmatcherSet := make(caddy.ModuleMap)\n\tfor name, matcher := range matcherMap {\n\t\tjsonBytes, err := json.Marshal(matcher)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"marshaling %T matcher: %v\", matcher, err)\n\t\t}\n\t\tmatcherSet[name] = jsonBytes\n\t}\n\n\treturn matcherSet, nil\n}\n\nvar wordRE = regexp.MustCompile(`\\w+`)\n\nconst regexpPlaceholderPrefix = \"http.regexp\"\n\n// MatcherErrorVarKey is the key used for the variable that\n// holds an optional error emitted from a request matcher,\n// to short-circuit the handler chain, since matchers cannot\n// return errors via the RequestMatcher interface.\n//\n// Deprecated: Matchers should implement RequestMatcherWithError\n// which can return an error directly, instead of smuggling it\n// through the vars map.\nconst MatcherErrorVarKey = \"matchers.error\"\n\n// Interface guards\nvar (\n\t_ RequestMatcherWithError = (*MatchHost)(nil)\n\t_ caddy.Provisioner       = (*MatchHost)(nil)\n\t_ RequestMatcherWithError = (*MatchPath)(nil)\n\t_ RequestMatcherWithError = (*MatchPathRE)(nil)\n\t_ caddy.Provisioner       = (*MatchPathRE)(nil)\n\t_ RequestMatcherWithError = (*MatchMethod)(nil)\n\t_ RequestMatcherWithError = (*MatchQuery)(nil)\n\t_ RequestMatcherWithError = (*MatchHeader)(nil)\n\t_ RequestMatcherWithError = (*MatchHeaderRE)(nil)\n\t_ caddy.Provisioner       = (*MatchHeaderRE)(nil)\n\t_ RequestMatcherWithError = (*MatchProtocol)(nil)\n\t_ RequestMatcherWithError = (*MatchNot)(nil)\n\t_ caddy.Provisioner       = (*MatchNot)(nil)\n\t_ caddy.Provisioner       = (*MatchRegexp)(nil)\n\n\t_ caddyfile.Unmarshaler = (*MatchHost)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchPath)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchPathRE)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchMethod)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchQuery)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchHeader)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchHeaderRE)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchProtocol)(nil)\n\t_ caddyfile.Unmarshaler = (*VarsMatcher)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchVarsRE)(nil)\n\n\t_ CELLibraryProducer = (*MatchHost)(nil)\n\t_ CELLibraryProducer = (*MatchPath)(nil)\n\t_ CELLibraryProducer = (*MatchPathRE)(nil)\n\t_ CELLibraryProducer = (*MatchMethod)(nil)\n\t_ CELLibraryProducer = (*MatchQuery)(nil)\n\t_ CELLibraryProducer = (*MatchHeader)(nil)\n\t_ CELLibraryProducer = (*MatchHeaderRE)(nil)\n\t_ CELLibraryProducer = (*MatchProtocol)(nil)\n\t_ CELLibraryProducer = (*VarsMatcher)(nil)\n\t_ CELLibraryProducer = (*MatchVarsRE)(nil)\n\n\t_ json.Marshaler   = (*MatchNot)(nil)\n\t_ json.Unmarshaler = (*MatchNot)(nil)\n)\n",
    "source_file": "modules/caddyhttp/matchers.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Invoke{})\n}\n\n// Invoke implements a handler that compiles and executes a\n// named route that was defined on the server.\n//\n// EXPERIMENTAL: Subject to change or removal.\ntype Invoke struct {\n\t// Name is the key of the named route to execute\n\tName string `json:\"name,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Invoke) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.invoke\",\n\t\tNew: func() caddy.Module { return new(Invoke) },\n\t}\n}\n\nfunc (invoke *Invoke) ServeHTTP(w http.ResponseWriter, r *http.Request, next Handler) error {\n\tserver := r.Context().Value(ServerCtxKey).(*Server)\n\tif route, ok := server.NamedRoutes[invoke.Name]; ok {\n\t\treturn route.Compile(next).ServeHTTP(w, r)\n\t}\n\treturn fmt.Errorf(\"invoke: route '%s' not found\", invoke.Name)\n}\n\n// Interface guards\nvar (\n\t_ MiddlewareHandler = (*Invoke)(nil)\n)\n",
    "source_file": "modules/caddyhttp/invoke.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyhttp\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\tweakrand \"math/rand\"\n\t\"path\"\n\t\"runtime\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// Error is a convenient way for a Handler to populate the\n// essential fields of a HandlerError. If err is itself a\n// HandlerError, then any essential fields that are not\n// set will be populated.\nfunc Error(statusCode int, err error) HandlerError {\n\tconst idLen = 9\n\tvar he HandlerError\n\tif errors.As(err, &he) {\n\t\tif he.ID == \"\" {\n\t\t\the.ID = randString(idLen, true)\n\t\t}\n\t\tif he.Trace == \"\" {\n\t\t\the.Trace = trace()\n\t\t}\n\t\tif he.StatusCode == 0 {\n\t\t\the.StatusCode = statusCode\n\t\t}\n\t\treturn he\n\t}\n\treturn HandlerError{\n\t\tID:         randString(idLen, true),\n\t\tStatusCode: statusCode,\n\t\tErr:        err,\n\t\tTrace:      trace(),\n\t}\n}\n\n// HandlerError is a serializable representation of\n// an error from within an HTTP handler.\ntype HandlerError struct {\n\tErr        error // the original error value and message\n\tStatusCode int   // the HTTP status code to associate with this error\n\n\tID    string // generated; for identifying this error in logs\n\tTrace string // produced from call stack\n}\n\nfunc (e HandlerError) Error() string {\n\tvar s string\n\tif e.ID != \"\" {\n\t\ts += fmt.Sprintf(\"{id=%s}\", e.ID)\n\t}\n\tif e.Trace != \"\" {\n\t\ts += \" \" + e.Trace\n\t}\n\tif e.StatusCode != 0 {\n\t\ts += fmt.Sprintf(\": HTTP %d\", e.StatusCode)\n\t}\n\tif e.Err != nil {\n\t\ts += \": \" + e.Err.Error()\n\t}\n\treturn strings.TrimSpace(s)\n}\n\n// Unwrap returns the underlying error value. See the `errors` package for info.\nfunc (e HandlerError) Unwrap() error { return e.Err }\n\n// randString returns a string of n random characters.\n// It is not even remotely secure OR a proper distribution.\n// But it's good enough for some things. It excludes certain\n// confusing characters like I, l, 1, 0, O, etc. If sameCase\n// is true, then uppercase letters are excluded.\nfunc randString(n int, sameCase bool) string {\n\tif n <= 0 {\n\t\treturn \"\"\n\t}\n\tdict := []byte(\"abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRTUVWXY23456789\")\n\tif sameCase {\n\t\tdict = []byte(\"abcdefghijkmnpqrstuvwxyz0123456789\")\n\t}\n\tb := make([]byte, n)\n\tfor i := range b {\n\t\t//nolint:gosec\n\t\tb[i] = dict[weakrand.Int63()%int64(len(dict))]\n\t}\n\treturn string(b)\n}\n\nfunc trace() string {\n\tif pc, file, line, ok := runtime.Caller(2); ok {\n\t\tfilename := path.Base(file)\n\t\tpkgAndFuncName := path.Base(runtime.FuncForPC(pc).Name())\n\t\treturn fmt.Sprintf(\"%s (%s:%d)\", pkgAndFuncName, filename, line)\n\t}\n\treturn \"\"\n}\n\n// ErrorCtxKey is the context key to use when storing\n// an error (for use with context.Context).\nconst ErrorCtxKey = caddy.CtxKey(\"handler_chain_error\")\n",
    "source_file": "modules/caddyhttp/errors.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(PEMLoader{})\n}\n\n// PEMLoader loads certificates and their associated keys by\n// decoding their PEM blocks directly. This has the advantage\n// of not needing to store them on disk at all.\ntype PEMLoader []CertKeyPEMPair\n\n// Provision implements caddy.Provisioner.\nfunc (pl PEMLoader) Provision(ctx caddy.Context) error {\n\trepl, ok := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif !ok {\n\t\trepl = caddy.NewReplacer()\n\t}\n\tfor k, pair := range pl {\n\t\tfor i, tag := range pair.Tags {\n\t\t\tpair.Tags[i] = repl.ReplaceKnown(tag, \"\")\n\t\t}\n\t\tpl[k] = CertKeyPEMPair{\n\t\t\tCertificatePEM: repl.ReplaceKnown(pair.CertificatePEM, \"\"),\n\t\t\tKeyPEM:         repl.ReplaceKnown(pair.KeyPEM, \"\"),\n\t\t\tTags:           pair.Tags,\n\t\t}\n\t}\n\treturn nil\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (PEMLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.certificates.load_pem\",\n\t\tNew: func() caddy.Module { return new(PEMLoader) },\n\t}\n}\n\n// CertKeyPEMPair pairs certificate and key PEM blocks.\ntype CertKeyPEMPair struct {\n\t// The certificate (public key) in PEM format.\n\tCertificatePEM string `json:\"certificate\"`\n\n\t// The private key in PEM format.\n\tKeyPEM string `json:\"key\"`\n\n\t// Arbitrary values to associate with this certificate.\n\t// Can be useful when you want to select a particular\n\t// certificate when there may be multiple valid candidates.\n\tTags []string `json:\"tags,omitempty\"`\n}\n\n// LoadCertificates returns the certificates contained in pl.\nfunc (pl PEMLoader) LoadCertificates() ([]Certificate, error) {\n\tcerts := make([]Certificate, 0, len(pl))\n\tfor i, pair := range pl {\n\t\tcert, err := tls.X509KeyPair([]byte(pair.CertificatePEM), []byte(pair.KeyPEM))\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"PEM pair %d: %v\", i, err)\n\t\t}\n\t\tcerts = append(certs, Certificate{\n\t\t\tCertificate: cert,\n\t\t\tTags:        pair.Tags,\n\t\t})\n\t}\n\treturn certs, nil\n}\n\n// Interface guard\nvar (\n\t_ CertificateLoader = (PEMLoader)(nil)\n\t_ caddy.Provisioner = (PEMLoader)(nil)\n)\n",
    "source_file": "modules/caddytls/pemloader.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"slices\"\n\n\t\"github.com/caddyserver/certmagic\"\n\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\n// CustomCertSelectionPolicy represents a policy for selecting the certificate\n// used to complete a handshake when there may be multiple options. All fields\n// specified must match the candidate certificate for it to be chosen.\n// This was needed to solve https://github.com/caddyserver/caddy/issues/2588.\ntype CustomCertSelectionPolicy struct {\n\t// The certificate must have one of these serial numbers.\n\tSerialNumber []bigInt `json:\"serial_number,omitempty\"`\n\n\t// The certificate must have one of these organization names.\n\tSubjectOrganization []string `json:\"subject_organization,omitempty\"`\n\n\t// The certificate must use this public key algorithm.\n\tPublicKeyAlgorithm PublicKeyAlgorithm `json:\"public_key_algorithm,omitempty\"`\n\n\t// The certificate must have at least one of the tags in the list.\n\tAnyTag []string `json:\"any_tag,omitempty\"`\n\n\t// The certificate must have all of the tags in the list.\n\tAllTags []string `json:\"all_tags,omitempty\"`\n}\n\n// SelectCertificate implements certmagic.CertificateSelector. It\n// only chooses a certificate that at least meets the criteria in\n// p. It then chooses the first non-expired certificate that is\n// compatible with the client. If none are valid, it chooses the\n// first viable candidate anyway.\nfunc (p CustomCertSelectionPolicy) SelectCertificate(hello *tls.ClientHelloInfo, choices []certmagic.Certificate) (certmagic.Certificate, error) {\n\tviable := make([]certmagic.Certificate, 0, len(choices))\n\nnextChoice:\n\tfor _, cert := range choices {\n\t\tif len(p.SerialNumber) > 0 {\n\t\t\tvar found bool\n\t\t\tfor _, sn := range p.SerialNumber {\n\t\t\t\tsnInt := sn.Int // avoid taking address of iteration variable (gosec warning)\n\t\t\t\tif cert.Leaf.SerialNumber.Cmp(&snInt) == 0 {\n\t\t\t\t\tfound = true\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t\tif !found {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif len(p.SubjectOrganization) > 0 {\n\t\t\tfound := slices.ContainsFunc(p.SubjectOrganization, func(s string) bool {\n\t\t\t\treturn slices.Contains(cert.Leaf.Subject.Organization, s)\n\t\t\t})\n\t\t\tif !found {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif p.PublicKeyAlgorithm != PublicKeyAlgorithm(x509.UnknownPublicKeyAlgorithm) &&\n\t\t\tPublicKeyAlgorithm(cert.Leaf.PublicKeyAlgorithm) != p.PublicKeyAlgorithm {\n\t\t\tcontinue\n\t\t}\n\n\t\tif len(p.AnyTag) > 0 {\n\t\t\tfound := slices.ContainsFunc(p.AnyTag, cert.HasTag)\n\t\t\tif !found {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif len(p.AllTags) > 0 {\n\t\t\tfor _, tag := range p.AllTags {\n\t\t\t\tif !cert.HasTag(tag) {\n\t\t\t\t\tcontinue nextChoice\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// this certificate at least meets the policy's requirements,\n\t\t// but we still have to check expiration and compatibility\n\t\tviable = append(viable, cert)\n\t}\n\n\tif len(viable) == 0 {\n\t\treturn certmagic.Certificate{}, fmt.Errorf(\"no certificates matched custom selection policy\")\n\t}\n\n\treturn certmagic.DefaultCertificateSelector(hello, viable)\n}\n\n// UnmarshalCaddyfile sets up the CustomCertSelectionPolicy from Caddyfile tokens. Syntax:\n//\n//\tcert_selection {\n//\t\tall_tags             <values...>\n//\t\tany_tag              <values...>\n//\t\tpublic_key_algorithm <dsa|ecdsa|rsa>\n//\t\tserial_number        <big_integers...>\n//\t\tsubject_organization <values...>\n//\t}\nfunc (p *CustomCertSelectionPolicy) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t_, wrapper := d.Next(), d.Val() // consume wrapper name\n\n\t// No same-line options are supported\n\tif d.CountRemainingArgs() > 0 {\n\t\treturn d.ArgErr()\n\t}\n\n\tvar hasPublicKeyAlgorithm bool\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\toptionName := d.Val()\n\t\tswitch optionName {\n\t\tcase \"all_tags\":\n\t\t\tif d.CountRemainingArgs() == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tp.AllTags = append(p.AllTags, d.RemainingArgs()...)\n\t\tcase \"any_tag\":\n\t\t\tif d.CountRemainingArgs() == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tp.AnyTag = append(p.AnyTag, d.RemainingArgs()...)\n\t\tcase \"public_key_algorithm\":\n\t\t\tif hasPublicKeyAlgorithm {\n\t\t\t\treturn d.Errf(\"duplicate %s option '%s'\", wrapper, optionName)\n\t\t\t}\n\t\t\tif d.CountRemainingArgs() != 1 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\td.NextArg()\n\t\t\tif err := p.PublicKeyAlgorithm.UnmarshalJSON([]byte(d.Val())); err != nil {\n\t\t\t\treturn d.Errf(\"parsing %s option '%s': %v\", wrapper, optionName, err)\n\t\t\t}\n\t\t\thasPublicKeyAlgorithm = true\n\t\tcase \"serial_number\":\n\t\t\tif d.CountRemainingArgs() == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tfor d.NextArg() {\n\t\t\t\tval, bi := d.Val(), bigInt{}\n\t\t\t\t_, ok := bi.SetString(val, 10)\n\t\t\t\tif !ok {\n\t\t\t\t\treturn d.Errf(\"parsing %s option '%s': invalid big.int value %s\", wrapper, optionName, val)\n\t\t\t\t}\n\t\t\t\tp.SerialNumber = append(p.SerialNumber, bi)\n\t\t\t}\n\t\tcase \"subject_organization\":\n\t\t\tif d.CountRemainingArgs() == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tp.SubjectOrganization = append(p.SubjectOrganization, d.RemainingArgs()...)\n\t\tdefault:\n\t\t\treturn d.ArgErr()\n\t\t}\n\n\t\t// No nested blocks are supported\n\t\tif d.NextBlock(nesting + 1) {\n\t\t\treturn d.Errf(\"malformed %s option '%s': blocks are not supported\", wrapper, optionName)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// bigInt is a big.Int type that interops with JSON encodings as a string.\ntype bigInt struct{ big.Int }\n\nfunc (bi bigInt) MarshalJSON() ([]byte, error) {\n\treturn json.Marshal(bi.String())\n}\n\nfunc (bi *bigInt) UnmarshalJSON(p []byte) error {\n\tif string(p) == \"null\" {\n\t\treturn nil\n\t}\n\tvar stringRep string\n\terr := json.Unmarshal(p, &stringRep)\n\tif err != nil {\n\t\treturn err\n\t}\n\t_, ok := bi.SetString(stringRep, 10)\n\tif !ok {\n\t\treturn fmt.Errorf(\"not a valid big integer: %s\", p)\n\t}\n\treturn nil\n}\n\n// Interface guard\nvar _ caddyfile.Unmarshaler = (*CustomCertSelectionPolicy)(nil)\n",
    "source_file": "modules/caddytls/certselection.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/klauspost/cpuid/v2\"\n)\n\n// CipherSuiteNameSupported returns true if name is\n// a supported cipher suite.\nfunc CipherSuiteNameSupported(name string) bool {\n\treturn CipherSuiteID(name) != 0\n}\n\n// CipherSuiteID returns the ID of the cipher suite associated with\n// the given name, or 0 if the name is not recognized/supported.\nfunc CipherSuiteID(name string) uint16 {\n\tfor _, cs := range SupportedCipherSuites() {\n\t\tif cs.Name == name {\n\t\t\treturn cs.ID\n\t\t}\n\t}\n\treturn 0\n}\n\n// SupportedCipherSuites returns a list of all the cipher suites\n// Caddy supports. The list is NOT ordered by security preference.\nfunc SupportedCipherSuites() []*tls.CipherSuite {\n\treturn tls.CipherSuites()\n}\n\n// defaultCipherSuites is the ordered list of all the cipher\n// suites we want to support by default, assuming AES-NI\n// (hardware acceleration for AES).\nvar defaultCipherSuitesWithAESNI = []uint16{\n\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\n\ttls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,\n\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\n\ttls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\n\ttls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,\n\ttls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,\n}\n\n// defaultCipherSuites is the ordered list of all the cipher\n// suites we want to support by default, assuming lack of\n// AES-NI (NO hardware acceleration for AES).\nvar defaultCipherSuitesWithoutAESNI = []uint16{\n\ttls.TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305,\n\ttls.TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305,\n\ttls.TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384,\n\ttls.TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384,\n\ttls.TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256,\n\ttls.TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256,\n}\n\n// getOptimalDefaultCipherSuites returns an appropriate cipher\n// suite to use depending on the hardware support for AES.\n//\n// See https://github.com/caddyserver/caddy/issues/1674\nfunc getOptimalDefaultCipherSuites() []uint16 {\n\tif cpuid.CPU.Supports(cpuid.AESNI) {\n\t\treturn defaultCipherSuitesWithAESNI\n\t}\n\treturn defaultCipherSuitesWithoutAESNI\n}\n\n// SupportedCurves is the unordered map of supported curves\n// or key exchange mechanisms (\"curves\" traditionally).\n// https://golang.org/pkg/crypto/tls/#CurveID\nvar SupportedCurves = map[string]tls.CurveID{\n\t\"x25519mlkem768\": tls.X25519MLKEM768,\n\t\"x25519\":         tls.X25519,\n\t\"secp256r1\":      tls.CurveP256,\n\t\"secp384r1\":      tls.CurveP384,\n\t\"secp521r1\":      tls.CurveP521,\n}\n\n// supportedCertKeyTypes is all the key types that are supported\n// for certificates that are obtained through ACME.\nvar supportedCertKeyTypes = map[string]certmagic.KeyType{\n\t\"rsa2048\": certmagic.RSA2048,\n\t\"rsa4096\": certmagic.RSA4096,\n\t\"p256\":    certmagic.P256,\n\t\"p384\":    certmagic.P384,\n\t\"ed25519\": certmagic.ED25519,\n}\n\n// defaultCurves is the list of only the curves or key exchange\n// mechanisms we want to use by default. The order is irrelevant.\n//\n// This list should only include mechanisms which are fast by\n// design (e.g. X25519) and those for which an optimized assembly\n// implementation exists (e.g. P256). The latter ones can be\n// found here:\n// https://github.com/golang/go/tree/master/src/crypto/elliptic\nvar defaultCurves = []tls.CurveID{\n\ttls.X25519MLKEM768,\n\ttls.X25519,\n\ttls.CurveP256,\n}\n\n// SupportedProtocols is a map of supported protocols.\nvar SupportedProtocols = map[string]uint16{\n\t\"tls1.2\": tls.VersionTLS12,\n\t\"tls1.3\": tls.VersionTLS13,\n}\n\n// unsupportedProtocols is a map of unsupported protocols.\n// Used for logging only, not enforcement.\nvar unsupportedProtocols = map[string]uint16{\n\t//nolint:staticcheck\n\t\"ssl3.0\": tls.VersionSSL30,\n\t\"tls1.0\": tls.VersionTLS10,\n\t\"tls1.1\": tls.VersionTLS11,\n}\n\n// publicKeyAlgorithms is the map of supported public key algorithms.\nvar publicKeyAlgorithms = map[string]x509.PublicKeyAlgorithm{\n\t\"rsa\":   x509.RSA,\n\t\"dsa\":   x509.DSA,\n\t\"ecdsa\": x509.ECDSA,\n}\n\n// ProtocolName returns the standard name for the passed protocol version ID\n// (e.g.  \"TLS1.3\") or a fallback representation of the ID value if the version\n// is not supported.\nfunc ProtocolName(id uint16) string {\n\tfor k, v := range SupportedProtocols {\n\t\tif v == id {\n\t\t\treturn k\n\t\t}\n\t}\n\n\tfor k, v := range unsupportedProtocols {\n\t\tif v == id {\n\t\t\treturn k\n\t\t}\n\t}\n\n\treturn fmt.Sprintf(\"0x%04x\", id)\n}\n",
    "source_file": "modules/caddytls/values.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddytls\n\nimport (\n\t\"context\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io/fs\"\n\tweakrand \"math/rand/v2\"\n\t\"path\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/cloudflare/circl/hpke\"\n\t\"github.com/cloudflare/circl/kem\"\n\t\"github.com/libdns/libdns\"\n\t\"go.uber.org/zap\"\n\t\"golang.org/x/crypto/cryptobyte\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(ECHDNSPublisher{})\n}\n\n// ECH enables Encrypted ClientHello (ECH) and configures its management.\n//\n// ECH helps protect site names (also called \"server names\" or \"domain names\"\n// or \"SNI\"), which are normally sent over plaintext when establishing a TLS\n// connection. With ECH, the true ClientHello is encrypted and wrapped by an\n// \"outer\" ClientHello that uses a more generic, shared server name that is\n// publicly known.\n//\n// Clients need to know which public name (and other parameters) to use when\n// connecting to a site with ECH, and the methods for this vary; however,\n// major browsers support reading ECH configurations from DNS records (which\n// is typically only secure when DNS-over-HTTPS or DNS-over-TLS is enabled in\n// the client). Caddy has the ability to automatically publish ECH configs to\n// DNS records if a DNS provider is configured either in the TLS app or with\n// each individual publication config object. (Requires a custom build with a\n// DNS provider module.)\n//\n// ECH requires at least TLS 1.3, so any TLS connection policies with ECH\n// applied will automatically upgrade the minimum TLS version to 1.3, even if\n// configured to a lower version.\n//\n// Note that, as of Caddy 2.10.0 (~March 2025), ECH keys are not automatically\n// rotated due to a limitation in the Go standard library (see\n// https://github.com/golang/go/issues/71920). This should be resolved when\n// Go 1.25 is released (~Aug. 2025), and Caddy will be updated to automatically\n// rotate ECH keys/configs at that point.\n//\n// EXPERIMENTAL: Subject to change.\ntype ECH struct {\n\t// The list of ECH configurations for which to automatically generate\n\t// and rotate keys. At least one is required to enable ECH.\n\t//\n\t// It is strongly recommended to use as few ECH configs as possible\n\t// to maximize the size of your anonymity set (see the ECH specification\n\t// for a definition). Typically, each server should have only one public\n\t// name, i.e. one config in this list.\n\tConfigs []ECHConfiguration `json:\"configs,omitempty\"`\n\n\t// Publication describes ways to publish ECH configs for clients to\n\t// discover and use. Without publication, most clients will not use\n\t// ECH at all, and those that do will suffer degraded performance.\n\t//\n\t// Most major browsers support ECH by way of publication to HTTPS\n\t// DNS RRs. (This also typically requires that they use DoH or DoT.)\n\tPublication []*ECHPublication `json:\"publication,omitempty\"`\n\n\t// map of public_name to list of configs\n\tconfigs map[string][]echConfig\n}\n\n// Provision loads or creates ECH configs and returns outer names (for certificate\n// management), but does not publish any ECH configs. The DNS module is used as\n// a default for later publishing if needed.\nfunc (ech *ECH) Provision(ctx caddy.Context) ([]string, error) {\n\tlogger := ctx.Logger().Named(\"ech\")\n\n\t// set up publication modules before we need to obtain a lock in storage,\n\t// since this is strictly internal and doesn't require synchronization\n\tfor i, pub := range ech.Publication {\n\t\tmods, err := ctx.LoadModule(pub, \"PublishersRaw\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"loading ECH publication modules: %v\", err)\n\t\t}\n\t\tfor _, modIface := range mods.(map[string]any) {\n\t\t\tech.Publication[i].publishers = append(ech.Publication[i].publishers, modIface.(ECHPublisher))\n\t\t}\n\t}\n\n\t// the rest of provisioning needs an exclusive lock so that instances aren't\n\t// stepping on each other when setting up ECH configs\n\tstorage := ctx.Storage()\n\tconst echLockName = \"ech_provision\"\n\tif err := storage.Lock(ctx, echLockName); err != nil {\n\t\treturn nil, err\n\t}\n\tdefer func() {\n\t\tif err := storage.Unlock(ctx, echLockName); err != nil {\n\t\t\tlogger.Error(\"unable to unlock ECH provisioning in storage\", zap.Error(err))\n\t\t}\n\t}()\n\n\tvar outerNames []string //nolint:prealloc // (FALSE POSITIVE - see https://github.com/alexkohler/prealloc/issues/30)\n\n\t// start by loading all the existing configs (even the older ones on the way out,\n\t// since some clients may still be using them if they haven't yet picked up on the\n\t// new configs)\n\tcfgKeys, err := storage.List(ctx, echConfigsKey, false)\n\tif err != nil && !errors.Is(err, fs.ErrNotExist) { // OK if dir doesn't exist; it will be created\n\t\treturn nil, err\n\t}\n\tfor _, cfgKey := range cfgKeys {\n\t\tcfg, err := loadECHConfig(ctx, path.Base(cfgKey))\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\t// if any part of the config's folder was corrupted, the load function will\n\t\t// clean it up and not return an error, since configs are immutable and\n\t\t// fairly ephemeral... so just check that we actually got a populated config\n\t\tif cfg.configBin == nil || cfg.privKeyBin == nil {\n\t\t\tcontinue\n\t\t}\n\t\tlogger.Debug(\"loaded ECH config\",\n\t\t\tzap.String(\"public_name\", cfg.RawPublicName),\n\t\t\tzap.Uint8(\"id\", cfg.ConfigID))\n\t\tech.configs[cfg.RawPublicName] = append(ech.configs[cfg.RawPublicName], cfg)\n\t\touterNames = append(outerNames, cfg.RawPublicName)\n\t}\n\n\t// all existing configs are now loaded; see if we need to make any new ones\n\t// based on the input configuration, and also mark the most recent one(s) as\n\t// current/active, so they can be used for ECH retries\n\tfor _, cfg := range ech.Configs {\n\t\tpublicName := strings.ToLower(strings.TrimSpace(cfg.PublicName))\n\n\t\tif list, ok := ech.configs[publicName]; ok && len(list) > 0 {\n\t\t\t// at least one config with this public name was loaded, so find the\n\t\t\t// most recent one and mark it as active to be used with retries\n\t\t\tvar mostRecentDate time.Time\n\t\t\tvar mostRecentIdx int\n\t\t\tfor i, c := range list {\n\t\t\t\tif mostRecentDate.IsZero() || c.meta.Created.After(mostRecentDate) {\n\t\t\t\t\tmostRecentDate = c.meta.Created\n\t\t\t\t\tmostRecentIdx = i\n\t\t\t\t}\n\t\t\t}\n\t\t\tlist[mostRecentIdx].sendAsRetry = true\n\t\t} else {\n\t\t\t// no config with this public name was loaded, so create one\n\t\t\techCfg, err := generateAndStoreECHConfig(ctx, publicName)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tlogger.Debug(\"generated new ECH config\",\n\t\t\t\tzap.String(\"public_name\", echCfg.RawPublicName),\n\t\t\t\tzap.Uint8(\"id\", echCfg.ConfigID))\n\t\t\tech.configs[publicName] = append(ech.configs[publicName], echCfg)\n\t\t\touterNames = append(outerNames, publicName)\n\t\t}\n\t}\n\n\treturn outerNames, nil\n}\n\nfunc (t *TLS) publishECHConfigs() error {\n\tlogger := t.logger.Named(\"ech\")\n\n\t// make publication exclusive, since we don't need to repeat this unnecessarily\n\tstorage := t.ctx.Storage()\n\tconst echLockName = \"ech_publish\"\n\tif err := storage.Lock(t.ctx, echLockName); err != nil {\n\t\treturn err\n\t}\n\tdefer func() {\n\t\tif err := storage.Unlock(t.ctx, echLockName); err != nil {\n\t\t\tlogger.Error(\"unable to unlock ECH provisioning in storage\", zap.Error(err))\n\t\t}\n\t}()\n\n\t// get the publication config, or use a default if not specified\n\t// (the default publication config should be to publish all ECH\n\t// configs to the app-global DNS provider; if no DNS provider is\n\t// configured, then this whole function is basically a no-op)\n\tpublicationList := t.EncryptedClientHello.Publication\n\tif publicationList == nil {\n\t\tif dnsProv, ok := t.dns.(ECHDNSProvider); ok {\n\t\t\tpublicationList = []*ECHPublication{\n\t\t\t\t{\n\t\t\t\t\tpublishers: []ECHPublisher{\n\t\t\t\t\t\t&ECHDNSPublisher{\n\t\t\t\t\t\t\tprovider: dnsProv,\n\t\t\t\t\t\t\tlogger:   t.logger,\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t}\n\t\t}\n\t}\n\n\t// for each publication config, build the list of ECH configs to\n\t// publish with it, and figure out which inner names to publish\n\t// to/for, then publish\n\tfor _, publication := range publicationList {\n\t\t// this publication is either configured for specific ECH configs,\n\t\t// or we just use an implied default of all ECH configs\n\t\tvar echCfgList echConfigList\n\t\tvar configIDs []uint8 // TODO: use IDs or the outer names?\n\t\tif publication.Configs == nil {\n\t\t\t// by default, publish all configs\n\t\t\tfor _, configs := range t.EncryptedClientHello.configs {\n\t\t\t\techCfgList = append(echCfgList, configs...)\n\t\t\t\tfor _, c := range configs {\n\t\t\t\t\tconfigIDs = append(configIDs, c.ConfigID)\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tfor _, cfgOuterName := range publication.Configs {\n\t\t\t\tif cfgList, ok := t.EncryptedClientHello.configs[cfgOuterName]; ok {\n\t\t\t\t\techCfgList = append(echCfgList, cfgList...)\n\t\t\t\t\tfor _, c := range cfgList {\n\t\t\t\t\t\tconfigIDs = append(configIDs, c.ConfigID)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// marshal the ECH config list as binary for publication\n\t\techCfgListBin, err := echCfgList.MarshalBinary()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"marshaling ECH config list: %v\", err)\n\t\t}\n\n\t\t// now we have our list of ECH configs to publish and the inner names\n\t\t// to publish for (i.e. the names being protected); iterate each publisher\n\t\t// and do the publish for any config+name that needs a publish\n\t\tfor _, publisher := range publication.publishers {\n\t\t\tpublisherKey := publisher.PublisherKey()\n\n\t\t\t// by default, publish for all (non-outer) server names, unless\n\t\t\t// a specific list of names is configured\n\t\t\tvar serverNamesSet map[string]struct{}\n\t\t\tif publication.Domains == nil {\n\t\t\t\tserverNamesSet = make(map[string]struct{}, len(t.serverNames))\n\t\t\t\tfor name := range t.serverNames {\n\t\t\t\t\tserverNamesSet[name] = struct{}{}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tserverNamesSet = make(map[string]struct{}, len(publication.Domains))\n\t\t\t\tfor _, name := range publication.Domains {\n\t\t\t\t\tserverNamesSet[name] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// remove any domains from the set which have already had all configs in the\n\t\t\t// list published by this publisher, to avoid always re-publishing unnecessarily\n\t\t\tfor configuredInnerName := range serverNamesSet {\n\t\t\t\tallConfigsPublished := true\n\t\t\t\tfor _, cfg := range echCfgList {\n\t\t\t\t\t// TODO: Potentially utilize the timestamp (map value) for recent-enough publication, instead of just checking for existence\n\t\t\t\t\tif _, ok := cfg.meta.Publications[publisherKey][configuredInnerName]; !ok {\n\t\t\t\t\t\tallConfigsPublished = false\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif allConfigsPublished {\n\t\t\t\t\tdelete(serverNamesSet, configuredInnerName)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// if all the (inner) domains have had this ECH config list published\n\t\t\t// by this publisher, then try the next publication config\n\t\t\tif len(serverNamesSet) == 0 {\n\t\t\t\tlogger.Debug(\"ECH config list already published by publisher for associated domains (or no domains to publish for)\",\n\t\t\t\t\tzap.Uint8s(\"config_ids\", configIDs),\n\t\t\t\t\tzap.String(\"publisher\", publisherKey))\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// convert the set of names to a slice\n\t\t\tdnsNamesToPublish := make([]string, 0, len(serverNamesSet))\n\t\t\tfor name := range serverNamesSet {\n\t\t\t\tdnsNamesToPublish = append(dnsNamesToPublish, name)\n\t\t\t}\n\n\t\t\tlogger.Debug(\"publishing ECH config list\",\n\t\t\t\tzap.Strings(\"domains\", dnsNamesToPublish),\n\t\t\t\tzap.Uint8s(\"config_ids\", configIDs))\n\n\t\t\t// publish this ECH config list with this publisher\n\t\t\tpubTime := time.Now()\n\t\t\terr := publisher.PublishECHConfigList(t.ctx, dnsNamesToPublish, echCfgListBin)\n\t\t\tif err == nil {\n\t\t\t\tt.logger.Info(\"published ECH configuration list\",\n\t\t\t\t\tzap.Strings(\"domains\", dnsNamesToPublish),\n\t\t\t\t\tzap.Uint8s(\"config_ids\", configIDs),\n\t\t\t\t\tzap.Error(err))\n\t\t\t\t// update publication history, so that we don't unnecessarily republish every time\n\t\t\t\tfor _, cfg := range echCfgList {\n\t\t\t\t\tif cfg.meta.Publications == nil {\n\t\t\t\t\t\tcfg.meta.Publications = make(publicationHistory)\n\t\t\t\t\t}\n\t\t\t\t\tif _, ok := cfg.meta.Publications[publisherKey]; !ok {\n\t\t\t\t\t\tcfg.meta.Publications[publisherKey] = make(map[string]time.Time)\n\t\t\t\t\t}\n\t\t\t\t\tfor _, name := range dnsNamesToPublish {\n\t\t\t\t\t\tcfg.meta.Publications[publisherKey][name] = pubTime\n\t\t\t\t\t}\n\t\t\t\t\tmetaBytes, err := json.Marshal(cfg.meta)\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"marshaling ECH config metadata: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t\tmetaKey := path.Join(echConfigsKey, strconv.Itoa(int(cfg.ConfigID)), \"meta.json\")\n\t\t\t\t\tif err := t.ctx.Storage().Store(t.ctx, metaKey, metaBytes); err != nil {\n\t\t\t\t\t\treturn fmt.Errorf(\"storing updated ECH config metadata: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tt.logger.Error(\"publishing ECH configuration list\",\n\t\t\t\t\tzap.Strings(\"domains\", publication.Domains),\n\t\t\t\t\tzap.Uint8s(\"config_ids\", configIDs),\n\t\t\t\t\tzap.Error(err))\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// loadECHConfig loads the config from storage with the given configID.\n// An error is not actually returned in some cases the config fails to\n// load because in some cases it just means the config ID folder has\n// been cleaned up in storage, maybe due to an incomplete set of keys\n// or corrupted contents; in any case, the only rectification is to\n// delete it and make new keys (an error IS returned if deleting the\n// corrupted keys fails, for example). Check the returned echConfig for\n// non-nil privKeyBin and configBin values before using.\nfunc loadECHConfig(ctx caddy.Context, configID string) (echConfig, error) {\n\tstorage := ctx.Storage()\n\tlogger := ctx.Logger()\n\n\tcfgIDKey := path.Join(echConfigsKey, configID)\n\tkeyKey := path.Join(cfgIDKey, \"key.bin\")\n\tconfigKey := path.Join(cfgIDKey, \"config.bin\")\n\tmetaKey := path.Join(cfgIDKey, \"meta.json\")\n\n\t// if loading anything fails, might as well delete this folder and free up\n\t// the config ID; spec is designed to rotate configs frequently anyway\n\t// (I consider it a more serious error if we can't clean up the folder,\n\t// since leaving stray storage keys is confusing)\n\tprivKeyBytes, err := storage.Load(ctx, keyKey)\n\tif err != nil {\n\t\tdelErr := storage.Delete(ctx, cfgIDKey)\n\t\tif delErr != nil {\n\t\t\treturn echConfig{}, fmt.Errorf(\"error loading private key (%v) and cleaning up parent storage key %s: %v\", err, cfgIDKey, delErr)\n\t\t}\n\t\tlogger.Warn(\"could not load ECH private key; deleting its config folder\",\n\t\t\tzap.String(\"config_id\", configID),\n\t\t\tzap.Error(err))\n\t\treturn echConfig{}, nil\n\t}\n\techConfigBytes, err := storage.Load(ctx, configKey)\n\tif err != nil {\n\t\tdelErr := storage.Delete(ctx, cfgIDKey)\n\t\tif delErr != nil {\n\t\t\treturn echConfig{}, fmt.Errorf(\"error loading ECH config (%v) and cleaning up parent storage key %s: %v\", err, cfgIDKey, delErr)\n\t\t}\n\t\tlogger.Warn(\"could not load ECH config; deleting its config folder\",\n\t\t\tzap.String(\"config_id\", configID),\n\t\t\tzap.Error(err))\n\t\treturn echConfig{}, nil\n\t}\n\tvar cfg echConfig\n\tif err := cfg.UnmarshalBinary(echConfigBytes); err != nil {\n\t\tdelErr := storage.Delete(ctx, cfgIDKey)\n\t\tif delErr != nil {\n\t\t\treturn echConfig{}, fmt.Errorf(\"error loading ECH config (%v) and cleaning up parent storage key %s: %v\", err, cfgIDKey, delErr)\n\t\t}\n\t\tlogger.Warn(\"could not load ECH config; deleted its config folder\",\n\t\t\tzap.String(\"config_id\", configID),\n\t\t\tzap.Error(err))\n\t\treturn echConfig{}, nil\n\t}\n\tmetaBytes, err := storage.Load(ctx, metaKey)\n\tif errors.Is(err, fs.ErrNotExist) {\n\t\tlogger.Warn(\"ECH config metadata file missing; will recreate at next publication\",\n\t\t\tzap.String(\"config_id\", configID),\n\t\t\tzap.Error(err))\n\t} else if err != nil {\n\t\tdelErr := storage.Delete(ctx, cfgIDKey)\n\t\tif delErr != nil {\n\t\t\treturn echConfig{}, fmt.Errorf(\"error loading ECH config metadata (%v) and cleaning up parent storage key %s: %v\", err, cfgIDKey, delErr)\n\t\t}\n\t\tlogger.Warn(\"could not load ECH config metadata; deleted its folder\",\n\t\t\tzap.String(\"config_id\", configID),\n\t\t\tzap.Error(err))\n\t\treturn echConfig{}, nil\n\t}\n\tvar meta echConfigMeta\n\tif len(metaBytes) > 0 {\n\t\tif err := json.Unmarshal(metaBytes, &meta); err != nil {\n\t\t\t// even though it's just metadata, reset the whole config since we can't reliably maintain it\n\t\t\tdelErr := storage.Delete(ctx, cfgIDKey)\n\t\t\tif delErr != nil {\n\t\t\t\treturn echConfig{}, fmt.Errorf(\"error decoding ECH metadata (%v) and cleaning up parent storage key %s: %v\", err, cfgIDKey, delErr)\n\t\t\t}\n\t\t\tlogger.Warn(\"could not JSON-decode ECH metadata; deleted its config folder\",\n\t\t\t\tzap.String(\"config_id\", configID),\n\t\t\t\tzap.Error(err))\n\t\t\treturn echConfig{}, nil\n\t\t}\n\t}\n\n\tcfg.privKeyBin = privKeyBytes\n\tcfg.configBin = echConfigBytes\n\tcfg.meta = meta\n\n\treturn cfg, nil\n}\n\nfunc generateAndStoreECHConfig(ctx caddy.Context, publicName string) (echConfig, error) {\n\t// Go currently has very strict requirements for server-side ECH configs,\n\t// to quote the Go 1.24 godoc (with typos of AEAD IDs corrected):\n\t//\n\t// \"Config should be a marshalled ECHConfig associated with PrivateKey. This\n\t// must match the config provided to clients byte-for-byte. The config\n\t// should only specify the DHKEM(X25519, HKDF-SHA256) KEM ID (0x0020), the\n\t// HKDF-SHA256 KDF ID (0x0001), and a subset of the following AEAD IDs:\n\t// AES-128-GCM (0x0001), AES-256-GCM (0x0002), ChaCha20Poly1305 (0x0003).\"\n\t//\n\t// So we need to be sure we generate a config within these parameters\n\t// so the Go TLS server can use it.\n\n\t// generate a key pair\n\tconst kemChoice = hpke.KEM_X25519_HKDF_SHA256\n\tpublicKey, privateKey, err := kemChoice.Scheme().GenerateKeyPair()\n\tif err != nil {\n\t\treturn echConfig{}, err\n\t}\n\n\t// find an available config ID\n\tconfigID, err := newECHConfigID(ctx)\n\tif err != nil {\n\t\treturn echConfig{}, fmt.Errorf(\"generating unique config ID: %v\", err)\n\t}\n\n\techCfg := echConfig{\n\t\tPublicKey:     publicKey,\n\t\tVersion:       draftTLSESNI22,\n\t\tConfigID:      configID,\n\t\tRawPublicName: publicName,\n\t\tKEMID:         kemChoice,\n\t\tCipherSuites: []hpkeSymmetricCipherSuite{\n\t\t\t{\n\t\t\t\tKDFID:  hpke.KDF_HKDF_SHA256,\n\t\t\t\tAEADID: hpke.AEAD_AES128GCM,\n\t\t\t},\n\t\t\t{\n\t\t\t\tKDFID:  hpke.KDF_HKDF_SHA256,\n\t\t\t\tAEADID: hpke.AEAD_AES256GCM,\n\t\t\t},\n\t\t\t{\n\t\t\t\tKDFID:  hpke.KDF_HKDF_SHA256,\n\t\t\t\tAEADID: hpke.AEAD_ChaCha20Poly1305,\n\t\t\t},\n\t\t},\n\t\tsendAsRetry: true,\n\t}\n\tmeta := echConfigMeta{\n\t\tCreated: time.Now(),\n\t}\n\n\tprivKeyBytes, err := privateKey.MarshalBinary()\n\tif err != nil {\n\t\treturn echConfig{}, fmt.Errorf(\"marshaling ECH private key: %v\", err)\n\t}\n\techConfigBytes, err := echCfg.MarshalBinary()\n\tif err != nil {\n\t\treturn echConfig{}, fmt.Errorf(\"marshaling ECH config: %v\", err)\n\t}\n\tmetaBytes, err := json.Marshal(meta)\n\tif err != nil {\n\t\treturn echConfig{}, fmt.Errorf(\"marshaling ECH config metadata: %v\", err)\n\t}\n\n\tparentKey := path.Join(echConfigsKey, strconv.Itoa(int(configID)))\n\tkeyKey := path.Join(parentKey, \"key.bin\")\n\tconfigKey := path.Join(parentKey, \"config.bin\")\n\tmetaKey := path.Join(parentKey, \"meta.json\")\n\n\tif err := ctx.Storage().Store(ctx, keyKey, privKeyBytes); err != nil {\n\t\treturn echConfig{}, fmt.Errorf(\"storing ECH private key: %v\", err)\n\t}\n\tif err := ctx.Storage().Store(ctx, configKey, echConfigBytes); err != nil {\n\t\treturn echConfig{}, fmt.Errorf(\"storing ECH config: %v\", err)\n\t}\n\tif err := ctx.Storage().Store(ctx, metaKey, metaBytes); err != nil {\n\t\treturn echConfig{}, fmt.Errorf(\"storing ECH config metadata: %v\", err)\n\t}\n\n\techCfg.privKeyBin = privKeyBytes\n\techCfg.configBin = echConfigBytes // this contains the public key\n\techCfg.meta = meta\n\n\treturn echCfg, nil\n}\n\n// ECH represents an Encrypted ClientHello configuration.\n//\n// EXPERIMENTAL: Subject to change.\ntype ECHConfiguration struct {\n\t// The public server name (SNI) that will be used in the outer ClientHello.\n\t// This should be a domain name for which this server is authoritative,\n\t// because Caddy will try to provision a certificate for this name. As an\n\t// outer SNI, it is never used for application data (HTTPS, etc.), but it\n\t// is necessary for enabling clients to connect securely in some cases.\n\t// If this field is empty or missing, or if Caddy cannot get a certificate\n\t// for this domain (e.g. the domain's DNS records do not point to this server),\n\t// client reliability becomes brittle, and you risk coercing clients to expose\n\t// true server names in plaintext, which compromises both the privacy of the\n\t// server and makes clients more vulnerable.\n\tPublicName string `json:\"public_name\"`\n}\n\n// ECHPublication configures publication of ECH config(s). It pairs a list\n// of ECH configs with the list of domains they are assigned to protect, and\n// describes how to publish those configs for those domains.\n//\n// Most servers will have only a single publication config, unless their\n// domains are spread across multiple DNS providers or require different\n// methods of publication.\n//\n// EXPERIMENTAL: Subject to change.\ntype ECHPublication struct {\n\t// The list of ECH configurations to publish, identified by public name.\n\t// If not set, all configs will be included for publication by default.\n\t//\n\t// It is generally advised to maximize the size of your anonymity set,\n\t// which implies using as few public names as possible for your sites.\n\t// Usually, only a single public name is used to protect all the sites\n\t// for a server\n\t//\n\t// EXPERIMENTAL: This field may be renamed or have its structure changed.\n\tConfigs []string `json:\"configs,omitempty\"`\n\n\t// The list of (\"inner\") domain names which are protected with the associated\n\t// ECH configurations.\n\t//\n\t// If not set, all server names registered with the TLS module will be\n\t// added to this list implicitly. (This registration is done automatically\n\t// by other Caddy apps that use the TLS module. They should register their\n\t// configured server names for this purpose. For example, the HTTP server\n\t// registers the hostnames for which it applies automatic HTTPS. This is\n\t// not something you, the user, have to do.) Most servers\n\t//\n\t// Names in this list should not appear in any other publication config\n\t// object with the same publishers, since the publications will likely\n\t// overwrite each other.\n\t//\n\t// NOTE: In order to publish ECH configs for domains configured for\n\t// On-Demand TLS that are not explicitly enumerated elsewhere in the\n\t// config, those domain names will have to be listed here. The only\n\t// time Caddy knows which domains it is serving with On-Demand TLS is\n\t// handshake-time, which is too late for publishing ECH configs; it\n\t// means the first connections would not protect the server names,\n\t// revealing that information to observers, and thus defeating the\n\t// purpose of ECH. Hence the need to list them here so Caddy can\n\t// proactively publish ECH configs before clients connect with those\n\t// server names in plaintext.\n\tDomains []string `json:\"domains,omitempty\"`\n\n\t// How to publish the ECH configurations so clients can know to use\n\t// ECH to connect more securely to the server.\n\tPublishersRaw caddy.ModuleMap `json:\"publishers,omitempty\" caddy:\"namespace=tls.ech.publishers\"`\n\tpublishers    []ECHPublisher\n}\n\n// ECHDNSProvider can service DNS entries for ECH purposes.\ntype ECHDNSProvider interface {\n\tlibdns.RecordGetter\n\tlibdns.RecordSetter\n}\n\n// ECHDNSPublisher configures how to publish an ECH configuration to\n// DNS records for the specified domains.\n//\n// EXPERIMENTAL: Subject to change.\ntype ECHDNSPublisher struct {\n\t// The DNS provider module which will establish the HTTPS record(s).\n\tProviderRaw json.RawMessage `json:\"provider,omitempty\" caddy:\"namespace=dns.providers inline_key=name\"`\n\tprovider    ECHDNSProvider\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (ECHDNSPublisher) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.ech.publishers.dns\",\n\t\tNew: func() caddy.Module { return new(ECHDNSPublisher) },\n\t}\n}\n\nfunc (dnsPub *ECHDNSPublisher) Provision(ctx caddy.Context) error {\n\tdnsProvMod, err := ctx.LoadModule(dnsPub, \"ProviderRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading ECH DNS provider module: %v\", err)\n\t}\n\tprov, ok := dnsProvMod.(ECHDNSProvider)\n\tif !ok {\n\t\treturn fmt.Errorf(\"ECH DNS provider module is not an ECH DNS Provider: %v\", err)\n\t}\n\tdnsPub.provider = prov\n\tdnsPub.logger = ctx.Logger()\n\treturn nil\n}\n\n// PublisherKey returns the name of the DNS provider module.\n// We intentionally omit specific provider configuration (or a hash thereof,\n// since the config is likely sensitive, potentially containing an API key)\n// because it is unlikely that specific configuration, such as an API key,\n// is relevant to unique key use as an ECH config publisher.\nfunc (dnsPub ECHDNSPublisher) PublisherKey() string {\n\treturn string(dnsPub.provider.(caddy.Module).CaddyModule().ID)\n}\n\n// PublishECHConfigList publishes the given ECH config list to the given DNS names.\nfunc (dnsPub *ECHDNSPublisher) PublishECHConfigList(ctx context.Context, innerNames []string, configListBin []byte) error {\n\tnameservers := certmagic.RecursiveNameservers(nil) // TODO: we could make resolvers configurable\n\nnextName:\n\tfor _, domain := range innerNames {\n\t\tzone, err := certmagic.FindZoneByFQDN(ctx, dnsPub.logger, domain, nameservers)\n\t\tif err != nil {\n\t\t\tdnsPub.logger.Error(\"could not determine zone for domain\",\n\t\t\t\tzap.String(\"domain\", domain),\n\t\t\t\tzap.Error(err))\n\t\t\tcontinue\n\t\t}\n\n\t\trelName := libdns.RelativeName(domain+\".\", zone)\n\n\t\t// get existing records for this domain; we need to make sure another\n\t\t// record exists for it so we don't accidentally trample a wildcard; we\n\t\t// also want to get any HTTPS record that may already exist for it so\n\t\t// we can augment the ech SvcParamKey with any other existing SvcParams\n\t\trecs, err := dnsPub.provider.GetRecords(ctx, zone)\n\t\tif err != nil {\n\t\t\tdnsPub.logger.Error(\"unable to get existing DNS records to publish ECH data to HTTPS DNS record\",\n\t\t\t\tzap.String(\"domain\", domain),\n\t\t\t\tzap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t\tvar httpsRec libdns.ServiceBinding\n\t\tvar nameHasExistingRecord bool\n\t\tfor _, rec := range recs {\n\t\t\trr := rec.RR()\n\t\t\tif rr.Name == relName {\n\t\t\t\t// CNAME records are exclusive of all other records, so we cannot publish an HTTPS\n\t\t\t\t// record for a domain that is CNAME'd. See #6922.\n\t\t\t\tif rr.Type == \"CNAME\" {\n\t\t\t\t\tdnsPub.logger.Warn(\"domain has CNAME record, so unable to publish ECH data to HTTPS record\",\n\t\t\t\t\t\tzap.String(\"domain\", domain),\n\t\t\t\t\t\tzap.String(\"cname_value\", rr.Data))\n\t\t\t\t\tcontinue nextName\n\t\t\t\t}\n\t\t\t\tnameHasExistingRecord = true\n\t\t\t\tif svcb, ok := rec.(libdns.ServiceBinding); ok && svcb.Scheme == \"https\" {\n\t\t\t\t\tif svcb.Target == \"\" || svcb.Target == \".\" {\n\t\t\t\t\t\thttpsRec = svcb\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif !nameHasExistingRecord {\n\t\t\t// Turns out if you publish a DNS record for a name that doesn't have any DNS record yet,\n\t\t\t// any wildcard records won't apply for the name anymore, meaning if a wildcard A/AAAA record\n\t\t\t// is used to resolve the domain to a server, publishing an HTTPS record could break resolution!\n\t\t\t// In theory, this should be a non-issue, at least for A/AAAA records, if the HTTPS record\n\t\t\t// includes ipv[4|6]hint SvcParamKeys,\n\t\t\tdnsPub.logger.Warn(\"domain does not have any existing records, so skipping publication of HTTPS record\",\n\t\t\t\tzap.String(\"domain\", domain),\n\t\t\t\tzap.String(\"relative_name\", relName),\n\t\t\t\tzap.String(\"zone\", zone))\n\t\t\tcontinue\n\t\t}\n\t\tparams := httpsRec.Params\n\t\tif params == nil {\n\t\t\tparams = make(libdns.SvcParams)\n\t\t}\n\n\t\t// overwrite only the \"ech\" SvcParamKey\n\t\tparams[\"ech\"] = []string{base64.StdEncoding.EncodeToString(configListBin)}\n\n\t\t// publish record\n\t\t_, err = dnsPub.provider.SetRecords(ctx, zone, []libdns.Record{\n\t\t\tlibdns.ServiceBinding{\n\t\t\t\t// HTTPS and SVCB RRs: RFC 9460 (https://www.rfc-editor.org/rfc/rfc9460)\n\t\t\t\tScheme:   \"https\",\n\t\t\t\tName:     relName,\n\t\t\t\tTTL:      5 * time.Minute, // TODO: low hard-coded value only temporary; change to a higher value once more field-tested and key rotation is implemented\n\t\t\t\tPriority: 2,               // allows a manual override with priority 1\n\t\t\t\tTarget:   \".\",\n\t\t\t\tParams:   params,\n\t\t\t},\n\t\t})\n\t\tif err != nil {\n\t\t\t// TODO: Maybe this should just stop and return the error...\n\t\t\tdnsPub.logger.Error(\"unable to publish ECH data to HTTPS DNS record\",\n\t\t\t\tzap.String(\"domain\", domain),\n\t\t\t\tzap.String(\"zone\", zone),\n\t\t\t\tzap.String(\"dns_record_name\", relName),\n\t\t\t\tzap.Error(err))\n\t\t\tcontinue\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// echConfig represents an ECHConfig from the specification,\n// [draft-ietf-tls-esni-22](https://www.ietf.org/archive/id/draft-ietf-tls-esni-22.html).\ntype echConfig struct {\n\t// \"The version of ECH for which this configuration is used.\n\t// The version is the same as the code point for the\n\t// encrypted_client_hello extension. Clients MUST ignore any\n\t// ECHConfig structure with a version they do not support.\"\n\tVersion uint16\n\n\t// The \"length\" and \"contents\" fields defined next in the\n\t// structure are implicitly taken care of by cryptobyte\n\t// when encoding the following fields:\n\n\t// HpkeKeyConfig fields:\n\tConfigID     uint8\n\tKEMID        hpke.KEM\n\tPublicKey    kem.PublicKey\n\tCipherSuites []hpkeSymmetricCipherSuite\n\n\t// ECHConfigContents fields:\n\tMaxNameLength uint8\n\tRawPublicName string\n\tRawExtensions []byte\n\n\t// these fields are not part of the spec, but are here for\n\t// our use when setting up TLS servers or maintenance\n\tconfigBin   []byte\n\tprivKeyBin  []byte\n\tmeta        echConfigMeta\n\tsendAsRetry bool\n}\n\nfunc (echCfg echConfig) MarshalBinary() ([]byte, error) {\n\tvar b cryptobyte.Builder\n\tif err := echCfg.marshalBinary(&b); err != nil {\n\t\treturn nil, err\n\t}\n\treturn b.Bytes()\n}\n\n// UnmarshalBinary decodes the data back into an ECH config.\n//\n// Borrowed from github.com/OmarTariq612/goech with modifications.\n// Original code: Copyright (c) 2023 Omar Tariq AbdEl-Raziq\nfunc (echCfg *echConfig) UnmarshalBinary(data []byte) error {\n\tvar content cryptobyte.String\n\tb := cryptobyte.String(data)\n\n\tif !b.ReadUint16(&echCfg.Version) {\n\t\treturn errInvalidLen\n\t}\n\tif echCfg.Version != draftTLSESNI22 {\n\t\treturn fmt.Errorf(\"supported version must be %d: got %d\", draftTLSESNI22, echCfg.Version)\n\t}\n\n\tif !b.ReadUint16LengthPrefixed(&content) || !b.Empty() {\n\t\treturn errInvalidLen\n\t}\n\n\tvar t cryptobyte.String\n\tvar pk []byte\n\n\tif !content.ReadUint8(&echCfg.ConfigID) ||\n\t\t!content.ReadUint16((*uint16)(&echCfg.KEMID)) ||\n\t\t!content.ReadUint16LengthPrefixed(&t) ||\n\t\t!t.ReadBytes(&pk, len(t)) ||\n\t\t!content.ReadUint16LengthPrefixed(&t) ||\n\t\tlen(t)%4 != 0 /* the length of (KDFs and AEADs) must be divisible by 4 */ {\n\t\treturn errInvalidLen\n\t}\n\n\tif !echCfg.KEMID.IsValid() {\n\t\treturn fmt.Errorf(\"invalid KEM ID: %d\", echCfg.KEMID)\n\t}\n\n\tvar err error\n\tif echCfg.PublicKey, err = echCfg.KEMID.Scheme().UnmarshalBinaryPublicKey(pk); err != nil {\n\t\treturn fmt.Errorf(\"parsing public_key: %w\", err)\n\t}\n\n\techCfg.CipherSuites = echCfg.CipherSuites[:0]\n\n\tfor !t.Empty() {\n\t\tvar hpkeKDF, hpkeAEAD uint16\n\t\tif !t.ReadUint16(&hpkeKDF) || !t.ReadUint16(&hpkeAEAD) {\n\t\t\t// we have already checked that the length is divisible by 4\n\t\t\tpanic(\"this must not happen\")\n\t\t}\n\t\tif !hpke.KDF(hpkeKDF).IsValid() {\n\t\t\treturn fmt.Errorf(\"invalid KDF ID: %d\", hpkeKDF)\n\t\t}\n\t\tif !hpke.AEAD(hpkeAEAD).IsValid() {\n\t\t\treturn fmt.Errorf(\"invalid AEAD ID: %d\", hpkeAEAD)\n\t\t}\n\t\techCfg.CipherSuites = append(echCfg.CipherSuites, hpkeSymmetricCipherSuite{\n\t\t\tKDFID:  hpke.KDF(hpkeKDF),\n\t\t\tAEADID: hpke.AEAD(hpkeAEAD),\n\t\t})\n\t}\n\n\tvar rawPublicName []byte\n\tif !content.ReadUint8(&echCfg.MaxNameLength) ||\n\t\t!content.ReadUint8LengthPrefixed(&t) ||\n\t\t!t.ReadBytes(&rawPublicName, len(t)) ||\n\t\t!content.ReadUint16LengthPrefixed(&t) ||\n\t\t!t.ReadBytes(&echCfg.RawExtensions, len(t)) ||\n\t\t!content.Empty() {\n\t\treturn errInvalidLen\n\t}\n\techCfg.RawPublicName = string(rawPublicName)\n\n\treturn nil\n}\n\nvar errInvalidLen = errors.New(\"invalid length\")\n\n// marshalBinary writes this config to the cryptobyte builder. If there is an error,\n// it will occur before any writes have happened.\nfunc (echCfg echConfig) marshalBinary(b *cryptobyte.Builder) error {\n\tpk, err := echCfg.PublicKey.MarshalBinary()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif l := len(echCfg.RawPublicName); l == 0 || l > 255 {\n\t\treturn fmt.Errorf(\"public name length (%d) must be in the range 1-255\", l)\n\t}\n\n\tb.AddUint16(echCfg.Version)\n\tb.AddUint16LengthPrefixed(func(b *cryptobyte.Builder) { // \"length\" field\n\t\tb.AddUint8(echCfg.ConfigID)\n\t\tb.AddUint16(uint16(echCfg.KEMID))\n\t\tb.AddUint16LengthPrefixed(func(b *cryptobyte.Builder) {\n\t\t\tb.AddBytes(pk)\n\t\t})\n\t\tb.AddUint16LengthPrefixed(func(b *cryptobyte.Builder) {\n\t\t\tfor _, cs := range echCfg.CipherSuites {\n\t\t\t\tb.AddUint16(uint16(cs.KDFID))\n\t\t\t\tb.AddUint16(uint16(cs.AEADID))\n\t\t\t}\n\t\t})\n\t\tb.AddUint8(uint8(min(len(echCfg.RawPublicName)+16, 255)))\n\t\tb.AddUint8LengthPrefixed(func(b *cryptobyte.Builder) {\n\t\t\tb.AddBytes([]byte(echCfg.RawPublicName))\n\t\t})\n\t\tb.AddUint16LengthPrefixed(func(child *cryptobyte.Builder) {\n\t\t\tchild.AddBytes(echCfg.RawExtensions)\n\t\t})\n\t})\n\n\treturn nil\n}\n\ntype hpkeSymmetricCipherSuite struct {\n\tKDFID  hpke.KDF\n\tAEADID hpke.AEAD\n}\n\ntype echConfigList []echConfig\n\nfunc (cl echConfigList) MarshalBinary() ([]byte, error) {\n\tvar b cryptobyte.Builder\n\tvar err error\n\n\t// the list's length prefixes the list, as with most opaque values\n\tb.AddUint16LengthPrefixed(func(b *cryptobyte.Builder) {\n\t\tfor _, cfg := range cl {\n\t\t\tif err = cfg.marshalBinary(b); err != nil {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t})\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn b.Bytes()\n}\n\nfunc newECHConfigID(ctx caddy.Context) (uint8, error) {\n\t// uint8 can be 0-255 inclusive\n\tconst uint8Range = 256\n\n\t// avoid repeating storage checks\n\ttried := make([]bool, uint8Range)\n\n\t// Try to find an available number with random rejection sampling;\n\t// i.e. choose a random number and see if it's already taken.\n\t// The hard limit on how many times we try to find an available\n\t// number is flexible... in theory, assuming uniform distribution,\n\t// 256 attempts should make each possible value show up exactly\n\t// once, but obviously that won't be the case. We can try more\n\t// times to try to ensure that every number gets a chance, which\n\t// is especially useful if few are available, or we can lower it\n\t// if we assume we should have found an available value by then\n\t// and want to limit runtime; for now I choose the middle ground\n\t// and just try as many times as there are possible values.\n\tfor i := 0; i < uint8Range && ctx.Err() == nil; i++ {\n\t\tnum := uint8(weakrand.N(uint8Range)) //nolint:gosec\n\n\t\t// don't try the same number a second time\n\t\tif tried[num] {\n\t\t\tcontinue\n\t\t}\n\t\ttried[num] = true\n\n\t\t// check to see if any of the subkeys use this config ID\n\t\tnumStr := strconv.Itoa(int(num))\n\t\ttrialPath := path.Join(echConfigsKey, numStr)\n\t\tif ctx.Storage().Exists(ctx, trialPath) {\n\t\t\tcontinue\n\t\t}\n\n\t\treturn num, nil\n\t}\n\n\tif err := ctx.Err(); err != nil {\n\t\treturn 0, err\n\t}\n\n\treturn 0, fmt.Errorf(\"depleted attempts to find an available config_id\")\n}\n\n// ECHPublisher is an interface for publishing ECHConfigList values\n// so that they can be used by clients.\ntype ECHPublisher interface {\n\t// Returns a key that is unique to this publisher and its configuration.\n\t// A publisher's ID combined with its config is a valid key.\n\t// It is used to prevent duplicating publications.\n\tPublisherKey() string\n\n\t// Publishes the ECH config list for the given innerNames. Some publishers\n\t// may not need a list of inner/protected names, and can ignore the argument;\n\t// most, however, will want to use it to know which inner names are to be\n\t// associated with the given ECH config list.\n\tPublishECHConfigList(ctx context.Context, innerNames []string, echConfigList []byte) error\n}\n\ntype echConfigMeta struct {\n\tCreated      time.Time          `json:\"created\"`\n\tPublications publicationHistory `json:\"publications\"`\n}\n\n// publicationHistory is a map of publisher key to\n// map of inner name to timestamp\ntype publicationHistory map[string]map[string]time.Time\n\n// The key prefix when putting ECH configs in storage. After this\n// comes the config ID.\nconst echConfigsKey = \"ech/configs\"\n\n// https://www.ietf.org/archive/id/draft-ietf-tls-esni-22.html\nconst draftTLSESNI22 = 0xfe0d\n\n// Interface guard\nvar _ ECHPublisher = (*ECHDNSPublisher)(nil)\n",
    "source_file": "modules/caddytls/ech.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/x509\"\n\t\"fmt\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(LeafPEMLoader{})\n}\n\n// LeafPEMLoader loads leaf certificates by\n// decoding their PEM blocks directly. This has the advantage\n// of not needing to store them on disk at all.\ntype LeafPEMLoader struct {\n\tCertificates []string `json:\"certificates,omitempty\"`\n}\n\n// Provision implements caddy.Provisioner.\nfunc (pl *LeafPEMLoader) Provision(ctx caddy.Context) error {\n\trepl, ok := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif !ok {\n\t\trepl = caddy.NewReplacer()\n\t}\n\tfor i, cert := range pl.Certificates {\n\t\tpl.Certificates[i] = repl.ReplaceKnown(cert, \"\")\n\t}\n\treturn nil\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (LeafPEMLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.leaf_cert_loader.pem\",\n\t\tNew: func() caddy.Module { return new(LeafPEMLoader) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (fl *LeafPEMLoader) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.NextArg()\n\tfl.Certificates = append(fl.Certificates, d.RemainingArgs()...)\n\treturn nil\n}\n\n// LoadLeafCertificates returns the certificates contained in pl.\nfunc (pl LeafPEMLoader) LoadLeafCertificates() ([]*x509.Certificate, error) {\n\tcerts := make([]*x509.Certificate, 0, len(pl.Certificates))\n\tfor i, cert := range pl.Certificates {\n\t\tderBytes, err := convertPEMToDER([]byte(cert))\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"PEM leaf certificate loader, cert %d: %v\", i, err)\n\t\t}\n\t\tcert, err := x509.ParseCertificate(derBytes)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"PEM cert %d: %v\", i, err)\n\t\t}\n\t\tcerts = append(certs, cert)\n\t}\n\treturn certs, nil\n}\n\n// Interface guard\nvar (\n\t_ LeafCertificateLoader = (*LeafPEMLoader)(nil)\n\t_ caddy.Provisioner     = (*LeafPEMLoader)(nil)\n)\n",
    "source_file": "modules/caddytls/leafpemloader.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"context\"\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(new(ZeroSSLIssuer))\n}\n\n// ZeroSSLIssuer uses the ZeroSSL API to get certificates.\n// Note that this is distinct from ZeroSSL's ACME endpoint.\n// To use ZeroSSL's ACME endpoint, use the ACMEIssuer\n// configured with ZeroSSL's ACME directory endpoint.\ntype ZeroSSLIssuer struct {\n\t// The API key (or \"access key\") for using the ZeroSSL API.\n\t// REQUIRED.\n\tAPIKey string `json:\"api_key,omitempty\"`\n\n\t// How many days the certificate should be valid for.\n\t// Only certain values are accepted; see ZeroSSL docs.\n\tValidityDays int `json:\"validity_days,omitempty\"`\n\n\t// The host to bind to when opening a listener for\n\t// verifying domain names (or IPs).\n\tListenHost string `json:\"listen_host,omitempty\"`\n\n\t// If HTTP is forwarded from port 80, specify the\n\t// forwarded port here.\n\tAlternateHTTPPort int `json:\"alternate_http_port,omitempty\"`\n\n\t// Use CNAME validation instead of HTTP. ZeroSSL's\n\t// API uses CNAME records for DNS validation, similar\n\t// to how Let's Encrypt uses TXT records for the\n\t// DNS challenge.\n\tCNAMEValidation *DNSChallengeConfig `json:\"cname_validation,omitempty\"`\n\n\tlogger  *zap.Logger\n\tstorage certmagic.Storage\n\tissuer  *certmagic.ZeroSSLIssuer\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (*ZeroSSLIssuer) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.issuance.zerossl\",\n\t\tNew: func() caddy.Module { return new(ZeroSSLIssuer) },\n\t}\n}\n\n// Provision sets up the issuer.\nfunc (iss *ZeroSSLIssuer) Provision(ctx caddy.Context) error {\n\tiss.logger = ctx.Logger()\n\tiss.storage = ctx.Storage()\n\trepl := caddy.NewReplacer()\n\n\tvar dnsManager *certmagic.DNSManager\n\tif iss.CNAMEValidation != nil && len(iss.CNAMEValidation.ProviderRaw) > 0 {\n\t\tval, err := ctx.LoadModule(iss.CNAMEValidation, \"ProviderRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading DNS provider module: %v\", err)\n\t\t}\n\t\tdnsManager = &certmagic.DNSManager{\n\t\t\tDNSProvider:        val.(certmagic.DNSProvider),\n\t\t\tTTL:                time.Duration(iss.CNAMEValidation.TTL),\n\t\t\tPropagationDelay:   time.Duration(iss.CNAMEValidation.PropagationDelay),\n\t\t\tPropagationTimeout: time.Duration(iss.CNAMEValidation.PropagationTimeout),\n\t\t\tResolvers:          iss.CNAMEValidation.Resolvers,\n\t\t\tOverrideDomain:     iss.CNAMEValidation.OverrideDomain,\n\t\t\tLogger:             iss.logger.Named(\"cname\"),\n\t\t}\n\t}\n\n\tiss.issuer = &certmagic.ZeroSSLIssuer{\n\t\tAPIKey:          repl.ReplaceAll(iss.APIKey, \"\"),\n\t\tValidityDays:    iss.ValidityDays,\n\t\tListenHost:      iss.ListenHost,\n\t\tAltHTTPPort:     iss.AlternateHTTPPort,\n\t\tStorage:         iss.storage,\n\t\tCNAMEValidation: dnsManager,\n\t\tLogger:          iss.logger,\n\t}\n\n\treturn nil\n}\n\n// Issue obtains a certificate for the given csr.\nfunc (iss *ZeroSSLIssuer) Issue(ctx context.Context, csr *x509.CertificateRequest) (*certmagic.IssuedCertificate, error) {\n\treturn iss.issuer.Issue(ctx, csr)\n}\n\n// IssuerKey returns the unique issuer key for the configured CA endpoint.\nfunc (iss *ZeroSSLIssuer) IssuerKey() string {\n\treturn iss.issuer.IssuerKey()\n}\n\n// Revoke revokes the given certificate.\nfunc (iss *ZeroSSLIssuer) Revoke(ctx context.Context, cert certmagic.CertificateResource, reason int) error {\n\treturn iss.issuer.Revoke(ctx, cert, reason)\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into iss.\n//\n//\t... zerossl <api_key> {\n//\t\t    validity_days <days>\n//\t\t    alt_http_port <port>\n//\t\t    dns <provider_name> ...\n//\t\t    propagation_delay <duration>\n//\t\t    propagation_timeout <duration>\n//\t\t    resolvers <list...>\n//\t\t    dns_ttl <duration>\n//\t}\nfunc (iss *ZeroSSLIssuer) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume issuer name\n\n\t// API key is required\n\tif !d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\tiss.APIKey = d.Val()\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"validity_days\":\n\t\t\tif iss.ValidityDays != 0 {\n\t\t\t\treturn d.Errf(\"validity days is already specified: %d\", iss.ValidityDays)\n\t\t\t}\n\t\t\tdays, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid number of days %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\tiss.ValidityDays = days\n\n\t\tcase \"alt_http_port\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tport, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid port %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\tiss.AlternateHTTPPort = port\n\n\t\tcase \"dns\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tprovName := d.Val()\n\t\t\tif iss.CNAMEValidation == nil {\n\t\t\t\tiss.CNAMEValidation = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, \"dns.providers.\"+provName)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiss.CNAMEValidation.ProviderRaw = caddyconfig.JSONModuleObject(unm, \"name\", provName, nil)\n\n\t\tcase \"propagation_delay\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdelayStr := d.Val()\n\t\t\tdelay, err := caddy.ParseDuration(delayStr)\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid propagation_delay duration %s: %v\", delayStr, err)\n\t\t\t}\n\t\t\tif iss.CNAMEValidation == nil {\n\t\t\t\tiss.CNAMEValidation = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tiss.CNAMEValidation.PropagationDelay = caddy.Duration(delay)\n\n\t\tcase \"propagation_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\ttimeoutStr := d.Val()\n\t\t\tvar timeout time.Duration\n\t\t\tif timeoutStr == \"-1\" {\n\t\t\t\ttimeout = time.Duration(-1)\n\t\t\t} else {\n\t\t\t\tvar err error\n\t\t\t\ttimeout, err = caddy.ParseDuration(timeoutStr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn d.Errf(\"invalid propagation_timeout duration %s: %v\", timeoutStr, err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif iss.CNAMEValidation == nil {\n\t\t\t\tiss.CNAMEValidation = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tiss.CNAMEValidation.PropagationTimeout = caddy.Duration(timeout)\n\n\t\tcase \"resolvers\":\n\t\t\tif iss.CNAMEValidation == nil {\n\t\t\t\tiss.CNAMEValidation = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tiss.CNAMEValidation.Resolvers = d.RemainingArgs()\n\t\t\tif len(iss.CNAMEValidation.Resolvers) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"dns_ttl\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tttlStr := d.Val()\n\t\t\tttl, err := caddy.ParseDuration(ttlStr)\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid dns_ttl duration %s: %v\", ttlStr, err)\n\t\t\t}\n\t\t\tif iss.CNAMEValidation == nil {\n\t\t\t\tiss.CNAMEValidation = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tiss.CNAMEValidation.TTL = caddy.Duration(ttl)\n\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized zerossl issuer property: %s\", d.Val())\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Interface guards\nvar (\n\t_ certmagic.Issuer  = (*ZeroSSLIssuer)(nil)\n\t_ certmagic.Revoker = (*ZeroSSLIssuer)(nil)\n\t_ caddy.Provisioner = (*ZeroSSLIssuer)(nil)\n)\n",
    "source_file": "modules/caddytls/zerosslissuer.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/x509\"\n\t\"encoding/pem\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/smallstep/certificates/authority/provisioner\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddypki\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(InternalIssuer{})\n}\n\n// InternalIssuer is a certificate issuer that generates\n// certificates internally using a locally-configured\n// CA which can be customized using the `pki` app.\ntype InternalIssuer struct {\n\t// The ID of the CA to use for signing. The default\n\t// CA ID is \"local\". The CA can be configured with the\n\t// `pki` app.\n\tCA string `json:\"ca,omitempty\"`\n\n\t// The validity period of certificates.\n\tLifetime caddy.Duration `json:\"lifetime,omitempty\"`\n\n\t// If true, the root will be the issuer instead of\n\t// the intermediate. This is NOT recommended and should\n\t// only be used when devices/clients do not properly\n\t// validate certificate chains.\n\tSignWithRoot bool `json:\"sign_with_root,omitempty\"`\n\n\tca     *caddypki.CA\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (InternalIssuer) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.issuance.internal\",\n\t\tNew: func() caddy.Module { return new(InternalIssuer) },\n\t}\n}\n\n// Provision sets up the issuer.\nfunc (iss *InternalIssuer) Provision(ctx caddy.Context) error {\n\tiss.logger = ctx.Logger()\n\n\t// set some defaults\n\tif iss.CA == \"\" {\n\t\tiss.CA = caddypki.DefaultCAID\n\t}\n\n\t// get a reference to the configured CA\n\tappModule, err := ctx.App(\"pki\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tpkiApp := appModule.(*caddypki.PKI)\n\tca, err := pkiApp.GetCA(ctx, iss.CA)\n\tif err != nil {\n\t\treturn err\n\t}\n\tiss.ca = ca\n\n\t// set any other default values\n\tif iss.Lifetime == 0 {\n\t\tiss.Lifetime = caddy.Duration(defaultInternalCertLifetime)\n\t}\n\n\treturn nil\n}\n\n// IssuerKey returns the unique issuer key for the\n// configured CA endpoint.\nfunc (iss InternalIssuer) IssuerKey() string {\n\treturn iss.ca.ID\n}\n\n// Issue issues a certificate to satisfy the CSR.\nfunc (iss InternalIssuer) Issue(ctx context.Context, csr *x509.CertificateRequest) (*certmagic.IssuedCertificate, error) {\n\t// prepare the signing authority\n\tauthCfg := caddypki.AuthorityConfig{\n\t\tSignWithRoot: iss.SignWithRoot,\n\t}\n\tauth, err := iss.ca.NewAuthority(authCfg)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// get the cert (public key) that will be used for signing\n\tvar issuerCert *x509.Certificate\n\tif iss.SignWithRoot {\n\t\tissuerCert = iss.ca.RootCertificate()\n\t} else {\n\t\tissuerCert = iss.ca.IntermediateCertificate()\n\t}\n\n\t// ensure issued certificate does not expire later than its issuer\n\tlifetime := time.Duration(iss.Lifetime)\n\tif time.Now().Add(lifetime).After(issuerCert.NotAfter) {\n\t\tlifetime = time.Until(issuerCert.NotAfter)\n\t\tiss.logger.Warn(\"cert lifetime would exceed issuer NotAfter, clamping lifetime\",\n\t\t\tzap.Duration(\"orig_lifetime\", time.Duration(iss.Lifetime)),\n\t\t\tzap.Duration(\"lifetime\", lifetime),\n\t\t\tzap.Time(\"not_after\", issuerCert.NotAfter),\n\t\t)\n\t}\n\n\tcertChain, err := auth.SignWithContext(ctx, csr, provisioner.SignOptions{}, customCertLifetime(caddy.Duration(lifetime)))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tvar buf bytes.Buffer\n\tfor _, cert := range certChain {\n\t\terr := pem.Encode(&buf, &pem.Block{Type: \"CERTIFICATE\", Bytes: cert.Raw})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\treturn &certmagic.IssuedCertificate{\n\t\tCertificate: buf.Bytes(),\n\t}, nil\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into iss.\n//\n//\t... internal {\n//\t    ca       <name>\n//\t    lifetime <duration>\n//\t    sign_with_root\n//\t}\nfunc (iss *InternalIssuer) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume issuer name\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"ca\":\n\t\t\tif !d.AllArgs(&iss.CA) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"lifetime\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiss.Lifetime = caddy.Duration(dur)\n\n\t\tcase \"sign_with_root\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tiss.SignWithRoot = true\n\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\n// customCertLifetime allows us to customize certificates that are issued\n// by Smallstep libs, particularly the NotBefore & NotAfter dates.\ntype customCertLifetime time.Duration\n\nfunc (d customCertLifetime) Modify(cert *x509.Certificate, _ provisioner.SignOptions) error {\n\tcert.NotBefore = time.Now()\n\tcert.NotAfter = cert.NotBefore.Add(time.Duration(d))\n\treturn nil\n}\n\nconst defaultInternalCertLifetime = 12 * time.Hour\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner               = (*InternalIssuer)(nil)\n\t_ certmagic.Issuer                = (*InternalIssuer)(nil)\n\t_ provisioner.CertificateModifier = (*customCertLifetime)(nil)\n)\n",
    "source_file": "modules/caddytls/internalissuer.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(PermissionByHTTP{})\n}\n\n// OnDemandConfig configures on-demand TLS, for obtaining\n// needed certificates at handshake-time. Because this\n// feature can easily be abused, Caddy must ask permission\n// to your application whether a particular domain is allowed\n// to have a certificate issued for it.\ntype OnDemandConfig struct {\n\t// Deprecated. WILL BE REMOVED SOON. Use 'permission' instead with the `http` module.\n\tAsk string `json:\"ask,omitempty\"`\n\n\t// REQUIRED. A module that will determine whether a\n\t// certificate is allowed to be loaded from storage\n\t// or obtained from an issuer on demand.\n\tPermissionRaw json.RawMessage `json:\"permission,omitempty\" caddy:\"namespace=tls.permission inline_key=module\"`\n\tpermission    OnDemandPermission\n}\n\n// OnDemandPermission is a type that can give permission for\n// whether a certificate should be allowed to be obtained or\n// loaded from storage on-demand.\n// EXPERIMENTAL: This API is experimental and subject to change.\ntype OnDemandPermission interface {\n\t// CertificateAllowed returns nil if a certificate for the given\n\t// name is allowed to be either obtained from an issuer or loaded\n\t// from storage on-demand.\n\t//\n\t// The context passed in has the associated *tls.ClientHelloInfo\n\t// value available at the certmagic.ClientHelloInfoCtxKey key.\n\t//\n\t// In the worst case, this function may be called as frequently\n\t// as every TLS handshake, so it should return as quick as possible\n\t// to reduce latency. In the normal case, this function is only\n\t// called when a certificate is needed that is not already loaded\n\t// into memory ready to serve.\n\tCertificateAllowed(ctx context.Context, name string) error\n}\n\n// PermissionByHTTP determines permission for a TLS certificate by\n// making a request to an HTTP endpoint.\ntype PermissionByHTTP struct {\n\t// The endpoint to access. It should be a full URL.\n\t// A query string parameter \"domain\" will be added to it,\n\t// containing the domain (or IP) for the desired certificate,\n\t// like so: `?domain=example.com`. Generally, this endpoint\n\t// is not exposed publicly to avoid a minor information leak\n\t// (which domains are serviced by your application).\n\t//\n\t// The endpoint must return a 200 OK status if a certificate\n\t// is allowed; anything else will cause it to be denied.\n\t// Redirects are not followed.\n\tEndpoint string `json:\"endpoint\"`\n\n\tlogger   *zap.Logger\n\treplacer *caddy.Replacer\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (PermissionByHTTP) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.permission.http\",\n\t\tNew: func() caddy.Module { return new(PermissionByHTTP) },\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (p *PermissionByHTTP) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tif !d.Next() {\n\t\treturn nil\n\t}\n\tif !d.AllArgs(&p.Endpoint) {\n\t\treturn d.ArgErr()\n\t}\n\treturn nil\n}\n\nfunc (p *PermissionByHTTP) Provision(ctx caddy.Context) error {\n\tp.logger = ctx.Logger()\n\tp.replacer = caddy.NewReplacer()\n\treturn nil\n}\n\nfunc (p PermissionByHTTP) CertificateAllowed(ctx context.Context, name string) error {\n\t// run replacer on endpoint URL (for environment variables) -- return errors to prevent surprises (#5036)\n\taskEndpoint, err := p.replacer.ReplaceOrErr(p.Endpoint, true, true)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"preparing 'ask' endpoint: %v\", err)\n\t}\n\n\taskURL, err := url.Parse(askEndpoint)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"parsing ask URL: %v\", err)\n\t}\n\tqs := askURL.Query()\n\tqs.Set(\"domain\", name)\n\taskURL.RawQuery = qs.Encode()\n\taskURLString := askURL.String()\n\n\tvar remote string\n\tif chi, ok := ctx.Value(certmagic.ClientHelloInfoCtxKey).(*tls.ClientHelloInfo); ok && chi != nil {\n\t\tremote = chi.Conn.RemoteAddr().String()\n\t}\n\n\tif c := p.logger.Check(zapcore.DebugLevel, \"asking permission endpoint\"); c != nil {\n\t\tc.Write(\n\t\t\tzap.String(\"remote\", remote),\n\t\t\tzap.String(\"domain\", name),\n\t\t\tzap.String(\"url\", askURLString),\n\t\t)\n\t}\n\n\tresp, err := onDemandAskClient.Get(askURLString)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"checking %v to determine if certificate for hostname '%s' should be allowed: %v\",\n\t\t\taskEndpoint, name, err)\n\t}\n\tresp.Body.Close()\n\n\tif c := p.logger.Check(zapcore.DebugLevel, \"response from permission endpoint\"); c != nil {\n\t\tc.Write(\n\t\t\tzap.String(\"remote\", remote),\n\t\t\tzap.String(\"domain\", name),\n\t\t\tzap.String(\"url\", askURLString),\n\t\t\tzap.Int(\"status\", resp.StatusCode),\n\t\t)\n\t}\n\n\tif resp.StatusCode < 200 || resp.StatusCode > 299 {\n\t\treturn fmt.Errorf(\"%s: %w %s - non-2xx status code %d\", name, ErrPermissionDenied, askEndpoint, resp.StatusCode)\n\t}\n\n\treturn nil\n}\n\n// ErrPermissionDenied is an error that should be wrapped or returned when the\n// configured permission module does not allow a certificate to be issued,\n// to distinguish that from other errors such as connection failure.\nvar ErrPermissionDenied = errors.New(\"certificate not allowed by permission module\")\n\n// These perpetual values are used for on-demand TLS.\nvar (\n\tonDemandAskClient = &http.Client{\n\t\tTimeout: 10 * time.Second,\n\t\tCheckRedirect: func(req *http.Request, via []*http.Request) error {\n\t\t\treturn fmt.Errorf(\"following http redirects is not allowed\")\n\t\t},\n\t}\n)\n\n// Interface guards\nvar (\n\t_ OnDemandPermission = (*PermissionByHTTP)(nil)\n\t_ caddy.Provisioner  = (*PermissionByHTTP)(nil)\n)\n",
    "source_file": "modules/caddytls/ondemand.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(LeafFolderLoader{})\n}\n\n// LeafFolderLoader loads certificates and their associated keys from disk\n// by recursively walking the specified directories, looking for PEM\n// files which contain both a certificate and a key.\ntype LeafFolderLoader struct {\n\tFolders []string `json:\"folders,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (LeafFolderLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.leaf_cert_loader.folder\",\n\t\tNew: func() caddy.Module { return new(LeafFolderLoader) },\n\t}\n}\n\n// Provision implements caddy.Provisioner.\nfunc (fl *LeafFolderLoader) Provision(ctx caddy.Context) error {\n\trepl, ok := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif !ok {\n\t\trepl = caddy.NewReplacer()\n\t}\n\tfor k, path := range fl.Folders {\n\t\tfl.Folders[k] = repl.ReplaceKnown(path, \"\")\n\t}\n\treturn nil\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (fl *LeafFolderLoader) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.NextArg()\n\tfl.Folders = append(fl.Folders, d.RemainingArgs()...)\n\treturn nil\n}\n\n// LoadLeafCertificates loads all the leaf certificates in the directories\n// listed in fl from all files ending with .pem.\nfunc (fl LeafFolderLoader) LoadLeafCertificates() ([]*x509.Certificate, error) {\n\tvar certs []*x509.Certificate\n\tfor _, dir := range fl.Folders {\n\t\terr := filepath.Walk(dir, func(fpath string, info os.FileInfo, err error) error {\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to traverse into path: %s\", fpath)\n\t\t\t}\n\t\t\tif info.IsDir() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif !strings.HasSuffix(strings.ToLower(info.Name()), \".pem\") {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tcertData, err := convertPEMFilesToDERBytes(fpath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcert, err := x509.ParseCertificate(certData)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"%s: %w\", fpath, err)\n\t\t\t}\n\n\t\t\tcerts = append(certs, cert)\n\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn certs, nil\n}\n\nvar (\n\t_ LeafCertificateLoader = (*LeafFolderLoader)(nil)\n\t_ caddy.Provisioner     = (*LeafFolderLoader)(nil)\n\t_ caddyfile.Unmarshaler = (*LeafFolderLoader)(nil)\n)\n",
    "source_file": "modules/caddytls/leaffolderloader.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"encoding/pem\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"reflect\"\n\t\"slices\"\n\t\"strings\"\n\n\t\"github.com/mholt/acmez/v3\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(LeafCertClientAuth{})\n}\n\n// ConnectionPolicies govern the establishment of TLS connections. It is\n// an ordered group of connection policies; the first matching policy will\n// be used to configure TLS connections at handshake-time.\ntype ConnectionPolicies []*ConnectionPolicy\n\n// Provision sets up each connection policy. It should be called\n// during the Validate() phase, after the TLS app (if any) is\n// already set up.\nfunc (cp ConnectionPolicies) Provision(ctx caddy.Context) error {\n\tfor i, pol := range cp {\n\t\t// matchers\n\t\tmods, err := ctx.LoadModule(pol, \"MatchersRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading handshake matchers: %v\", err)\n\t\t}\n\t\tfor _, modIface := range mods.(map[string]any) {\n\t\t\tcp[i].matchers = append(cp[i].matchers, modIface.(ConnectionMatcher))\n\t\t}\n\n\t\t// enable HTTP/2 by default\n\t\tif pol.ALPN == nil {\n\t\t\tpol.ALPN = append(pol.ALPN, defaultALPN...)\n\t\t}\n\n\t\t// pre-build standard TLS config so we don't have to at handshake-time\n\t\terr = pol.buildStandardTLSConfig(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"connection policy %d: building standard TLS config: %s\", i, err)\n\t\t}\n\n\t\tif pol.ClientAuthentication != nil && len(pol.ClientAuthentication.VerifiersRaw) > 0 {\n\t\t\tclientCertValidations, err := ctx.LoadModule(pol.ClientAuthentication, \"VerifiersRaw\")\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading client cert verifiers: %v\", err)\n\t\t\t}\n\t\t\tfor _, validator := range clientCertValidations.([]any) {\n\t\t\t\tcp[i].ClientAuthentication.verifiers = append(cp[i].ClientAuthentication.verifiers, validator.(ClientCertificateVerifier))\n\t\t\t}\n\t\t}\n\n\t\tif len(pol.HandshakeContextRaw) > 0 {\n\t\t\tmodIface, err := ctx.LoadModule(pol, \"HandshakeContextRaw\")\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading handshake context module: %v\", err)\n\t\t\t}\n\t\t\tcp[i].handshakeContext = modIface.(HandshakeContext)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// TLSConfig returns a standard-lib-compatible TLS configuration which\n// selects the first matching policy based on the ClientHello.\nfunc (cp ConnectionPolicies) TLSConfig(ctx caddy.Context) *tls.Config {\n\t// using ServerName to match policies is extremely common, especially in configs\n\t// with lots and lots of different policies; we can fast-track those by indexing\n\t// them by SNI, so we don't have to iterate potentially thousands of policies\n\t// (TODO: this map does not account for wildcards, see if this is a problem in practice? look for reports of high connection latency with wildcard certs but low latency for non-wildcards in multi-thousand-cert deployments)\n\tindexedBySNI := make(map[string]ConnectionPolicies)\n\tif len(cp) > 30 {\n\t\tfor _, p := range cp {\n\t\t\tfor _, m := range p.matchers {\n\t\t\t\tif sni, ok := m.(MatchServerName); ok {\n\t\t\t\t\tfor _, sniName := range sni {\n\t\t\t\t\t\t// index for fast lookups during handshakes\n\t\t\t\t\t\tindexedBySNI[sniName] = append(indexedBySNI[sniName], p)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tgetConfigForClient := func(hello *tls.ClientHelloInfo) (*tls.Config, error) {\n\t\t// filter policies by SNI first, if possible, to speed things up\n\t\t// when there may be lots of policies\n\t\tpossiblePolicies := cp\n\t\tif indexedPolicies, ok := indexedBySNI[hello.ServerName]; ok {\n\t\t\tpossiblePolicies = indexedPolicies\n\t\t}\n\n\tpolicyLoop:\n\t\tfor _, pol := range possiblePolicies {\n\t\t\tfor _, matcher := range pol.matchers {\n\t\t\t\tif !matcher.Match(hello) {\n\t\t\t\t\tcontinue policyLoop\n\t\t\t\t}\n\t\t\t}\n\t\t\tif pol.Drop {\n\t\t\t\treturn nil, fmt.Errorf(\"dropping connection\")\n\t\t\t}\n\t\t\treturn pol.TLSConfig, nil\n\t\t}\n\n\t\treturn nil, fmt.Errorf(\"no server TLS configuration available for ClientHello: %+v\", hello)\n\t}\n\n\ttlsCfg := &tls.Config{\n\t\tMinVersion:         tls.VersionTLS12,\n\t\tGetConfigForClient: getConfigForClient,\n\t}\n\n\t// enable ECH, if configured\n\tif tlsAppIface, err := ctx.AppIfConfigured(\"tls\"); err == nil {\n\t\ttlsApp := tlsAppIface.(*TLS)\n\n\t\tif tlsApp.EncryptedClientHello != nil && len(tlsApp.EncryptedClientHello.configs) > 0 {\n\t\t\t// if no publication was configured, we apply ECH to all server names by default,\n\t\t\t// but the TLS app needs to know what they are in this case, since they don't appear\n\t\t\t// in its config (remember, TLS connection policies are used by *other* apps to\n\t\t\t// run TLS servers) -- we skip names with placeholders\n\t\t\tif tlsApp.EncryptedClientHello.Publication == nil {\n\t\t\t\tvar echNames []string\n\t\t\t\trepl := caddy.NewReplacer()\n\t\t\t\tfor _, p := range cp {\n\t\t\t\t\tfor _, m := range p.matchers {\n\t\t\t\t\t\tif sni, ok := m.(MatchServerName); ok {\n\t\t\t\t\t\t\tfor _, name := range sni {\n\t\t\t\t\t\t\t\tfinalName := strings.ToLower(repl.ReplaceAll(name, \"\"))\n\t\t\t\t\t\t\t\techNames = append(echNames, finalName)\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\ttlsApp.RegisterServerNames(echNames)\n\t\t\t}\n\n\t\t\t// TODO: Ideally, ECH keys should be rotated. However, as of Go 1.24, the std lib implementation\n\t\t\t// does not support safely modifying the tls.Config's EncryptedClientHelloKeys field.\n\t\t\t// So, we implement static ECH keys temporarily. See https://github.com/golang/go/issues/71920.\n\t\t\t// Revisit this after Go 1.25 is released and implement key rotation.\n\t\t\tvar stdECHKeys []tls.EncryptedClientHelloKey\n\t\t\tfor _, echConfigs := range tlsApp.EncryptedClientHello.configs {\n\t\t\t\tfor _, c := range echConfigs {\n\t\t\t\t\tstdECHKeys = append(stdECHKeys, tls.EncryptedClientHelloKey{\n\t\t\t\t\t\tConfig:      c.configBin,\n\t\t\t\t\t\tPrivateKey:  c.privKeyBin,\n\t\t\t\t\t\tSendAsRetry: c.sendAsRetry,\n\t\t\t\t\t})\n\t\t\t\t}\n\t\t\t}\n\t\t\ttlsCfg.EncryptedClientHelloKeys = stdECHKeys\n\t\t}\n\t}\n\n\treturn tlsCfg\n}\n\n// ConnectionPolicy specifies the logic for handling a TLS handshake.\n// An empty policy is valid; safe and sensible defaults will be used.\ntype ConnectionPolicy struct {\n\t// How to match this policy with a TLS ClientHello. If\n\t// this policy is the first to match, it will be used.\n\tMatchersRaw caddy.ModuleMap `json:\"match,omitempty\" caddy:\"namespace=tls.handshake_match\"`\n\tmatchers    []ConnectionMatcher\n\n\t// How to choose a certificate if more than one matched\n\t// the given ServerName (SNI) value.\n\tCertSelection *CustomCertSelectionPolicy `json:\"certificate_selection,omitempty\"`\n\n\t// The list of cipher suites to support. Caddy's\n\t// defaults are modern and secure.\n\tCipherSuites []string `json:\"cipher_suites,omitempty\"`\n\n\t// The list of elliptic curves to support. Caddy's\n\t// defaults are modern and secure.\n\tCurves []string `json:\"curves,omitempty\"`\n\n\t// Protocols to use for Application-Layer Protocol\n\t// Negotiation (ALPN) during the handshake.\n\tALPN []string `json:\"alpn,omitempty\"`\n\n\t// Minimum TLS protocol version to allow. Default: `tls1.2`\n\tProtocolMin string `json:\"protocol_min,omitempty\"`\n\n\t// Maximum TLS protocol version to allow. Default: `tls1.3`\n\tProtocolMax string `json:\"protocol_max,omitempty\"`\n\n\t// Reject TLS connections. EXPERIMENTAL: May change.\n\tDrop bool `json:\"drop,omitempty\"`\n\n\t// Enables and configures TLS client authentication.\n\tClientAuthentication *ClientAuthentication `json:\"client_authentication,omitempty\"`\n\n\t// DefaultSNI becomes the ServerName in a ClientHello if there\n\t// is no policy configured for the empty SNI value.\n\tDefaultSNI string `json:\"default_sni,omitempty\"`\n\n\t// FallbackSNI becomes the ServerName in a ClientHello if\n\t// the original ServerName doesn't match any certificates\n\t// in the cache. The use cases for this are very niche;\n\t// typically if a client is a CDN and passes through the\n\t// ServerName of the downstream handshake but can accept\n\t// a certificate with the origin's hostname instead, then\n\t// you would set this to your origin's hostname. Note that\n\t// Caddy must be managing a certificate for this name.\n\t//\n\t// This feature is EXPERIMENTAL and subject to change or removal.\n\tFallbackSNI string `json:\"fallback_sni,omitempty\"`\n\n\t// Also known as \"SSLKEYLOGFILE\", TLS secrets will be written to\n\t// this file in NSS key log format which can then be parsed by\n\t// Wireshark and other tools. This is INSECURE as it allows other\n\t// programs or tools to decrypt TLS connections. However, this\n\t// capability can be useful for debugging and troubleshooting.\n\t// **ENABLING THIS LOG COMPROMISES SECURITY!**\n\t//\n\t// This feature is EXPERIMENTAL and subject to change or removal.\n\tInsecureSecretsLog string `json:\"insecure_secrets_log,omitempty\"`\n\n\t// A module that can manipulate the context passed into CertMagic's\n\t// certificate management functions during TLS handshakes.\n\t// EXPERIMENTAL - subject to change or removal.\n\tHandshakeContextRaw json.RawMessage `json:\"handshake_context,omitempty\" caddy:\"namespace=tls.context inline_key=module\"`\n\thandshakeContext    HandshakeContext\n\n\t// TLSConfig is the fully-formed, standard lib TLS config\n\t// used to serve TLS connections. Provision all\n\t// ConnectionPolicies to populate this. It is exported only\n\t// so it can be minimally adjusted after provisioning\n\t// if necessary (like to adjust NextProtos to disable HTTP/2),\n\t// and may be unexported in the future.\n\tTLSConfig *tls.Config `json:\"-\"`\n}\n\ntype HandshakeContext interface {\n\t// HandshakeContext returns a context to pass into CertMagic's\n\t// GetCertificate function used to serve, load, and manage certs\n\t// during TLS handshakes. Generally you'll start with the context\n\t// from the ClientHelloInfo, but you may use other information\n\t// from it as well. Return an error to abort the handshake.\n\tHandshakeContext(*tls.ClientHelloInfo) (context.Context, error)\n}\n\nfunc (p *ConnectionPolicy) buildStandardTLSConfig(ctx caddy.Context) error {\n\ttlsAppIface, err := ctx.App(\"tls\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting tls app: %v\", err)\n\t}\n\ttlsApp := tlsAppIface.(*TLS)\n\n\t// fill in some \"easy\" default values, but for other values\n\t// (such as slices), we should ensure that they start empty\n\t// so the user-provided config can fill them in; then we will\n\t// fill in a default config at the end if they are still unset\n\tcfg := &tls.Config{\n\t\tNextProtos: p.ALPN,\n\t\tGetCertificate: func(hello *tls.ClientHelloInfo) (*tls.Certificate, error) {\n\t\t\t// TODO: I don't love how this works: we pre-build certmagic configs\n\t\t\t// so that handshakes are faster. Unfortunately, certmagic configs are\n\t\t\t// comprised of settings from both a TLS connection policy and a TLS\n\t\t\t// automation policy. The only two fields (as of March 2020; v2 beta 17)\n\t\t\t// of a certmagic config that come from the TLS connection policy are\n\t\t\t// CertSelection and DefaultServerName, so an automation policy is what\n\t\t\t// builds the base certmagic config. Since the pre-built config is\n\t\t\t// shared, I don't think we can change any of its fields per-handshake,\n\t\t\t// hence the awkward shallow copy (dereference) here and the subsequent\n\t\t\t// changing of some of its fields. I'm worried this dereference allocates\n\t\t\t// more at handshake-time, but I don't know how to practically pre-build\n\t\t\t// a certmagic config for each combination of conn policy + automation policy...\n\t\t\tcfg := *tlsApp.getConfigForName(hello.ServerName)\n\t\t\tif p.CertSelection != nil {\n\t\t\t\t// you would think we could just set this whether or not\n\t\t\t\t// p.CertSelection is nil, but that leads to panics if\n\t\t\t\t// it is, because cfg.CertSelection is an interface,\n\t\t\t\t// so it will have a non-nil value even if the actual\n\t\t\t\t// value underlying it is nil (sigh)\n\t\t\t\tcfg.CertSelection = p.CertSelection\n\t\t\t}\n\t\t\tcfg.DefaultServerName = p.DefaultSNI\n\t\t\tcfg.FallbackServerName = p.FallbackSNI\n\n\t\t\t// TODO: experimental: if a handshake context module is configured, allow it\n\t\t\t// to modify the context before passing it into CertMagic's GetCertificate\n\t\t\tctx := hello.Context()\n\t\t\tif p.handshakeContext != nil {\n\t\t\t\tctx, err = p.handshakeContext.HandshakeContext(hello)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"handshake context: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn cfg.GetCertificateWithContext(ctx, hello)\n\t\t},\n\t\tMinVersion: tls.VersionTLS12,\n\t\tMaxVersion: tls.VersionTLS13,\n\t}\n\n\t// session tickets support\n\tif tlsApp.SessionTickets != nil {\n\t\tcfg.SessionTicketsDisabled = tlsApp.SessionTickets.Disabled\n\n\t\t// session ticket key rotation\n\t\ttlsApp.SessionTickets.register(cfg)\n\t\tctx.OnCancel(func() {\n\t\t\t// do cleanup when the context is canceled because,\n\t\t\t// though unlikely, it is possible that a context\n\t\t\t// needing a TLS server config could exist for less\n\t\t\t// than the lifetime of the whole app\n\t\t\ttlsApp.SessionTickets.unregister(cfg)\n\t\t})\n\t}\n\n\t// TODO: Clean up session ticket active locks in storage if app (or process) is being closed!\n\n\t// add all the cipher suites in order, without duplicates\n\tcipherSuitesAdded := make(map[uint16]struct{})\n\tfor _, csName := range p.CipherSuites {\n\t\tcsID := CipherSuiteID(csName)\n\t\tif csID == 0 {\n\t\t\treturn fmt.Errorf(\"unsupported cipher suite: %s\", csName)\n\t\t}\n\t\tif _, ok := cipherSuitesAdded[csID]; !ok {\n\t\t\tcipherSuitesAdded[csID] = struct{}{}\n\t\t\tcfg.CipherSuites = append(cfg.CipherSuites, csID)\n\t\t}\n\t}\n\n\t// add all the curve preferences in order, without duplicates\n\tcurvesAdded := make(map[tls.CurveID]struct{})\n\tfor _, curveName := range p.Curves {\n\t\tcurveID := SupportedCurves[curveName]\n\t\tif _, ok := curvesAdded[curveID]; !ok {\n\t\t\tcurvesAdded[curveID] = struct{}{}\n\t\t\tcfg.CurvePreferences = append(cfg.CurvePreferences, curveID)\n\t\t}\n\t}\n\n\t// ensure ALPN includes the ACME TLS-ALPN protocol\n\talpnFound := slices.Contains(p.ALPN, acmez.ACMETLS1Protocol)\n\tif !alpnFound && (cfg.NextProtos == nil || len(cfg.NextProtos) > 0) {\n\t\tcfg.NextProtos = append(cfg.NextProtos, acmez.ACMETLS1Protocol)\n\t}\n\n\t// min and max protocol versions\n\tif (p.ProtocolMin != \"\" && p.ProtocolMax != \"\") && p.ProtocolMin > p.ProtocolMax {\n\t\treturn fmt.Errorf(\"protocol min (%x) cannot be greater than protocol max (%x)\", p.ProtocolMin, p.ProtocolMax)\n\t}\n\tif p.ProtocolMin != \"\" {\n\t\tcfg.MinVersion = SupportedProtocols[p.ProtocolMin]\n\t}\n\tif p.ProtocolMax != \"\" {\n\t\tcfg.MaxVersion = SupportedProtocols[p.ProtocolMax]\n\t}\n\n\t// client authentication\n\tif p.ClientAuthentication != nil {\n\t\tif err := p.ClientAuthentication.provision(ctx); err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning client CA: %v\", err)\n\t\t}\n\t\tif err := p.ClientAuthentication.ConfigureTLSConfig(cfg); err != nil {\n\t\t\treturn fmt.Errorf(\"configuring TLS client authentication: %v\", err)\n\t\t}\n\n\t\t// Prevent privilege escalation in case multiple vhosts are configured for\n\t\t// this TLS server; we could potentially figure out if that's the case, but\n\t\t// that might be complex to get right every time. Actually, two proper\n\t\t// solutions could leave tickets enabled, but I am not sure how to do them\n\t\t// properly without significant time investment; there may be new Go\n\t\t// APIs that alloaw this (Wrap/UnwrapSession?) but I do not know how to use\n\t\t// them at this time. TODO: one of these is a possible future enhancement:\n\t\t// A) Prevent resumptions across server identities (certificates): binding the ticket to the\n\t\t// certificate we would serve in a full handshake, or even bind a ticket to the exact SNI\n\t\t// it was issued under (though there are proposals for session resumption across hostnames).\n\t\t// B) Prevent resumptions falsely authenticating a client: include the realm in the ticket,\n\t\t// so that it can be validated upon resumption.\n\t\tcfg.SessionTicketsDisabled = true\n\t}\n\n\tif p.InsecureSecretsLog != \"\" {\n\t\tfilename, err := caddy.NewReplacer().ReplaceOrErr(p.InsecureSecretsLog, true, true)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfilename, err = caddy.FastAbs(filename)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tlogFile, _, err := secretsLogPool.LoadOrNew(filename, func() (caddy.Destructor, error) {\n\t\t\tw, err := os.OpenFile(filename, os.O_WRONLY|os.O_CREATE|os.O_APPEND, 0o600)\n\t\t\treturn destructableWriter{w}, err\n\t\t})\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tctx.OnCancel(func() { _, _ = secretsLogPool.Delete(filename) })\n\n\t\tcfg.KeyLogWriter = logFile.(io.Writer)\n\n\t\tif c := tlsApp.logger.Check(zapcore.WarnLevel, \"TLS SECURITY COMPROMISED: secrets logging is enabled!\"); c != nil {\n\t\t\tc.Write(zap.String(\"log_filename\", filename))\n\t\t}\n\t}\n\n\tsetDefaultTLSParams(cfg)\n\n\tp.TLSConfig = cfg\n\n\treturn nil\n}\n\n// SettingsEmpty returns true if p's settings (fields\n// except the matchers) are all empty/unset.\nfunc (p ConnectionPolicy) SettingsEmpty() bool {\n\treturn p.CertSelection == nil &&\n\t\tp.CipherSuites == nil &&\n\t\tp.Curves == nil &&\n\t\tp.ALPN == nil &&\n\t\tp.ProtocolMin == \"\" &&\n\t\tp.ProtocolMax == \"\" &&\n\t\tp.ClientAuthentication == nil &&\n\t\tp.DefaultSNI == \"\" &&\n\t\tp.FallbackSNI == \"\" &&\n\t\tp.InsecureSecretsLog == \"\"\n}\n\n// SettingsEmpty returns true if p's settings (fields\n// except the matchers) are the same as q.\nfunc (p ConnectionPolicy) SettingsEqual(q ConnectionPolicy) bool {\n\tp.MatchersRaw = nil\n\tq.MatchersRaw = nil\n\treturn reflect.DeepEqual(p, q)\n}\n\n// UnmarshalCaddyfile sets up the ConnectionPolicy from Caddyfile tokens. Syntax:\n//\n//\tconnection_policy {\n//\t\talpn                  <values...>\n//\t\tcert_selection {\n//\t\t\t...\n//\t\t}\n//\t\tciphers               <cipher_suites...>\n//\t\tclient_auth {\n//\t\t\t...\n//\t\t}\n//\t\tcurves                <curves...>\n//\t\tdefault_sni           <server_name>\n//\t\tmatch {\n//\t\t\t...\n//\t\t}\n//\t\tprotocols             <min> [<max>]\n//\t\t# EXPERIMENTAL:\n//\t\tdrop\n//\t\tfallback_sni          <server_name>\n//\t\tinsecure_secrets_log  <log_file>\n//\t}\nfunc (cp *ConnectionPolicy) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t_, wrapper := d.Next(), d.Val()\n\n\t// No same-line options are supported\n\tif d.CountRemainingArgs() > 0 {\n\t\treturn d.ArgErr()\n\t}\n\n\tvar hasCertSelection, hasClientAuth, hasDefaultSNI, hasDrop,\n\t\thasFallbackSNI, hasInsecureSecretsLog, hasMatch, hasProtocols bool\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\toptionName := d.Val()\n\t\tswitch optionName {\n\t\tcase \"alpn\":\n\t\t\tif d.CountRemainingArgs() == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tcp.ALPN = append(cp.ALPN, d.RemainingArgs()...)\n\t\tcase \"cert_selection\":\n\t\t\tif hasCertSelection {\n\t\t\t\treturn d.Errf(\"duplicate %s option '%s'\", wrapper, optionName)\n\t\t\t}\n\t\t\tp := &CustomCertSelectionPolicy{}\n\t\t\tif err := p.UnmarshalCaddyfile(d.NewFromNextSegment()); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcp.CertSelection, hasCertSelection = p, true\n\t\tcase \"client_auth\":\n\t\t\tif hasClientAuth {\n\t\t\t\treturn d.Errf(\"duplicate %s option '%s'\", wrapper, optionName)\n\t\t\t}\n\t\t\tca := &ClientAuthentication{}\n\t\t\tif err := ca.UnmarshalCaddyfile(d.NewFromNextSegment()); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcp.ClientAuthentication, hasClientAuth = ca, true\n\t\tcase \"ciphers\":\n\t\t\tif d.CountRemainingArgs() == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tcp.CipherSuites = append(cp.CipherSuites, d.RemainingArgs()...)\n\t\tcase \"curves\":\n\t\t\tif d.CountRemainingArgs() == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tcp.Curves = append(cp.Curves, d.RemainingArgs()...)\n\t\tcase \"default_sni\":\n\t\t\tif hasDefaultSNI {\n\t\t\t\treturn d.Errf(\"duplicate %s option '%s'\", wrapper, optionName)\n\t\t\t}\n\t\t\tif d.CountRemainingArgs() != 1 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\t_, cp.DefaultSNI, hasDefaultSNI = d.NextArg(), d.Val(), true\n\t\tcase \"drop\": // EXPERIMENTAL\n\t\t\tif hasDrop {\n\t\t\t\treturn d.Errf(\"duplicate %s option '%s'\", wrapper, optionName)\n\t\t\t}\n\t\t\tcp.Drop, hasDrop = true, true\n\t\tcase \"fallback_sni\": // EXPERIMENTAL\n\t\t\tif hasFallbackSNI {\n\t\t\t\treturn d.Errf(\"duplicate %s option '%s'\", wrapper, optionName)\n\t\t\t}\n\t\t\tif d.CountRemainingArgs() != 1 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\t_, cp.FallbackSNI, hasFallbackSNI = d.NextArg(), d.Val(), true\n\t\tcase \"insecure_secrets_log\": // EXPERIMENTAL\n\t\t\tif hasInsecureSecretsLog {\n\t\t\t\treturn d.Errf(\"duplicate %s option '%s'\", wrapper, optionName)\n\t\t\t}\n\t\t\tif d.CountRemainingArgs() != 1 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\t_, cp.InsecureSecretsLog, hasInsecureSecretsLog = d.NextArg(), d.Val(), true\n\t\tcase \"match\":\n\t\t\tif hasMatch {\n\t\t\t\treturn d.Errf(\"duplicate %s option '%s'\", wrapper, optionName)\n\t\t\t}\n\t\t\tmatcherSet, err := ParseCaddyfileNestedMatcherSet(d)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcp.MatchersRaw, hasMatch = matcherSet, true\n\t\tcase \"protocols\":\n\t\t\tif hasProtocols {\n\t\t\t\treturn d.Errf(\"duplicate %s option '%s'\", wrapper, optionName)\n\t\t\t}\n\t\t\tif d.CountRemainingArgs() == 0 || d.CountRemainingArgs() > 2 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\t_, cp.ProtocolMin, hasProtocols = d.NextArg(), d.Val(), true\n\t\t\tif d.NextArg() {\n\t\t\t\tcp.ProtocolMax = d.Val()\n\t\t\t}\n\t\tdefault:\n\t\t\treturn d.ArgErr()\n\t\t}\n\n\t\t// No nested blocks are supported\n\t\tif d.NextBlock(nesting + 1) {\n\t\t\treturn d.Errf(\"malformed %s option '%s': blocks are not supported\", wrapper, optionName)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// ClientAuthentication configures TLS client auth.\ntype ClientAuthentication struct {\n\t// Certificate authority module which provides the certificate pool of trusted certificates\n\tCARaw json.RawMessage `json:\"ca,omitempty\" caddy:\"namespace=tls.ca_pool.source inline_key=provider\"`\n\tca    CA\n\n\t// Deprecated: Use the `ca` field with the `tls.ca_pool.source.inline` module instead.\n\t// A list of base64 DER-encoded CA certificates\n\t// against which to validate client certificates.\n\t// Client certs which are not signed by any of\n\t// these CAs will be rejected.\n\tTrustedCACerts []string `json:\"trusted_ca_certs,omitempty\"`\n\n\t// Deprecated: Use the `ca` field with the `tls.ca_pool.source.file` module instead.\n\t// TrustedCACertPEMFiles is a list of PEM file names\n\t// from which to load certificates of trusted CAs.\n\t// Client certificates which are not signed by any of\n\t// these CA certificates will be rejected.\n\tTrustedCACertPEMFiles []string `json:\"trusted_ca_certs_pem_files,omitempty\"`\n\n\t// Deprecated: This field is deprecated and will be removed in\n\t// a future version. Please use the `validators` field instead\n\t// with the tls.client_auth.verifier.leaf module instead.\n\t//\n\t// A list of base64 DER-encoded client leaf certs\n\t// to accept. If this list is not empty, client certs\n\t// which are not in this list will be rejected.\n\tTrustedLeafCerts []string `json:\"trusted_leaf_certs,omitempty\"`\n\n\t// Client certificate verification modules. These can perform\n\t// custom client authentication checks, such as ensuring the\n\t// certificate is not revoked.\n\tVerifiersRaw []json.RawMessage `json:\"verifiers,omitempty\" caddy:\"namespace=tls.client_auth.verifier inline_key=verifier\"`\n\n\tverifiers []ClientCertificateVerifier\n\n\t// The mode for authenticating the client. Allowed values are:\n\t//\n\t// Mode | Description\n\t// -----|---------------\n\t// `request` | Ask clients for a certificate, but allow even if there isn't one; do not verify it\n\t// `require` | Require clients to present a certificate, but do not verify it\n\t// `verify_if_given` | Ask clients for a certificate; allow even if there isn't one, but verify it if there is\n\t// `require_and_verify` | Require clients to present a valid certificate that is verified\n\t//\n\t// The default mode is `require_and_verify` if any\n\t// TrustedCACerts or TrustedCACertPEMFiles or TrustedLeafCerts\n\t// are provided; otherwise, the default mode is `require`.\n\tMode string `json:\"mode,omitempty\"`\n\n\texistingVerifyPeerCert func([][]byte, [][]*x509.Certificate) error\n}\n\n// UnmarshalCaddyfile parses the Caddyfile segment to set up the client authentication. Syntax:\n//\n//\tclient_auth {\n//\t\tmode                   [request|require|verify_if_given|require_and_verify]\n//\t \ttrust_pool\t\t\t   <module> {\n//\t\t\t...\n//\t\t}\n//\t\tverifier               <module>\n//\t}\n//\n// If `mode` is not provided, it defaults to `require_and_verify` if `trust_pool` is provided.\n// Otherwise, it defaults to `require`.\nfunc (ca *ClientAuthentication) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tfor d.NextArg() {\n\t\t// consume any tokens on the same line, if any.\n\t}\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tsubdir := d.Val()\n\t\tswitch subdir {\n\t\tcase \"mode\":\n\t\t\tif d.CountRemainingArgs() > 1 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif !d.Args(&ca.Mode) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\tcase \"trusted_ca_cert\":\n\t\t\tcaddy.Log().Warn(\"The 'trusted_ca_cert' field is deprecated. Use the 'trust_pool' field instead.\")\n\t\t\tif len(ca.CARaw) != 0 {\n\t\t\t\treturn d.Err(\"cannot specify both 'trust_pool' and 'trusted_ca_cert' or 'trusted_ca_cert_file'\")\n\t\t\t}\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tca.TrustedCACerts = append(ca.TrustedCACerts, d.Val())\n\t\tcase \"trusted_leaf_cert\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tca.TrustedLeafCerts = append(ca.TrustedLeafCerts, d.Val())\n\t\tcase \"trusted_ca_cert_file\":\n\t\t\tcaddy.Log().Warn(\"The 'trusted_ca_cert_file' field is deprecated. Use the 'trust_pool' field instead.\")\n\t\t\tif len(ca.CARaw) != 0 {\n\t\t\t\treturn d.Err(\"cannot specify both 'trust_pool' and 'trusted_ca_cert' or 'trusted_ca_cert_file'\")\n\t\t\t}\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tfilename := d.Val()\n\t\t\tders, err := convertPEMFilesToDER(filename)\n\t\t\tif err != nil {\n\t\t\t\treturn d.WrapErr(err)\n\t\t\t}\n\t\t\tca.TrustedCACerts = append(ca.TrustedCACerts, ders...)\n\t\tcase \"trusted_leaf_cert_file\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tfilename := d.Val()\n\t\t\tders, err := convertPEMFilesToDER(filename)\n\t\t\tif err != nil {\n\t\t\t\treturn d.WrapErr(err)\n\t\t\t}\n\t\t\tca.TrustedLeafCerts = append(ca.TrustedLeafCerts, ders...)\n\t\tcase \"trust_pool\":\n\t\t\tif len(ca.TrustedCACerts) != 0 {\n\t\t\t\treturn d.Err(\"cannot specify both 'trust_pool' and 'trusted_ca_cert' or 'trusted_ca_cert_file'\")\n\t\t\t}\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tmodName := d.Val()\n\t\t\tmod, err := caddyfile.UnmarshalModule(d, \"tls.ca_pool.source.\"+modName)\n\t\t\tif err != nil {\n\t\t\t\treturn d.WrapErr(err)\n\t\t\t}\n\t\t\tcaMod, ok := mod.(CA)\n\t\t\tif !ok {\n\t\t\t\treturn fmt.Errorf(\"trust_pool module '%s' is not a certificate pool provider\", caMod)\n\t\t\t}\n\t\t\tca.CARaw = caddyconfig.JSONModuleObject(caMod, \"provider\", modName, nil)\n\t\tcase \"verifier\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\t\tvType := d.Val()\n\t\t\tmodID := \"tls.client_auth.verifier.\" + vType\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\t_, ok := unm.(ClientCertificateVerifier)\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"module '%s' is not a caddytls.ClientCertificateVerifier\", modID)\n\t\t\t}\n\t\t\tca.VerifiersRaw = append(ca.VerifiersRaw, caddyconfig.JSONModuleObject(unm, \"verifier\", vType, nil))\n\t\tdefault:\n\t\t\treturn d.Errf(\"unknown subdirective for client_auth: %s\", subdir)\n\t\t}\n\t}\n\n\t// only trust_ca_cert or trust_ca_cert_file was specified\n\tif len(ca.TrustedCACerts) > 0 {\n\t\tfileMod := &InlineCAPool{}\n\t\tfileMod.TrustedCACerts = append(fileMod.TrustedCACerts, ca.TrustedCACerts...)\n\t\tca.CARaw = caddyconfig.JSONModuleObject(fileMod, \"provider\", \"inline\", nil)\n\t\tca.TrustedCACertPEMFiles, ca.TrustedCACerts = nil, nil\n\t}\n\treturn nil\n}\n\nfunc convertPEMFilesToDER(filename string) ([]string, error) {\n\tcertDataPEM, err := os.ReadFile(filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar ders []string\n\t// while block is not nil, we have more certificates in the file\n\tfor block, rest := pem.Decode(certDataPEM); block != nil; block, rest = pem.Decode(rest) {\n\t\tif block.Type != \"CERTIFICATE\" {\n\t\t\treturn nil, fmt.Errorf(\"no CERTIFICATE pem block found in %s\", filename)\n\t\t}\n\t\tders = append(\n\t\t\tders,\n\t\t\tbase64.StdEncoding.EncodeToString(block.Bytes),\n\t\t)\n\t}\n\t// if we decoded nothing, return an error\n\tif len(ders) == 0 {\n\t\treturn nil, fmt.Errorf(\"no CERTIFICATE pem block found in %s\", filename)\n\t}\n\treturn ders, nil\n}\n\nfunc (clientauth *ClientAuthentication) provision(ctx caddy.Context) error {\n\tif len(clientauth.CARaw) > 0 && (len(clientauth.TrustedCACerts) > 0 || len(clientauth.TrustedCACertPEMFiles) > 0) {\n\t\treturn fmt.Errorf(\"conflicting config for client authentication trust CA\")\n\t}\n\n\t// convert all named file paths to inline\n\tif len(clientauth.TrustedCACertPEMFiles) > 0 {\n\t\tfor _, fpath := range clientauth.TrustedCACertPEMFiles {\n\t\t\tders, err := convertPEMFilesToDER(fpath)\n\t\t\tif err != nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tclientauth.TrustedCACerts = append(clientauth.TrustedCACerts, ders...)\n\t\t}\n\t}\n\n\t// if we have TrustedCACerts explicitly set, create an 'inline' CA and return\n\tif len(clientauth.TrustedCACerts) > 0 {\n\t\tcaPool := InlineCAPool{\n\t\t\tTrustedCACerts: clientauth.TrustedCACerts,\n\t\t}\n\t\terr := caPool.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn nil\n\t\t}\n\t\tclientauth.ca = caPool\n\t}\n\n\t// if we don't have any CARaw set, there's not much work to do\n\tif clientauth.CARaw == nil {\n\t\treturn nil\n\t}\n\tcaRaw, err := ctx.LoadModule(clientauth, \"CARaw\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tca, ok := caRaw.(CA)\n\tif !ok {\n\t\treturn fmt.Errorf(\"'ca' module '%s' is not a certificate pool provider\", ca)\n\t}\n\tclientauth.ca = ca\n\n\treturn nil\n}\n\n// Active returns true if clientauth has an actionable configuration.\nfunc (clientauth ClientAuthentication) Active() bool {\n\treturn len(clientauth.TrustedCACerts) > 0 ||\n\t\tlen(clientauth.TrustedCACertPEMFiles) > 0 ||\n\t\tlen(clientauth.TrustedLeafCerts) > 0 || // TODO: DEPRECATED\n\t\tlen(clientauth.VerifiersRaw) > 0 ||\n\t\tlen(clientauth.Mode) > 0 ||\n\t\tclientauth.CARaw != nil || clientauth.ca != nil\n}\n\n// ConfigureTLSConfig sets up cfg to enforce clientauth's configuration.\nfunc (clientauth *ClientAuthentication) ConfigureTLSConfig(cfg *tls.Config) error {\n\t// if there's no actionable client auth, simply disable it\n\tif !clientauth.Active() {\n\t\tcfg.ClientAuth = tls.NoClientCert\n\t\treturn nil\n\t}\n\n\t// enforce desired mode of client authentication\n\tif len(clientauth.Mode) > 0 {\n\t\tswitch clientauth.Mode {\n\t\tcase \"request\":\n\t\t\tcfg.ClientAuth = tls.RequestClientCert\n\t\tcase \"require\":\n\t\t\tcfg.ClientAuth = tls.RequireAnyClientCert\n\t\tcase \"verify_if_given\":\n\t\t\tcfg.ClientAuth = tls.VerifyClientCertIfGiven\n\t\tcase \"require_and_verify\":\n\t\t\tcfg.ClientAuth = tls.RequireAndVerifyClientCert\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"client auth mode not recognized: %s\", clientauth.Mode)\n\t\t}\n\t} else {\n\t\t// otherwise, set a safe default mode\n\t\tif len(clientauth.TrustedCACerts) > 0 ||\n\t\t\tlen(clientauth.TrustedCACertPEMFiles) > 0 ||\n\t\t\tlen(clientauth.TrustedLeafCerts) > 0 ||\n\t\t\tclientauth.CARaw != nil || clientauth.ca != nil {\n\t\t\tcfg.ClientAuth = tls.RequireAndVerifyClientCert\n\t\t} else {\n\t\t\tcfg.ClientAuth = tls.RequireAnyClientCert\n\t\t}\n\t}\n\n\t// enforce CA verification by adding CA certs to the ClientCAs pool\n\tif clientauth.ca != nil {\n\t\tcfg.ClientCAs = clientauth.ca.CertPool()\n\t}\n\n\t// TODO: DEPRECATED: Only here for backwards compatibility.\n\t// If leaf cert is specified, enforce by adding a client auth module\n\tif len(clientauth.TrustedLeafCerts) > 0 {\n\t\tcaddy.Log().Named(\"tls.connection_policy\").Warn(\"trusted_leaf_certs is deprecated; use leaf verifier module instead\")\n\t\tvar trustedLeafCerts []*x509.Certificate\n\t\tfor _, clientCertString := range clientauth.TrustedLeafCerts {\n\t\t\tclientCert, err := decodeBase64DERCert(clientCertString)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"parsing certificate: %v\", err)\n\t\t\t}\n\t\t\ttrustedLeafCerts = append(trustedLeafCerts, clientCert)\n\t\t}\n\t\tclientauth.verifiers = append(clientauth.verifiers, LeafCertClientAuth{trustedLeafCerts: trustedLeafCerts})\n\t}\n\n\t// if a custom verification function already exists, wrap it\n\tclientauth.existingVerifyPeerCert = cfg.VerifyPeerCertificate\n\tcfg.VerifyPeerCertificate = clientauth.verifyPeerCertificate\n\treturn nil\n}\n\n// verifyPeerCertificate is for use as a tls.Config.VerifyPeerCertificate\n// callback to do custom client certificate verification. It is intended\n// for installation only by clientauth.ConfigureTLSConfig().\nfunc (clientauth *ClientAuthentication) verifyPeerCertificate(rawCerts [][]byte, verifiedChains [][]*x509.Certificate) error {\n\t// first use any pre-existing custom verification function\n\tif clientauth.existingVerifyPeerCert != nil {\n\t\terr := clientauth.existingVerifyPeerCert(rawCerts, verifiedChains)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tfor _, verifier := range clientauth.verifiers {\n\t\terr := verifier.VerifyClientCertificate(rawCerts, verifiedChains)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// decodeBase64DERCert base64-decodes, then DER-decodes, certStr.\nfunc decodeBase64DERCert(certStr string) (*x509.Certificate, error) {\n\tderBytes, err := base64.StdEncoding.DecodeString(certStr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn x509.ParseCertificate(derBytes)\n}\n\n// setDefaultTLSParams sets the default TLS cipher suites, protocol versions,\n// and server preferences of cfg if they are not already set; it does not\n// overwrite values, only fills in missing values.\nfunc setDefaultTLSParams(cfg *tls.Config) {\n\tif len(cfg.CipherSuites) == 0 {\n\t\tcfg.CipherSuites = getOptimalDefaultCipherSuites()\n\t}\n\n\t// Not a cipher suite, but still important for mitigating protocol downgrade attacks\n\t// (prepend since having it at end breaks http2 due to non-h2-approved suites before it)\n\tcfg.CipherSuites = append([]uint16{tls.TLS_FALLBACK_SCSV}, cfg.CipherSuites...)\n\n\tif len(cfg.CurvePreferences) == 0 {\n\t\tcfg.CurvePreferences = defaultCurves\n\t}\n\n\t// crypto/tls docs:\n\t// \"If EncryptedClientHelloKeys is set, MinVersion, if set, must be VersionTLS13.\"\n\tif cfg.EncryptedClientHelloKeys != nil && cfg.MinVersion != 0 && cfg.MinVersion < tls.VersionTLS13 {\n\t\tcfg.MinVersion = tls.VersionTLS13\n\t}\n}\n\n// LeafCertClientAuth verifies the client's leaf certificate.\ntype LeafCertClientAuth struct {\n\tLeafCertificateLoadersRaw []json.RawMessage `json:\"leaf_certs_loaders,omitempty\" caddy:\"namespace=tls.leaf_cert_loader inline_key=loader\"`\n\ttrustedLeafCerts          []*x509.Certificate\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (LeafCertClientAuth) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.client_auth.verifier.leaf\",\n\t\tNew: func() caddy.Module { return new(LeafCertClientAuth) },\n\t}\n}\n\nfunc (l *LeafCertClientAuth) Provision(ctx caddy.Context) error {\n\tif l.LeafCertificateLoadersRaw == nil {\n\t\treturn nil\n\t}\n\tval, err := ctx.LoadModule(l, \"LeafCertificateLoadersRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"could not parse leaf certificates loaders: %s\", err.Error())\n\t}\n\ttrustedLeafCertloaders := []LeafCertificateLoader{}\n\tfor _, loader := range val.([]any) {\n\t\ttrustedLeafCertloaders = append(trustedLeafCertloaders, loader.(LeafCertificateLoader))\n\t}\n\ttrustedLeafCertificates := []*x509.Certificate{}\n\tfor _, loader := range trustedLeafCertloaders {\n\t\tcerts, err := loader.LoadLeafCertificates()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"could not load leaf certificates: %s\", err.Error())\n\t\t}\n\t\ttrustedLeafCertificates = append(trustedLeafCertificates, certs...)\n\t}\n\tl.trustedLeafCerts = trustedLeafCertificates\n\treturn nil\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (l *LeafCertClientAuth) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.NextArg()\n\n\t// accommodate the use of one-liners\n\tif d.CountRemainingArgs() > 1 {\n\t\td.NextArg()\n\t\tmodName := d.Val()\n\t\tmod, err := caddyfile.UnmarshalModule(d, \"tls.leaf_cert_loader.\"+modName)\n\t\tif err != nil {\n\t\t\treturn d.WrapErr(err)\n\t\t}\n\t\tvMod, ok := mod.(LeafCertificateLoader)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"leaf module '%s' is not a leaf certificate loader\", vMod)\n\t\t}\n\t\tl.LeafCertificateLoadersRaw = append(\n\t\t\tl.LeafCertificateLoadersRaw,\n\t\t\tcaddyconfig.JSONModuleObject(vMod, \"loader\", modName, nil),\n\t\t)\n\t\treturn nil\n\t}\n\n\t// accommodate the use of nested blocks\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tmodName := d.Val()\n\t\tmod, err := caddyfile.UnmarshalModule(d, \"tls.leaf_cert_loader.\"+modName)\n\t\tif err != nil {\n\t\t\treturn d.WrapErr(err)\n\t\t}\n\t\tvMod, ok := mod.(LeafCertificateLoader)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"leaf module '%s' is not a leaf certificate loader\", vMod)\n\t\t}\n\t\tl.LeafCertificateLoadersRaw = append(\n\t\t\tl.LeafCertificateLoadersRaw,\n\t\t\tcaddyconfig.JSONModuleObject(vMod, \"loader\", modName, nil),\n\t\t)\n\t}\n\treturn nil\n}\n\nfunc (l LeafCertClientAuth) VerifyClientCertificate(rawCerts [][]byte, _ [][]*x509.Certificate) error {\n\tif len(rawCerts) == 0 {\n\t\treturn fmt.Errorf(\"no client certificate provided\")\n\t}\n\n\tremoteLeafCert, err := x509.ParseCertificate(rawCerts[0])\n\tif err != nil {\n\t\treturn fmt.Errorf(\"can't parse the given certificate: %s\", err.Error())\n\t}\n\n\tif slices.ContainsFunc(l.trustedLeafCerts, remoteLeafCert.Equal) {\n\t\treturn nil\n\t}\n\n\treturn fmt.Errorf(\"client leaf certificate failed validation\")\n}\n\n// PublicKeyAlgorithm is a JSON-unmarshalable wrapper type.\ntype PublicKeyAlgorithm x509.PublicKeyAlgorithm\n\n// UnmarshalJSON satisfies json.Unmarshaler.\nfunc (a *PublicKeyAlgorithm) UnmarshalJSON(b []byte) error {\n\talgoStr := strings.ToLower(strings.Trim(string(b), `\"`))\n\talgo, ok := publicKeyAlgorithms[algoStr]\n\tif !ok {\n\t\treturn fmt.Errorf(\"unrecognized public key algorithm: %s (expected one of %v)\",\n\t\t\talgoStr, publicKeyAlgorithms)\n\t}\n\t*a = PublicKeyAlgorithm(algo)\n\treturn nil\n}\n\n// ConnectionMatcher is a type which matches TLS handshakes.\ntype ConnectionMatcher interface {\n\tMatch(*tls.ClientHelloInfo) bool\n}\n\n// LeafCertificateLoader is a type that loads the trusted leaf certificates\n// for the tls.leaf_cert_loader modules\ntype LeafCertificateLoader interface {\n\tLoadLeafCertificates() ([]*x509.Certificate, error)\n}\n\n// ClientCertificateVerifier is a type which verifies client certificates.\n// It is called during verifyPeerCertificate in the TLS handshake.\ntype ClientCertificateVerifier interface {\n\tVerifyClientCertificate(rawCerts [][]byte, verifiedChains [][]*x509.Certificate) error\n}\n\nvar defaultALPN = []string{\"h2\", \"http/1.1\"}\n\ntype destructableWriter struct{ *os.File }\n\nfunc (d destructableWriter) Destruct() error { return d.Close() }\n\nvar secretsLogPool = caddy.NewUsagePool()\n\n// Interface guards\nvar (\n\t_ caddyfile.Unmarshaler = (*ClientAuthentication)(nil)\n\t_ caddyfile.Unmarshaler = (*ConnectionPolicy)(nil)\n\t_ caddyfile.Unmarshaler = (*LeafCertClientAuth)(nil)\n)\n\n// ParseCaddyfileNestedMatcherSet parses the Caddyfile tokens for a nested\n// matcher set, and returns its raw module map value.\nfunc ParseCaddyfileNestedMatcherSet(d *caddyfile.Dispenser) (caddy.ModuleMap, error) {\n\tmatcherMap := make(map[string]ConnectionMatcher)\n\n\ttokensByMatcherName := make(map[string][]caddyfile.Token)\n\tfor nesting := d.Nesting(); d.NextArg() || d.NextBlock(nesting); {\n\t\tmatcherName := d.Val()\n\t\ttokensByMatcherName[matcherName] = append(tokensByMatcherName[matcherName], d.NextSegment()...)\n\t}\n\n\tfor matcherName, tokens := range tokensByMatcherName {\n\t\tdd := caddyfile.NewDispenser(tokens)\n\t\tdd.Next() // consume wrapper name\n\n\t\tunm, err := caddyfile.UnmarshalModule(dd, \"tls.handshake_match.\"+matcherName)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcm, ok := unm.(ConnectionMatcher)\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"matcher module '%s' is not a connection matcher\", matcherName)\n\t\t}\n\t\tmatcherMap[matcherName] = cm\n\t}\n\n\tmatcherSet := make(caddy.ModuleMap)\n\tfor name, matcher := range matcherMap {\n\t\tjsonBytes, err := json.Marshal(matcher)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"marshaling %T matcher: %v\", matcher, err)\n\t\t}\n\t\tmatcherSet[name] = jsonBytes\n\t}\n\n\treturn matcherSet, nil\n}\n",
    "source_file": "modules/caddytls/connpolicy.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"net\"\n\t\"slices\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/mholt/acmez/v3\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\t\"golang.org/x/net/idna\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// AutomationConfig governs the automated management of TLS certificates.\ntype AutomationConfig struct {\n\t// The list of automation policies. The first policy matching\n\t// a certificate or subject name will be applied.\n\tPolicies []*AutomationPolicy `json:\"policies,omitempty\"`\n\n\t// On-Demand TLS defers certificate operations to the\n\t// moment they are needed, e.g. during a TLS handshake.\n\t// Useful when you don't know all the hostnames at\n\t// config-time, or when you are not in control of the\n\t// domain names you are managing certificates for.\n\t// In 2015, Caddy became the first web server to\n\t// implement this experimental technology.\n\t//\n\t// Note that this field does not enable on-demand TLS;\n\t// it only configures it for when it is used. To enable\n\t// it, create an automation policy with `on_demand`.\n\tOnDemand *OnDemandConfig `json:\"on_demand,omitempty\"`\n\n\t// Caddy staples OCSP (and caches the response) for all\n\t// qualifying certificates by default. This setting\n\t// changes how often it scans responses for freshness,\n\t// and updates them if they are getting stale. Default: 1h\n\tOCSPCheckInterval caddy.Duration `json:\"ocsp_interval,omitempty\"`\n\n\t// Every so often, Caddy will scan all loaded, managed\n\t// certificates for expiration. This setting changes how\n\t// frequently the scan for expiring certificates is\n\t// performed. Default: 10m\n\tRenewCheckInterval caddy.Duration `json:\"renew_interval,omitempty\"`\n\n\t// How often to scan storage units for old or expired\n\t// assets and remove them. These scans exert lots of\n\t// reads (and list operations) on the storage module, so\n\t// choose a longer interval for large deployments.\n\t// Default: 24h\n\t//\n\t// Storage will always be cleaned when the process first\n\t// starts. Then, a new cleaning will be started this\n\t// duration after the previous cleaning started if the\n\t// previous cleaning finished in less than half the time\n\t// of this interval (otherwise next start will be skipped).\n\tStorageCleanInterval caddy.Duration `json:\"storage_clean_interval,omitempty\"`\n\n\tdefaultPublicAutomationPolicy   *AutomationPolicy\n\tdefaultInternalAutomationPolicy *AutomationPolicy // only initialized if necessary\n}\n\n// AutomationPolicy designates the policy for automating the\n// management (obtaining, renewal, and revocation) of managed\n// TLS certificates.\n//\n// An AutomationPolicy value is not valid until it has been\n// provisioned; use the `AddAutomationPolicy()` method on the\n// TLS app to properly provision a new policy.\ntype AutomationPolicy struct {\n\t// Which subjects (hostnames or IP addresses) this policy applies to.\n\t//\n\t// This list is a filter, not a command. In other words, it is used\n\t// only to filter whether this policy should apply to a subject that\n\t// needs a certificate; it does NOT command the TLS app to manage a\n\t// certificate for that subject. To have Caddy automate a certificate\n\t// or specific subjects, use the \"automate\" certificate loader module\n\t// of the TLS app.\n\tSubjectsRaw []string `json:\"subjects,omitempty\"`\n\n\t// The modules that may issue certificates. Default: internal if all\n\t// subjects do not qualify for public certificates; otherwise acme and\n\t// zerossl.\n\tIssuersRaw []json.RawMessage `json:\"issuers,omitempty\" caddy:\"namespace=tls.issuance inline_key=module\"`\n\n\t// Modules that can get a custom certificate to use for any\n\t// given TLS handshake at handshake-time. Custom certificates\n\t// can be useful if another entity is managing certificates\n\t// and Caddy need only get it and serve it. Specifying a Manager\n\t// enables on-demand TLS, i.e. it has the side-effect of setting\n\t// the on_demand parameter to `true`.\n\t//\n\t// TODO: This is an EXPERIMENTAL feature. Subject to change or removal.\n\tManagersRaw []json.RawMessage `json:\"get_certificate,omitempty\" caddy:\"namespace=tls.get_certificate inline_key=via\"`\n\n\t// If true, certificates will be requested with MustStaple. Not all\n\t// CAs support this, and there are potentially serious consequences\n\t// of enabling this feature without proper threat modeling.\n\tMustStaple bool `json:\"must_staple,omitempty\"`\n\n\t// How long before a certificate's expiration to try renewing it,\n\t// as a function of its total lifetime. As a general and conservative\n\t// rule, it is a good idea to renew a certificate when it has about\n\t// 1/3 of its total lifetime remaining. This utilizes the majority\n\t// of the certificate's lifetime while still saving time to\n\t// troubleshoot problems. However, for extremely short-lived certs,\n\t// you may wish to increase the ratio to ~1/2.\n\tRenewalWindowRatio float64 `json:\"renewal_window_ratio,omitempty\"`\n\n\t// The type of key to generate for certificates.\n\t// Supported values: `ed25519`, `p256`, `p384`, `rsa2048`, `rsa4096`.\n\tKeyType string `json:\"key_type,omitempty\"`\n\n\t// Optionally configure a separate storage module associated with this\n\t// manager, instead of using Caddy's global/default-configured storage.\n\tStorageRaw json.RawMessage `json:\"storage,omitempty\" caddy:\"namespace=caddy.storage inline_key=module\"`\n\n\t// If true, certificates will be managed \"on demand\"; that is, during\n\t// TLS handshakes or when needed, as opposed to at startup or config\n\t// load. This enables On-Demand TLS for this policy.\n\tOnDemand bool `json:\"on_demand,omitempty\"`\n\n\t// If true, private keys already existing in storage\n\t// will be reused. Otherwise, a new key will be\n\t// created for every new certificate to mitigate\n\t// pinning and reduce the scope of key compromise.\n\t// TEMPORARY: Key pinning is against industry best practices.\n\t// This property will likely be removed in the future.\n\t// Do not rely on it forever; watch the release notes.\n\tReusePrivateKeys bool `json:\"reuse_private_keys,omitempty\"`\n\n\t// Disables OCSP stapling. Disabling OCSP stapling puts clients at\n\t// greater risk, reduces their privacy, and usually lowers client\n\t// performance. It is NOT recommended to disable this unless you\n\t// are able to justify the costs.\n\t// EXPERIMENTAL. Subject to change.\n\tDisableOCSPStapling bool `json:\"disable_ocsp_stapling,omitempty\"`\n\n\t// Overrides the URLs of OCSP responders embedded in certificates.\n\t// Each key is a OCSP server URL to override, and its value is the\n\t// replacement. An empty value will disable querying of that server.\n\t// EXPERIMENTAL. Subject to change.\n\tOCSPOverrides map[string]string `json:\"ocsp_overrides,omitempty\"`\n\n\t// Issuers and Managers store the decoded issuer and manager modules;\n\t// they are only used to populate an underlying certmagic.Config's\n\t// fields during provisioning so that the modules can survive a\n\t// re-provisioning.\n\tIssuers  []certmagic.Issuer  `json:\"-\"`\n\tManagers []certmagic.Manager `json:\"-\"`\n\n\tsubjects []string\n\tmagic    *certmagic.Config\n\tstorage  certmagic.Storage\n}\n\n// Provision sets up ap and builds its underlying CertMagic config.\nfunc (ap *AutomationPolicy) Provision(tlsApp *TLS) error {\n\t// replace placeholders in subjects to allow environment variables\n\trepl := caddy.NewReplacer()\n\tsubjects := make([]string, len(ap.SubjectsRaw))\n\tfor i, sub := range ap.SubjectsRaw {\n\t\tsub = repl.ReplaceAll(sub, \"\")\n\t\tsubASCII, err := idna.ToASCII(sub)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"could not convert automation policy subject '%s' to punycode: %v\", sub, err)\n\t\t}\n\t\tsubjects[i] = subASCII\n\t}\n\tap.subjects = subjects\n\n\t// policy-specific storage implementation\n\tif ap.StorageRaw != nil {\n\t\tval, err := tlsApp.ctx.LoadModule(ap, \"StorageRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading TLS storage module: %v\", err)\n\t\t}\n\t\tcmStorage, err := val.(caddy.StorageConverter).CertMagicStorage()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"creating TLS storage configuration: %v\", err)\n\t\t}\n\t\tap.storage = cmStorage\n\t}\n\n\t// we don't store loaded modules directly in the certmagic config since\n\t// policy provisioning may happen more than once (during auto-HTTPS) and\n\t// loading a module clears its config bytes; thus, load the module and\n\t// store them on the policy before putting it on the config\n\n\t// load and provision any cert manager modules\n\tvar hadExplicitManagers bool\n\tif ap.ManagersRaw != nil {\n\t\thadExplicitManagers = true\n\t\tvals, err := tlsApp.ctx.LoadModule(ap, \"ManagersRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading external certificate manager modules: %v\", err)\n\t\t}\n\t\tfor _, getCertVal := range vals.([]any) {\n\t\t\tap.Managers = append(ap.Managers, getCertVal.(certmagic.Manager))\n\t\t}\n\t}\n\n\t// load and provision any explicitly-configured issuer modules\n\tif ap.IssuersRaw != nil {\n\t\tval, err := tlsApp.ctx.LoadModule(ap, \"IssuersRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading TLS automation management module: %s\", err)\n\t\t}\n\t\tfor _, issVal := range val.([]any) {\n\t\t\tap.Issuers = append(ap.Issuers, issVal.(certmagic.Issuer))\n\t\t}\n\t}\n\n\tissuers := ap.Issuers\n\tif len(issuers) == 0 {\n\t\tvar err error\n\t\tissuers, err = DefaultIssuersProvisioned(tlsApp.ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tkeyType := ap.KeyType\n\tif keyType != \"\" {\n\t\tvar err error\n\t\tkeyType, err = caddy.NewReplacer().ReplaceOrErr(ap.KeyType, true, true)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"invalid key type %s: %s\", ap.KeyType, err)\n\t\t}\n\t\tif _, ok := supportedCertKeyTypes[keyType]; !ok {\n\t\t\treturn fmt.Errorf(\"unrecognized key type: %s\", keyType)\n\t\t}\n\t}\n\tkeySource := certmagic.StandardKeyGenerator{\n\t\tKeyType: supportedCertKeyTypes[keyType],\n\t}\n\n\tstorage := ap.storage\n\tif storage == nil {\n\t\tstorage = tlsApp.ctx.Storage()\n\t}\n\n\t// on-demand TLS\n\tvar ond *certmagic.OnDemandConfig\n\tif ap.OnDemand || len(ap.Managers) > 0 {\n\t\t// permission module is now required after a number of negligence cases that allowed abuse;\n\t\t// but it may still be optional for explicit subjects (bounded, non-wildcard), for the\n\t\t// internal issuer since it doesn't cause public PKI pressure on ACME servers; subtly, it\n\t\t// is useful to allow on-demand TLS to be enabled so Managers can be used, but to still\n\t\t// prevent issuance from Issuers (when Managers don't provide a certificate) if there's no\n\t\t// permission module configured\n\t\tnoProtections := ap.isWildcardOrDefault() && !ap.onlyInternalIssuer() && (tlsApp.Automation == nil || tlsApp.Automation.OnDemand == nil || tlsApp.Automation.OnDemand.permission == nil)\n\t\tfailClosed := noProtections && !hadExplicitManagers // don't allow on-demand issuance (other than implicit managers) if no managers have been explicitly configured\n\t\tif noProtections {\n\t\t\tif !hadExplicitManagers {\n\t\t\t\t// no managers, no explicitly-configured permission module, this is a config error\n\t\t\t\treturn fmt.Errorf(\"on-demand TLS cannot be enabled without a permission module to prevent abuse; please refer to documentation for details\")\n\t\t\t}\n\t\t\t// allow on-demand to be enabled but only for the purpose of the Managers; issuance won't be allowed from Issuers\n\t\t\ttlsApp.logger.Warn(\"on-demand TLS can only get certificates from the configured external manager(s) because no ask endpoint / permission module is specified\")\n\t\t}\n\t\tond = &certmagic.OnDemandConfig{\n\t\t\tDecisionFunc: func(ctx context.Context, name string) error {\n\t\t\t\tif failClosed {\n\t\t\t\t\treturn fmt.Errorf(\"no permission module configured; certificates not allowed except from external Managers\")\n\t\t\t\t}\n\t\t\t\tif tlsApp.Automation == nil || tlsApp.Automation.OnDemand == nil {\n\t\t\t\t\treturn nil\n\t\t\t\t}\n\n\t\t\t\t// logging the remote IP can be useful for servers that want to count\n\t\t\t\t// attempts from clients to detect patterns of abuse -- it should NOT be\n\t\t\t\t// used solely for decision making, however\n\t\t\t\tvar remoteIP string\n\t\t\t\tif hello, ok := ctx.Value(certmagic.ClientHelloInfoCtxKey).(*tls.ClientHelloInfo); ok && hello != nil {\n\t\t\t\t\tif remote := hello.Conn.RemoteAddr(); remote != nil {\n\t\t\t\t\t\tremoteIP, _, _ = net.SplitHostPort(remote.String())\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif c := tlsApp.logger.Check(zapcore.DebugLevel, \"asking for permission for on-demand certificate\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.String(\"remote_ip\", remoteIP),\n\t\t\t\t\t\tzap.String(\"domain\", name),\n\t\t\t\t\t)\n\t\t\t\t}\n\n\t\t\t\t// ask the permission module if this cert is allowed\n\t\t\t\tif err := tlsApp.Automation.OnDemand.permission.CertificateAllowed(ctx, name); err != nil {\n\t\t\t\t\t// distinguish true errors from denials, because it's important to elevate actual errors\n\t\t\t\t\tif errors.Is(err, ErrPermissionDenied) {\n\t\t\t\t\t\tif c := tlsApp.logger.Check(zapcore.DebugLevel, \"on-demand certificate issuance denied\"); c != nil {\n\t\t\t\t\t\t\tc.Write(\n\t\t\t\t\t\t\t\tzap.String(\"domain\", name),\n\t\t\t\t\t\t\t\tzap.Error(err),\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tif c := tlsApp.logger.Check(zapcore.ErrorLevel, \"failed to get permission for on-demand certificate\"); c != nil {\n\t\t\t\t\t\t\tc.Write(\n\t\t\t\t\t\t\t\tzap.String(\"domain\", name),\n\t\t\t\t\t\t\t\tzap.Error(err),\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\treturn err\n\t\t\t\t}\n\n\t\t\t\treturn nil\n\t\t\t},\n\t\t\tManagers: ap.Managers,\n\t\t}\n\t}\n\n\ttemplate := certmagic.Config{\n\t\tMustStaple:         ap.MustStaple,\n\t\tRenewalWindowRatio: ap.RenewalWindowRatio,\n\t\tKeySource:          keySource,\n\t\tOnEvent:            tlsApp.onEvent,\n\t\tOnDemand:           ond,\n\t\tReusePrivateKeys:   ap.ReusePrivateKeys,\n\t\tOCSP: certmagic.OCSPConfig{\n\t\t\tDisableStapling:    ap.DisableOCSPStapling,\n\t\t\tResponderOverrides: ap.OCSPOverrides,\n\t\t},\n\t\tStorage: storage,\n\t\tIssuers: issuers,\n\t\tLogger:  tlsApp.logger,\n\t}\n\tcertCacheMu.RLock()\n\tap.magic = certmagic.New(certCache, template)\n\tcertCacheMu.RUnlock()\n\n\t// sometimes issuers may need the parent certmagic.Config in\n\t// order to function properly (for example, ACMEIssuer needs\n\t// access to the correct storage and cache so it can solve\n\t// ACME challenges -- it's an annoying, inelegant circular\n\t// dependency that I don't know how to resolve nicely!)\n\tfor _, issuer := range ap.magic.Issuers {\n\t\tif annoying, ok := issuer.(ConfigSetter); ok {\n\t\t\tannoying.SetConfig(ap.magic)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Subjects returns the list of subjects with all placeholders replaced.\nfunc (ap *AutomationPolicy) Subjects() []string {\n\treturn ap.subjects\n}\n\n// AllInternalSubjects returns true if all the subjects on this policy are internal.\nfunc (ap *AutomationPolicy) AllInternalSubjects() bool {\n\treturn !slices.ContainsFunc(ap.subjects, func(s string) bool {\n\t\treturn !certmagic.SubjectIsInternal(s)\n\t})\n}\n\nfunc (ap *AutomationPolicy) onlyInternalIssuer() bool {\n\tif len(ap.Issuers) != 1 {\n\t\treturn false\n\t}\n\t_, ok := ap.Issuers[0].(*InternalIssuer)\n\treturn ok\n}\n\n// isWildcardOrDefault determines if the subjects include any wildcard domains,\n// or is the \"default\" policy (i.e. no subjects) which is unbounded.\nfunc (ap *AutomationPolicy) isWildcardOrDefault() bool {\n\tisWildcardOrDefault := len(ap.subjects) == 0\n\n\tfor _, sub := range ap.subjects {\n\t\tif strings.HasPrefix(sub, \"*\") {\n\t\t\tisWildcardOrDefault = true\n\t\t\tbreak\n\t\t}\n\t}\n\treturn isWildcardOrDefault\n}\n\n// DefaultIssuers returns empty Issuers (not provisioned) to be used as defaults.\n// This function is experimental and has no compatibility promises.\nfunc DefaultIssuers(userEmail string) []certmagic.Issuer {\n\tissuers := []certmagic.Issuer{new(ACMEIssuer)}\n\tif strings.TrimSpace(userEmail) != \"\" {\n\t\tissuers = append(issuers, &ACMEIssuer{\n\t\t\tCA:    certmagic.ZeroSSLProductionCA,\n\t\t\tEmail: userEmail,\n\t\t})\n\t}\n\treturn issuers\n}\n\n// DefaultIssuersProvisioned returns empty but provisioned default Issuers from\n// DefaultIssuers(). This function is experimental and has no compatibility promises.\nfunc DefaultIssuersProvisioned(ctx caddy.Context) ([]certmagic.Issuer, error) {\n\tissuers := DefaultIssuers(\"\")\n\tfor i, iss := range issuers {\n\t\tif prov, ok := iss.(caddy.Provisioner); ok {\n\t\t\terr := prov.Provision(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"provisioning default issuer %d: %T: %v\", i, iss, err)\n\t\t\t}\n\t\t}\n\t}\n\treturn issuers, nil\n}\n\n// ChallengesConfig configures the ACME challenges.\ntype ChallengesConfig struct {\n\t// HTTP configures the ACME HTTP challenge. This\n\t// challenge is enabled and used automatically\n\t// and by default.\n\tHTTP *HTTPChallengeConfig `json:\"http,omitempty\"`\n\n\t// TLSALPN configures the ACME TLS-ALPN challenge.\n\t// This challenge is enabled and used automatically\n\t// and by default.\n\tTLSALPN *TLSALPNChallengeConfig `json:\"tls-alpn,omitempty\"`\n\n\t// Configures the ACME DNS challenge. Because this\n\t// challenge typically requires credentials for\n\t// interfacing with a DNS provider, this challenge is\n\t// not enabled by default. This is the only challenge\n\t// type which does not require a direct connection\n\t// to Caddy from an external server.\n\t//\n\t// NOTE: DNS providers are currently being upgraded,\n\t// and this API is subject to change, but should be\n\t// stabilized soon.\n\tDNS *DNSChallengeConfig `json:\"dns,omitempty\"`\n\n\t// Optionally customize the host to which a listener\n\t// is bound if required for solving a challenge.\n\tBindHost string `json:\"bind_host,omitempty\"`\n}\n\n// HTTPChallengeConfig configures the ACME HTTP challenge.\ntype HTTPChallengeConfig struct {\n\t// If true, the HTTP challenge will be disabled.\n\tDisabled bool `json:\"disabled,omitempty\"`\n\n\t// An alternate port on which to service this\n\t// challenge. Note that the HTTP challenge port is\n\t// hard-coded into the spec and cannot be changed,\n\t// so you would have to forward packets from the\n\t// standard HTTP challenge port to this one.\n\tAlternatePort int `json:\"alternate_port,omitempty\"`\n}\n\n// TLSALPNChallengeConfig configures the ACME TLS-ALPN challenge.\ntype TLSALPNChallengeConfig struct {\n\t// If true, the TLS-ALPN challenge will be disabled.\n\tDisabled bool `json:\"disabled,omitempty\"`\n\n\t// An alternate port on which to service this\n\t// challenge. Note that the TLS-ALPN challenge port\n\t// is hard-coded into the spec and cannot be changed,\n\t// so you would have to forward packets from the\n\t// standard TLS-ALPN challenge port to this one.\n\tAlternatePort int `json:\"alternate_port,omitempty\"`\n}\n\n// DNSChallengeConfig configures the ACME DNS challenge.\n//\n// NOTE: This API is still experimental and is subject to change.\ntype DNSChallengeConfig struct {\n\t// The DNS provider module to use which will manage\n\t// the DNS records relevant to the ACME challenge.\n\t// Required.\n\tProviderRaw json.RawMessage `json:\"provider,omitempty\" caddy:\"namespace=dns.providers inline_key=name\"`\n\n\t// The TTL of the TXT record used for the DNS challenge.\n\tTTL caddy.Duration `json:\"ttl,omitempty\"`\n\n\t// How long to wait before starting propagation checks.\n\t// Default: 0 (no wait).\n\tPropagationDelay caddy.Duration `json:\"propagation_delay,omitempty\"`\n\n\t// Maximum time to wait for temporary DNS record to appear.\n\t// Set to -1 to disable propagation checks.\n\t// Default: 2 minutes.\n\tPropagationTimeout caddy.Duration `json:\"propagation_timeout,omitempty\"`\n\n\t// Custom DNS resolvers to prefer over system/built-in defaults.\n\t// Often necessary to configure when using split-horizon DNS.\n\tResolvers []string `json:\"resolvers,omitempty\"`\n\n\t// Override the domain to use for the DNS challenge. This\n\t// is to delegate the challenge to a different domain,\n\t// e.g. one that updates faster or one with a provider API.\n\tOverrideDomain string `json:\"override_domain,omitempty\"`\n\n\tsolver acmez.Solver\n}\n\n// ConfigSetter is implemented by certmagic.Issuers that\n// need access to a parent certmagic.Config as part of\n// their provisioning phase. For example, the ACMEIssuer\n// requires a config so it can access storage and the\n// cache to solve ACME challenges.\ntype ConfigSetter interface {\n\tSetConfig(cfg *certmagic.Config)\n}\n",
    "source_file": "modules/caddytls/automation.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddytls\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/tailscale/tscert\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Tailscale{})\n\tcaddy.RegisterModule(HTTPCertGetter{})\n}\n\n// Tailscale is a module that can get certificates from the local Tailscale process.\ntype Tailscale struct {\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Tailscale) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.get_certificate.tailscale\",\n\t\tNew: func() caddy.Module { return new(Tailscale) },\n\t}\n}\n\nfunc (ts *Tailscale) Provision(ctx caddy.Context) error {\n\tts.logger = ctx.Logger()\n\treturn nil\n}\n\nfunc (ts Tailscale) GetCertificate(ctx context.Context, hello *tls.ClientHelloInfo) (*tls.Certificate, error) {\n\tcanGetCert, err := ts.canHazCertificate(ctx, hello)\n\tif err == nil && !canGetCert {\n\t\treturn nil, nil // pass-thru: Tailscale can't offer a cert for this name\n\t}\n\tif err != nil {\n\t\tif c := ts.logger.Check(zapcore.WarnLevel, \"could not get status; will try to get certificate anyway\"); c != nil {\n\t\t\tc.Write(zap.Error(err))\n\t\t}\n\t}\n\treturn tscert.GetCertificateWithContext(ctx, hello)\n}\n\n// canHazCertificate returns true if Tailscale reports it can get a certificate for the given ClientHello.\nfunc (ts Tailscale) canHazCertificate(ctx context.Context, hello *tls.ClientHelloInfo) (bool, error) {\n\tif !strings.HasSuffix(strings.ToLower(hello.ServerName), tailscaleDomainAliasEnding) {\n\t\treturn false, nil\n\t}\n\tstatus, err := tscert.GetStatus(ctx)\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tfor _, domain := range status.CertDomains {\n\t\tif certmagic.MatchWildcard(hello.ServerName, domain) {\n\t\t\treturn true, nil\n\t\t}\n\t}\n\treturn false, nil\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into ts.\n//\n//\t... tailscale\nfunc (Tailscale) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume cert manager name\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\treturn nil\n}\n\n// tailscaleDomainAliasEnding is the ending for all Tailscale custom domains.\nconst tailscaleDomainAliasEnding = \".ts.net\"\n\n// HTTPCertGetter can get a certificate via HTTP(S) request.\ntype HTTPCertGetter struct {\n\t// The URL from which to download the certificate. Required.\n\t//\n\t// The URL will be augmented with query string parameters taken\n\t// from the TLS handshake:\n\t//\n\t// - server_name: The SNI value\n\t// - signature_schemes: Comma-separated list of hex IDs of signatures\n\t// - cipher_suites: Comma-separated list of hex IDs of cipher suites\n\t//\n\t// To be valid, the response must be HTTP 200 with a PEM body\n\t// consisting of blocks for the certificate chain and the private\n\t// key.\n\t//\n\t// To indicate that this manager is not managing a certificate for\n\t// the described handshake, the endpoint should return HTTP 204\n\t// (No Content). Error statuses will indicate that the manager is\n\t// capable of providing a certificate but was unable to.\n\tURL string `json:\"url,omitempty\"`\n\n\tctx context.Context\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (hcg HTTPCertGetter) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.get_certificate.http\",\n\t\tNew: func() caddy.Module { return new(HTTPCertGetter) },\n\t}\n}\n\nfunc (hcg *HTTPCertGetter) Provision(ctx caddy.Context) error {\n\thcg.ctx = ctx\n\tif hcg.URL == \"\" {\n\t\treturn fmt.Errorf(\"URL is required\")\n\t}\n\treturn nil\n}\n\nfunc (hcg HTTPCertGetter) GetCertificate(ctx context.Context, hello *tls.ClientHelloInfo) (*tls.Certificate, error) {\n\tsigs := make([]string, len(hello.SignatureSchemes))\n\tfor i, sig := range hello.SignatureSchemes {\n\t\tsigs[i] = fmt.Sprintf(\"%x\", uint16(sig)) // you won't believe what %x uses if the val is a Stringer\n\t}\n\tsuites := make([]string, len(hello.CipherSuites))\n\tfor i, cs := range hello.CipherSuites {\n\t\tsuites[i] = fmt.Sprintf(\"%x\", cs)\n\t}\n\n\tparsed, err := url.Parse(hcg.URL)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tqs := parsed.Query()\n\tqs.Set(\"server_name\", hello.ServerName)\n\tqs.Set(\"signature_schemes\", strings.Join(sigs, \",\"))\n\tqs.Set(\"cipher_suites\", strings.Join(suites, \",\"))\n\tlocalIP, _, err := net.SplitHostPort(hello.Conn.LocalAddr().String())\n\tif err == nil && localIP != \"\" {\n\t\tqs.Set(\"local_ip\", localIP)\n\t}\n\tparsed.RawQuery = qs.Encode()\n\n\treq, err := http.NewRequestWithContext(hcg.ctx, http.MethodGet, parsed.String(), nil)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tresp, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdefer resp.Body.Close()\n\tif resp.StatusCode == http.StatusNoContent {\n\t\t// endpoint is not managing certs for this handshake\n\t\treturn nil, nil\n\t}\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn nil, fmt.Errorf(\"got HTTP %d\", resp.StatusCode)\n\t}\n\n\tbodyBytes, err := io.ReadAll(resp.Body)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"error reading response body: %v\", err)\n\t}\n\n\tcert, err := tlsCertFromCertAndKeyPEMBundle(bodyBytes)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn &cert, nil\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into ts.\n//\n//\t... http <url>\nfunc (hcg *HTTPCertGetter) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume cert manager name\n\n\tif !d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\thcg.URL = d.Val()\n\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\tif d.NextBlock(0) {\n\t\treturn d.Err(\"block not allowed here\")\n\t}\n\treturn nil\n}\n\n// Interface guards\nvar (\n\t_ certmagic.Manager     = (*Tailscale)(nil)\n\t_ caddy.Provisioner     = (*Tailscale)(nil)\n\t_ caddyfile.Unmarshaler = (*Tailscale)(nil)\n\n\t_ certmagic.Manager     = (*HTTPCertGetter)(nil)\n\t_ caddy.Provisioner     = (*HTTPCertGetter)(nil)\n\t_ caddyfile.Unmarshaler = (*HTTPCertGetter)(nil)\n)\n",
    "source_file": "modules/caddytls/certmanagers.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"context\"\n\t\"crypto/x509\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/caddyserver/zerossl\"\n\t\"github.com/mholt/acmez/v3/acme\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(ACMEIssuer{})\n}\n\n// ACMEIssuer manages certificates using the ACME protocol (RFC 8555).\ntype ACMEIssuer struct {\n\t// The URL to the CA's ACME directory endpoint. Default:\n\t// https://acme-v02.api.letsencrypt.org/directory\n\tCA string `json:\"ca,omitempty\"`\n\n\t// The URL to the test CA's ACME directory endpoint.\n\t// This endpoint is only used during retries if there\n\t// is a failure using the primary CA. Default:\n\t// https://acme-staging-v02.api.letsencrypt.org/directory\n\tTestCA string `json:\"test_ca,omitempty\"`\n\n\t// Your email address, so the CA can contact you if necessary.\n\t// Not required, but strongly recommended to provide one so\n\t// you can be reached if there is a problem. Your email is\n\t// not sent to any Caddy mothership or used for any purpose\n\t// other than ACME transactions.\n\tEmail string `json:\"email,omitempty\"`\n\n\t// Optionally select an ACME profile to use for certificate\n\t// orders. Must be a profile name offered by the ACME server,\n\t// which are listed at its directory endpoint.\n\t//\n\t// EXPERIMENTAL: Subject to change.\n\t// See https://datatracker.ietf.org/doc/draft-aaron-acme-profiles/\n\tProfile string `json:\"profile,omitempty\"`\n\n\t// If you have an existing account with the ACME server, put\n\t// the private key here in PEM format. The ACME client will\n\t// look up your account information with this key first before\n\t// trying to create a new one. You can use placeholders here,\n\t// for example if you have it in an environment variable.\n\tAccountKey string `json:\"account_key,omitempty\"`\n\n\t// If using an ACME CA that requires an external account\n\t// binding, specify the CA-provided credentials here.\n\tExternalAccount *acme.EAB `json:\"external_account,omitempty\"`\n\n\t// Time to wait before timing out an ACME operation.\n\t// Default: 0 (no timeout)\n\tACMETimeout caddy.Duration `json:\"acme_timeout,omitempty\"`\n\n\t// Configures the various ACME challenge types.\n\tChallenges *ChallengesConfig `json:\"challenges,omitempty\"`\n\n\t// An array of files of CA certificates to accept when connecting to the\n\t// ACME CA. Generally, you should only use this if the ACME CA endpoint\n\t// is internal or for development/testing purposes.\n\tTrustedRootsPEMFiles []string `json:\"trusted_roots_pem_files,omitempty\"`\n\n\t// Preferences for selecting alternate certificate chains, if offered\n\t// by the CA. By default, the first offered chain will be selected.\n\t// If configured, the chains may be sorted and the first matching chain\n\t// will be selected.\n\tPreferredChains *ChainPreference `json:\"preferred_chains,omitempty\"`\n\n\t// The validity period to ask the CA to issue a certificate for.\n\t// Default: 0 (CA chooses lifetime).\n\t// This value is used to compute the \"notAfter\" field of the ACME order;\n\t// therefore the system must have a reasonably synchronized clock.\n\t// NOTE: Not all CAs support this. Check with your CA's ACME\n\t// documentation to see if this is allowed and what values may\n\t// be used. EXPERIMENTAL: Subject to change.\n\tCertificateLifetime caddy.Duration `json:\"certificate_lifetime,omitempty\"`\n\n\t// Forward proxy module\n\tNetworkProxyRaw json.RawMessage `json:\"network_proxy,omitempty\" caddy:\"namespace=caddy.network_proxy inline_key=from\"`\n\n\trootPool *x509.CertPool\n\tlogger   *zap.Logger\n\n\ttemplate certmagic.ACMEIssuer  // set at Provision\n\tmagic    *certmagic.Config     // set at PreCheck\n\tissuer   *certmagic.ACMEIssuer // set at PreCheck; result of template + magic\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (ACMEIssuer) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.issuance.acme\",\n\t\tNew: func() caddy.Module { return new(ACMEIssuer) },\n\t}\n}\n\n// Provision sets up iss.\nfunc (iss *ACMEIssuer) Provision(ctx caddy.Context) error {\n\tiss.logger = ctx.Logger()\n\n\trepl := caddy.NewReplacer()\n\n\t// expand email address, if non-empty\n\tif iss.Email != \"\" {\n\t\temail, err := repl.ReplaceOrErr(iss.Email, true, true)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"expanding email address '%s': %v\", iss.Email, err)\n\t\t}\n\t\tiss.Email = email\n\t}\n\n\t// expand account key, if non-empty\n\tif iss.AccountKey != \"\" {\n\t\taccountKey, err := repl.ReplaceOrErr(iss.AccountKey, true, true)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"expanding account key PEM '%s': %v\", iss.AccountKey, err)\n\t\t}\n\t\tiss.AccountKey = accountKey\n\t}\n\n\t// DNS challenge provider, if not already established\n\tif iss.Challenges != nil && iss.Challenges.DNS != nil && iss.Challenges.DNS.solver == nil {\n\t\tvar prov certmagic.DNSProvider\n\t\tif iss.Challenges.DNS.ProviderRaw != nil {\n\t\t\t// a challenge provider has been locally configured - use it\n\t\t\tval, err := ctx.LoadModule(iss.Challenges.DNS, \"ProviderRaw\")\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading DNS provider module: %v\", err)\n\t\t\t}\n\t\t\tprov = val.(certmagic.DNSProvider)\n\t\t} else if tlsAppIface, err := ctx.AppIfConfigured(\"tls\"); err == nil {\n\t\t\t// no locally configured DNS challenge provider, but if there is\n\t\t\t// a global DNS module configured with the TLS app, use that\n\t\t\ttlsApp := tlsAppIface.(*TLS)\n\t\t\tif tlsApp.dns != nil {\n\t\t\t\tprov = tlsApp.dns.(certmagic.DNSProvider)\n\t\t\t}\n\t\t}\n\t\tif prov == nil {\n\t\t\treturn fmt.Errorf(\"DNS challenge enabled, but no DNS provider configured\")\n\t\t}\n\t\tiss.Challenges.DNS.solver = &certmagic.DNS01Solver{\n\t\t\tDNSManager: certmagic.DNSManager{\n\t\t\t\tDNSProvider:        prov,\n\t\t\t\tTTL:                time.Duration(iss.Challenges.DNS.TTL),\n\t\t\t\tPropagationDelay:   time.Duration(iss.Challenges.DNS.PropagationDelay),\n\t\t\t\tPropagationTimeout: time.Duration(iss.Challenges.DNS.PropagationTimeout),\n\t\t\t\tResolvers:          iss.Challenges.DNS.Resolvers,\n\t\t\t\tOverrideDomain:     iss.Challenges.DNS.OverrideDomain,\n\t\t\t},\n\t\t}\n\t}\n\n\t// add any custom CAs to trust store\n\tif len(iss.TrustedRootsPEMFiles) > 0 {\n\t\tiss.rootPool = x509.NewCertPool()\n\t\tfor _, pemFile := range iss.TrustedRootsPEMFiles {\n\t\t\tpemData, err := os.ReadFile(pemFile)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading trusted root CA's PEM file: %s: %v\", pemFile, err)\n\t\t\t}\n\t\t\tif !iss.rootPool.AppendCertsFromPEM(pemData) {\n\t\t\t\treturn fmt.Errorf(\"unable to add %s to trust pool: %v\", pemFile, err)\n\t\t\t}\n\t\t}\n\t}\n\n\tvar err error\n\tiss.template, err = iss.makeIssuerTemplate(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc (iss *ACMEIssuer) makeIssuerTemplate(ctx caddy.Context) (certmagic.ACMEIssuer, error) {\n\ttemplate := certmagic.ACMEIssuer{\n\t\tCA:                iss.CA,\n\t\tTestCA:            iss.TestCA,\n\t\tEmail:             iss.Email,\n\t\tProfile:           iss.Profile,\n\t\tAccountKeyPEM:     iss.AccountKey,\n\t\tCertObtainTimeout: time.Duration(iss.ACMETimeout),\n\t\tTrustedRoots:      iss.rootPool,\n\t\tExternalAccount:   iss.ExternalAccount,\n\t\tNotAfter:          time.Duration(iss.CertificateLifetime),\n\t\tLogger:            iss.logger,\n\t}\n\n\tif len(iss.NetworkProxyRaw) != 0 {\n\t\tproxyMod, err := ctx.LoadModule(iss, \"NetworkProxyRaw\")\n\t\tif err != nil {\n\t\t\treturn template, fmt.Errorf(\"failed to load network_proxy module: %v\", err)\n\t\t}\n\t\tif m, ok := proxyMod.(caddy.ProxyFuncProducer); ok {\n\t\t\ttemplate.HTTPProxy = m.ProxyFunc()\n\t\t} else {\n\t\t\treturn template, fmt.Errorf(\"network_proxy module is not `(func(*http.Request) (*url.URL, error))``\")\n\t\t}\n\t}\n\n\tif iss.Challenges != nil {\n\t\tif iss.Challenges.HTTP != nil {\n\t\t\ttemplate.DisableHTTPChallenge = iss.Challenges.HTTP.Disabled\n\t\t\ttemplate.AltHTTPPort = iss.Challenges.HTTP.AlternatePort\n\t\t}\n\t\tif iss.Challenges.TLSALPN != nil {\n\t\t\ttemplate.DisableTLSALPNChallenge = iss.Challenges.TLSALPN.Disabled\n\t\t\ttemplate.AltTLSALPNPort = iss.Challenges.TLSALPN.AlternatePort\n\t\t}\n\t\tif iss.Challenges.DNS != nil {\n\t\t\ttemplate.DNS01Solver = iss.Challenges.DNS.solver\n\t\t}\n\t\ttemplate.ListenHost = iss.Challenges.BindHost\n\t}\n\n\tif iss.PreferredChains != nil {\n\t\ttemplate.PreferredChains = certmagic.ChainPreference{\n\t\t\tSmallest:       iss.PreferredChains.Smallest,\n\t\t\tAnyCommonName:  iss.PreferredChains.AnyCommonName,\n\t\t\tRootCommonName: iss.PreferredChains.RootCommonName,\n\t\t}\n\t}\n\n\t// ZeroSSL requires EAB, but we can generate that automatically (requires an email address be configured)\n\tif strings.HasPrefix(iss.CA, \"https://acme.zerossl.com/\") {\n\t\ttemplate.NewAccountFunc = func(ctx context.Context, acmeIss *certmagic.ACMEIssuer, acct acme.Account) (acme.Account, error) {\n\t\t\tif acmeIss.ExternalAccount != nil {\n\t\t\t\treturn acct, nil\n\t\t\t}\n\t\t\tvar err error\n\t\t\tacmeIss.ExternalAccount, acct, err = iss.generateZeroSSLEABCredentials(ctx, acct)\n\t\t\treturn acct, err\n\t\t}\n\t}\n\n\treturn template, nil\n}\n\n// SetConfig sets the associated certmagic config for this issuer.\n// This is required because ACME needs values from the config in\n// order to solve the challenges during issuance. This implements\n// the ConfigSetter interface.\nfunc (iss *ACMEIssuer) SetConfig(cfg *certmagic.Config) {\n\tiss.magic = cfg\n\tiss.issuer = certmagic.NewACMEIssuer(cfg, iss.template)\n}\n\n// PreCheck implements the certmagic.PreChecker interface.\nfunc (iss *ACMEIssuer) PreCheck(ctx context.Context, names []string, interactive bool) error {\n\treturn iss.issuer.PreCheck(ctx, names, interactive)\n}\n\n// Issue obtains a certificate for the given csr.\nfunc (iss *ACMEIssuer) Issue(ctx context.Context, csr *x509.CertificateRequest) (*certmagic.IssuedCertificate, error) {\n\treturn iss.issuer.Issue(ctx, csr)\n}\n\n// IssuerKey returns the unique issuer key for the configured CA endpoint.\nfunc (iss *ACMEIssuer) IssuerKey() string {\n\treturn iss.issuer.IssuerKey()\n}\n\n// Revoke revokes the given certificate.\nfunc (iss *ACMEIssuer) Revoke(ctx context.Context, cert certmagic.CertificateResource, reason int) error {\n\treturn iss.issuer.Revoke(ctx, cert, reason)\n}\n\n// GetACMEIssuer returns iss. This is useful when other types embed ACMEIssuer, because\n// type-asserting them to *ACMEIssuer will fail, but type-asserting them to an interface\n// with only this method will succeed, and will still allow the embedded ACMEIssuer\n// to be accessed and manipulated.\nfunc (iss *ACMEIssuer) GetACMEIssuer() *ACMEIssuer { return iss }\n\n// GetRenewalInfo wraps the underlying GetRenewalInfo method and satisfies\n// the CertMagic interface for ARI support.\nfunc (iss *ACMEIssuer) GetRenewalInfo(ctx context.Context, cert certmagic.Certificate) (acme.RenewalInfo, error) {\n\treturn iss.issuer.GetRenewalInfo(ctx, cert)\n}\n\n// generateZeroSSLEABCredentials generates ZeroSSL EAB credentials for the primary contact email\n// on the issuer. It should only be usedif the CA endpoint is ZeroSSL. An email address is required.\nfunc (iss *ACMEIssuer) generateZeroSSLEABCredentials(ctx context.Context, acct acme.Account) (*acme.EAB, acme.Account, error) {\n\tif strings.TrimSpace(iss.Email) == \"\" {\n\t\treturn nil, acme.Account{}, fmt.Errorf(\"your email address is required to use ZeroSSL's ACME endpoint\")\n\t}\n\n\tif len(acct.Contact) == 0 {\n\t\t// we borrow the email from config or the default email, so ensure it's saved with the account\n\t\tacct.Contact = []string{\"mailto:\" + iss.Email}\n\t}\n\n\tendpoint := zerossl.BaseURL + \"/acme/eab-credentials-email\"\n\tform := url.Values{\"email\": []string{iss.Email}}\n\tbody := strings.NewReader(form.Encode())\n\n\treq, err := http.NewRequestWithContext(ctx, http.MethodPost, endpoint, body)\n\tif err != nil {\n\t\treturn nil, acct, fmt.Errorf(\"forming request: %v\", err)\n\t}\n\treq.Header.Set(\"Content-Type\", \"application/x-www-form-urlencoded\")\n\treq.Header.Set(\"User-Agent\", certmagic.UserAgent)\n\n\tresp, err := http.DefaultClient.Do(req)\n\tif err != nil {\n\t\treturn nil, acct, fmt.Errorf(\"performing EAB credentials request: %v\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\tvar result struct {\n\t\tSuccess bool `json:\"success\"`\n\t\tError   struct {\n\t\t\tCode int    `json:\"code\"`\n\t\t\tType string `json:\"type\"`\n\t\t} `json:\"error\"`\n\t\tEABKID     string `json:\"eab_kid\"`\n\t\tEABHMACKey string `json:\"eab_hmac_key\"`\n\t}\n\terr = json.NewDecoder(resp.Body).Decode(&result)\n\tif err != nil {\n\t\treturn nil, acct, fmt.Errorf(\"decoding API response: %v\", err)\n\t}\n\tif result.Error.Code != 0 {\n\t\t// do this check first because ZeroSSL's API returns 200 on errors\n\t\treturn nil, acct, fmt.Errorf(\"failed getting EAB credentials: HTTP %d: %s (code %d)\",\n\t\t\tresp.StatusCode, result.Error.Type, result.Error.Code)\n\t}\n\tif resp.StatusCode != http.StatusOK {\n\t\treturn nil, acct, fmt.Errorf(\"failed getting EAB credentials: HTTP %d\", resp.StatusCode)\n\t}\n\n\tif c := iss.logger.Check(zapcore.InfoLevel, \"generated EAB credentials\"); c != nil {\n\t\tc.Write(zap.String(\"key_id\", result.EABKID))\n\t}\n\n\treturn &acme.EAB{\n\t\tKeyID:  result.EABKID,\n\t\tMACKey: result.EABHMACKey,\n\t}, acct, nil\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into iss.\n//\n//\t... acme [<directory_url>] {\n//\t    dir <directory_url>\n//\t    test_dir <test_directory_url>\n//\t    email <email>\n//\t    profile <profile_name>\n//\t    timeout <duration>\n//\t    disable_http_challenge\n//\t    disable_tlsalpn_challenge\n//\t    alt_http_port    <port>\n//\t    alt_tlsalpn_port <port>\n//\t    eab <key_id> <mac_key>\n//\t    trusted_roots <pem_files...>\n//\t    dns <provider_name> [<options>]\n//\t    propagation_delay <duration>\n//\t    propagation_timeout <duration>\n//\t    resolvers <dns_servers...>\n//\t    dns_ttl <duration>\n//\t    dns_challenge_override_domain <domain>\n//\t    preferred_chains [smallest] {\n//\t        root_common_name <common_names...>\n//\t        any_common_name  <common_names...>\n//\t    }\n//\t}\nfunc (iss *ACMEIssuer) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume issuer name\n\n\tif d.NextArg() {\n\t\tiss.CA = d.Val()\n\t\tif d.NextArg() {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"lifetime\":\n\t\t\tvar lifetimeStr string\n\t\t\tif !d.AllArgs(&lifetimeStr) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tlifetime, err := caddy.ParseDuration(lifetimeStr)\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid lifetime %s: %v\", lifetimeStr, err)\n\t\t\t}\n\t\t\tif lifetime < 0 {\n\t\t\t\treturn d.Errf(\"lifetime must be >= 0: %s\", lifetime)\n\t\t\t}\n\t\t\tiss.CertificateLifetime = caddy.Duration(lifetime)\n\n\t\tcase \"dir\":\n\t\t\tif iss.CA != \"\" {\n\t\t\t\treturn d.Errf(\"directory is already specified: %s\", iss.CA)\n\t\t\t}\n\t\t\tif !d.AllArgs(&iss.CA) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"test_dir\":\n\t\t\tif !d.AllArgs(&iss.TestCA) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"email\":\n\t\t\tif !d.AllArgs(&iss.Email) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"profile\":\n\t\t\tif !d.AllArgs(&iss.Profile) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"timeout\":\n\t\t\tvar timeoutStr string\n\t\t\tif !d.AllArgs(&timeoutStr) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\ttimeout, err := caddy.ParseDuration(timeoutStr)\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid timeout duration %s: %v\", timeoutStr, err)\n\t\t\t}\n\t\t\tiss.ACMETimeout = caddy.Duration(timeout)\n\n\t\tcase \"disable_http_challenge\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.HTTP == nil {\n\t\t\t\tiss.Challenges.HTTP = new(HTTPChallengeConfig)\n\t\t\t}\n\t\t\tiss.Challenges.HTTP.Disabled = true\n\n\t\tcase \"disable_tlsalpn_challenge\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.TLSALPN == nil {\n\t\t\t\tiss.Challenges.TLSALPN = new(TLSALPNChallengeConfig)\n\t\t\t}\n\t\t\tiss.Challenges.TLSALPN.Disabled = true\n\n\t\tcase \"alt_http_port\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tport, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid port %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.HTTP == nil {\n\t\t\t\tiss.Challenges.HTTP = new(HTTPChallengeConfig)\n\t\t\t}\n\t\t\tiss.Challenges.HTTP.AlternatePort = port\n\n\t\tcase \"alt_tlsalpn_port\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tport, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid port %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.TLSALPN == nil {\n\t\t\t\tiss.Challenges.TLSALPN = new(TLSALPNChallengeConfig)\n\t\t\t}\n\t\t\tiss.Challenges.TLSALPN.AlternatePort = port\n\n\t\tcase \"eab\":\n\t\t\tiss.ExternalAccount = new(acme.EAB)\n\t\t\tif !d.AllArgs(&iss.ExternalAccount.KeyID, &iss.ExternalAccount.MACKey) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"trusted_roots\":\n\t\t\tiss.TrustedRootsPEMFiles = d.RemainingArgs()\n\n\t\tcase \"dns\":\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.DNS == nil {\n\t\t\t\tiss.Challenges.DNS = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tif d.NextArg() {\n\t\t\t\tprovName := d.Val()\n\t\t\t\tunm, err := caddyfile.UnmarshalModule(d, \"dns.providers.\"+provName)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t\tiss.Challenges.DNS.ProviderRaw = caddyconfig.JSONModuleObject(unm, \"name\", provName, nil)\n\t\t\t}\n\n\t\tcase \"propagation_delay\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdelayStr := d.Val()\n\t\t\tdelay, err := caddy.ParseDuration(delayStr)\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid propagation_delay duration %s: %v\", delayStr, err)\n\t\t\t}\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.DNS == nil {\n\t\t\t\tiss.Challenges.DNS = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tiss.Challenges.DNS.PropagationDelay = caddy.Duration(delay)\n\n\t\tcase \"propagation_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\ttimeoutStr := d.Val()\n\t\t\tvar timeout time.Duration\n\t\t\tif timeoutStr == \"-1\" {\n\t\t\t\ttimeout = time.Duration(-1)\n\t\t\t} else {\n\t\t\t\tvar err error\n\t\t\t\ttimeout, err = caddy.ParseDuration(timeoutStr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn d.Errf(\"invalid propagation_timeout duration %s: %v\", timeoutStr, err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.DNS == nil {\n\t\t\t\tiss.Challenges.DNS = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tiss.Challenges.DNS.PropagationTimeout = caddy.Duration(timeout)\n\n\t\tcase \"resolvers\":\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.DNS == nil {\n\t\t\t\tiss.Challenges.DNS = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tiss.Challenges.DNS.Resolvers = d.RemainingArgs()\n\t\t\tif len(iss.Challenges.DNS.Resolvers) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"dns_ttl\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tttlStr := d.Val()\n\t\t\tttl, err := caddy.ParseDuration(ttlStr)\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid dns_ttl duration %s: %v\", ttlStr, err)\n\t\t\t}\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.DNS == nil {\n\t\t\t\tiss.Challenges.DNS = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tiss.Challenges.DNS.TTL = caddy.Duration(ttl)\n\n\t\tcase \"dns_challenge_override_domain\":\n\t\t\targ := d.RemainingArgs()\n\t\t\tif len(arg) != 1 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif iss.Challenges == nil {\n\t\t\t\tiss.Challenges = new(ChallengesConfig)\n\t\t\t}\n\t\t\tif iss.Challenges.DNS == nil {\n\t\t\t\tiss.Challenges.DNS = new(DNSChallengeConfig)\n\t\t\t}\n\t\t\tiss.Challenges.DNS.OverrideDomain = arg[0]\n\n\t\tcase \"preferred_chains\":\n\t\t\tchainPref, err := ParseCaddyfilePreferredChainsOptions(d)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tiss.PreferredChains = chainPref\n\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized ACME issuer property: %s\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc ParseCaddyfilePreferredChainsOptions(d *caddyfile.Dispenser) (*ChainPreference, error) {\n\tchainPref := new(ChainPreference)\n\tif d.NextArg() {\n\t\tsmallestOpt := d.Val()\n\t\tif smallestOpt == \"smallest\" {\n\t\t\ttrueBool := true\n\t\t\tchainPref.Smallest = &trueBool\n\t\t\tif d.NextArg() { // Only one argument allowed\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tif d.NextBlock(d.Nesting()) { // Don't allow other options when smallest == true\n\t\t\t\treturn nil, d.Err(\"No more options are accepted when using the 'smallest' option\")\n\t\t\t}\n\t\t} else { // Smallest option should always be 'smallest' or unset\n\t\t\treturn nil, d.Errf(\"Invalid argument '%s'\", smallestOpt)\n\t\t}\n\t}\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"root_common_name\":\n\t\t\trootCommonNameOpt := d.RemainingArgs()\n\t\t\tchainPref.RootCommonName = rootCommonNameOpt\n\t\t\tif rootCommonNameOpt == nil {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tif chainPref.AnyCommonName != nil {\n\t\t\t\treturn nil, d.Err(\"Can't set root_common_name when any_common_name is already set\")\n\t\t\t}\n\n\t\tcase \"any_common_name\":\n\t\t\tanyCommonNameOpt := d.RemainingArgs()\n\t\t\tchainPref.AnyCommonName = anyCommonNameOpt\n\t\t\tif anyCommonNameOpt == nil {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tif chainPref.RootCommonName != nil {\n\t\t\t\treturn nil, d.Err(\"Can't set any_common_name when root_common_name is already set\")\n\t\t\t}\n\n\t\tdefault:\n\t\t\treturn nil, d.Errf(\"Received unrecognized parameter '%s'\", d.Val())\n\t\t}\n\t}\n\n\tif chainPref.Smallest == nil && chainPref.RootCommonName == nil && chainPref.AnyCommonName == nil {\n\t\treturn nil, d.Err(\"No options for preferred_chains received\")\n\t}\n\n\treturn chainPref, nil\n}\n\n// ChainPreference describes the client's preferred certificate chain,\n// useful if the CA offers alternate chains. The first matching chain\n// will be selected.\ntype ChainPreference struct {\n\t// Prefer chains with the fewest number of bytes.\n\tSmallest *bool `json:\"smallest,omitempty\"`\n\n\t// Select first chain having a root with one of\n\t// these common names.\n\tRootCommonName []string `json:\"root_common_name,omitempty\"`\n\n\t// Select first chain that has any issuer with one\n\t// of these common names.\n\tAnyCommonName []string `json:\"any_common_name,omitempty\"`\n}\n\n// Interface guards\nvar (\n\t_ certmagic.PreChecker        = (*ACMEIssuer)(nil)\n\t_ certmagic.Issuer            = (*ACMEIssuer)(nil)\n\t_ certmagic.Revoker           = (*ACMEIssuer)(nil)\n\t_ certmagic.RenewalInfoGetter = (*ACMEIssuer)(nil)\n\t_ caddy.Provisioner           = (*ACMEIssuer)(nil)\n\t_ ConfigSetter                = (*ACMEIssuer)(nil)\n\t_ caddyfile.Unmarshaler       = (*ACMEIssuer)(nil)\n)\n",
    "source_file": "modules/caddytls/acmeissuer.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"bytes\"\n\t\"crypto/tls\"\n\t\"encoding/pem\"\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(FolderLoader{})\n}\n\n// FolderLoader loads certificates and their associated keys from disk\n// by recursively walking the specified directories, looking for PEM\n// files which contain both a certificate and a key.\ntype FolderLoader []string\n\n// CaddyModule returns the Caddy module information.\nfunc (FolderLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.certificates.load_folders\",\n\t\tNew: func() caddy.Module { return new(FolderLoader) },\n\t}\n}\n\n// Provision implements caddy.Provisioner.\nfunc (fl FolderLoader) Provision(ctx caddy.Context) error {\n\trepl, ok := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif !ok {\n\t\trepl = caddy.NewReplacer()\n\t}\n\tfor k, path := range fl {\n\t\tfl[k] = repl.ReplaceKnown(path, \"\")\n\t}\n\treturn nil\n}\n\n// LoadCertificates loads all the certificates+keys in the directories\n// listed in fl from all files ending with .pem. This method of loading\n// certificates expects the certificate and key to be bundled into the\n// same file.\nfunc (fl FolderLoader) LoadCertificates() ([]Certificate, error) {\n\tvar certs []Certificate\n\tfor _, dir := range fl {\n\t\terr := filepath.Walk(dir, func(fpath string, info os.FileInfo, err error) error {\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"unable to traverse into path: %s\", fpath)\n\t\t\t}\n\t\t\tif info.IsDir() {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif !strings.HasSuffix(strings.ToLower(info.Name()), \".pem\") {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tbundle, err := os.ReadFile(fpath)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcert, err := tlsCertFromCertAndKeyPEMBundle(bundle)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"%s: %w\", fpath, err)\n\t\t\t}\n\n\t\t\tcerts = append(certs, Certificate{Certificate: cert})\n\n\t\t\treturn nil\n\t\t})\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\treturn certs, nil\n}\n\nfunc tlsCertFromCertAndKeyPEMBundle(bundle []byte) (tls.Certificate, error) {\n\tcertBuilder, keyBuilder := new(bytes.Buffer), new(bytes.Buffer)\n\tvar foundKey bool // use only the first key in the file\n\n\tfor {\n\t\t// Decode next block so we can see what type it is\n\t\tvar derBlock *pem.Block\n\t\tderBlock, bundle = pem.Decode(bundle)\n\t\tif derBlock == nil {\n\t\t\tbreak\n\t\t}\n\n\t\tif derBlock.Type == \"CERTIFICATE\" {\n\t\t\t// Re-encode certificate as PEM, appending to certificate chain\n\t\t\tif err := pem.Encode(certBuilder, derBlock); err != nil {\n\t\t\t\treturn tls.Certificate{}, err\n\t\t\t}\n\t\t} else if derBlock.Type == \"EC PARAMETERS\" {\n\t\t\t// EC keys generated from openssl can be composed of two blocks:\n\t\t\t// parameters and key (parameter block should come first)\n\t\t\tif !foundKey {\n\t\t\t\t// Encode parameters\n\t\t\t\tif err := pem.Encode(keyBuilder, derBlock); err != nil {\n\t\t\t\t\treturn tls.Certificate{}, err\n\t\t\t\t}\n\n\t\t\t\t// Key must immediately follow\n\t\t\t\tderBlock, bundle = pem.Decode(bundle)\n\t\t\t\tif derBlock == nil || derBlock.Type != \"EC PRIVATE KEY\" {\n\t\t\t\t\treturn tls.Certificate{}, fmt.Errorf(\"expected elliptic private key to immediately follow EC parameters\")\n\t\t\t\t}\n\t\t\t\tif err := pem.Encode(keyBuilder, derBlock); err != nil {\n\t\t\t\t\treturn tls.Certificate{}, err\n\t\t\t\t}\n\t\t\t\tfoundKey = true\n\t\t\t}\n\t\t} else if derBlock.Type == \"PRIVATE KEY\" || strings.HasSuffix(derBlock.Type, \" PRIVATE KEY\") {\n\t\t\t// RSA key\n\t\t\tif !foundKey {\n\t\t\t\tif err := pem.Encode(keyBuilder, derBlock); err != nil {\n\t\t\t\t\treturn tls.Certificate{}, err\n\t\t\t\t}\n\t\t\t\tfoundKey = true\n\t\t\t}\n\t\t} else {\n\t\t\treturn tls.Certificate{}, fmt.Errorf(\"unrecognized PEM block type: %s\", derBlock.Type)\n\t\t}\n\t}\n\n\tcertPEMBytes, keyPEMBytes := certBuilder.Bytes(), keyBuilder.Bytes()\n\tif len(certPEMBytes) == 0 {\n\t\treturn tls.Certificate{}, fmt.Errorf(\"failed to parse PEM data\")\n\t}\n\tif len(keyPEMBytes) == 0 {\n\t\treturn tls.Certificate{}, fmt.Errorf(\"no private key block found\")\n\t}\n\n\t// if the start of the key file looks like an encrypted private key,\n\t// reject it with a helpful error message\n\tif strings.HasPrefix(string(keyPEMBytes[:40]), \"ENCRYPTED\") {\n\t\treturn tls.Certificate{}, fmt.Errorf(\"encrypted private keys are not supported; please decrypt the key first\")\n\t}\n\n\tcert, err := tls.X509KeyPair(certPEMBytes, keyPEMBytes)\n\tif err != nil {\n\t\treturn tls.Certificate{}, fmt.Errorf(\"making X509 key pair: %v\", err)\n\t}\n\n\treturn cert, nil\n}\n\nvar (\n\t_ CertificateLoader = (FolderLoader)(nil)\n\t_ caddy.Provisioner = (FolderLoader)(nil)\n)\n",
    "source_file": "modules/caddytls/folderloader.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/certmagic\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(StorageLoader{})\n}\n\n// StorageLoader loads certificates and their associated keys\n// from the globally configured storage module.\ntype StorageLoader struct {\n\t// A list of pairs of certificate and key file names along with their\n\t// encoding format so that they can be loaded from storage.\n\tPairs []CertKeyFilePair `json:\"pairs,omitempty\"`\n\n\t// Reference to the globally configured storage module.\n\tstorage certmagic.Storage\n\n\tctx caddy.Context\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (StorageLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.certificates.load_storage\",\n\t\tNew: func() caddy.Module { return new(StorageLoader) },\n\t}\n}\n\n// Provision loads the storage module for sl.\nfunc (sl *StorageLoader) Provision(ctx caddy.Context) error {\n\tsl.storage = ctx.Storage()\n\tsl.ctx = ctx\n\n\trepl, ok := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif !ok {\n\t\trepl = caddy.NewReplacer()\n\t}\n\tfor k, pair := range sl.Pairs {\n\t\tfor i, tag := range pair.Tags {\n\t\t\tpair.Tags[i] = repl.ReplaceKnown(tag, \"\")\n\t\t}\n\t\tsl.Pairs[k] = CertKeyFilePair{\n\t\t\tCertificate: repl.ReplaceKnown(pair.Certificate, \"\"),\n\t\t\tKey:         repl.ReplaceKnown(pair.Key, \"\"),\n\t\t\tFormat:      repl.ReplaceKnown(pair.Format, \"\"),\n\t\t\tTags:        pair.Tags,\n\t\t}\n\t}\n\treturn nil\n}\n\n// LoadCertificates returns the certificates to be loaded by sl.\nfunc (sl StorageLoader) LoadCertificates() ([]Certificate, error) {\n\tcerts := make([]Certificate, 0, len(sl.Pairs))\n\tfor _, pair := range sl.Pairs {\n\t\tcertData, err := sl.storage.Load(sl.ctx, pair.Certificate)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tkeyData, err := sl.storage.Load(sl.ctx, pair.Key)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tvar cert tls.Certificate\n\t\tswitch pair.Format {\n\t\tcase \"\":\n\t\t\tfallthrough\n\n\t\tcase \"pem\":\n\t\t\t// if the start of the key file looks like an encrypted private key,\n\t\t\t// reject it with a helpful error message\n\t\t\tif strings.Contains(string(keyData[:40]), \"ENCRYPTED\") {\n\t\t\t\treturn nil, fmt.Errorf(\"encrypted private keys are not supported; please decrypt the key first\")\n\t\t\t}\n\n\t\t\tcert, err = tls.X509KeyPair(certData, keyData)\n\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unrecognized certificate/key encoding format: %s\", pair.Format)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcerts = append(certs, Certificate{Certificate: cert, Tags: pair.Tags})\n\t}\n\treturn certs, nil\n}\n\n// Interface guard\nvar (\n\t_ CertificateLoader = (*StorageLoader)(nil)\n\t_ caddy.Provisioner = (*StorageLoader)(nil)\n)\n",
    "source_file": "modules/caddytls/storageloader.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/x509\"\n\t\"encoding/pem\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(LeafFileLoader{})\n}\n\n// LeafFileLoader loads leaf certificates from disk.\ntype LeafFileLoader struct {\n\tFiles []string `json:\"files,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (LeafFileLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.leaf_cert_loader.file\",\n\t\tNew: func() caddy.Module { return new(LeafFileLoader) },\n\t}\n}\n\n// Provision implements caddy.Provisioner.\nfunc (fl *LeafFileLoader) Provision(ctx caddy.Context) error {\n\trepl, ok := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif !ok {\n\t\trepl = caddy.NewReplacer()\n\t}\n\tfor k, path := range fl.Files {\n\t\tfl.Files[k] = repl.ReplaceKnown(path, \"\")\n\t}\n\treturn nil\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (fl *LeafFileLoader) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.NextArg()\n\tfl.Files = append(fl.Files, d.RemainingArgs()...)\n\treturn nil\n}\n\n// LoadLeafCertificates returns the certificates to be loaded by fl.\nfunc (fl LeafFileLoader) LoadLeafCertificates() ([]*x509.Certificate, error) {\n\tcertificates := make([]*x509.Certificate, 0, len(fl.Files))\n\tfor _, path := range fl.Files {\n\t\tders, err := convertPEMFilesToDERBytes(path)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcerts, err := x509.ParseCertificates(ders)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcertificates = append(certificates, certs...)\n\t}\n\treturn certificates, nil\n}\n\nfunc convertPEMFilesToDERBytes(filename string) ([]byte, error) {\n\tcertDataPEM, err := os.ReadFile(filename)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tvar ders []byte\n\t// while block is not nil, we have more certificates in the file\n\tfor block, rest := pem.Decode(certDataPEM); block != nil; block, rest = pem.Decode(rest) {\n\t\tif block.Type != \"CERTIFICATE\" {\n\t\t\treturn nil, fmt.Errorf(\"no CERTIFICATE pem block found in %s\", filename)\n\t\t}\n\t\tders = append(\n\t\t\tders,\n\t\t\tblock.Bytes...,\n\t\t)\n\t}\n\t// if we decoded nothing, return an error\n\tif len(ders) == 0 {\n\t\treturn nil, fmt.Errorf(\"no CERTIFICATE pem block found in %s\", filename)\n\t}\n\treturn ders, nil\n}\n\n// Interface guard\nvar (\n\t_ LeafCertificateLoader = (*LeafFileLoader)(nil)\n\t_ caddy.Provisioner     = (*LeafFileLoader)(nil)\n\t_ caddyfile.Unmarshaler = (*LeafFileLoader)(nil)\n)\n",
    "source_file": "modules/caddytls/leaffileloader.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/x509\"\n\t\"encoding/json\"\n\t\"encoding/pem\"\n\t\"fmt\"\n\n\t\"github.com/caddyserver/certmagic\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(LeafStorageLoader{})\n}\n\n// LeafStorageLoader loads leaf certificates from the\n// globally configured storage module.\ntype LeafStorageLoader struct {\n\t// A list of certificate file names to be loaded from storage.\n\tCertificates []string `json:\"certificates,omitempty\"`\n\n\t// The storage module where the trusted leaf certificates are stored. Absent\n\t// explicit storage implies the use of Caddy default storage.\n\tStorageRaw json.RawMessage `json:\"storage,omitempty\" caddy:\"namespace=caddy.storage inline_key=module\"`\n\n\t// Reference to the globally configured storage module.\n\tstorage certmagic.Storage\n\n\tctx caddy.Context\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (LeafStorageLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.leaf_cert_loader.storage\",\n\t\tNew: func() caddy.Module { return new(LeafStorageLoader) },\n\t}\n}\n\n// Provision loads the storage module for sl.\nfunc (sl *LeafStorageLoader) Provision(ctx caddy.Context) error {\n\tif sl.StorageRaw != nil {\n\t\tval, err := ctx.LoadModule(sl, \"StorageRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading storage module: %v\", err)\n\t\t}\n\t\tcmStorage, err := val.(caddy.StorageConverter).CertMagicStorage()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"creating storage configuration: %v\", err)\n\t\t}\n\t\tsl.storage = cmStorage\n\t}\n\tif sl.storage == nil {\n\t\tsl.storage = ctx.Storage()\n\t}\n\tsl.ctx = ctx\n\n\trepl, ok := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif !ok {\n\t\trepl = caddy.NewReplacer()\n\t}\n\tfor k, path := range sl.Certificates {\n\t\tsl.Certificates[k] = repl.ReplaceKnown(path, \"\")\n\t}\n\treturn nil\n}\n\n// LoadLeafCertificates returns the certificates to be loaded by sl.\nfunc (sl LeafStorageLoader) LoadLeafCertificates() ([]*x509.Certificate, error) {\n\tcertificates := make([]*x509.Certificate, 0, len(sl.Certificates))\n\tfor _, path := range sl.Certificates {\n\t\tcertData, err := sl.storage.Load(sl.ctx, path)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tders, err := convertPEMToDER(certData)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcerts, err := x509.ParseCertificates(ders)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tcertificates = append(certificates, certs...)\n\t}\n\treturn certificates, nil\n}\n\nfunc convertPEMToDER(pemData []byte) ([]byte, error) {\n\tvar ders []byte\n\t// while block is not nil, we have more certificates in the file\n\tfor block, rest := pem.Decode(pemData); block != nil; block, rest = pem.Decode(rest) {\n\t\tif block.Type != \"CERTIFICATE\" {\n\t\t\treturn nil, fmt.Errorf(\"no CERTIFICATE pem block found in the given pem data\")\n\t\t}\n\t\tders = append(\n\t\t\tders,\n\t\t\tblock.Bytes...,\n\t\t)\n\t}\n\t// if we decoded nothing, return an error\n\tif len(ders) == 0 {\n\t\treturn nil, fmt.Errorf(\"no CERTIFICATE pem block found in the given pem data\")\n\t}\n\treturn ders, nil\n}\n\n// Interface guard\nvar (\n\t_ LeafCertificateLoader = (*LeafStorageLoader)(nil)\n\t_ caddy.Provisioner     = (*LeafStorageLoader)(nil)\n)\n",
    "source_file": "modules/caddytls/leafstorageloader.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"log\"\n\t\"net\"\n\t\"net/http\"\n\t\"runtime/debug\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/libdns/libdns\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/internal\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyevents\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(TLS{})\n\tcaddy.RegisterModule(AutomateLoader{})\n}\n\nvar (\n\tcertCache   *certmagic.Cache\n\tcertCacheMu sync.RWMutex\n)\n\n// TLS provides TLS facilities including certificate\n// loading and management, client auth, and more.\ntype TLS struct {\n\t// Certificates to load into memory for quick recall during\n\t// TLS handshakes. Each key is the name of a certificate\n\t// loader module.\n\t//\n\t// The \"automate\" certificate loader module can be used to\n\t// specify a list of subjects that need certificates to be\n\t// managed automatically, including subdomains that may\n\t// already be covered by a managed wildcard certificate.\n\t// The first matching automation policy will be used\n\t// to manage automated certificate(s).\n\t//\n\t// All loaded certificates get pooled\n\t// into the same cache and may be used to complete TLS\n\t// handshakes for the relevant server names (SNI).\n\t// Certificates loaded manually (anything other than\n\t// \"automate\") are not automatically managed and will\n\t// have to be refreshed manually before they expire.\n\tCertificatesRaw caddy.ModuleMap `json:\"certificates,omitempty\" caddy:\"namespace=tls.certificates\"`\n\n\t// Configures certificate automation.\n\tAutomation *AutomationConfig `json:\"automation,omitempty\"`\n\n\t// Configures session ticket ephemeral keys (STEKs).\n\tSessionTickets *SessionTicketService `json:\"session_tickets,omitempty\"`\n\n\t// Configures the in-memory certificate cache.\n\tCache *CertCacheOptions `json:\"cache,omitempty\"`\n\n\t// Disables OCSP stapling for manually-managed certificates only.\n\t// To configure OCSP stapling for automated certificates, use an\n\t// automation policy instead.\n\t//\n\t// Disabling OCSP stapling puts clients at greater risk, reduces their\n\t// privacy, and usually lowers client performance. It is NOT recommended\n\t// to disable this unless you are able to justify the costs.\n\t//\n\t// EXPERIMENTAL. Subject to change.\n\tDisableOCSPStapling bool `json:\"disable_ocsp_stapling,omitempty\"`\n\n\t// Disables checks in certmagic that the configured storage is ready\n\t// and able to handle writing new content to it. These checks are\n\t// intended to prevent information loss (newly issued certificates), but\n\t// can be expensive on the storage.\n\t//\n\t// Disabling these checks should only be done when the storage\n\t// can be trusted to have enough capacity and no other problems.\n\t//\n\t// EXPERIMENTAL. Subject to change.\n\tDisableStorageCheck bool `json:\"disable_storage_check,omitempty\"`\n\n\t// Disables the automatic cleanup of the storage backend.\n\t// This is useful when TLS is not being used to store certificates\n\t// and the user wants run their server in a read-only mode.\n\t//\n\t// Storage cleaning creates two files: instance.uuid and last_clean.json.\n\t// The instance.uuid file is used to identify the instance of Caddy\n\t// in a cluster. The last_clean.json file is used to store the last\n\t// time the storage was cleaned.\n\t//\n\t// EXPERIMENTAL. Subject to change.\n\tDisableStorageClean bool `json:\"disable_storage_clean,omitempty\"`\n\n\t// Enable Encrypted ClientHello (ECH). ECH protects the server name\n\t// (SNI) and other sensitive parameters of a normally-plaintext TLS\n\t// ClientHello during a handshake.\n\t//\n\t// EXPERIMENTAL: Subject to change.\n\tEncryptedClientHello *ECH `json:\"encrypted_client_hello,omitempty\"`\n\n\t// The default DNS provider module to use when a DNS module is needed.\n\t//\n\t// EXPERIMENTAL: Subject to change.\n\tDNSRaw json.RawMessage `json:\"dns,omitempty\" caddy:\"namespace=dns.providers inline_key=name\"`\n\tdns    any             // technically, it should be any/all of the libdns interfaces (RecordSetter, RecordAppender, etc.)\n\n\tcertificateLoaders []CertificateLoader\n\tautomateNames      map[string]struct{}\n\tctx                caddy.Context\n\tstorageCleanTicker *time.Ticker\n\tstorageCleanStop   chan struct{}\n\tlogger             *zap.Logger\n\tevents             *caddyevents.App\n\n\tserverNames   map[string]struct{}\n\tserverNamesMu *sync.Mutex\n\n\t// set of subjects with managed certificates,\n\t// and hashes of manually-loaded certificates\n\t// (managing's value is an optional issuer key, for distinction)\n\tmanaging, loaded map[string]string\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (TLS) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls\",\n\t\tNew: func() caddy.Module { return new(TLS) },\n\t}\n}\n\n// Provision sets up the configuration for the TLS app.\nfunc (t *TLS) Provision(ctx caddy.Context) error {\n\teventsAppIface, err := ctx.App(\"events\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting events app: %v\", err)\n\t}\n\tt.events = eventsAppIface.(*caddyevents.App)\n\tt.ctx = ctx\n\tt.logger = ctx.Logger()\n\trepl := caddy.NewReplacer()\n\tt.managing, t.loaded = make(map[string]string), make(map[string]string)\n\tt.serverNames = make(map[string]struct{})\n\tt.serverNamesMu = new(sync.Mutex)\n\n\t// set up default DNS module, if any, and make sure it implements all the\n\t// common libdns interfaces, since it could be used for a variety of things\n\t// (do this before provisioning other modules, since they may rely on this)\n\tif len(t.DNSRaw) > 0 {\n\t\tdnsMod, err := ctx.LoadModule(t, \"DNSRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading overall DNS provider module: %v\", err)\n\t\t}\n\t\tswitch dnsMod.(type) {\n\t\tcase interface {\n\t\t\tlibdns.RecordAppender\n\t\t\tlibdns.RecordDeleter\n\t\t\tlibdns.RecordGetter\n\t\t\tlibdns.RecordSetter\n\t\t}:\n\t\tdefault:\n\t\t\treturn fmt.Errorf(\"DNS module does not implement the most common libdns interfaces: %T\", dnsMod)\n\t\t}\n\t\tt.dns = dnsMod\n\t}\n\n\t// set up a new certificate cache; this (re)loads all certificates\n\tcacheOpts := certmagic.CacheOptions{\n\t\tGetConfigForCert: func(cert certmagic.Certificate) (*certmagic.Config, error) {\n\t\t\treturn t.getConfigForName(cert.Names[0]), nil\n\t\t},\n\t\tLogger: t.logger.Named(\"cache\"),\n\t}\n\tif t.Automation != nil {\n\t\tcacheOpts.OCSPCheckInterval = time.Duration(t.Automation.OCSPCheckInterval)\n\t\tcacheOpts.RenewCheckInterval = time.Duration(t.Automation.RenewCheckInterval)\n\t}\n\tif t.Cache != nil {\n\t\tcacheOpts.Capacity = t.Cache.Capacity\n\t}\n\tif cacheOpts.Capacity <= 0 {\n\t\tcacheOpts.Capacity = 10000\n\t}\n\n\tcertCacheMu.Lock()\n\tif certCache == nil {\n\t\tcertCache = certmagic.NewCache(cacheOpts)\n\t} else {\n\t\tcertCache.SetOptions(cacheOpts)\n\t}\n\tcertCacheMu.Unlock()\n\n\t// certificate loaders\n\tval, err := ctx.LoadModule(t, \"CertificatesRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading certificate loader modules: %s\", err)\n\t}\n\tfor modName, modIface := range val.(map[string]any) {\n\t\tif modName == \"automate\" {\n\t\t\t// special case; these will be loaded in later using our automation facilities,\n\t\t\t// which we want to avoid doing during provisioning\n\t\t\tif automateNames, ok := modIface.(*AutomateLoader); ok && automateNames != nil {\n\t\t\t\tif t.automateNames == nil {\n\t\t\t\t\tt.automateNames = make(map[string]struct{})\n\t\t\t\t}\n\t\t\t\trepl := caddy.NewReplacer()\n\t\t\t\tfor _, sub := range *automateNames {\n\t\t\t\t\tt.automateNames[repl.ReplaceAll(sub, \"\")] = struct{}{}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn fmt.Errorf(\"loading certificates with 'automate' requires array of strings, got: %T\", modIface)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tt.certificateLoaders = append(t.certificateLoaders, modIface.(CertificateLoader))\n\t}\n\n\t// using the certificate loaders we just initialized, load\n\t// manual/static (unmanaged) certificates - we do this in\n\t// provision so that other apps (such as http) can know which\n\t// certificates have been manually loaded, and also so that\n\t// commands like validate can be a better test\n\tcertCacheMu.RLock()\n\tmagic := certmagic.New(certCache, certmagic.Config{\n\t\tStorage: ctx.Storage(),\n\t\tLogger:  t.logger,\n\t\tOnEvent: t.onEvent,\n\t\tOCSP: certmagic.OCSPConfig{\n\t\t\tDisableStapling: t.DisableOCSPStapling,\n\t\t},\n\t\tDisableStorageCheck: t.DisableStorageCheck,\n\t})\n\tcertCacheMu.RUnlock()\n\tfor _, loader := range t.certificateLoaders {\n\t\tcerts, err := loader.LoadCertificates()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading certificates: %v\", err)\n\t\t}\n\t\tfor _, cert := range certs {\n\t\t\thash, err := magic.CacheUnmanagedTLSCertificate(ctx, cert.Certificate, cert.Tags)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"caching unmanaged certificate: %v\", err)\n\t\t\t}\n\t\t\tt.loaded[hash] = \"\"\n\t\t}\n\t}\n\n\t// on-demand permission module\n\tif t.Automation != nil && t.Automation.OnDemand != nil && t.Automation.OnDemand.PermissionRaw != nil {\n\t\tif t.Automation.OnDemand.Ask != \"\" {\n\t\t\treturn fmt.Errorf(\"on-demand TLS config conflict: both 'ask' endpoint and a 'permission' module are specified; 'ask' is deprecated, so use only the permission module\")\n\t\t}\n\t\tval, err := ctx.LoadModule(t.Automation.OnDemand, \"PermissionRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading on-demand TLS permission module: %v\", err)\n\t\t}\n\t\tt.Automation.OnDemand.permission = val.(OnDemandPermission)\n\t}\n\n\t// automation/management policies\n\tif t.Automation == nil {\n\t\tt.Automation = new(AutomationConfig)\n\t}\n\tt.Automation.defaultPublicAutomationPolicy = new(AutomationPolicy)\n\terr = t.Automation.defaultPublicAutomationPolicy.Provision(t)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"provisioning default public automation policy: %v\", err)\n\t}\n\tfor n := range t.automateNames {\n\t\t// if any names specified by the \"automate\" loader do not qualify for a public\n\t\t// certificate, we should initialize a default internal automation policy\n\t\t// (but we don't want to do this unnecessarily, since it may prompt for password!)\n\t\tif certmagic.SubjectQualifiesForPublicCert(n) {\n\t\t\tcontinue\n\t\t}\n\t\tt.Automation.defaultInternalAutomationPolicy = &AutomationPolicy{\n\t\t\tIssuersRaw: []json.RawMessage{json.RawMessage(`{\"module\":\"internal\"}`)},\n\t\t}\n\t\terr = t.Automation.defaultInternalAutomationPolicy.Provision(t)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning default internal automation policy: %v\", err)\n\t\t}\n\t\tbreak\n\t}\n\tfor i, ap := range t.Automation.Policies {\n\t\terr := ap.Provision(t)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning automation policy %d: %v\", i, err)\n\t\t}\n\t}\n\n\t// run replacer on ask URL (for environment variables) -- return errors to prevent surprises (#5036)\n\tif t.Automation != nil && t.Automation.OnDemand != nil && t.Automation.OnDemand.Ask != \"\" {\n\t\tt.Automation.OnDemand.Ask, err = repl.ReplaceOrErr(t.Automation.OnDemand.Ask, true, true)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"preparing 'ask' endpoint: %v\", err)\n\t\t}\n\t\tperm := PermissionByHTTP{\n\t\t\tEndpoint: t.Automation.OnDemand.Ask,\n\t\t}\n\t\tif err := perm.Provision(ctx); err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning 'ask' module: %v\", err)\n\t\t}\n\t\tt.Automation.OnDemand.permission = perm\n\t}\n\n\t// session ticket ephemeral keys (STEK) service and provider\n\tif t.SessionTickets != nil {\n\t\terr := t.SessionTickets.provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning session tickets configuration: %v\", err)\n\t\t}\n\t}\n\n\t// ECH (Encrypted ClientHello) initialization\n\tif t.EncryptedClientHello != nil {\n\t\tt.EncryptedClientHello.configs = make(map[string][]echConfig)\n\t\touterNames, err := t.EncryptedClientHello.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning Encrypted ClientHello components: %v\", err)\n\t\t}\n\n\t\t// outer names should have certificates to reduce client brittleness\n\t\tfor _, outerName := range outerNames {\n\t\t\tif outerName == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif !t.HasCertificateForSubject(outerName) {\n\t\t\t\tif t.automateNames == nil {\n\t\t\t\t\tt.automateNames = make(map[string]struct{})\n\t\t\t\t}\n\t\t\t\tt.automateNames[outerName] = struct{}{}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Validate validates t's configuration.\nfunc (t *TLS) Validate() error {\n\tif t.Automation != nil {\n\t\t// ensure that host aren't repeated; since only the first\n\t\t// automation policy is used, repeating a host in the lists\n\t\t// isn't useful and is probably a mistake; same for two\n\t\t// catch-all/default policies\n\t\tvar hasDefault bool\n\t\thostSet := make(map[string]int)\n\t\tfor i, ap := range t.Automation.Policies {\n\t\t\tif len(ap.subjects) == 0 {\n\t\t\t\tif hasDefault {\n\t\t\t\t\treturn fmt.Errorf(\"automation policy %d is the second policy that acts as default/catch-all, but will never be used\", i)\n\t\t\t\t}\n\t\t\t\thasDefault = true\n\t\t\t}\n\t\t\tfor _, h := range ap.subjects {\n\t\t\t\tif first, ok := hostSet[h]; ok {\n\t\t\t\t\treturn fmt.Errorf(\"automation policy %d: cannot apply more than one automation policy to host: %s (first match in policy %d)\", i, h, first)\n\t\t\t\t}\n\t\t\t\thostSet[h] = i\n\t\t\t}\n\t\t}\n\t}\n\tif t.Cache != nil {\n\t\tif t.Cache.Capacity < 0 {\n\t\t\treturn fmt.Errorf(\"cache capacity must be >= 0\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// Start activates the TLS module.\nfunc (t *TLS) Start() error {\n\t// warn if on-demand TLS is enabled but no restrictions are in place\n\tif t.Automation.OnDemand == nil || (t.Automation.OnDemand.Ask == \"\" && t.Automation.OnDemand.permission == nil) {\n\t\tfor _, ap := range t.Automation.Policies {\n\t\t\tif ap.OnDemand && ap.isWildcardOrDefault() {\n\t\t\t\tif c := t.logger.Check(zapcore.WarnLevel, \"YOUR SERVER MAY BE VULNERABLE TO ABUSE: on-demand TLS is enabled, but no protections are in place\"); c != nil {\n\t\t\t\t\tc.Write(zap.String(\"docs\", \"https://caddyserver.com/docs/automatic-https#on-demand-tls\"))\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\t// now that we are running, and all manual certificates have\n\t// been loaded, time to load the automated/managed certificates\n\terr := t.Manage(t.automateNames)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"automate: managing %v: %v\", t.automateNames, err)\n\t}\n\n\t// publish ECH configs in the background; does not need to block\n\t// server startup, as it could take a while\n\tif t.EncryptedClientHello != nil {\n\t\tgo func() {\n\t\t\tif err := t.publishECHConfigs(); err != nil {\n\t\t\t\tt.logger.Named(\"ech\").Error(\"publication(s) failed\", zap.Error(err))\n\t\t\t}\n\t\t}()\n\t}\n\n\tif !t.DisableStorageClean {\n\t\t// start the storage cleaner goroutine and ticker,\n\t\t// which cleans out expired certificates and more\n\t\tt.keepStorageClean()\n\t}\n\n\treturn nil\n}\n\n// Stop stops the TLS module and cleans up any allocations.\nfunc (t *TLS) Stop() error {\n\t// stop the storage cleaner goroutine and ticker\n\tif t.storageCleanStop != nil {\n\t\tclose(t.storageCleanStop)\n\t}\n\tif t.storageCleanTicker != nil {\n\t\tt.storageCleanTicker.Stop()\n\t}\n\treturn nil\n}\n\n// Cleanup frees up resources allocated during Provision.\nfunc (t *TLS) Cleanup() error {\n\t// stop the session ticket rotation goroutine\n\tif t.SessionTickets != nil {\n\t\tt.SessionTickets.stop()\n\t}\n\n\t// if a new TLS app was loaded, remove certificates from the cache that are no longer\n\t// being managed or loaded by the new config; if there is no more TLS app running,\n\t// then stop cert maintenance and let the cert cache be GC'ed\n\tif nextTLS, err := caddy.ActiveContext().AppIfConfigured(\"tls\"); err == nil && nextTLS != nil {\n\t\tnextTLSApp := nextTLS.(*TLS)\n\n\t\t// compute which certificates were managed or loaded into the cert cache by this\n\t\t// app instance (which is being stopped) that are not managed or loaded by the\n\t\t// new app instance (which just started), and remove them from the cache\n\t\tvar noLongerManaged []certmagic.SubjectIssuer\n\t\tvar noLongerLoaded []string\n\t\treManage := make(map[string]struct{})\n\t\tfor subj, currentIssuerKey := range t.managing {\n\t\t\t// It's a bit nuanced: managed certs can sometimes be different enough that we have to\n\t\t\t// swap them out for a different one, even if they are for the same subject/domain.\n\t\t\t// We consider \"private\" certs (internal CA/locally-trusted/etc) to be significantly\n\t\t\t// distinct from \"public\" certs (production CAs/globally-trusted/etc) because of the\n\t\t\t// implications when it comes to actual deployments: switching between an internal CA\n\t\t\t// and a production CA, for example, is quite significant. Switching from one public CA\n\t\t\t// to another, however, is not, and for our purposes we consider those to be the same.\n\t\t\t// Anyway, if the next TLS app does not manage a cert for this name at all, definitely\n\t\t\t// remove it from the cache. But if it does, and it's not the same kind of issuer/CA\n\t\t\t// as we have, also remove it, so that it can swap it out for the right one.\n\t\t\tif nextIssuerKey, ok := nextTLSApp.managing[subj]; !ok || nextIssuerKey != currentIssuerKey {\n\t\t\t\t// next app is not managing a cert for this domain at all or is using a different issuer, so remove it\n\t\t\t\tnoLongerManaged = append(noLongerManaged, certmagic.SubjectIssuer{Subject: subj, IssuerKey: currentIssuerKey})\n\n\t\t\t\t// then, if the next app is managing a cert for this name, but with a different issuer, re-manage it\n\t\t\t\tif ok && nextIssuerKey != currentIssuerKey {\n\t\t\t\t\treManage[subj] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tfor hash := range t.loaded {\n\t\t\tif _, ok := nextTLSApp.loaded[hash]; !ok {\n\t\t\t\tnoLongerLoaded = append(noLongerLoaded, hash)\n\t\t\t}\n\t\t}\n\n\t\t// remove the certs\n\t\tcertCacheMu.RLock()\n\t\tcertCache.RemoveManaged(noLongerManaged)\n\t\tcertCache.Remove(noLongerLoaded)\n\t\tcertCacheMu.RUnlock()\n\n\t\t// give the new TLS app a \"kick\" to manage certs that it is configured for\n\t\t// with its own configuration instead of the one we just evicted\n\t\tif err := nextTLSApp.Manage(reManage); err != nil {\n\t\t\tif c := t.logger.Check(zapcore.ErrorLevel, \"re-managing unloaded certificates with new config\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.Strings(\"subjects\", internal.MaxSizeSubjectsListForLog(reManage, 1000)),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t}\n\t\t}\n\t} else {\n\t\t// no more TLS app running, so delete in-memory cert cache, if it was created yet\n\t\tcertCacheMu.RLock()\n\t\thasCache := certCache != nil\n\t\tcertCacheMu.RUnlock()\n\t\tif hasCache {\n\t\t\tcertCache.Stop()\n\t\t\tcertCacheMu.Lock()\n\t\t\tcertCache = nil\n\t\t\tcertCacheMu.Unlock()\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Manage immediately begins managing subjects according to the\n// matching automation policy. The subjects are given in a map\n// to prevent duplication and also because quick lookups are\n// needed to assess wildcard coverage, if any, depending on\n// certain config parameters (with lots of subjects, computing\n// wildcard coverage over a slice can be highly inefficient).\nfunc (t *TLS) Manage(subjects map[string]struct{}) error {\n\t// for a large number of names, we can be more memory-efficient\n\t// by making only one certmagic.Config for all the names that\n\t// use that config, rather than calling ManageAsync once for\n\t// every name; so first, bin names by AutomationPolicy\n\tpolicyToNames := make(map[*AutomationPolicy][]string)\n\tfor subj := range subjects {\n\t\tap := t.getAutomationPolicyForName(subj)\n\t\t// by default, if a wildcard that covers the subj is also being\n\t\t// managed, either by a previous call to Manage or by this one,\n\t\t// prefer using that over individual certs for its subdomains;\n\t\t// but users can disable this and force getting a certificate for\n\t\t// subdomains by adding the name to the 'automate' cert loader\n\t\tif t.managingWildcardFor(subj, subjects) {\n\t\t\tif _, ok := t.automateNames[subj]; !ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\tpolicyToNames[ap] = append(policyToNames[ap], subj)\n\t}\n\n\t// now that names are grouped by policy, we can simply make one\n\t// certmagic.Config for each (potentially large) group of names\n\t// and call ManageAsync just once for the whole batch\n\tfor ap, names := range policyToNames {\n\t\terr := ap.magic.ManageAsync(t.ctx.Context, names)\n\t\tif err != nil {\n\t\t\tconst maxNamesToDisplay = 100\n\t\t\tif len(names) > maxNamesToDisplay {\n\t\t\t\tnames = append(names[:maxNamesToDisplay], fmt.Sprintf(\"(and %d more...)\", len(names)-maxNamesToDisplay))\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"automate: manage %v: %v\", names, err)\n\t\t}\n\t\tfor _, name := range names {\n\t\t\t// certs that are issued solely by our internal issuer are a little bit of\n\t\t\t// a special case: if you have an initial config that manages example.com\n\t\t\t// using internal CA, then after testing it you switch to a production CA,\n\t\t\t// you wouldn't want to keep using the same self-signed cert, obviously;\n\t\t\t// so we differentiate these by associating the subject with its issuer key;\n\t\t\t// we do this because CertMagic has no notion of \"InternalIssuer\" like we\n\t\t\t// do, so we have to do this logic ourselves\n\t\t\tvar issuerKey string\n\t\t\tif len(ap.Issuers) == 1 {\n\t\t\t\tif intIss, ok := ap.Issuers[0].(*InternalIssuer); ok && intIss != nil {\n\t\t\t\t\tissuerKey = intIss.IssuerKey()\n\t\t\t\t}\n\t\t\t}\n\t\t\tt.managing[name] = issuerKey\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// managingWildcardFor returns true if the app is managing a certificate that covers that\n// subject name (including consideration of wildcards), either from its internal list of\n// names that it IS managing certs for, or from the otherSubjsToManage which includes names\n// that WILL be managed.\nfunc (t *TLS) managingWildcardFor(subj string, otherSubjsToManage map[string]struct{}) bool {\n\t// TODO: we could also consider manually-loaded certs using t.HasCertificateForSubject(),\n\t// but that does not account for how manually-loaded certs may be restricted as to which\n\t// hostnames or ClientHellos they can be used with by tags, etc; I don't *think* anyone\n\t// necessarily wants this anyway, but I thought I'd note this here for now (if we did\n\t// consider manually-loaded certs, we'd probably want to rename the method since it\n\t// wouldn't be just about managed certs anymore)\n\n\t// IP addresses must match exactly\n\tif ip := net.ParseIP(subj); ip != nil {\n\t\t_, managing := t.managing[subj]\n\t\treturn managing\n\t}\n\n\t// replace labels of the domain with wildcards until we get a match\n\tlabels := strings.Split(subj, \".\")\n\tfor i := range labels {\n\t\tif labels[i] == \"*\" {\n\t\t\tcontinue\n\t\t}\n\t\tlabels[i] = \"*\"\n\t\tcandidate := strings.Join(labels, \".\")\n\t\tif _, ok := t.managing[candidate]; ok {\n\t\t\treturn true\n\t\t}\n\t\tif _, ok := otherSubjsToManage[candidate]; ok {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n\n// RegisterServerNames registers the provided DNS names with the TLS app.\n// This is currently used to auto-publish Encrypted ClientHello (ECH)\n// configurations, if enabled. Use of this function by apps using the TLS\n// app removes the need for the user to redundantly specify domain names\n// in their configuration. This function separates hostname and port\n// (keeping only the hotsname) and filters IP addresses, which can't be\n// used with ECH.\n//\n// EXPERIMENTAL: This function and its semantics/behavior are subject to change.\nfunc (t *TLS) RegisterServerNames(dnsNames []string) {\n\tt.serverNamesMu.Lock()\n\tfor _, name := range dnsNames {\n\t\thost, _, err := net.SplitHostPort(name)\n\t\tif err != nil {\n\t\t\thost = name\n\t\t}\n\t\tif strings.TrimSpace(host) != \"\" && !certmagic.SubjectIsIP(host) {\n\t\t\tt.serverNames[strings.ToLower(host)] = struct{}{}\n\t\t}\n\t}\n\tt.serverNamesMu.Unlock()\n}\n\n// HandleHTTPChallenge ensures that the ACME HTTP challenge or ZeroSSL HTTP\n// validation request is handled for the certificate named by r.Host, if it\n// is an HTTP challenge request. It requires that the automation policy for\n// r.Host has an issuer that implements GetACMEIssuer() or is a *ZeroSSLIssuer.\nfunc (t *TLS) HandleHTTPChallenge(w http.ResponseWriter, r *http.Request) bool {\n\tacmeChallenge := certmagic.LooksLikeHTTPChallenge(r)\n\tzerosslValidation := certmagic.LooksLikeZeroSSLHTTPValidation(r)\n\n\t// no-op if it's not an ACME challenge request\n\tif !acmeChallenge && !zerosslValidation {\n\t\treturn false\n\t}\n\n\t// try all the issuers until we find the one that initiated the challenge\n\tap := t.getAutomationPolicyForName(r.Host)\n\n\tif acmeChallenge {\n\t\ttype acmeCapable interface{ GetACMEIssuer() *ACMEIssuer }\n\n\t\tfor _, iss := range ap.magic.Issuers {\n\t\t\tif acmeIssuer, ok := iss.(acmeCapable); ok {\n\t\t\t\tif acmeIssuer.GetACMEIssuer().issuer.HandleHTTPChallenge(w, r) {\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// it's possible another server in this process initiated the challenge;\n\t\t// users have requested that Caddy only handle HTTP challenges it initiated,\n\t\t// so that users can proxy the others through to their backends; but we\n\t\t// might not have an automation policy for all identifiers that are trying\n\t\t// to get certificates (e.g. the admin endpoint), so we do this manual check\n\t\tif challenge, ok := certmagic.GetACMEChallenge(r.Host); ok {\n\t\t\treturn certmagic.SolveHTTPChallenge(t.logger, w, r, challenge.Challenge)\n\t\t}\n\t} else if zerosslValidation {\n\t\tfor _, iss := range ap.magic.Issuers {\n\t\t\tif ziss, ok := iss.(*ZeroSSLIssuer); ok {\n\t\t\t\tif ziss.issuer.HandleZeroSSLHTTPValidation(w, r) {\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn false\n}\n\n// AddAutomationPolicy provisions and adds ap to the list of the app's\n// automation policies. If an existing automation policy exists that has\n// fewer hosts in its list than ap does, ap will be inserted before that\n// other policy (this helps ensure that ap will be prioritized/chosen\n// over, say, a catch-all policy).\nfunc (t *TLS) AddAutomationPolicy(ap *AutomationPolicy) error {\n\tif t.Automation == nil {\n\t\tt.Automation = new(AutomationConfig)\n\t}\n\terr := ap.Provision(t)\n\tif err != nil {\n\t\treturn err\n\t}\n\t// sort new automation policies just before any other which is a superset\n\t// of this one; if we find an existing policy that covers every subject in\n\t// ap but less specifically (e.g. a catch-all policy, or one with wildcards\n\t// or with fewer subjects), insert ap just before it, otherwise ap would\n\t// never be used because the first matching policy is more general\n\tfor i, existing := range t.Automation.Policies {\n\t\t// first see if existing is superset of ap for all names\n\t\tvar otherIsSuperset bool\n\touter:\n\t\tfor _, thisSubj := range ap.subjects {\n\t\t\tfor _, otherSubj := range existing.subjects {\n\t\t\t\tif certmagic.MatchWildcard(thisSubj, otherSubj) {\n\t\t\t\t\totherIsSuperset = true\n\t\t\t\t\tbreak outer\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// if existing AP is a superset or if it contains fewer names (i.e. is\n\t\t// more general), then new AP is more specific, so insert before it\n\t\tif otherIsSuperset || len(existing.SubjectsRaw) < len(ap.SubjectsRaw) {\n\t\t\tt.Automation.Policies = append(t.Automation.Policies[:i],\n\t\t\t\tappend([]*AutomationPolicy{ap}, t.Automation.Policies[i:]...)...)\n\t\t\treturn nil\n\t\t}\n\t}\n\t// otherwise just append the new one\n\tt.Automation.Policies = append(t.Automation.Policies, ap)\n\treturn nil\n}\n\nfunc (t *TLS) getConfigForName(name string) *certmagic.Config {\n\tap := t.getAutomationPolicyForName(name)\n\treturn ap.magic\n}\n\n// getAutomationPolicyForName returns the first matching automation policy\n// for the given subject name. If no matching policy can be found, the\n// default policy is used, depending on whether the name qualifies for a\n// public certificate or not.\nfunc (t *TLS) getAutomationPolicyForName(name string) *AutomationPolicy {\n\tfor _, ap := range t.Automation.Policies {\n\t\tif len(ap.subjects) == 0 {\n\t\t\treturn ap // no host filter is an automatic match\n\t\t}\n\t\tfor _, h := range ap.subjects {\n\t\t\tif certmagic.MatchWildcard(name, h) {\n\t\t\t\treturn ap\n\t\t\t}\n\t\t}\n\t}\n\tif certmagic.SubjectQualifiesForPublicCert(name) || t.Automation.defaultInternalAutomationPolicy == nil {\n\t\treturn t.Automation.defaultPublicAutomationPolicy\n\t}\n\treturn t.Automation.defaultInternalAutomationPolicy\n}\n\n// AllMatchingCertificates returns the list of all certificates in\n// the cache which could be used to satisfy the given SAN.\nfunc AllMatchingCertificates(san string) []certmagic.Certificate {\n\treturn certCache.AllMatchingCertificates(san)\n}\n\nfunc (t *TLS) HasCertificateForSubject(subject string) bool {\n\tcertCacheMu.RLock()\n\tallMatchingCerts := certCache.AllMatchingCertificates(subject)\n\tcertCacheMu.RUnlock()\n\tfor _, cert := range allMatchingCerts {\n\t\t// check if the cert is manually loaded by this config\n\t\tif _, ok := t.loaded[cert.Hash()]; ok {\n\t\t\treturn true\n\t\t}\n\t\t// check if the cert is automatically managed by this config\n\t\tfor _, name := range cert.Names {\n\t\t\tif _, ok := t.managing[name]; ok {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}\n\n// keepStorageClean starts a goroutine that immediately cleans up all\n// known storage units if it was not recently done, and then runs the\n// operation at every tick from t.storageCleanTicker.\nfunc (t *TLS) keepStorageClean() {\n\tt.storageCleanTicker = time.NewTicker(t.storageCleanInterval())\n\tt.storageCleanStop = make(chan struct{})\n\tgo func() {\n\t\tdefer func() {\n\t\t\tif err := recover(); err != nil {\n\t\t\t\tlog.Printf(\"[PANIC] storage cleaner: %v\\n%s\", err, debug.Stack())\n\t\t\t}\n\t\t}()\n\t\tt.cleanStorageUnits()\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-t.storageCleanStop:\n\t\t\t\treturn\n\t\t\tcase <-t.storageCleanTicker.C:\n\t\t\t\tt.cleanStorageUnits()\n\t\t\t}\n\t\t}\n\t}()\n}\n\nfunc (t *TLS) cleanStorageUnits() {\n\tstorageCleanMu.Lock()\n\tdefer storageCleanMu.Unlock()\n\n\t// TODO: This check might not be needed anymore now that CertMagic syncs\n\t// and throttles storage cleaning globally across the cluster.\n\t// The original comment below might be outdated:\n\t//\n\t// If storage was cleaned recently, don't do it again for now. Although the ticker\n\t// calling this function drops missed ticks for us, config reloads discard the old\n\t// ticker and replace it with a new one, possibly invoking a cleaning to happen again\n\t// too soon. (We divide the interval by 2 because the actual cleaning takes non-zero\n\t// time, and we don't want to skip cleanings if we don't have to; whereas if a cleaning\n\t// took most of the interval, we'd probably want to skip the next one so we aren't\n\t// constantly cleaning. This allows cleanings to take up to half the interval's\n\t// duration before we decide to skip the next one.)\n\tif !storageClean.IsZero() && time.Since(storageClean) < t.storageCleanInterval()/2 {\n\t\treturn\n\t}\n\n\tid, err := caddy.InstanceID()\n\tif err != nil {\n\t\tif c := t.logger.Check(zapcore.WarnLevel, \"unable to get instance ID; storage clean stamps will be incomplete\"); c != nil {\n\t\t\tc.Write(zap.Error(err))\n\t\t}\n\t}\n\toptions := certmagic.CleanStorageOptions{\n\t\tLogger:                 t.logger,\n\t\tInstanceID:             id.String(),\n\t\tInterval:               t.storageCleanInterval(),\n\t\tOCSPStaples:            true,\n\t\tExpiredCerts:           true,\n\t\tExpiredCertGracePeriod: 24 * time.Hour * 14,\n\t}\n\n\t// start with the default/global storage\n\terr = certmagic.CleanStorage(t.ctx, t.ctx.Storage(), options)\n\tif err != nil {\n\t\t// probably don't want to return early, since we should still\n\t\t// see if any other storages can get cleaned up\n\t\tif c := t.logger.Check(zapcore.ErrorLevel, \"could not clean default/global storage\"); c != nil {\n\t\t\tc.Write(zap.Error(err))\n\t\t}\n\t}\n\n\t// then clean each storage defined in ACME automation policies\n\tif t.Automation != nil {\n\t\tfor _, ap := range t.Automation.Policies {\n\t\t\tif ap.storage == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif err := certmagic.CleanStorage(t.ctx, ap.storage, options); err != nil {\n\t\t\t\tif c := t.logger.Check(zapcore.ErrorLevel, \"could not clean storage configured in automation policy\"); c != nil {\n\t\t\t\t\tc.Write(zap.Error(err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// remember last time storage was finished cleaning\n\tstorageClean = time.Now()\n\n\tt.logger.Info(\"finished cleaning storage units\")\n}\n\nfunc (t *TLS) storageCleanInterval() time.Duration {\n\tif t.Automation != nil && t.Automation.StorageCleanInterval > 0 {\n\t\treturn time.Duration(t.Automation.StorageCleanInterval)\n\t}\n\treturn defaultStorageCleanInterval\n}\n\n// onEvent translates CertMagic events into Caddy events then dispatches them.\nfunc (t *TLS) onEvent(ctx context.Context, eventName string, data map[string]any) error {\n\tevt := t.events.Emit(t.ctx, eventName, data)\n\treturn evt.Aborted\n}\n\n// CertificateLoader is a type that can load certificates.\n// Certificates can optionally be associated with tags.\ntype CertificateLoader interface {\n\tLoadCertificates() ([]Certificate, error)\n}\n\n// Certificate is a TLS certificate, optionally\n// associated with arbitrary tags.\ntype Certificate struct {\n\ttls.Certificate\n\tTags []string\n}\n\n// AutomateLoader will automatically manage certificates for the names in the\n// list, including obtaining and renewing certificates. Automated certificates\n// are managed according to their matching automation policy, configured\n// elsewhere in this app.\n//\n// Technically, this is a no-op certificate loader module that is treated as\n// a special case: it uses this app's automation features to load certificates\n// for the list of hostnames, rather than loading certificates manually. But\n// the end result is the same: certificates for these subject names will be\n// loaded into the in-memory cache and may then be used.\ntype AutomateLoader []string\n\n// CaddyModule returns the Caddy module information.\nfunc (AutomateLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.certificates.automate\",\n\t\tNew: func() caddy.Module { return new(AutomateLoader) },\n\t}\n}\n\n// CertCacheOptions configures the certificate cache.\ntype CertCacheOptions struct {\n\t// Maximum number of certificates to allow in the\n\t// cache. If reached, certificates will be randomly\n\t// evicted to make room for new ones. Default: 10,000\n\tCapacity int `json:\"capacity,omitempty\"`\n}\n\n// Variables related to storage cleaning.\nvar (\n\tdefaultStorageCleanInterval = 24 * time.Hour\n\n\tstorageClean   time.Time\n\tstorageCleanMu sync.Mutex\n)\n\n// Interface guards\nvar (\n\t_ caddy.App          = (*TLS)(nil)\n\t_ caddy.Provisioner  = (*TLS)(nil)\n\t_ caddy.Validator    = (*TLS)(nil)\n\t_ caddy.CleanerUpper = (*TLS)(nil)\n)\n",
    "source_file": "modules/caddytls/tls.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"os\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(FileLoader{})\n}\n\n// FileLoader loads certificates and their associated keys from disk.\ntype FileLoader []CertKeyFilePair\n\n// Provision implements caddy.Provisioner.\nfunc (fl FileLoader) Provision(ctx caddy.Context) error {\n\trepl, ok := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif !ok {\n\t\trepl = caddy.NewReplacer()\n\t}\n\tfor k, pair := range fl {\n\t\tfor i, tag := range pair.Tags {\n\t\t\tpair.Tags[i] = repl.ReplaceKnown(tag, \"\")\n\t\t}\n\t\tfl[k] = CertKeyFilePair{\n\t\t\tCertificate: repl.ReplaceKnown(pair.Certificate, \"\"),\n\t\t\tKey:         repl.ReplaceKnown(pair.Key, \"\"),\n\t\t\tFormat:      repl.ReplaceKnown(pair.Format, \"\"),\n\t\t\tTags:        pair.Tags,\n\t\t}\n\t}\n\treturn nil\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (FileLoader) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.certificates.load_files\",\n\t\tNew: func() caddy.Module { return new(FileLoader) },\n\t}\n}\n\n// CertKeyFilePair pairs certificate and key file names along with their\n// encoding format so that they can be loaded from disk.\ntype CertKeyFilePair struct {\n\t// Path to the certificate (public key) file.\n\tCertificate string `json:\"certificate\"`\n\n\t// Path to the private key file.\n\tKey string `json:\"key\"`\n\n\t// The format of the cert and key. Can be \"pem\". Default: \"pem\"\n\tFormat string `json:\"format,omitempty\"`\n\n\t// Arbitrary values to associate with this certificate.\n\t// Can be useful when you want to select a particular\n\t// certificate when there may be multiple valid candidates.\n\tTags []string `json:\"tags,omitempty\"`\n}\n\n// LoadCertificates returns the certificates to be loaded by fl.\nfunc (fl FileLoader) LoadCertificates() ([]Certificate, error) {\n\tcerts := make([]Certificate, 0, len(fl))\n\tfor _, pair := range fl {\n\t\tcertData, err := os.ReadFile(pair.Certificate)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tkeyData, err := os.ReadFile(pair.Key)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tvar cert tls.Certificate\n\t\tswitch pair.Format {\n\t\tcase \"\":\n\t\t\tfallthrough\n\n\t\tcase \"pem\":\n\t\t\t// if the start of the key file looks like an encrypted private key,\n\t\t\t// reject it with a helpful error message\n\t\t\tif strings.Contains(string(keyData[:40]), \"ENCRYPTED\") {\n\t\t\t\treturn nil, fmt.Errorf(\"encrypted private keys are not supported; please decrypt the key first\")\n\t\t\t}\n\n\t\t\tcert, err = tls.X509KeyPair(certData, keyData)\n\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unrecognized certificate/key encoding format: %s\", pair.Format)\n\t\t}\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tcerts = append(certs, Certificate{Certificate: cert, Tags: pair.Tags})\n\t}\n\treturn certs, nil\n}\n\n// Interface guard\nvar (\n\t_ CertificateLoader = (FileLoader)(nil)\n\t_ caddy.Provisioner = (FileLoader)(nil)\n)\n",
    "source_file": "modules/caddytls/fileloader.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddytls\n\nimport (\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"os\"\n\t\"reflect\"\n\n\t\"github.com/caddyserver/certmagic\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddypki\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(InlineCAPool{})\n\tcaddy.RegisterModule(FileCAPool{})\n\tcaddy.RegisterModule(PKIRootCAPool{})\n\tcaddy.RegisterModule(PKIIntermediateCAPool{})\n\tcaddy.RegisterModule(StoragePool{})\n\tcaddy.RegisterModule(HTTPCertPool{})\n}\n\n// The interface to be implemented by all guest modules part of\n// the namespace 'tls.ca_pool.source.'\ntype CA interface {\n\tCertPool() *x509.CertPool\n}\n\n// InlineCAPool is a certificate authority pool provider coming from\n// a DER-encoded certificates in the config\ntype InlineCAPool struct {\n\t// A list of base64 DER-encoded CA certificates\n\t// against which to validate client certificates.\n\t// Client certs which are not signed by any of\n\t// these CAs will be rejected.\n\tTrustedCACerts []string `json:\"trusted_ca_certs,omitempty\"`\n\n\tpool *x509.CertPool\n}\n\n// CaddyModule implements caddy.Module.\nfunc (icp InlineCAPool) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID: \"tls.ca_pool.source.inline\",\n\t\tNew: func() caddy.Module {\n\t\t\treturn new(InlineCAPool)\n\t\t},\n\t}\n}\n\n// Provision implements caddy.Provisioner.\nfunc (icp *InlineCAPool) Provision(ctx caddy.Context) error {\n\tcaPool := x509.NewCertPool()\n\tfor i, clientCAString := range icp.TrustedCACerts {\n\t\tclientCA, err := decodeBase64DERCert(clientCAString)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"parsing certificate at index %d: %v\", i, err)\n\t\t}\n\t\tcaPool.AddCert(clientCA)\n\t}\n\ticp.pool = caPool\n\n\treturn nil\n}\n\n// Syntax:\n//\n//\ttrust_pool inline {\n//\t\ttrust_der <base64_der_cert>...\n//\t}\n//\n// The 'trust_der' directive can be specified multiple times.\nfunc (icp *InlineCAPool) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume module name\n\tif d.CountRemainingArgs() > 0 {\n\t\treturn d.ArgErr()\n\t}\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"trust_der\":\n\t\t\ticp.TrustedCACerts = append(icp.TrustedCACerts, d.RemainingArgs()...)\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized directive: %s\", d.Val())\n\t\t}\n\t}\n\tif len(icp.TrustedCACerts) == 0 {\n\t\treturn d.Err(\"no certificates specified\")\n\t}\n\treturn nil\n}\n\n// CertPool implements CA.\nfunc (icp InlineCAPool) CertPool() *x509.CertPool {\n\treturn icp.pool\n}\n\n// FileCAPool generates trusted root certificates pool from the designated DER and PEM file\ntype FileCAPool struct {\n\t// TrustedCACertPEMFiles is a list of PEM file names\n\t// from which to load certificates of trusted CAs.\n\t// Client certificates which are not signed by any of\n\t// these CA certificates will be rejected.\n\tTrustedCACertPEMFiles []string `json:\"pem_files,omitempty\"`\n\n\tpool *x509.CertPool\n}\n\n// CaddyModule implements caddy.Module.\nfunc (FileCAPool) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID: \"tls.ca_pool.source.file\",\n\t\tNew: func() caddy.Module {\n\t\t\treturn new(FileCAPool)\n\t\t},\n\t}\n}\n\n// Loads and decodes the DER and pem files to generate the certificate pool\nfunc (f *FileCAPool) Provision(ctx caddy.Context) error {\n\tcaPool := x509.NewCertPool()\n\tfor _, pemFile := range f.TrustedCACertPEMFiles {\n\t\tpemContents, err := os.ReadFile(pemFile)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"reading %s: %v\", pemFile, err)\n\t\t}\n\t\tcaPool.AppendCertsFromPEM(pemContents)\n\t}\n\tf.pool = caPool\n\treturn nil\n}\n\n// Syntax:\n//\n//\ttrust_pool file [<pem_file>...] {\n//\t\tpem_file <pem_file>...\n//\t}\n//\n// The 'pem_file' directive can be specified multiple times.\nfunc (fcap *FileCAPool) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume module name\n\tfcap.TrustedCACertPEMFiles = append(fcap.TrustedCACertPEMFiles, d.RemainingArgs()...)\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"pem_file\":\n\t\t\tfcap.TrustedCACertPEMFiles = append(fcap.TrustedCACertPEMFiles, d.RemainingArgs()...)\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized directive: %s\", d.Val())\n\t\t}\n\t}\n\tif len(fcap.TrustedCACertPEMFiles) == 0 {\n\t\treturn d.Err(\"no certificates specified\")\n\t}\n\treturn nil\n}\n\nfunc (f FileCAPool) CertPool() *x509.CertPool {\n\treturn f.pool\n}\n\n// PKIRootCAPool extracts the trusted root certificates from Caddy's native 'pki' app\ntype PKIRootCAPool struct {\n\t// List of the Authority names that are configured in the `pki` app whose root certificates are trusted\n\tAuthority []string `json:\"authority,omitempty\"`\n\n\tca   []*caddypki.CA\n\tpool *x509.CertPool\n}\n\n// CaddyModule implements caddy.Module.\nfunc (PKIRootCAPool) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID: \"tls.ca_pool.source.pki_root\",\n\t\tNew: func() caddy.Module {\n\t\t\treturn new(PKIRootCAPool)\n\t\t},\n\t}\n}\n\n// Loads the PKI app and load the root certificates into the certificate pool\nfunc (p *PKIRootCAPool) Provision(ctx caddy.Context) error {\n\tpkiApp, err := ctx.AppIfConfigured(\"pki\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"pki_root CA pool requires that a PKI app is configured: %v\", err)\n\t}\n\tpki := pkiApp.(*caddypki.PKI)\n\tfor _, caID := range p.Authority {\n\t\tc, err := pki.GetCA(ctx, caID)\n\t\tif err != nil || c == nil {\n\t\t\treturn fmt.Errorf(\"getting CA %s: %v\", caID, err)\n\t\t}\n\t\tp.ca = append(p.ca, c)\n\t}\n\n\tcaPool := x509.NewCertPool()\n\tfor _, ca := range p.ca {\n\t\tcaPool.AddCert(ca.RootCertificate())\n\t}\n\tp.pool = caPool\n\n\treturn nil\n}\n\n// Syntax:\n//\n//\ttrust_pool pki_root [<ca_name>...] {\n//\t\tauthority <ca_name>...\n//\t}\n//\n// The 'authority' directive can be specified multiple times.\nfunc (pkir *PKIRootCAPool) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume module name\n\tpkir.Authority = append(pkir.Authority, d.RemainingArgs()...)\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"authority\":\n\t\t\tpkir.Authority = append(pkir.Authority, d.RemainingArgs()...)\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized directive: %s\", d.Val())\n\t\t}\n\t}\n\tif len(pkir.Authority) == 0 {\n\t\treturn d.Err(\"no authorities specified\")\n\t}\n\treturn nil\n}\n\n// return the certificate pool generated with root certificates from the PKI app\nfunc (p PKIRootCAPool) CertPool() *x509.CertPool {\n\treturn p.pool\n}\n\n// PKIIntermediateCAPool extracts the trusted intermediate certificates from Caddy's native 'pki' app\ntype PKIIntermediateCAPool struct {\n\t// List of the Authority names that are configured in the `pki` app whose intermediate certificates are trusted\n\tAuthority []string `json:\"authority,omitempty\"`\n\n\tca   []*caddypki.CA\n\tpool *x509.CertPool\n}\n\n// CaddyModule implements caddy.Module.\nfunc (PKIIntermediateCAPool) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID: \"tls.ca_pool.source.pki_intermediate\",\n\t\tNew: func() caddy.Module {\n\t\t\treturn new(PKIIntermediateCAPool)\n\t\t},\n\t}\n}\n\n// Loads the PKI app and load the intermediate certificates into the certificate pool\nfunc (p *PKIIntermediateCAPool) Provision(ctx caddy.Context) error {\n\tpkiApp, err := ctx.AppIfConfigured(\"pki\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"pki_intermediate CA pool requires that a PKI app is configured: %v\", err)\n\t}\n\tpki := pkiApp.(*caddypki.PKI)\n\tfor _, caID := range p.Authority {\n\t\tc, err := pki.GetCA(ctx, caID)\n\t\tif err != nil || c == nil {\n\t\t\treturn fmt.Errorf(\"getting CA %s: %v\", caID, err)\n\t\t}\n\t\tp.ca = append(p.ca, c)\n\t}\n\n\tcaPool := x509.NewCertPool()\n\tfor _, ca := range p.ca {\n\t\tcaPool.AddCert(ca.IntermediateCertificate())\n\t}\n\tp.pool = caPool\n\treturn nil\n}\n\n// Syntax:\n//\n//\ttrust_pool pki_intermediate [<ca_name>...] {\n//\t\tauthority <ca_name>...\n//\t}\n//\n// The 'authority' directive can be specified multiple times.\nfunc (pic *PKIIntermediateCAPool) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume module name\n\tpic.Authority = append(pic.Authority, d.RemainingArgs()...)\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"authority\":\n\t\t\tpic.Authority = append(pic.Authority, d.RemainingArgs()...)\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized directive: %s\", d.Val())\n\t\t}\n\t}\n\tif len(pic.Authority) == 0 {\n\t\treturn d.Err(\"no authorities specified\")\n\t}\n\treturn nil\n}\n\n// return the certificate pool generated with intermediate certificates from the PKI app\nfunc (p PKIIntermediateCAPool) CertPool() *x509.CertPool {\n\treturn p.pool\n}\n\n// StoragePool extracts the trusted certificates root from Caddy storage\ntype StoragePool struct {\n\t// The storage module where the trusted root certificates are stored. Absent\n\t// explicit storage implies the use of Caddy default storage.\n\tStorageRaw json.RawMessage `json:\"storage,omitempty\" caddy:\"namespace=caddy.storage inline_key=module\"`\n\n\t// The storage key/index to the location of the certificates\n\tPEMKeys []string `json:\"pem_keys,omitempty\"`\n\n\tstorage certmagic.Storage\n\tpool    *x509.CertPool\n}\n\n// CaddyModule implements caddy.Module.\nfunc (StoragePool) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID: \"tls.ca_pool.source.storage\",\n\t\tNew: func() caddy.Module {\n\t\t\treturn new(StoragePool)\n\t\t},\n\t}\n}\n\n// Provision implements caddy.Provisioner.\nfunc (ca *StoragePool) Provision(ctx caddy.Context) error {\n\tif ca.StorageRaw != nil {\n\t\tval, err := ctx.LoadModule(ca, \"StorageRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading storage module: %v\", err)\n\t\t}\n\t\tcmStorage, err := val.(caddy.StorageConverter).CertMagicStorage()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"creating storage configuration: %v\", err)\n\t\t}\n\t\tca.storage = cmStorage\n\t}\n\tif ca.storage == nil {\n\t\tca.storage = ctx.Storage()\n\t}\n\tif len(ca.PEMKeys) == 0 {\n\t\treturn fmt.Errorf(\"no PEM keys specified\")\n\t}\n\tcaPool := x509.NewCertPool()\n\tfor _, caID := range ca.PEMKeys {\n\t\tbs, err := ca.storage.Load(ctx, caID)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error loading cert '%s' from storage: %s\", caID, err)\n\t\t}\n\t\tif !caPool.AppendCertsFromPEM(bs) {\n\t\t\treturn fmt.Errorf(\"failed to add certificate '%s' to pool\", caID)\n\t\t}\n\t}\n\tca.pool = caPool\n\n\treturn nil\n}\n\n// Syntax:\n//\n//\ttrust_pool storage [<storage_keys>...] {\n//\t\tstorage <storage_module>\n//\t\tkeys\t<storage_keys>...\n//\t}\n//\n// The 'keys' directive can be specified multiple times.\n// The'storage' directive is optional and defaults to the default storage module.\nfunc (sp *StoragePool) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume module name\n\tsp.PEMKeys = append(sp.PEMKeys, d.RemainingArgs()...)\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"storage\":\n\t\t\tif sp.StorageRaw != nil {\n\t\t\t\treturn d.Err(\"storage module already set\")\n\t\t\t}\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tmodStem := d.Val()\n\t\t\tmodID := \"caddy.storage.\" + modStem\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tstorage, ok := unm.(caddy.StorageConverter)\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"module %s is not a caddy.StorageConverter\", modID)\n\t\t\t}\n\t\t\tsp.StorageRaw = caddyconfig.JSONModuleObject(storage, \"module\", modStem, nil)\n\t\tcase \"keys\":\n\t\t\tsp.PEMKeys = append(sp.PEMKeys, d.RemainingArgs()...)\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized directive: %s\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (p StoragePool) CertPool() *x509.CertPool {\n\treturn p.pool\n}\n\n// TLSConfig holds configuration related to the TLS configuration for the\n// transport/client.\n// copied from with minor modifications: modules/caddyhttp/reverseproxy/httptransport.go\ntype TLSConfig struct {\n\t// Provides the guest module that provides the trusted certificate authority (CA) certificates\n\tCARaw json.RawMessage `json:\"ca,omitempty\" caddy:\"namespace=tls.ca_pool.source inline_key=provider\"`\n\n\t// If true, TLS verification of server certificates will be disabled.\n\t// This is insecure and may be removed in the future. Do not use this\n\t// option except in testing or local development environments.\n\tInsecureSkipVerify bool `json:\"insecure_skip_verify,omitempty\"`\n\n\t// The duration to allow a TLS handshake to a server. Default: No timeout.\n\tHandshakeTimeout caddy.Duration `json:\"handshake_timeout,omitempty\"`\n\n\t// The server name used when verifying the certificate received in the TLS\n\t// handshake. By default, this will use the upstream address' host part.\n\t// You only need to override this if your upstream address does not match the\n\t// certificate the upstream is likely to use. For example if the upstream\n\t// address is an IP address, then you would need to configure this to the\n\t// hostname being served by the upstream server. Currently, this does not\n\t// support placeholders because the TLS config is not provisioned on each\n\t// connection, so a static value must be used.\n\tServerName string `json:\"server_name,omitempty\"`\n\n\t// TLS renegotiation level. TLS renegotiation is the act of performing\n\t// subsequent handshakes on a connection after the first.\n\t// The level can be:\n\t//  - \"never\": (the default) disables renegotiation.\n\t//  - \"once\": allows a remote server to request renegotiation once per connection.\n\t//  - \"freely\": allows a remote server to repeatedly request renegotiation.\n\tRenegotiation string `json:\"renegotiation,omitempty\"`\n}\n\nfunc (t *TLSConfig) unmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"ca\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tmodStem := d.Val()\n\t\t\tmodID := \"tls.ca_pool.source.\" + modStem\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tca, ok := unm.(CA)\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"module %s is not a caddytls.CA\", modID)\n\t\t\t}\n\t\t\tt.CARaw = caddyconfig.JSONModuleObject(ca, \"provider\", modStem, nil)\n\t\tcase \"insecure_skip_verify\":\n\t\t\tt.InsecureSkipVerify = true\n\t\tcase \"handshake_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tt.HandshakeTimeout = caddy.Duration(dur)\n\t\tcase \"server_name\":\n\t\t\tif !d.Args(&t.ServerName) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\tcase \"renegotiation\":\n\t\t\tif !d.Args(&t.Renegotiation) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tswitch t.Renegotiation {\n\t\t\tcase \"never\", \"once\", \"freely\":\n\t\t\t\tcontinue\n\t\t\tdefault:\n\t\t\t\tt.Renegotiation = \"\"\n\t\t\t\treturn d.Errf(\"unrecognized renegotiation level: %s\", t.Renegotiation)\n\t\t\t}\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized directive: %s\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\n// MakeTLSClientConfig returns a tls.Config usable by a client to a backend.\n// If there is no custom TLS configuration, a nil config may be returned.\n// copied from with minor modifications: modules/caddyhttp/reverseproxy/httptransport.go\nfunc (t *TLSConfig) makeTLSClientConfig(ctx caddy.Context) (*tls.Config, error) {\n\trepl := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif repl == nil {\n\t\trepl = caddy.NewReplacer()\n\t}\n\tcfg := new(tls.Config)\n\n\tif t.CARaw != nil {\n\t\tcaRaw, err := ctx.LoadModule(t, \"CARaw\")\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tca := caRaw.(CA)\n\t\tcfg.RootCAs = ca.CertPool()\n\t}\n\n\t// Renegotiation\n\tswitch t.Renegotiation {\n\tcase \"never\", \"\":\n\t\tcfg.Renegotiation = tls.RenegotiateNever\n\tcase \"once\":\n\t\tcfg.Renegotiation = tls.RenegotiateOnceAsClient\n\tcase \"freely\":\n\t\tcfg.Renegotiation = tls.RenegotiateFreelyAsClient\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"invalid TLS renegotiation level: %v\", t.Renegotiation)\n\t}\n\n\t// override for the server name used verify the TLS handshake\n\tcfg.ServerName = repl.ReplaceKnown(cfg.ServerName, \"\")\n\n\t// throw all security out the window\n\tcfg.InsecureSkipVerify = t.InsecureSkipVerify\n\n\t// only return a config if it's not empty\n\tif reflect.DeepEqual(cfg, new(tls.Config)) {\n\t\treturn nil, nil\n\t}\n\n\treturn cfg, nil\n}\n\n// The HTTPCertPool fetches the trusted root certificates from HTTP(S)\n// endpoints. The TLS connection properties can be customized, including custom\n// trusted root certificate. One example usage of this module is to get the trusted\n// certificates from another Caddy instance that is running the PKI app and ACME server.\ntype HTTPCertPool struct {\n\t// the list of URLs that respond with PEM-encoded certificates to trust.\n\tEndpoints []string `json:\"endpoints,omitempty\"`\n\n\t// Customize the TLS connection knobs to used during the HTTP call\n\tTLS *TLSConfig `json:\"tls,omitempty\"`\n\n\tpool *x509.CertPool\n}\n\n// CaddyModule implements caddy.Module.\nfunc (HTTPCertPool) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID: \"tls.ca_pool.source.http\",\n\t\tNew: func() caddy.Module {\n\t\t\treturn new(HTTPCertPool)\n\t\t},\n\t}\n}\n\n// Provision implements caddy.Provisioner.\nfunc (hcp *HTTPCertPool) Provision(ctx caddy.Context) error {\n\tcaPool := x509.NewCertPool()\n\n\tcustomTransport := http.DefaultTransport.(*http.Transport).Clone()\n\tif hcp.TLS != nil {\n\t\ttlsConfig, err := hcp.TLS.makeTLSClientConfig(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tcustomTransport.TLSClientConfig = tlsConfig\n\t}\n\n\thttpClient := *http.DefaultClient\n\thttpClient.Transport = customTransport\n\n\tfor _, uri := range hcp.Endpoints {\n\t\treq, err := http.NewRequestWithContext(ctx, http.MethodGet, uri, nil)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tres, err := httpClient.Do(req)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tpembs, err := io.ReadAll(res.Body)\n\t\tres.Body.Close()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif !caPool.AppendCertsFromPEM(pembs) {\n\t\t\treturn fmt.Errorf(\"failed to add certs from URL: %s\", uri)\n\t\t}\n\t}\n\thcp.pool = caPool\n\treturn nil\n}\n\n// Syntax:\n//\n//\ttrust_pool http [<endpoints...>] {\n//\t\t\tendpoints \t<endpoints...>\n//\t\t\ttls \t\t<tls_config>\n//\t}\n//\n// tls_config:\n//\n//\t\tca <ca_module>\n//\t\tinsecure_skip_verify\n//\t\thandshake_timeout <duration>\n//\t\tserver_name <name>\n//\t\trenegotiation <never|once|freely>\n//\n//\t<ca_module> is the name of the CA module to source the trust\n//\n// certificate pool and follows the syntax of the named CA module.\nfunc (hcp *HTTPCertPool) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume module name\n\thcp.Endpoints = append(hcp.Endpoints, d.RemainingArgs()...)\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"endpoints\":\n\t\t\tif d.CountRemainingArgs() == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\thcp.Endpoints = append(hcp.Endpoints, d.RemainingArgs()...)\n\t\tcase \"tls\":\n\t\t\tif hcp.TLS != nil {\n\t\t\t\treturn d.Err(\"tls block already defined\")\n\t\t\t}\n\t\t\thcp.TLS = new(TLSConfig)\n\t\t\tif err := hcp.TLS.unmarshalCaddyfile(d); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized directive: %s\", d.Val())\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// report error if the endpoints are not valid URLs\nfunc (hcp HTTPCertPool) Validate() (err error) {\n\tfor _, u := range hcp.Endpoints {\n\t\t_, e := url.Parse(u)\n\t\tif e != nil {\n\t\t\terr = errors.Join(err, e)\n\t\t}\n\t}\n\treturn err\n}\n\n// CertPool return the certificate pool generated from the HTTP responses\nfunc (hcp HTTPCertPool) CertPool() *x509.CertPool {\n\treturn hcp.pool\n}\n\nvar (\n\t_ caddy.Module          = (*InlineCAPool)(nil)\n\t_ caddy.Provisioner     = (*InlineCAPool)(nil)\n\t_ CA                    = (*InlineCAPool)(nil)\n\t_ caddyfile.Unmarshaler = (*InlineCAPool)(nil)\n\n\t_ caddy.Module          = (*FileCAPool)(nil)\n\t_ caddy.Provisioner     = (*FileCAPool)(nil)\n\t_ CA                    = (*FileCAPool)(nil)\n\t_ caddyfile.Unmarshaler = (*FileCAPool)(nil)\n\n\t_ caddy.Module          = (*PKIRootCAPool)(nil)\n\t_ caddy.Provisioner     = (*PKIRootCAPool)(nil)\n\t_ CA                    = (*PKIRootCAPool)(nil)\n\t_ caddyfile.Unmarshaler = (*PKIRootCAPool)(nil)\n\n\t_ caddy.Module          = (*PKIIntermediateCAPool)(nil)\n\t_ caddy.Provisioner     = (*PKIIntermediateCAPool)(nil)\n\t_ CA                    = (*PKIIntermediateCAPool)(nil)\n\t_ caddyfile.Unmarshaler = (*PKIIntermediateCAPool)(nil)\n\n\t_ caddy.Module          = (*StoragePool)(nil)\n\t_ caddy.Provisioner     = (*StoragePool)(nil)\n\t_ CA                    = (*StoragePool)(nil)\n\t_ caddyfile.Unmarshaler = (*StoragePool)(nil)\n\n\t_ caddy.Module          = (*HTTPCertPool)(nil)\n\t_ caddy.Provisioner     = (*HTTPCertPool)(nil)\n\t_ caddy.Validator       = (*HTTPCertPool)(nil)\n\t_ CA                    = (*HTTPCertPool)(nil)\n\t_ caddyfile.Unmarshaler = (*HTTPCertPool)(nil)\n)\n",
    "source_file": "modules/caddytls/capools.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"crypto/rand\"\n\t\"crypto/tls\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"runtime/debug\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// SessionTicketService configures and manages TLS session tickets.\ntype SessionTicketService struct {\n\t// KeySource is the method by which Caddy produces or obtains\n\t// TLS session ticket keys (STEKs). By default, Caddy generates\n\t// them internally using a secure pseudorandom source.\n\tKeySource json.RawMessage `json:\"key_source,omitempty\" caddy:\"namespace=tls.stek inline_key=provider\"`\n\n\t// How often Caddy rotates STEKs. Default: 12h.\n\tRotationInterval caddy.Duration `json:\"rotation_interval,omitempty\"`\n\n\t// The maximum number of keys to keep in rotation. Default: 4.\n\tMaxKeys int `json:\"max_keys,omitempty\"`\n\n\t// Disables STEK rotation.\n\tDisableRotation bool `json:\"disable_rotation,omitempty\"`\n\n\t// Disables TLS session resumption by tickets.\n\tDisabled bool `json:\"disabled,omitempty\"`\n\n\tkeySource   STEKProvider\n\tconfigs     map[*tls.Config]struct{}\n\tstopChan    chan struct{}\n\tcurrentKeys [][32]byte\n\tmu          *sync.Mutex\n}\n\nfunc (s *SessionTicketService) provision(ctx caddy.Context) error {\n\ts.configs = make(map[*tls.Config]struct{})\n\ts.mu = new(sync.Mutex)\n\n\t// establish sane defaults\n\tif s.RotationInterval == 0 {\n\t\ts.RotationInterval = caddy.Duration(defaultSTEKRotationInterval)\n\t}\n\tif s.MaxKeys <= 0 {\n\t\ts.MaxKeys = defaultMaxSTEKs\n\t}\n\tif s.KeySource == nil {\n\t\ts.KeySource = json.RawMessage(`{\"provider\":\"standard\"}`)\n\t}\n\n\t// load the STEK module, which will provide keys\n\tval, err := ctx.LoadModule(s, \"KeySource\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading TLS session ticket ephemeral keys provider module: %s\", err)\n\t}\n\ts.keySource = val.(STEKProvider)\n\n\t// if session tickets or just rotation are\n\t// disabled, no need to start service\n\tif s.Disabled || s.DisableRotation {\n\t\treturn nil\n\t}\n\n\t// start the STEK module; this ensures we have\n\t// a starting key before any config needs one\n\treturn s.start()\n}\n\n// start loads the starting STEKs and spawns a goroutine\n// which loops to rotate the STEKs, which continues until\n// stop() is called. If start() was already called, this\n// is a no-op.\nfunc (s *SessionTicketService) start() error {\n\tif s.stopChan != nil {\n\t\treturn nil\n\t}\n\ts.stopChan = make(chan struct{})\n\n\t// initializing the key source gives us our\n\t// initial key(s) to start with; if successful,\n\t// we need to be sure to call Next() so that\n\t// the key source can know when it is done\n\tinitialKeys, err := s.keySource.Initialize(s)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"setting STEK module configuration: %v\", err)\n\t}\n\n\ts.mu.Lock()\n\ts.currentKeys = initialKeys\n\ts.mu.Unlock()\n\n\t// keep the keys rotated\n\tgo s.stayUpdated()\n\n\treturn nil\n}\n\n// stayUpdated is a blocking function which rotates\n// the keys whenever new ones are sent. It reads\n// from keysChan until s.stop() is called.\nfunc (s *SessionTicketService) stayUpdated() {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tlog.Printf(\"[PANIC] session ticket service: %v\\n%s\", err, debug.Stack())\n\t\t}\n\t}()\n\n\t// this call is essential when Initialize()\n\t// returns without error, because the stop\n\t// channel is the only way the key source\n\t// will know when to clean up\n\tkeysChan := s.keySource.Next(s.stopChan)\n\n\tfor {\n\t\tselect {\n\t\tcase newKeys := <-keysChan:\n\t\t\ts.mu.Lock()\n\t\t\ts.currentKeys = newKeys\n\t\t\tconfigs := s.configs\n\t\t\ts.mu.Unlock()\n\t\t\tfor cfg := range configs {\n\t\t\t\tcfg.SetSessionTicketKeys(newKeys)\n\t\t\t}\n\t\tcase <-s.stopChan:\n\t\t\treturn\n\t\t}\n\t}\n}\n\n// stop terminates the key rotation goroutine.\nfunc (s *SessionTicketService) stop() {\n\tif s.stopChan != nil {\n\t\tclose(s.stopChan)\n\t}\n}\n\n// register sets the session ticket keys on cfg\n// and keeps them updated. Any values registered\n// must be unregistered, or they will not be\n// garbage-collected. s.start() must have been\n// called first. If session tickets are disabled\n// or if ticket key rotation is disabled, this\n// function is a no-op.\nfunc (s *SessionTicketService) register(cfg *tls.Config) {\n\tif s.Disabled || s.DisableRotation {\n\t\treturn\n\t}\n\ts.mu.Lock()\n\tcfg.SetSessionTicketKeys(s.currentKeys)\n\ts.configs[cfg] = struct{}{}\n\ts.mu.Unlock()\n}\n\n// unregister stops session key management on cfg and\n// removes the internal stored reference to cfg. If\n// session tickets are disabled or if ticket key rotation\n// is disabled, this function is a no-op.\nfunc (s *SessionTicketService) unregister(cfg *tls.Config) {\n\tif s.Disabled || s.DisableRotation {\n\t\treturn\n\t}\n\ts.mu.Lock()\n\tdelete(s.configs, cfg)\n\ts.mu.Unlock()\n}\n\n// RotateSTEKs rotates the keys in keys by producing a new key and eliding\n// the oldest one. The new slice of keys is returned.\nfunc (s SessionTicketService) RotateSTEKs(keys [][32]byte) ([][32]byte, error) {\n\t// produce a new key\n\tnewKey, err := s.generateSTEK()\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"generating STEK: %v\", err)\n\t}\n\n\t// we need to prepend this new key to the list of\n\t// keys so that it is preferred, but we need to be\n\t// careful that we do not grow the slice larger\n\t// than MaxKeys, otherwise we'll be storing one\n\t// more key in memory than we expect; so be sure\n\t// that the slice does not grow beyond the limit\n\t// even for a brief period of time, since there's\n\t// no guarantee when that extra allocation will\n\t// be overwritten; this is why we first trim the\n\t// length to one less the max, THEN prepend the\n\t// new key\n\tif len(keys) >= s.MaxKeys {\n\t\tkeys[len(keys)-1] = [32]byte{} // zero-out memory of oldest key\n\t\tkeys = keys[:s.MaxKeys-1]      // trim length of slice\n\t}\n\tkeys = append([][32]byte{newKey}, keys...) // prepend new key\n\n\treturn keys, nil\n}\n\n// generateSTEK generates key material suitable for use as a\n// session ticket ephemeral key.\nfunc (s *SessionTicketService) generateSTEK() ([32]byte, error) {\n\tvar newTicketKey [32]byte\n\t_, err := io.ReadFull(rand.Reader, newTicketKey[:])\n\treturn newTicketKey, err\n}\n\n// STEKProvider is a type that can provide session ticket ephemeral\n// keys (STEKs).\ntype STEKProvider interface {\n\t// Initialize provides the STEK configuration to the STEK\n\t// module so that it can obtain and manage keys accordingly.\n\t// It returns the initial key(s) to use. Implementations can\n\t// rely on Next() being called if Initialize() returns\n\t// without error, so that it may know when it is done.\n\tInitialize(config *SessionTicketService) ([][32]byte, error)\n\n\t// Next returns the channel through which the next session\n\t// ticket keys will be transmitted until doneChan is closed.\n\t// Keys should be sent on keysChan as they are updated.\n\t// When doneChan is closed, any resources allocated in\n\t// Initialize() must be cleaned up.\n\tNext(doneChan <-chan struct{}) (keysChan <-chan [][32]byte)\n}\n\nconst (\n\tdefaultSTEKRotationInterval = 12 * time.Hour\n\tdefaultMaxSTEKs             = 4\n)\n",
    "source_file": "modules/caddytls/sessiontickets.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddytls\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"net\"\n\t\"net/netip\"\n\t\"regexp\"\n\t\"slices\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/internal\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(MatchServerName{})\n\tcaddy.RegisterModule(MatchServerNameRE{})\n\tcaddy.RegisterModule(MatchRemoteIP{})\n\tcaddy.RegisterModule(MatchLocalIP{})\n}\n\n// MatchServerName matches based on SNI. Names in\n// this list may use left-most-label wildcards,\n// similar to wildcard certificates.\ntype MatchServerName []string\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchServerName) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.handshake_match.sni\",\n\t\tNew: func() caddy.Module { return new(MatchServerName) },\n\t}\n}\n\n// Match matches hello based on SNI.\nfunc (m MatchServerName) Match(hello *tls.ClientHelloInfo) bool {\n\tvar repl *caddy.Replacer\n\t// caddytls.TestServerNameMatcher calls this function without any context\n\tif ctx := hello.Context(); ctx != nil {\n\t\t// In some situations the existing context may have no replacer\n\t\tif replAny := ctx.Value(caddy.ReplacerCtxKey); replAny != nil {\n\t\t\trepl = replAny.(*caddy.Replacer)\n\t\t}\n\t}\n\n\tif repl == nil {\n\t\trepl = caddy.NewReplacer()\n\t}\n\n\tfor _, name := range m {\n\t\trs := repl.ReplaceAll(name, \"\")\n\t\tif certmagic.MatchWildcard(hello.ServerName, rs) {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// UnmarshalCaddyfile sets up the MatchServerName from Caddyfile tokens. Syntax:\n//\n//\tsni <domains...>\nfunc (m *MatchServerName) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tfor d.Next() {\n\t\twrapper := d.Val()\n\n\t\t// At least one same-line option must be provided\n\t\tif d.CountRemainingArgs() == 0 {\n\t\t\treturn d.ArgErr()\n\t\t}\n\n\t\t*m = append(*m, d.RemainingArgs()...)\n\n\t\t// No blocks are supported\n\t\tif d.NextBlock(d.Nesting()) {\n\t\t\treturn d.Errf(\"malformed TLS handshake matcher '%s': blocks are not supported\", wrapper)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// MatchRegexp is an embeddable type for matching\n// using regular expressions. It adds placeholders\n// to the request's replacer. In fact, it is a copy of\n// caddyhttp.MatchRegexp with a local replacer prefix\n// and placeholders support in a regular expression pattern.\ntype MatchRegexp struct {\n\t// A unique name for this regular expression. Optional,\n\t// but useful to prevent overwriting captures from other\n\t// regexp matchers.\n\tName string `json:\"name,omitempty\"`\n\n\t// The regular expression to evaluate, in RE2 syntax,\n\t// which is the same general syntax used by Go, Perl,\n\t// and Python. For details, see\n\t// [Go's regexp package](https://golang.org/pkg/regexp/).\n\t// Captures are accessible via placeholders. Unnamed\n\t// capture groups are exposed as their numeric, 1-based\n\t// index, while named capture groups are available by\n\t// the capture group name.\n\tPattern string `json:\"pattern\"`\n\n\tcompiled *regexp.Regexp\n}\n\n// Provision compiles the regular expression which may include placeholders.\nfunc (mre *MatchRegexp) Provision(caddy.Context) error {\n\trepl := caddy.NewReplacer()\n\tre, err := regexp.Compile(repl.ReplaceAll(mre.Pattern, \"\"))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"compiling matcher regexp %s: %v\", mre.Pattern, err)\n\t}\n\tmre.compiled = re\n\treturn nil\n}\n\n// Validate ensures mre is set up correctly.\nfunc (mre *MatchRegexp) Validate() error {\n\tif mre.Name != \"\" && !wordRE.MatchString(mre.Name) {\n\t\treturn fmt.Errorf(\"invalid regexp name (must contain only word characters): %s\", mre.Name)\n\t}\n\treturn nil\n}\n\n// Match returns true if input matches the compiled regular\n// expression in m. It sets values on the replacer repl\n// associated with capture groups, using the given scope\n// (namespace).\nfunc (mre *MatchRegexp) Match(input string, repl *caddy.Replacer) bool {\n\tmatches := mre.compiled.FindStringSubmatch(input)\n\tif matches == nil {\n\t\treturn false\n\t}\n\n\t// save all capture groups, first by index\n\tfor i, match := range matches {\n\t\tkeySuffix := \".\" + strconv.Itoa(i)\n\t\tif mre.Name != \"\" {\n\t\t\trepl.Set(regexpPlaceholderPrefix+\".\"+mre.Name+keySuffix, match)\n\t\t}\n\t\trepl.Set(regexpPlaceholderPrefix+keySuffix, match)\n\t}\n\n\t// then by name\n\tfor i, name := range mre.compiled.SubexpNames() {\n\t\t// skip the first element (the full match), and empty names\n\t\tif i == 0 || name == \"\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tkeySuffix := \".\" + name\n\t\tif mre.Name != \"\" {\n\t\t\trepl.Set(regexpPlaceholderPrefix+\".\"+mre.Name+keySuffix, matches[i])\n\t\t}\n\t\trepl.Set(regexpPlaceholderPrefix+keySuffix, matches[i])\n\t}\n\n\treturn true\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (mre *MatchRegexp) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\t// If this is the second iteration of the loop\n\t\t// then there's more than one *_regexp matcher,\n\t\t// and we would end up overwriting the old one\n\t\tif mre.Pattern != \"\" {\n\t\t\treturn d.Err(\"regular expression can only be used once per named matcher\")\n\t\t}\n\n\t\targs := d.RemainingArgs()\n\t\tswitch len(args) {\n\t\tcase 1:\n\t\t\tmre.Pattern = args[0]\n\t\tcase 2:\n\t\t\tmre.Name = args[0]\n\t\t\tmre.Pattern = args[1]\n\t\tdefault:\n\t\t\treturn d.ArgErr()\n\t\t}\n\n\t\t// Default to the named matcher's name, if no regexp name is provided.\n\t\t// Note: it requires d.SetContext(caddyfile.MatcherNameCtxKey, value)\n\t\t// called before this unmarshalling, otherwise it wouldn't work.\n\t\tif mre.Name == \"\" {\n\t\t\tmre.Name = d.GetContextString(caddyfile.MatcherNameCtxKey)\n\t\t}\n\n\t\tif d.NextBlock(0) {\n\t\t\treturn d.Err(\"malformed regexp matcher: blocks are not supported\")\n\t\t}\n\t}\n\treturn nil\n}\n\n// MatchServerNameRE matches based on SNI using a regular expression.\ntype MatchServerNameRE struct{ MatchRegexp }\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchServerNameRE) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.handshake_match.sni_regexp\",\n\t\tNew: func() caddy.Module { return new(MatchServerNameRE) },\n\t}\n}\n\n// Match matches hello based on SNI using a regular expression.\nfunc (m MatchServerNameRE) Match(hello *tls.ClientHelloInfo) bool {\n\t// Note: caddytls.TestServerNameMatcher calls this function without any context\n\tctx := hello.Context()\n\tif ctx == nil {\n\t\t// layer4.Connection implements GetContext() to pass its context here,\n\t\t// since hello.Context() returns nil\n\t\tif mayHaveContext, ok := hello.Conn.(interface{ GetContext() context.Context }); ok {\n\t\t\tctx = mayHaveContext.GetContext()\n\t\t}\n\t}\n\n\tvar repl *caddy.Replacer\n\tif ctx != nil {\n\t\t// In some situations the existing context may have no replacer\n\t\tif replAny := ctx.Value(caddy.ReplacerCtxKey); replAny != nil {\n\t\t\trepl = replAny.(*caddy.Replacer)\n\t\t}\n\t}\n\n\tif repl == nil {\n\t\trepl = caddy.NewReplacer()\n\t}\n\n\treturn m.MatchRegexp.Match(hello.ServerName, repl)\n}\n\n// MatchRemoteIP matches based on the remote IP of the\n// connection. Specific IPs or CIDR ranges can be specified.\n//\n// Note that IPs can sometimes be spoofed, so do not rely\n// on this as a replacement for actual authentication.\ntype MatchRemoteIP struct {\n\t// The IPs or CIDR ranges to match.\n\tRanges []string `json:\"ranges,omitempty\"`\n\n\t// The IPs or CIDR ranges to *NOT* match.\n\tNotRanges []string `json:\"not_ranges,omitempty\"`\n\n\tcidrs    []netip.Prefix\n\tnotCidrs []netip.Prefix\n\tlogger   *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchRemoteIP) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.handshake_match.remote_ip\",\n\t\tNew: func() caddy.Module { return new(MatchRemoteIP) },\n\t}\n}\n\n// Provision parses m's IP ranges, either from IP or CIDR expressions.\nfunc (m *MatchRemoteIP) Provision(ctx caddy.Context) error {\n\trepl := caddy.NewReplacer()\n\tm.logger = ctx.Logger()\n\tfor _, str := range m.Ranges {\n\t\trs := repl.ReplaceAll(str, \"\")\n\t\tcidrs, err := m.parseIPRange(rs)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tm.cidrs = append(m.cidrs, cidrs...)\n\t}\n\tfor _, str := range m.NotRanges {\n\t\trs := repl.ReplaceAll(str, \"\")\n\t\tcidrs, err := m.parseIPRange(rs)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tm.notCidrs = append(m.notCidrs, cidrs...)\n\t}\n\treturn nil\n}\n\n// Match matches hello based on the connection's remote IP.\nfunc (m MatchRemoteIP) Match(hello *tls.ClientHelloInfo) bool {\n\tremoteAddr := hello.Conn.RemoteAddr().String()\n\tipStr, _, err := net.SplitHostPort(remoteAddr)\n\tif err != nil {\n\t\tipStr = remoteAddr // weird; maybe no port?\n\t}\n\tipAddr, err := netip.ParseAddr(ipStr)\n\tif err != nil {\n\t\tif c := m.logger.Check(zapcore.ErrorLevel, \"invalid client IP address\"); c != nil {\n\t\t\tc.Write(zap.String(\"ip\", ipStr))\n\t\t}\n\t\treturn false\n\t}\n\treturn (len(m.cidrs) == 0 || m.matches(ipAddr, m.cidrs)) &&\n\t\t(len(m.notCidrs) == 0 || !m.matches(ipAddr, m.notCidrs))\n}\n\nfunc (MatchRemoteIP) parseIPRange(str string) ([]netip.Prefix, error) {\n\tvar cidrs []netip.Prefix\n\tif strings.Contains(str, \"/\") {\n\t\tipNet, err := netip.ParsePrefix(str)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"parsing CIDR expression: %v\", err)\n\t\t}\n\t\tcidrs = append(cidrs, ipNet)\n\t} else {\n\t\tipAddr, err := netip.ParseAddr(str)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid IP address: '%s': %v\", str, err)\n\t\t}\n\t\tip := netip.PrefixFrom(ipAddr, ipAddr.BitLen())\n\t\tcidrs = append(cidrs, ip)\n\t}\n\treturn cidrs, nil\n}\n\nfunc (MatchRemoteIP) matches(ip netip.Addr, ranges []netip.Prefix) bool {\n\treturn slices.ContainsFunc(ranges, func(prefix netip.Prefix) bool {\n\t\treturn prefix.Contains(ip)\n\t})\n}\n\n// UnmarshalCaddyfile sets up the MatchRemoteIP from Caddyfile tokens. Syntax:\n//\n//\tremote_ip <ranges...>\n//\n// Note: IPs and CIDRs prefixed with ! symbol are treated as not_ranges\nfunc (m *MatchRemoteIP) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tfor d.Next() {\n\t\twrapper := d.Val()\n\n\t\t// At least one same-line option must be provided\n\t\tif d.CountRemainingArgs() == 0 {\n\t\t\treturn d.ArgErr()\n\t\t}\n\n\t\tfor d.NextArg() {\n\t\t\tval := d.Val()\n\t\t\tvar exclamation bool\n\t\t\tif len(val) > 1 && val[0] == '!' {\n\t\t\t\texclamation, val = true, val[1:]\n\t\t\t}\n\t\t\tranges := []string{val}\n\t\t\tif val == \"private_ranges\" {\n\t\t\t\tranges = internal.PrivateRangesCIDR()\n\t\t\t}\n\t\t\tif exclamation {\n\t\t\t\tm.NotRanges = append(m.NotRanges, ranges...)\n\t\t\t} else {\n\t\t\t\tm.Ranges = append(m.Ranges, ranges...)\n\t\t\t}\n\t\t}\n\n\t\t// No blocks are supported\n\t\tif d.NextBlock(d.Nesting()) {\n\t\t\treturn d.Errf(\"malformed TLS handshake matcher '%s': blocks are not supported\", wrapper)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// MatchLocalIP matches based on the IP address of the interface\n// receiving the connection. Specific IPs or CIDR ranges can be specified.\ntype MatchLocalIP struct {\n\t// The IPs or CIDR ranges to match.\n\tRanges []string `json:\"ranges,omitempty\"`\n\n\tcidrs  []netip.Prefix\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchLocalIP) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.handshake_match.local_ip\",\n\t\tNew: func() caddy.Module { return new(MatchLocalIP) },\n\t}\n}\n\n// Provision parses m's IP ranges, either from IP or CIDR expressions.\nfunc (m *MatchLocalIP) Provision(ctx caddy.Context) error {\n\trepl := caddy.NewReplacer()\n\tm.logger = ctx.Logger()\n\tfor _, str := range m.Ranges {\n\t\trs := repl.ReplaceAll(str, \"\")\n\t\tcidrs, err := m.parseIPRange(rs)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tm.cidrs = append(m.cidrs, cidrs...)\n\t}\n\treturn nil\n}\n\n// Match matches hello based on the connection's remote IP.\nfunc (m MatchLocalIP) Match(hello *tls.ClientHelloInfo) bool {\n\tlocalAddr := hello.Conn.LocalAddr().String()\n\tipStr, _, err := net.SplitHostPort(localAddr)\n\tif err != nil {\n\t\tipStr = localAddr // weird; maybe no port?\n\t}\n\tipAddr, err := netip.ParseAddr(ipStr)\n\tif err != nil {\n\t\tif c := m.logger.Check(zapcore.ErrorLevel, \"invalid local IP address\"); c != nil {\n\t\t\tc.Write(zap.String(\"ip\", ipStr))\n\t\t}\n\t\treturn false\n\t}\n\treturn (len(m.cidrs) == 0 || m.matches(ipAddr, m.cidrs))\n}\n\nfunc (MatchLocalIP) parseIPRange(str string) ([]netip.Prefix, error) {\n\tvar cidrs []netip.Prefix\n\tif strings.Contains(str, \"/\") {\n\t\tipNet, err := netip.ParsePrefix(str)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"parsing CIDR expression: %v\", err)\n\t\t}\n\t\tcidrs = append(cidrs, ipNet)\n\t} else {\n\t\tipAddr, err := netip.ParseAddr(str)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"invalid IP address: '%s': %v\", str, err)\n\t\t}\n\t\tip := netip.PrefixFrom(ipAddr, ipAddr.BitLen())\n\t\tcidrs = append(cidrs, ip)\n\t}\n\treturn cidrs, nil\n}\n\nfunc (MatchLocalIP) matches(ip netip.Addr, ranges []netip.Prefix) bool {\n\treturn slices.ContainsFunc(ranges, func(prefix netip.Prefix) bool {\n\t\treturn prefix.Contains(ip)\n\t})\n}\n\n// UnmarshalCaddyfile sets up the MatchLocalIP from Caddyfile tokens. Syntax:\n//\n//\tlocal_ip <ranges...>\nfunc (m *MatchLocalIP) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tfor d.Next() {\n\t\twrapper := d.Val()\n\n\t\t// At least one same-line option must be provided\n\t\tif d.CountRemainingArgs() == 0 {\n\t\t\treturn d.ArgErr()\n\t\t}\n\n\t\tfor d.NextArg() {\n\t\t\tval := d.Val()\n\t\t\tif val == \"private_ranges\" {\n\t\t\t\tm.Ranges = append(m.Ranges, internal.PrivateRangesCIDR()...)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tm.Ranges = append(m.Ranges, val)\n\t\t}\n\n\t\t// No blocks are supported\n\t\tif d.NextBlock(d.Nesting()) {\n\t\t\treturn d.Errf(\"malformed TLS handshake matcher '%s': blocks are not supported\", wrapper)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Interface guards\nvar (\n\t_ ConnectionMatcher = (*MatchLocalIP)(nil)\n\t_ ConnectionMatcher = (*MatchRemoteIP)(nil)\n\t_ ConnectionMatcher = (*MatchServerName)(nil)\n\t_ ConnectionMatcher = (*MatchServerNameRE)(nil)\n\n\t_ caddy.Provisioner = (*MatchLocalIP)(nil)\n\t_ caddy.Provisioner = (*MatchRemoteIP)(nil)\n\t_ caddy.Provisioner = (*MatchServerNameRE)(nil)\n\n\t_ caddyfile.Unmarshaler = (*MatchLocalIP)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchRemoteIP)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchServerName)(nil)\n\t_ caddyfile.Unmarshaler = (*MatchServerNameRE)(nil)\n)\n\nvar wordRE = regexp.MustCompile(`\\w+`)\n\nconst regexpPlaceholderPrefix = \"tls.regexp\"\n",
    "source_file": "modules/caddytls/matchers.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddyfs\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io/fs\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Filesystems{})\n\thttpcaddyfile.RegisterGlobalOption(\"filesystem\", parseFilesystems)\n}\n\ntype moduleEntry struct {\n\tKey           string          `json:\"name,omitempty\"`\n\tFileSystemRaw json.RawMessage `json:\"file_system,omitempty\" caddy:\"namespace=caddy.fs inline_key=backend\"`\n\tfileSystem    fs.FS\n}\n\n// Filesystems loads caddy.fs modules into the global filesystem map\ntype Filesystems struct {\n\tFilesystems []*moduleEntry `json:\"filesystems\"`\n\n\tdefers []func()\n}\n\nfunc parseFilesystems(d *caddyfile.Dispenser, existingVal any) (any, error) {\n\tp := &Filesystems{}\n\tcurrent, ok := existingVal.(*Filesystems)\n\tif ok {\n\t\tp = current\n\t}\n\tx := &moduleEntry{}\n\terr := x.UnmarshalCaddyfile(d)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tp.Filesystems = append(p.Filesystems, x)\n\treturn p, nil\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Filesystems) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"caddy.filesystems\",\n\t\tNew: func() caddy.Module { return new(Filesystems) },\n\t}\n}\n\nfunc (xs *Filesystems) Start() error { return nil }\nfunc (xs *Filesystems) Stop() error  { return nil }\n\nfunc (xs *Filesystems) Provision(ctx caddy.Context) error {\n\t// load the filesystem module\n\tfor _, f := range xs.Filesystems {\n\t\tif len(f.FileSystemRaw) > 0 {\n\t\t\tmod, err := ctx.LoadModule(f, \"FileSystemRaw\")\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading file system module: %v\", err)\n\t\t\t}\n\t\t\tf.fileSystem = mod.(fs.FS)\n\t\t}\n\t\t// register that module\n\t\tctx.Logger().Debug(\"registering fs\", zap.String(\"fs\", f.Key))\n\t\tctx.FileSystems().Register(f.Key, f.fileSystem)\n\t\t// remember to unregister the module when we are done\n\t\txs.defers = append(xs.defers, func() {\n\t\t\tctx.Logger().Debug(\"unregistering fs\", zap.String(\"fs\", f.Key))\n\t\t\tctx.FileSystems().Unregister(f.Key)\n\t\t})\n\t}\n\treturn nil\n}\n\nfunc (f *Filesystems) Cleanup() error {\n\tfor _, v := range f.defers {\n\t\tv()\n\t}\n\treturn nil\n}\n\nfunc (f *moduleEntry) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tfor d.Next() {\n\t\t// key required for now\n\t\tif !d.Args(&f.Key) {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t\t// get the module json\n\t\tif !d.NextArg() {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t\tname := d.Val()\n\t\tmodID := \"caddy.fs.\" + name\n\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tfsys, ok := unm.(fs.FS)\n\t\tif !ok {\n\t\t\treturn d.Errf(\"module %s (%T) is not a supported file system implementation (requires fs.FS)\", modID, unm)\n\t\t}\n\t\tf.FileSystemRaw = caddyconfig.JSONModuleObject(fsys, \"backend\", name, nil)\n\t}\n\treturn nil\n}\n",
    "source_file": "modules/caddyfs/filesystem.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage filestorage\n\nimport (\n\t\"github.com/caddyserver/certmagic\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(FileStorage{})\n}\n\n// FileStorage is a certmagic.Storage wrapper for certmagic.FileStorage.\ntype FileStorage struct {\n\t// The base path to the folder used for storage.\n\tRoot string `json:\"root,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (FileStorage) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"caddy.storage.file_system\",\n\t\tNew: func() caddy.Module { return new(FileStorage) },\n\t}\n}\n\n// CertMagicStorage converts s to a certmagic.Storage instance.\nfunc (s FileStorage) CertMagicStorage() (certmagic.Storage, error) {\n\treturn &certmagic.FileStorage{Path: s.Root}, nil\n}\n\n// UnmarshalCaddyfile sets up the storage module from Caddyfile tokens.\nfunc (s *FileStorage) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tif !d.Next() {\n\t\treturn d.Err(\"expected tokens\")\n\t}\n\tif d.NextArg() {\n\t\ts.Root = d.Val()\n\t}\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"root\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif s.Root != \"\" {\n\t\t\t\treturn d.Err(\"root already set\")\n\t\t\t}\n\t\t\ts.Root = d.Val()\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized parameter '%s'\", d.Val())\n\t\t}\n\t}\n\tif s.Root == \"\" {\n\t\treturn d.Err(\"missing root path (to use default, omit storage config entirely)\")\n\t}\n\treturn nil\n}\n\n// Interface guards\nvar (\n\t_ caddy.StorageConverter = (*FileStorage)(nil)\n\t_ caddyfile.Unmarshaler  = (*FileStorage)(nil)\n)\n",
    "source_file": "modules/filestorage/filestorage.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddypki\n\nimport (\n\t\"crypto/x509\"\n\t\"encoding/json\"\n\t\"encoding/pem\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"os\"\n\t\"path\"\n\n\t\"github.com/smallstep/truststore\"\n\t\"github.com/spf13/cobra\"\n\n\tcaddycmd \"github.com/caddyserver/caddy/v2/cmd\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddycmd.RegisterCommand(caddycmd.Command{\n\t\tName:  \"trust\",\n\t\tUsage: \"[--ca <id>] [--address <listen>] [--config <path> [--adapter <name>]]\",\n\t\tShort: \"Installs a CA certificate into local trust stores\",\n\t\tLong: `\nAdds a root certificate into the local trust stores.\n\nCaddy will attempt to install its root certificates into the local\ntrust stores automatically when they are first generated, but it\nmight fail if Caddy doesn't have the appropriate permissions to\nwrite to the trust store. This command is necessary to pre-install\nthe certificates before using them, if the server process runs as an\nunprivileged user (such as via systemd).\n\nBy default, this command installs the root certificate for Caddy's\ndefault CA (i.e. 'local'). You may specify the ID of another CA\nwith the --ca flag.\n\nThis command will attempt to connect to Caddy's admin API running at\n'` + caddy.DefaultAdminListen + `' to fetch the root certificate. You may\nexplicitly specify the --address, or use the --config flag to load\nthe admin address from your config, if not using the default.`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"ca\", \"\", \"\", \"The ID of the CA to trust (defaults to 'local')\")\n\t\t\tcmd.Flags().StringP(\"address\", \"\", \"\", \"Address of the administration API listener (if --config is not used)\")\n\t\t\tcmd.Flags().StringP(\"config\", \"c\", \"\", \"Configuration file (if --address is not used)\")\n\t\t\tcmd.Flags().StringP(\"adapter\", \"a\", \"\", \"Name of config adapter to apply (if --config is used)\")\n\t\t\tcmd.RunE = caddycmd.WrapCommandFuncForCobra(cmdTrust)\n\t\t},\n\t})\n\n\tcaddycmd.RegisterCommand(caddycmd.Command{\n\t\tName:  \"untrust\",\n\t\tUsage: \"[--cert <path>] | [[--ca <id>] [--address <listen>] [--config <path> [--adapter <name>]]]\",\n\t\tShort: \"Untrusts a locally-trusted CA certificate\",\n\t\tLong: `\nUntrusts a root certificate from the local trust store(s).\n\nThis command uninstalls trust; it does not necessarily delete the\nroot certificate from trust stores entirely. Thus, repeatedly\ntrusting and untrusting new certificates can fill up trust databases.\n\nThis command does not delete or modify certificate files from Caddy's\nconfigured storage.\n\nThis command can be used in one of two ways. Either by specifying\nwhich certificate to untrust by a direct path to the certificate\nfile with the --cert flag, or by fetching the root certificate for\nthe CA from the admin API (default behaviour).\n\nIf the admin API is used, then the CA defaults to 'local'. You may\nspecify the ID of another CA with the --ca flag. By default, this\nwill attempt to connect to the Caddy's admin API running at\n'` + caddy.DefaultAdminListen + `' to fetch the root certificate.\nYou may explicitly specify the --address, or use the --config flag\nto load the admin address from your config, if not using the default.`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"cert\", \"p\", \"\", \"The path to the CA certificate to untrust\")\n\t\t\tcmd.Flags().StringP(\"ca\", \"\", \"\", \"The ID of the CA to untrust (defaults to 'local')\")\n\t\t\tcmd.Flags().StringP(\"address\", \"\", \"\", \"Address of the administration API listener (if --config is not used)\")\n\t\t\tcmd.Flags().StringP(\"config\", \"c\", \"\", \"Configuration file (if --address is not used)\")\n\t\t\tcmd.Flags().StringP(\"adapter\", \"a\", \"\", \"Name of config adapter to apply (if --config is used)\")\n\t\t\tcmd.RunE = caddycmd.WrapCommandFuncForCobra(cmdUntrust)\n\t\t},\n\t})\n}\n\nfunc cmdTrust(fl caddycmd.Flags) (int, error) {\n\tcaID := fl.String(\"ca\")\n\taddrFlag := fl.String(\"address\")\n\tconfigFlag := fl.String(\"config\")\n\tconfigAdapterFlag := fl.String(\"adapter\")\n\n\t// Prepare the URI to the admin endpoint\n\tif caID == \"\" {\n\t\tcaID = DefaultCAID\n\t}\n\n\t// Determine where we're sending the request to get the CA info\n\tadminAddr, err := caddycmd.DetermineAdminAPIAddress(addrFlag, nil, configFlag, configAdapterFlag)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"couldn't determine admin API address: %v\", err)\n\t}\n\n\t// Fetch the root cert from the admin API\n\trootCert, err := rootCertFromAdmin(adminAddr, caID)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// Set up the CA struct; we only need to fill in the root\n\t// because we're only using it to make use of the installRoot()\n\t// function. Also needs a logger for warnings, and a \"cert path\"\n\t// for the root cert; since we're loading from the API and we\n\t// don't know the actual storage path via this flow, we'll just\n\t// pass through the admin API address instead.\n\tca := CA{\n\t\tlog:          caddy.Log(),\n\t\troot:         rootCert,\n\t\trootCertPath: adminAddr + path.Join(adminPKIEndpointBase, \"ca\", caID),\n\t}\n\n\t// Install the cert!\n\terr = ca.installRoot()\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\nfunc cmdUntrust(fl caddycmd.Flags) (int, error) {\n\tcertFile := fl.String(\"cert\")\n\tcaID := fl.String(\"ca\")\n\taddrFlag := fl.String(\"address\")\n\tconfigFlag := fl.String(\"config\")\n\tconfigAdapterFlag := fl.String(\"adapter\")\n\n\tif certFile != \"\" && (caID != \"\" || addrFlag != \"\" || configFlag != \"\") {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"conflicting command line arguments, cannot use --cert with other flags\")\n\t}\n\n\t// If a file was specified, try to uninstall the cert matching that file\n\tif certFile != \"\" {\n\t\t// Sanity check, make sure cert file exists first\n\t\t_, err := os.Stat(certFile)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"accessing certificate file: %v\", err)\n\t\t}\n\n\t\t// Uninstall the file!\n\t\terr = truststore.UninstallFile(certFile,\n\t\t\ttruststore.WithDebug(),\n\t\t\ttruststore.WithFirefox(),\n\t\t\ttruststore.WithJava())\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"failed to uninstall certificate file: %v\", err)\n\t\t}\n\n\t\treturn caddy.ExitCodeSuccess, nil\n\t}\n\n\t// Prepare the URI to the admin endpoint\n\tif caID == \"\" {\n\t\tcaID = DefaultCAID\n\t}\n\n\t// Determine where we're sending the request to get the CA info\n\tadminAddr, err := caddycmd.DetermineAdminAPIAddress(addrFlag, nil, configFlag, configAdapterFlag)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"couldn't determine admin API address: %v\", err)\n\t}\n\n\t// Fetch the root cert from the admin API\n\trootCert, err := rootCertFromAdmin(adminAddr, caID)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\t// Uninstall the cert!\n\terr = truststore.Uninstall(rootCert,\n\t\ttruststore.WithDebug(),\n\t\ttruststore.WithFirefox(),\n\t\ttruststore.WithJava())\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"failed to uninstall certificate file: %v\", err)\n\t}\n\n\treturn caddy.ExitCodeSuccess, nil\n}\n\n// rootCertFromAdmin makes the API request to fetch the root certificate for the named CA via admin API.\nfunc rootCertFromAdmin(adminAddr string, caID string) (*x509.Certificate, error) {\n\turi := path.Join(adminPKIEndpointBase, \"ca\", caID)\n\n\t// Make the request to fetch the CA info\n\tresp, err := caddycmd.AdminAPIRequest(adminAddr, http.MethodGet, uri, make(http.Header), nil)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"requesting CA info: %v\", err)\n\t}\n\tdefer resp.Body.Close()\n\n\t// Decode the response\n\tcaInfo := new(caInfo)\n\terr = json.NewDecoder(resp.Body).Decode(caInfo)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to decode JSON response: %v\", err)\n\t}\n\n\t// Decode the root cert\n\trootBlock, _ := pem.Decode([]byte(caInfo.RootCert))\n\tif rootBlock == nil {\n\t\treturn nil, fmt.Errorf(\"failed to decode root certificate: %v\", err)\n\t}\n\trootCert, err := x509.ParseCertificate(rootBlock.Bytes)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"failed to parse root certificate: %v\", err)\n\t}\n\n\treturn rootCert, nil\n}\n",
    "source_file": "modules/caddypki/command.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddypki\n\nimport (\n\t\"crypto\"\n\t\"crypto/x509\"\n\t\"time\"\n\n\t\"go.step.sm/crypto/keyutil\"\n\t\"go.step.sm/crypto/x509util\"\n)\n\nfunc generateRoot(commonName string) (*x509.Certificate, crypto.Signer, error) {\n\ttemplate, signer, err := newCert(commonName, x509util.DefaultRootTemplate, defaultRootLifetime)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\troot, err := x509util.CreateCertificate(template, template, signer.Public(), signer)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\treturn root, signer, nil\n}\n\nfunc generateIntermediate(commonName string, rootCrt *x509.Certificate, rootKey crypto.Signer, lifetime time.Duration) (*x509.Certificate, crypto.Signer, error) {\n\ttemplate, signer, err := newCert(commonName, x509util.DefaultIntermediateTemplate, lifetime)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tintermediate, err := x509util.CreateCertificate(template, rootCrt, signer.Public(), rootKey)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\treturn intermediate, signer, nil\n}\n\nfunc newCert(commonName, templateName string, lifetime time.Duration) (cert *x509.Certificate, signer crypto.Signer, err error) {\n\tsigner, err = keyutil.GenerateDefaultSigner()\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\tcsr, err := x509util.CreateCertificateRequest(commonName, []string{}, signer)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\ttemplate, err := x509util.NewCertificate(csr, x509util.WithTemplate(templateName, x509util.CreateTemplateData(commonName, []string{})))\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tcert = template.GetCertificate()\n\tcert.NotBefore = time.Now().Truncate(time.Second)\n\tcert.NotAfter = cert.NotBefore.Add(lifetime)\n\treturn cert, signer, nil\n}\n",
    "source_file": "modules/caddypki/certificates.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddypki\n\nimport (\n\t\"crypto/x509\"\n\t\"fmt\"\n\t\"log\"\n\t\"runtime/debug\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n)\n\nfunc (p *PKI) maintenance() {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tlog.Printf(\"[PANIC] PKI maintenance: %v\\n%s\", err, debug.Stack())\n\t\t}\n\t}()\n\n\tticker := time.NewTicker(10 * time.Minute) // TODO: make configurable\n\tdefer ticker.Stop()\n\n\tfor {\n\t\tselect {\n\t\tcase <-ticker.C:\n\t\t\tp.renewCerts()\n\t\tcase <-p.ctx.Done():\n\t\t\treturn\n\t\t}\n\t}\n}\n\nfunc (p *PKI) renewCerts() {\n\tfor _, ca := range p.CAs {\n\t\terr := p.renewCertsForCA(ca)\n\t\tif err != nil {\n\t\t\tp.log.Error(\"renewing intermediate certificates\",\n\t\t\t\tzap.Error(err),\n\t\t\t\tzap.String(\"ca\", ca.ID))\n\t\t}\n\t}\n}\n\nfunc (p *PKI) renewCertsForCA(ca *CA) error {\n\tca.mu.Lock()\n\tdefer ca.mu.Unlock()\n\n\tlog := p.log.With(zap.String(\"ca\", ca.ID))\n\n\t// only maintain the root if it's not manually provided in the config\n\tif ca.Root == nil {\n\t\tif needsRenewal(ca.root) {\n\t\t\t// TODO: implement root renewal (use same key)\n\t\t\tlog.Warn(\"root certificate expiring soon (FIXME: ROOT RENEWAL NOT YET IMPLEMENTED)\",\n\t\t\t\tzap.Duration(\"time_remaining\", time.Until(ca.inter.NotAfter)),\n\t\t\t)\n\t\t}\n\t}\n\n\t// only maintain the intermediate if it's not manually provided in the config\n\tif ca.Intermediate == nil {\n\t\tif needsRenewal(ca.inter) {\n\t\t\tlog.Info(\"intermediate expires soon; renewing\",\n\t\t\t\tzap.Duration(\"time_remaining\", time.Until(ca.inter.NotAfter)),\n\t\t\t)\n\n\t\t\trootCert, rootKey, err := ca.loadOrGenRoot()\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"loading root key: %v\", err)\n\t\t\t}\n\t\t\tinterCert, interKey, err := ca.genIntermediate(rootCert, rootKey)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"generating new certificate: %v\", err)\n\t\t\t}\n\t\t\tca.inter, ca.interKey = interCert, interKey\n\n\t\t\tlog.Info(\"renewed intermediate\",\n\t\t\t\tzap.Time(\"new_expiration\", ca.inter.NotAfter),\n\t\t\t)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc needsRenewal(cert *x509.Certificate) bool {\n\tlifetime := cert.NotAfter.Sub(cert.NotBefore)\n\trenewalWindow := time.Duration(float64(lifetime) * renewalWindowRatio)\n\trenewalWindowStart := cert.NotAfter.Add(-renewalWindow)\n\treturn time.Now().After(renewalWindowStart)\n}\n\nconst renewalWindowRatio = 0.2 // TODO: make configurable\n",
    "source_file": "modules/caddypki/maintain.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddypki\n\nimport (\n\t\"bytes\"\n\t\"crypto\"\n\t\"crypto/x509\"\n\t\"encoding/pem\"\n\t\"fmt\"\n\t\"os\"\n\n\t\"github.com/caddyserver/certmagic\"\n)\n\nfunc pemDecodeSingleCert(pemDER []byte) (*x509.Certificate, error) {\n\tpemBlock, remaining := pem.Decode(pemDER)\n\tif pemBlock == nil {\n\t\treturn nil, fmt.Errorf(\"no PEM block found\")\n\t}\n\tif len(remaining) > 0 {\n\t\treturn nil, fmt.Errorf(\"input contained more than a single PEM block\")\n\t}\n\tif pemBlock.Type != \"CERTIFICATE\" {\n\t\treturn nil, fmt.Errorf(\"expected PEM block type to be CERTIFICATE, but got '%s'\", pemBlock.Type)\n\t}\n\treturn x509.ParseCertificate(pemBlock.Bytes)\n}\n\nfunc pemEncodeCert(der []byte) ([]byte, error) {\n\treturn pemEncode(\"CERTIFICATE\", der)\n}\n\nfunc pemEncode(blockType string, b []byte) ([]byte, error) {\n\tvar buf bytes.Buffer\n\terr := pem.Encode(&buf, &pem.Block{Type: blockType, Bytes: b})\n\treturn buf.Bytes(), err\n}\n\nfunc trusted(cert *x509.Certificate) bool {\n\tchains, err := cert.Verify(x509.VerifyOptions{})\n\treturn len(chains) > 0 && err == nil\n}\n\n// KeyPair represents a public-private key pair, where the\n// public key is also called a certificate.\ntype KeyPair struct {\n\t// The certificate. By default, this should be the path to\n\t// a PEM file unless format is something else.\n\tCertificate string `json:\"certificate,omitempty\"`\n\n\t// The private key. By default, this should be the path to\n\t// a PEM file unless format is something else.\n\tPrivateKey string `json:\"private_key,omitempty\"`\n\n\t// The format in which the certificate and private\n\t// key are provided. Default: pem_file\n\tFormat string `json:\"format,omitempty\"`\n}\n\n// Load loads the certificate and key.\nfunc (kp KeyPair) Load() (*x509.Certificate, crypto.Signer, error) {\n\tswitch kp.Format {\n\tcase \"\", \"pem_file\":\n\t\tcertData, err := os.ReadFile(kp.Certificate)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\t\tcert, err := pemDecodeSingleCert(certData)\n\t\tif err != nil {\n\t\t\treturn nil, nil, err\n\t\t}\n\n\t\tvar key crypto.Signer\n\t\tif kp.PrivateKey != \"\" {\n\t\t\tkeyData, err := os.ReadFile(kp.PrivateKey)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t\tkey, err = certmagic.PEMDecodePrivateKey(keyData)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, nil, err\n\t\t\t}\n\t\t}\n\n\t\treturn cert, key, nil\n\n\tdefault:\n\t\treturn nil, nil, fmt.Errorf(\"unsupported format: %s\", kp.Format)\n\t}\n}\n",
    "source_file": "modules/caddypki/crypto.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2020 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddypki\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(adminAPI{})\n}\n\n// adminAPI is a module that serves PKI endpoints to retrieve\n// information about the CAs being managed by Caddy.\ntype adminAPI struct {\n\tctx    caddy.Context\n\tlog    *zap.Logger\n\tpkiApp *PKI\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (adminAPI) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"admin.api.pki\",\n\t\tNew: func() caddy.Module { return new(adminAPI) },\n\t}\n}\n\n// Provision sets up the adminAPI module.\nfunc (a *adminAPI) Provision(ctx caddy.Context) error {\n\ta.ctx = ctx\n\ta.log = ctx.Logger(a) // TODO: passing in 'a' is a hack until the admin API is officially extensible (see #5032)\n\n\t// Avoid initializing PKI if it wasn't configured.\n\t// We intentionally ignore the error since it's not\n\t// fatal if the PKI app is not explicitly configured.\n\tpkiApp, err := ctx.AppIfConfigured(\"pki\")\n\tif err == nil {\n\t\ta.pkiApp = pkiApp.(*PKI)\n\t}\n\n\treturn nil\n}\n\n// Routes returns the admin routes for the PKI app.\nfunc (a *adminAPI) Routes() []caddy.AdminRoute {\n\treturn []caddy.AdminRoute{\n\t\t{\n\t\t\tPattern: adminPKIEndpointBase,\n\t\t\tHandler: caddy.AdminHandlerFunc(a.handleAPIEndpoints),\n\t\t},\n\t}\n}\n\n// handleAPIEndpoints routes API requests within adminPKIEndpointBase.\nfunc (a *adminAPI) handleAPIEndpoints(w http.ResponseWriter, r *http.Request) error {\n\turi := strings.TrimPrefix(r.URL.Path, \"/pki/\")\n\tparts := strings.Split(uri, \"/\")\n\tswitch {\n\tcase len(parts) == 2 && parts[0] == \"ca\" && parts[1] != \"\":\n\t\treturn a.handleCAInfo(w, r)\n\tcase len(parts) == 3 && parts[0] == \"ca\" && parts[1] != \"\" && parts[2] == \"certificates\":\n\t\treturn a.handleCACerts(w, r)\n\t}\n\treturn caddy.APIError{\n\t\tHTTPStatus: http.StatusNotFound,\n\t\tErr:        fmt.Errorf(\"resource not found: %v\", r.URL.Path),\n\t}\n}\n\n// handleCAInfo returns information about a particular\n// CA by its ID. If the CA ID is the default, then the CA will be\n// provisioned if it has not already been. Other CA IDs will return an\n// error if they have not been previously provisioned.\nfunc (a *adminAPI) handleCAInfo(w http.ResponseWriter, r *http.Request) error {\n\tif r.Method != http.MethodGet {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusMethodNotAllowed,\n\t\t\tErr:        fmt.Errorf(\"method not allowed: %v\", r.Method),\n\t\t}\n\t}\n\n\tca, err := a.getCAFromAPIRequestPath(r)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\trootCert, interCert, err := rootAndIntermediatePEM(ca)\n\tif err != nil {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusInternalServerError,\n\t\t\tErr:        fmt.Errorf(\"failed to get root and intermediate cert for CA %s: %v\", ca.ID, err),\n\t\t}\n\t}\n\n\trepl := ca.newReplacer()\n\n\tresponse := caInfo{\n\t\tID:               ca.ID,\n\t\tName:             ca.Name,\n\t\tRootCN:           repl.ReplaceAll(ca.RootCommonName, \"\"),\n\t\tIntermediateCN:   repl.ReplaceAll(ca.IntermediateCommonName, \"\"),\n\t\tRootCert:         string(rootCert),\n\t\tIntermediateCert: string(interCert),\n\t}\n\n\tencoded, err := json.Marshal(response)\n\tif err != nil {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusInternalServerError,\n\t\t\tErr:        err,\n\t\t}\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\t_, _ = w.Write(encoded)\n\n\treturn nil\n}\n\n// handleCACerts returns the certificate chain for a particular\n// CA by its ID. If the CA ID is the default, then the CA will be\n// provisioned if it has not already been. Other CA IDs will return an\n// error if they have not been previously provisioned.\nfunc (a *adminAPI) handleCACerts(w http.ResponseWriter, r *http.Request) error {\n\tif r.Method != http.MethodGet {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusMethodNotAllowed,\n\t\t\tErr:        fmt.Errorf(\"method not allowed: %v\", r.Method),\n\t\t}\n\t}\n\n\tca, err := a.getCAFromAPIRequestPath(r)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\trootCert, interCert, err := rootAndIntermediatePEM(ca)\n\tif err != nil {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusInternalServerError,\n\t\t\tErr:        fmt.Errorf(\"failed to get root and intermediate cert for CA %s: %v\", ca.ID, err),\n\t\t}\n\t}\n\n\tw.Header().Set(\"Content-Type\", \"application/pem-certificate-chain\")\n\t_, err = w.Write(interCert)\n\tif err == nil {\n\t\t_, _ = w.Write(rootCert)\n\t}\n\n\treturn nil\n}\n\nfunc (a *adminAPI) getCAFromAPIRequestPath(r *http.Request) (*CA, error) {\n\t// Grab the CA ID from the request path, it should be the 4th segment (/pki/ca/<ca>)\n\tid := strings.Split(r.URL.Path, \"/\")[3]\n\tif id == \"\" {\n\t\treturn nil, caddy.APIError{\n\t\t\tHTTPStatus: http.StatusBadRequest,\n\t\t\tErr:        fmt.Errorf(\"missing CA in path\"),\n\t\t}\n\t}\n\n\t// Find the CA by ID, if PKI is configured\n\tvar ca *CA\n\tvar ok bool\n\tif a.pkiApp != nil {\n\t\tca, ok = a.pkiApp.CAs[id]\n\t}\n\n\t// If we didn't find the CA, and PKI is not configured\n\t// then we'll either error out if the CA ID is not the\n\t// default. If the CA ID is the default, then we'll\n\t// provision it, because the user probably aims to\n\t// change their config to enable PKI immediately after\n\t// if they actually requested the local CA ID.\n\tif !ok {\n\t\tif id != DefaultCAID {\n\t\t\treturn nil, caddy.APIError{\n\t\t\t\tHTTPStatus: http.StatusNotFound,\n\t\t\t\tErr:        fmt.Errorf(\"no certificate authority configured with id: %s\", id),\n\t\t\t}\n\t\t}\n\n\t\t// Provision the default CA, which generates and stores a root\n\t\t// certificate in storage, if one doesn't already exist.\n\t\tca = new(CA)\n\t\terr := ca.Provision(a.ctx, id, a.log)\n\t\tif err != nil {\n\t\t\treturn nil, caddy.APIError{\n\t\t\t\tHTTPStatus: http.StatusInternalServerError,\n\t\t\t\tErr:        fmt.Errorf(\"failed to provision CA %s, %w\", id, err),\n\t\t\t}\n\t\t}\n\t}\n\n\treturn ca, nil\n}\n\nfunc rootAndIntermediatePEM(ca *CA) (root, inter []byte, err error) {\n\troot, err = pemEncodeCert(ca.RootCertificate().Raw)\n\tif err != nil {\n\t\treturn\n\t}\n\tinter, err = pemEncodeCert(ca.IntermediateCertificate().Raw)\n\tif err != nil {\n\t\treturn\n\t}\n\treturn\n}\n\n// caInfo is the response structure for the CA info API endpoint.\ntype caInfo struct {\n\tID               string `json:\"id\"`\n\tName             string `json:\"name\"`\n\tRootCN           string `json:\"root_common_name\"`\n\tIntermediateCN   string `json:\"intermediate_common_name\"`\n\tRootCert         string `json:\"root_certificate\"`\n\tIntermediateCert string `json:\"intermediate_certificate\"`\n}\n\n// adminPKIEndpointBase is the base admin endpoint under which all PKI admin endpoints exist.\nconst adminPKIEndpointBase = \"/pki/\"\n\n// Interface guards\nvar (\n\t_ caddy.AdminRouter = (*adminAPI)(nil)\n\t_ caddy.Provisioner = (*adminAPI)(nil)\n)\n",
    "source_file": "modules/caddypki/adminapi.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddypki\n\nimport (\n\t\"fmt\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(PKI{})\n}\n\n// PKI provides Public Key Infrastructure facilities for Caddy.\n//\n// This app can define certificate authorities (CAs) which are capable\n// of signing certificates. Other modules can be configured to use\n// the CAs defined by this app for issuing certificates or getting\n// key information needed for establishing trust.\ntype PKI struct {\n\t// The certificate authorities to manage. Each CA is keyed by an\n\t// ID that is used to uniquely identify it from other CAs.\n\t// At runtime, the GetCA() method should be used instead to ensure\n\t// the default CA is provisioned if it hadn't already been.\n\t// The default CA ID is \"local\".\n\tCAs map[string]*CA `json:\"certificate_authorities,omitempty\"`\n\n\tctx caddy.Context\n\tlog *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (PKI) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"pki\",\n\t\tNew: func() caddy.Module { return new(PKI) },\n\t}\n}\n\n// Provision sets up the configuration for the PKI app.\nfunc (p *PKI) Provision(ctx caddy.Context) error {\n\tp.ctx = ctx\n\tp.log = ctx.Logger()\n\n\tfor caID, ca := range p.CAs {\n\t\terr := ca.Provision(ctx, caID, p.log)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning CA '%s': %v\", caID, err)\n\t\t}\n\t}\n\n\t// if this app is initialized at all, ensure there's at\n\t// least a default CA that can be used: the standard CA\n\t// which is used implicitly for signing local-use certs\n\tif len(p.CAs) == 0 {\n\t\terr := p.ProvisionDefaultCA(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning CA '%s': %v\", DefaultCAID, err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// ProvisionDefaultCA sets up the default CA.\nfunc (p *PKI) ProvisionDefaultCA(ctx caddy.Context) error {\n\tif p.CAs == nil {\n\t\tp.CAs = make(map[string]*CA)\n\t}\n\n\tp.CAs[DefaultCAID] = new(CA)\n\treturn p.CAs[DefaultCAID].Provision(ctx, DefaultCAID, p.log)\n}\n\n// Start starts the PKI app.\nfunc (p *PKI) Start() error {\n\t// install roots to trust store, if not disabled\n\tfor _, ca := range p.CAs {\n\t\tif ca.InstallTrust != nil && !*ca.InstallTrust {\n\t\t\tca.log.Info(\"root certificate trust store installation disabled; unconfigured clients may show warnings\",\n\t\t\t\tzap.String(\"path\", ca.rootCertPath))\n\t\t\tcontinue\n\t\t}\n\n\t\tif err := ca.installRoot(); err != nil {\n\t\t\t// could be some system dependencies that are missing;\n\t\t\t// shouldn't totally prevent startup, but we should log it\n\t\t\tca.log.Error(\"failed to install root certificate\",\n\t\t\t\tzap.Error(err),\n\t\t\t\tzap.String(\"certificate_file\", ca.rootCertPath))\n\t\t}\n\t}\n\n\t// see if root/intermediates need renewal...\n\tp.renewCerts()\n\n\t// ...and keep them renewed\n\tgo p.maintenance()\n\n\treturn nil\n}\n\n// Stop stops the PKI app.\nfunc (p *PKI) Stop() error {\n\treturn nil\n}\n\n// GetCA retrieves a CA by ID. If the ID is the default\n// CA ID, and it hasn't been provisioned yet, it will\n// be provisioned.\nfunc (p *PKI) GetCA(ctx caddy.Context, id string) (*CA, error) {\n\tca, ok := p.CAs[id]\n\tif !ok {\n\t\t// for anything other than the default CA ID, error out if it wasn't configured\n\t\tif id != DefaultCAID {\n\t\t\treturn nil, fmt.Errorf(\"no certificate authority configured with id: %s\", id)\n\t\t}\n\n\t\t// for the default CA ID, provision it, because we want it to \"just work\"\n\t\terr := p.ProvisionDefaultCA(ctx)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to provision default CA: %s\", err)\n\t\t}\n\t\tca = p.CAs[id]\n\t}\n\n\treturn ca, nil\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner = (*PKI)(nil)\n\t_ caddy.App         = (*PKI)(nil)\n)\n",
    "source_file": "modules/caddypki/pki.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddypki\n\nimport (\n\t\"crypto\"\n\t\"crypto/x509\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io/fs\"\n\t\"path\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/smallstep/certificates/authority\"\n\t\"github.com/smallstep/certificates/db\"\n\t\"github.com/smallstep/truststore\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// CA describes a certificate authority, which consists of\n// root/signing certificates and various settings pertaining\n// to the issuance of certificates and trusting them.\ntype CA struct {\n\t// The user-facing name of the certificate authority.\n\tName string `json:\"name,omitempty\"`\n\n\t// The name to put in the CommonName field of the\n\t// root certificate.\n\tRootCommonName string `json:\"root_common_name,omitempty\"`\n\n\t// The name to put in the CommonName field of the\n\t// intermediate certificates.\n\tIntermediateCommonName string `json:\"intermediate_common_name,omitempty\"`\n\n\t// The lifetime for the intermediate certificates\n\tIntermediateLifetime caddy.Duration `json:\"intermediate_lifetime,omitempty\"`\n\n\t// Whether Caddy will attempt to install the CA's root\n\t// into the system trust store, as well as into Java\n\t// and Mozilla Firefox trust stores. Default: true.\n\tInstallTrust *bool `json:\"install_trust,omitempty\"`\n\n\t// The root certificate to use; if null, one will be generated.\n\tRoot *KeyPair `json:\"root,omitempty\"`\n\n\t// The intermediate (signing) certificate; if null, one will be generated.\n\tIntermediate *KeyPair `json:\"intermediate,omitempty\"`\n\n\t// Optionally configure a separate storage module associated with this\n\t// issuer, instead of using Caddy's global/default-configured storage.\n\t// This can be useful if you want to keep your signing keys in a\n\t// separate location from your leaf certificates.\n\tStorageRaw json.RawMessage `json:\"storage,omitempty\" caddy:\"namespace=caddy.storage inline_key=module\"`\n\n\t// The unique config-facing ID of the certificate authority.\n\t// Since the ID is set in JSON config via object key, this\n\t// field is exported only for purposes of config generation\n\t// and module provisioning.\n\tID string `json:\"-\"`\n\n\tstorage     certmagic.Storage\n\troot, inter *x509.Certificate\n\tinterKey    any // TODO: should we just store these as crypto.Signer?\n\tmu          *sync.RWMutex\n\n\trootCertPath string // mainly used for logging purposes if trusting\n\tlog          *zap.Logger\n\tctx          caddy.Context\n}\n\n// Provision sets up the CA.\nfunc (ca *CA) Provision(ctx caddy.Context, id string, log *zap.Logger) error {\n\tca.mu = new(sync.RWMutex)\n\tca.log = log.Named(\"ca.\" + id)\n\tca.ctx = ctx\n\n\tif id == \"\" {\n\t\treturn fmt.Errorf(\"CA ID is required (use 'local' for the default CA)\")\n\t}\n\tca.mu.Lock()\n\tca.ID = id\n\tca.mu.Unlock()\n\n\tif ca.StorageRaw != nil {\n\t\tval, err := ctx.LoadModule(ca, \"StorageRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading storage module: %v\", err)\n\t\t}\n\t\tcmStorage, err := val.(caddy.StorageConverter).CertMagicStorage()\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"creating storage configuration: %v\", err)\n\t\t}\n\t\tca.storage = cmStorage\n\t}\n\tif ca.storage == nil {\n\t\tca.storage = ctx.Storage()\n\t}\n\n\tif ca.Name == \"\" {\n\t\tca.Name = defaultCAName\n\t}\n\tif ca.RootCommonName == \"\" {\n\t\tca.RootCommonName = defaultRootCommonName\n\t}\n\tif ca.IntermediateCommonName == \"\" {\n\t\tca.IntermediateCommonName = defaultIntermediateCommonName\n\t}\n\tif ca.IntermediateLifetime == 0 {\n\t\tca.IntermediateLifetime = caddy.Duration(defaultIntermediateLifetime)\n\t} else if time.Duration(ca.IntermediateLifetime) >= defaultRootLifetime {\n\t\treturn fmt.Errorf(\"intermediate certificate lifetime must be less than root certificate lifetime (%s)\", defaultRootLifetime)\n\t}\n\n\t// load the certs and key that will be used for signing\n\tvar rootCert, interCert *x509.Certificate\n\tvar rootKey, interKey crypto.Signer\n\tvar err error\n\tif ca.Root != nil {\n\t\tif ca.Root.Format == \"\" || ca.Root.Format == \"pem_file\" {\n\t\t\tca.rootCertPath = ca.Root.Certificate\n\t\t}\n\t\trootCert, rootKey, err = ca.Root.Load()\n\t} else {\n\t\tca.rootCertPath = \"storage:\" + ca.storageKeyRootCert()\n\t\trootCert, rootKey, err = ca.loadOrGenRoot()\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\tif ca.Intermediate != nil {\n\t\tinterCert, interKey, err = ca.Intermediate.Load()\n\t} else {\n\t\tinterCert, interKey, err = ca.loadOrGenIntermediate(rootCert, rootKey)\n\t}\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tca.mu.Lock()\n\tca.root, ca.inter, ca.interKey = rootCert, interCert, interKey\n\tca.mu.Unlock()\n\n\treturn nil\n}\n\n// RootCertificate returns the CA's root certificate (public key).\nfunc (ca CA) RootCertificate() *x509.Certificate {\n\tca.mu.RLock()\n\tdefer ca.mu.RUnlock()\n\treturn ca.root\n}\n\n// RootKey returns the CA's root private key. Since the root key is\n// not cached in memory long-term, it needs to be loaded from storage,\n// which could yield an error.\nfunc (ca CA) RootKey() (any, error) {\n\t_, rootKey, err := ca.loadOrGenRoot()\n\treturn rootKey, err\n}\n\n// IntermediateCertificate returns the CA's intermediate\n// certificate (public key).\nfunc (ca CA) IntermediateCertificate() *x509.Certificate {\n\tca.mu.RLock()\n\tdefer ca.mu.RUnlock()\n\treturn ca.inter\n}\n\n// IntermediateKey returns the CA's intermediate private key.\nfunc (ca CA) IntermediateKey() any {\n\tca.mu.RLock()\n\tdefer ca.mu.RUnlock()\n\treturn ca.interKey\n}\n\n// NewAuthority returns a new Smallstep-powered signing authority for this CA.\n// Note that we receive *CA (a pointer) in this method to ensure the closure within it, which\n// executes at a later time, always has the only copy of the CA so it can access the latest,\n// renewed certificates since NewAuthority was called. See #4517 and #4669.\nfunc (ca *CA) NewAuthority(authorityConfig AuthorityConfig) (*authority.Authority, error) {\n\t// get the root certificate and the issuer cert+key\n\trootCert := ca.RootCertificate()\n\n\t// set up the signer; cert/key which signs the leaf certs\n\tvar signerOption authority.Option\n\tif authorityConfig.SignWithRoot {\n\t\t// if we're signing with root, we can just pass the\n\t\t// cert/key directly, since it's unlikely to expire\n\t\t// while Caddy is running (long lifetime)\n\t\tvar issuerCert *x509.Certificate\n\t\tvar issuerKey any\n\t\tissuerCert = rootCert\n\t\tvar err error\n\t\tissuerKey, err = ca.RootKey()\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"loading signing key: %v\", err)\n\t\t}\n\t\tsignerOption = authority.WithX509Signer(issuerCert, issuerKey.(crypto.Signer))\n\t} else {\n\t\t// if we're signing with intermediate, we need to make\n\t\t// sure it's always fresh, because the intermediate may\n\t\t// renew while Caddy is running (medium lifetime)\n\t\tsignerOption = authority.WithX509SignerFunc(func() ([]*x509.Certificate, crypto.Signer, error) {\n\t\t\tissuerCert := ca.IntermediateCertificate()\n\t\t\tissuerKey := ca.IntermediateKey().(crypto.Signer)\n\t\t\tca.log.Debug(\"using intermediate signer\",\n\t\t\t\tzap.String(\"serial\", issuerCert.SerialNumber.String()),\n\t\t\t\tzap.String(\"not_before\", issuerCert.NotBefore.String()),\n\t\t\t\tzap.String(\"not_after\", issuerCert.NotAfter.String()))\n\t\t\treturn []*x509.Certificate{issuerCert}, issuerKey, nil\n\t\t})\n\t}\n\n\topts := []authority.Option{\n\t\tauthority.WithConfig(&authority.Config{\n\t\t\tAuthorityConfig: authorityConfig.AuthConfig,\n\t\t}),\n\t\tsignerOption,\n\t\tauthority.WithX509RootCerts(rootCert),\n\t}\n\n\t// Add a database if we have one\n\tif authorityConfig.DB != nil {\n\t\topts = append(opts, authority.WithDatabase(*authorityConfig.DB))\n\t}\n\tauth, err := authority.NewEmbedded(opts...)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"initializing certificate authority: %v\", err)\n\t}\n\n\treturn auth, nil\n}\n\nfunc (ca CA) loadOrGenRoot() (rootCert *x509.Certificate, rootKey crypto.Signer, err error) {\n\tif ca.Root != nil {\n\t\treturn ca.Root.Load()\n\t}\n\trootCertPEM, err := ca.storage.Load(ca.ctx, ca.storageKeyRootCert())\n\tif err != nil {\n\t\tif !errors.Is(err, fs.ErrNotExist) {\n\t\t\treturn nil, nil, fmt.Errorf(\"loading root cert: %v\", err)\n\t\t}\n\n\t\t// TODO: should we require that all or none of the assets are required before overwriting anything?\n\t\trootCert, rootKey, err = ca.genRoot()\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"generating root: %v\", err)\n\t\t}\n\t}\n\n\tif rootCert == nil {\n\t\trootCert, err = pemDecodeSingleCert(rootCertPEM)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"parsing root certificate PEM: %v\", err)\n\t\t}\n\t}\n\tif rootKey == nil {\n\t\trootKeyPEM, err := ca.storage.Load(ca.ctx, ca.storageKeyRootKey())\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"loading root key: %v\", err)\n\t\t}\n\t\trootKey, err = certmagic.PEMDecodePrivateKey(rootKeyPEM)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"decoding root key: %v\", err)\n\t\t}\n\t}\n\n\treturn rootCert, rootKey, nil\n}\n\nfunc (ca CA) genRoot() (rootCert *x509.Certificate, rootKey crypto.Signer, err error) {\n\trepl := ca.newReplacer()\n\n\trootCert, rootKey, err = generateRoot(repl.ReplaceAll(ca.RootCommonName, \"\"))\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"generating CA root: %v\", err)\n\t}\n\trootCertPEM, err := pemEncodeCert(rootCert.Raw)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"encoding root certificate: %v\", err)\n\t}\n\terr = ca.storage.Store(ca.ctx, ca.storageKeyRootCert(), rootCertPEM)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"saving root certificate: %v\", err)\n\t}\n\trootKeyPEM, err := certmagic.PEMEncodePrivateKey(rootKey)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"encoding root key: %v\", err)\n\t}\n\terr = ca.storage.Store(ca.ctx, ca.storageKeyRootKey(), rootKeyPEM)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"saving root key: %v\", err)\n\t}\n\n\treturn rootCert, rootKey, nil\n}\n\nfunc (ca CA) loadOrGenIntermediate(rootCert *x509.Certificate, rootKey crypto.Signer) (interCert *x509.Certificate, interKey crypto.Signer, err error) {\n\tinterCertPEM, err := ca.storage.Load(ca.ctx, ca.storageKeyIntermediateCert())\n\tif err != nil {\n\t\tif !errors.Is(err, fs.ErrNotExist) {\n\t\t\treturn nil, nil, fmt.Errorf(\"loading intermediate cert: %v\", err)\n\t\t}\n\n\t\t// TODO: should we require that all or none of the assets are required before overwriting anything?\n\t\tinterCert, interKey, err = ca.genIntermediate(rootCert, rootKey)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"generating new intermediate cert: %v\", err)\n\t\t}\n\t}\n\n\tif interCert == nil {\n\t\tinterCert, err = pemDecodeSingleCert(interCertPEM)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"decoding intermediate certificate PEM: %v\", err)\n\t\t}\n\t}\n\n\tif interKey == nil {\n\t\tinterKeyPEM, err := ca.storage.Load(ca.ctx, ca.storageKeyIntermediateKey())\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"loading intermediate key: %v\", err)\n\t\t}\n\t\tinterKey, err = certmagic.PEMDecodePrivateKey(interKeyPEM)\n\t\tif err != nil {\n\t\t\treturn nil, nil, fmt.Errorf(\"decoding intermediate key: %v\", err)\n\t\t}\n\t}\n\n\treturn interCert, interKey, nil\n}\n\nfunc (ca CA) genIntermediate(rootCert *x509.Certificate, rootKey crypto.Signer) (interCert *x509.Certificate, interKey crypto.Signer, err error) {\n\trepl := ca.newReplacer()\n\n\tinterCert, interKey, err = generateIntermediate(repl.ReplaceAll(ca.IntermediateCommonName, \"\"), rootCert, rootKey, time.Duration(ca.IntermediateLifetime))\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"generating CA intermediate: %v\", err)\n\t}\n\tinterCertPEM, err := pemEncodeCert(interCert.Raw)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"encoding intermediate certificate: %v\", err)\n\t}\n\terr = ca.storage.Store(ca.ctx, ca.storageKeyIntermediateCert(), interCertPEM)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"saving intermediate certificate: %v\", err)\n\t}\n\tinterKeyPEM, err := certmagic.PEMEncodePrivateKey(interKey)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"encoding intermediate key: %v\", err)\n\t}\n\terr = ca.storage.Store(ca.ctx, ca.storageKeyIntermediateKey(), interKeyPEM)\n\tif err != nil {\n\t\treturn nil, nil, fmt.Errorf(\"saving intermediate key: %v\", err)\n\t}\n\n\treturn interCert, interKey, nil\n}\n\nfunc (ca CA) storageKeyCAPrefix() string {\n\treturn path.Join(\"pki\", \"authorities\", certmagic.StorageKeys.Safe(ca.ID))\n}\n\nfunc (ca CA) storageKeyRootCert() string {\n\treturn path.Join(ca.storageKeyCAPrefix(), \"root.crt\")\n}\n\nfunc (ca CA) storageKeyRootKey() string {\n\treturn path.Join(ca.storageKeyCAPrefix(), \"root.key\")\n}\n\nfunc (ca CA) storageKeyIntermediateCert() string {\n\treturn path.Join(ca.storageKeyCAPrefix(), \"intermediate.crt\")\n}\n\nfunc (ca CA) storageKeyIntermediateKey() string {\n\treturn path.Join(ca.storageKeyCAPrefix(), \"intermediate.key\")\n}\n\nfunc (ca CA) newReplacer() *caddy.Replacer {\n\trepl := caddy.NewReplacer()\n\trepl.Set(\"pki.ca.name\", ca.Name)\n\treturn repl\n}\n\n// installRoot installs this CA's root certificate into the\n// local trust store(s) if it is not already trusted. The CA\n// must already be provisioned.\nfunc (ca CA) installRoot() error {\n\t// avoid password prompt if already trusted\n\tif trusted(ca.root) {\n\t\tca.log.Info(\"root certificate is already trusted by system\",\n\t\t\tzap.String(\"path\", ca.rootCertPath))\n\t\treturn nil\n\t}\n\n\tca.log.Warn(\"installing root certificate (you might be prompted for password)\",\n\t\tzap.String(\"path\", ca.rootCertPath))\n\n\treturn truststore.Install(ca.root,\n\t\ttruststore.WithDebug(),\n\t\ttruststore.WithFirefox(),\n\t\ttruststore.WithJava(),\n\t)\n}\n\n// AuthorityConfig is used to help a CA configure\n// the underlying signing authority.\ntype AuthorityConfig struct {\n\tSignWithRoot bool\n\n\t// TODO: should we just embed the underlying authority.Config struct type?\n\tDB         *db.AuthDB\n\tAuthConfig *authority.AuthConfig\n}\n\nconst (\n\t// DefaultCAID is the default CA ID.\n\tDefaultCAID = \"local\"\n\n\tdefaultCAName                 = \"Caddy Local Authority\"\n\tdefaultRootCommonName         = \"{pki.ca.name} - {time.now.year} ECC Root\"\n\tdefaultIntermediateCommonName = \"{pki.ca.name} - ECC Intermediate\"\n\n\tdefaultRootLifetime         = 24 * time.Hour * 30 * 12 * 10\n\tdefaultIntermediateLifetime = 24 * time.Hour * 7\n)\n",
    "source_file": "modules/caddypki/ca.go",
    "chunk_type": "code"
  },
  {
    "content": "package standard\n\nimport (\n\t// standard Caddy modules\n\t_ \"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyevents\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyevents/eventsconfig\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyfs\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/standard\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddypki\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddypki/acmeserver\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddytls\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddytls/distributedstek\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddytls/standardstek\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/filestorage\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/logging\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/metrics\"\n)\n",
    "source_file": "modules/standard/imports.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyevents\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(App{})\n}\n\n// App implements a global eventing system within Caddy.\n// Modules can emit and subscribe to events, providing\n// hooks into deep parts of the code base that aren't\n// otherwise accessible. Events provide information about\n// what and when things are happening, and this facility\n// allows handlers to take action when events occur,\n// add information to the event's metadata, and even\n// control program flow in some cases.\n//\n// Events are propagated in a DOM-like fashion. An event\n// emitted from module `a.b.c` (the \"origin\") will first\n// invoke handlers listening to `a.b.c`, then `a.b`,\n// then `a`, then those listening regardless of origin.\n// If a handler returns the special error Aborted, then\n// propagation immediately stops and the event is marked\n// as aborted. Emitters may optionally choose to adjust\n// program flow based on an abort.\n//\n// Modules can subscribe to events by origin and/or name.\n// A handler is invoked only if it is subscribed to the\n// event by name and origin. Subscriptions should be\n// registered during the provisioning phase, before apps\n// are started.\n//\n// Event handlers are fired synchronously as part of the\n// regular flow of the program. This allows event handlers\n// to control the flow of the program if the origin permits\n// it and also allows handlers to convey new information\n// back into the origin module before it continues.\n// In essence, event handlers are similar to HTTP\n// middleware handlers.\n//\n// Event bindings/subscribers are unordered; i.e.\n// event handlers are invoked in an arbitrary order.\n// Event handlers should not rely on the logic of other\n// handlers to succeed.\n//\n// The entirety of this app module is EXPERIMENTAL and\n// subject to change. Pay attention to release notes.\ntype App struct {\n\t// Subscriptions bind handlers to one or more events\n\t// either globally or scoped to specific modules or module\n\t// namespaces.\n\tSubscriptions []*Subscription `json:\"subscriptions,omitempty\"`\n\n\t// Map of event name to map of module ID/namespace to handlers\n\tsubscriptions map[string]map[caddy.ModuleID][]Handler\n\n\tlogger  *zap.Logger\n\tstarted bool\n}\n\n// Subscription represents binding of one or more handlers to\n// one or more events.\ntype Subscription struct {\n\t// The name(s) of the event(s) to bind to. Default: all events.\n\tEvents []string `json:\"events,omitempty\"`\n\n\t// The ID or namespace of the module(s) from which events\n\t// originate to listen to for events. Default: all modules.\n\t//\n\t// Events propagate up, so events emitted by module \"a.b.c\"\n\t// will also trigger the event for \"a.b\" and \"a\". Thus, to\n\t// receive all events from \"a.b.c\" and \"a.b.d\", for example,\n\t// one can subscribe to either \"a.b\" or all of \"a\" entirely.\n\tModules []caddy.ModuleID `json:\"modules,omitempty\"`\n\n\t// The event handler modules. These implement the actual\n\t// behavior to invoke when an event occurs. At least one\n\t// handler is required.\n\tHandlersRaw []json.RawMessage `json:\"handlers,omitempty\" caddy:\"namespace=events.handlers inline_key=handler\"`\n\n\t// The decoded handlers; Go code that is subscribing to\n\t// an event should set this field directly; HandlersRaw\n\t// is meant for JSON configuration to fill out this field.\n\tHandlers []Handler `json:\"-\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (App) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"events\",\n\t\tNew: func() caddy.Module { return new(App) },\n\t}\n}\n\n// Provision sets up the app.\nfunc (app *App) Provision(ctx caddy.Context) error {\n\tapp.logger = ctx.Logger()\n\tapp.subscriptions = make(map[string]map[caddy.ModuleID][]Handler)\n\n\tfor _, sub := range app.Subscriptions {\n\t\tif sub.HandlersRaw == nil {\n\t\t\tcontinue\n\t\t}\n\t\thandlersIface, err := ctx.LoadModule(sub, \"HandlersRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading event subscriber modules: %v\", err)\n\t\t}\n\t\tfor _, h := range handlersIface.([]any) {\n\t\t\tsub.Handlers = append(sub.Handlers, h.(Handler))\n\t\t}\n\t\tif len(sub.Handlers) == 0 {\n\t\t\t// pointless to bind without any handlers\n\t\t\treturn fmt.Errorf(\"no handlers defined\")\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Start runs the app.\nfunc (app *App) Start() error {\n\tfor _, sub := range app.Subscriptions {\n\t\tif err := app.Subscribe(sub); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\tapp.started = true\n\n\treturn nil\n}\n\n// Stop gracefully shuts down the app.\nfunc (app *App) Stop() error {\n\treturn nil\n}\n\n// Subscribe binds one or more event handlers to one or more events\n// according to the subscription s. For now, subscriptions can only\n// be created during the provision phase; new bindings cannot be\n// created after the events app has started.\nfunc (app *App) Subscribe(s *Subscription) error {\n\tif app.started {\n\t\treturn fmt.Errorf(\"events already started; new subscriptions closed\")\n\t}\n\n\t// handle special case of catch-alls (omission of event name or module space implies all)\n\tif len(s.Events) == 0 {\n\t\ts.Events = []string{\"\"}\n\t}\n\tif len(s.Modules) == 0 {\n\t\ts.Modules = []caddy.ModuleID{\"\"}\n\t}\n\n\tfor _, eventName := range s.Events {\n\t\tif app.subscriptions[eventName] == nil {\n\t\t\tapp.subscriptions[eventName] = make(map[caddy.ModuleID][]Handler)\n\t\t}\n\t\tfor _, originModule := range s.Modules {\n\t\t\tapp.subscriptions[eventName][originModule] = append(app.subscriptions[eventName][originModule], s.Handlers...)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// On is syntactic sugar for Subscribe() that binds a single handler\n// to a single event from any module. If the eventName is empty string,\n// it counts for all events.\nfunc (app *App) On(eventName string, handler Handler) error {\n\treturn app.Subscribe(&Subscription{\n\t\tEvents:   []string{eventName},\n\t\tHandlers: []Handler{handler},\n\t})\n}\n\n// Emit creates and dispatches an event named eventName to all relevant handlers with\n// the metadata data. Events are emitted and propagated synchronously. The returned Event\n// value will have any additional information from the invoked handlers.\n//\n// Note that the data map is not copied, for efficiency. After Emit() is called, the\n// data passed in should not be changed in other goroutines.\nfunc (app *App) Emit(ctx caddy.Context, eventName string, data map[string]any) caddy.Event {\n\tlogger := app.logger.With(zap.String(\"name\", eventName))\n\n\te, err := caddy.NewEvent(ctx, eventName, data)\n\tif err != nil {\n\t\tlogger.Error(\"failed to create event\", zap.Error(err))\n\t}\n\n\tvar originModule caddy.ModuleInfo\n\tvar originModuleID caddy.ModuleID\n\tvar originModuleName string\n\tif origin := e.Origin(); origin != nil {\n\t\toriginModule = origin.CaddyModule()\n\t\toriginModuleID = originModule.ID\n\t\toriginModuleName = originModule.String()\n\t}\n\n\tlogger = logger.With(\n\t\tzap.String(\"id\", e.ID().String()),\n\t\tzap.String(\"origin\", originModuleName))\n\n\t// add event info to replacer, make sure it's in the context\n\trepl, ok := ctx.Context.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tif !ok {\n\t\trepl = caddy.NewReplacer()\n\t\tctx.Context = context.WithValue(ctx.Context, caddy.ReplacerCtxKey, repl)\n\t}\n\trepl.Map(func(key string) (any, bool) {\n\t\tswitch key {\n\t\tcase \"event\":\n\t\t\treturn e, true\n\t\tcase \"event.id\":\n\t\t\treturn e.ID(), true\n\t\tcase \"event.name\":\n\t\t\treturn e.Name(), true\n\t\tcase \"event.time\":\n\t\t\treturn e.Timestamp(), true\n\t\tcase \"event.time_unix\":\n\t\t\treturn e.Timestamp().UnixMilli(), true\n\t\tcase \"event.module\":\n\t\t\treturn originModuleID, true\n\t\tcase \"event.data\":\n\t\t\treturn e.Data, true\n\t\t}\n\n\t\tif strings.HasPrefix(key, \"event.data.\") {\n\t\t\tkey = strings.TrimPrefix(key, \"event.data.\")\n\t\t\tif val, ok := e.Data[key]; ok {\n\t\t\t\treturn val, true\n\t\t\t}\n\t\t}\n\n\t\treturn nil, false\n\t})\n\n\tlogger = logger.WithLazy(zap.Any(\"data\", e.Data))\n\n\tlogger.Debug(\"event\")\n\n\t// invoke handlers bound to the event by name and also all events; this for loop\n\t// iterates twice at most: once for the event name, once for \"\" (all events)\n\tfor {\n\t\tmoduleID := originModuleID\n\n\t\t// implement propagation up the module tree (i.e. start with \"a.b.c\" then \"a.b\" then \"a\" then \"\")\n\t\tfor {\n\t\t\tif app.subscriptions[eventName] == nil {\n\t\t\t\tbreak // shortcut if event not bound at all\n\t\t\t}\n\n\t\t\tfor _, handler := range app.subscriptions[eventName][moduleID] {\n\t\t\t\tselect {\n\t\t\t\tcase <-ctx.Done():\n\t\t\t\t\tlogger.Error(\"context canceled; event handling stopped\")\n\t\t\t\t\treturn e\n\t\t\t\tdefault:\n\t\t\t\t}\n\n\t\t\t\t// this log can be a useful sanity check to ensure your handlers are in fact being invoked\n\t\t\t\t// (see https://github.com/mholt/caddy-events-exec/issues/6)\n\t\t\t\tlogger.Debug(\"invoking subscribed handler\",\n\t\t\t\t\tzap.String(\"subscribed_to\", eventName),\n\t\t\t\t\tzap.Any(\"handler\", handler))\n\n\t\t\t\tif err := handler.Handle(ctx, e); err != nil {\n\t\t\t\t\taborted := errors.Is(err, caddy.ErrEventAborted)\n\n\t\t\t\t\tlogger.Error(\"handler error\",\n\t\t\t\t\t\tzap.Error(err),\n\t\t\t\t\t\tzap.Bool(\"aborted\", aborted))\n\n\t\t\t\t\tif aborted {\n\t\t\t\t\t\te.Aborted = err\n\t\t\t\t\t\treturn e\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif moduleID == \"\" {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tlastDot := strings.LastIndex(string(moduleID), \".\")\n\t\t\tif lastDot < 0 {\n\t\t\t\tmoduleID = \"\" // include handlers bound to events regardless of module\n\t\t\t} else {\n\t\t\t\tmoduleID = moduleID[:lastDot]\n\t\t\t}\n\t\t}\n\n\t\t// include handlers listening to all events\n\t\tif eventName == \"\" {\n\t\t\tbreak\n\t\t}\n\t\teventName = \"\"\n\t}\n\n\treturn e\n}\n\n// Handler is a type that can handle events.\ntype Handler interface {\n\tHandle(context.Context, caddy.Event) error\n}\n\n// Interface guards\nvar (\n\t_ caddy.App         = (*App)(nil)\n\t_ caddy.Provisioner = (*App)(nil)\n)\n",
    "source_file": "modules/caddyevents/app.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Package eventsconfig is for configuring caddyevents.App with the\n// Caddyfile. This code can't be in the caddyevents package because\n// the httpcaddyfile package imports caddyhttp, which imports\n// caddyevents: hence, it creates an import cycle.\npackage eventsconfig\n\nimport (\n\t\"encoding/json\"\n\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyevents\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterGlobalOption(\"events\", parseApp)\n}\n\n// parseApp configures the \"events\" global option from Caddyfile to set up the events app.\n// Syntax:\n//\n//\tevents {\n//\t\ton <event> <handler_module...>\n//\t}\n//\n// If <event> is *, then it will bind to all events.\nfunc parseApp(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tapp := new(caddyevents.App)\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"on\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\teventName := d.Val()\n\t\t\tif eventName == \"*\" {\n\t\t\t\teventName = \"\"\n\t\t\t}\n\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\thandlerName := d.Val()\n\t\t\tmodID := \"events.handlers.\" + handlerName\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\tapp.Subscriptions = append(app.Subscriptions, &caddyevents.Subscription{\n\t\t\t\tEvents: []string{eventName},\n\t\t\t\tHandlersRaw: []json.RawMessage{\n\t\t\t\t\tcaddyconfig.JSONModuleObject(unm, \"handler\", handlerName, nil),\n\t\t\t\t},\n\t\t\t})\n\n\t\tdefault:\n\t\t\treturn nil, d.ArgErr()\n\t\t}\n\t}\n\n\treturn httpcaddyfile.App{\n\t\tName:  \"events\",\n\t\tValue: caddyconfig.JSON(app, nil),\n\t}, nil\n}\n",
    "source_file": "modules/caddyevents/eventsconfig/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "package acmeserver\n\nimport (\n\t\"github.com/smallstep/certificates/authority/policy\"\n\t\"github.com/smallstep/certificates/authority/provisioner\"\n)\n\n// Policy defines the criteria for the ACME server\n// of when to issue a certificate. Refer to the\n// [Certificate Issuance Policy](https://smallstep.com/docs/step-ca/policies/)\n// on Smallstep website for the evaluation criteria.\ntype Policy struct {\n\t// If a rule set is configured to allow a certain type of name,\n\t// all other types of names are automatically denied.\n\tAllow *RuleSet `json:\"allow,omitempty\"`\n\n\t// If a rule set is configured to deny a certain type of name,\n\t// all other types of names are still allowed.\n\tDeny *RuleSet `json:\"deny,omitempty\"`\n\n\t// If set to true, the ACME server will allow issuing wildcard certificates.\n\tAllowWildcardNames bool `json:\"allow_wildcard_names,omitempty\"`\n}\n\n// RuleSet is the specific set of SAN criteria for a certificate\n// to be issued or denied.\ntype RuleSet struct {\n\t// Domains is a list of DNS domains that are allowed to be issued.\n\t// It can be in the form of FQDN for specific domain name, or\n\t// a wildcard domain name format, e.g. *.example.com, to allow\n\t// sub-domains of a domain.\n\tDomains []string `json:\"domains,omitempty\"`\n\n\t// IP ranges in the form of CIDR notation or specific IP addresses\n\t// to be approved or denied for certificates. Non-CIDR IP addresses\n\t// are matched exactly.\n\tIPRanges []string `json:\"ip_ranges,omitempty\"`\n}\n\n// normalizeAllowRules returns `nil` if policy is nil, the `Allow` rule is `nil`,\n// or all rules within the `Allow` rule are empty. Otherwise, it returns the X509NameOptions\n// with the content of the `Allow` rule.\nfunc (p *Policy) normalizeAllowRules() *policy.X509NameOptions {\n\tif (p == nil) || (p.Allow == nil) || (len(p.Allow.Domains) == 0 && len(p.Allow.IPRanges) == 0) {\n\t\treturn nil\n\t}\n\treturn &policy.X509NameOptions{\n\t\tDNSDomains: p.Allow.Domains,\n\t\tIPRanges:   p.Allow.IPRanges,\n\t}\n}\n\n// normalizeDenyRules returns `nil` if policy is nil, the `Deny` rule is `nil`,\n// or all rules within the `Deny` rule are empty. Otherwise, it returns the X509NameOptions\n// with the content of the `Deny` rule.\nfunc (p *Policy) normalizeDenyRules() *policy.X509NameOptions {\n\tif (p == nil) || (p.Deny == nil) || (len(p.Deny.Domains) == 0 && len(p.Deny.IPRanges) == 0) {\n\t\treturn nil\n\t}\n\treturn &policy.X509NameOptions{\n\t\tDNSDomains: p.Deny.Domains,\n\t\tIPRanges:   p.Deny.IPRanges,\n\t}\n}\n\n// normalizeRules returns `nil` if policy is nil, the `Allow` and `Deny` rules are `nil`,\nfunc (p *Policy) normalizeRules() *provisioner.X509Options {\n\tif p == nil {\n\t\treturn nil\n\t}\n\n\tallow := p.normalizeAllowRules()\n\tdeny := p.normalizeDenyRules()\n\tif allow == nil && deny == nil && !p.AllowWildcardNames {\n\t\treturn nil\n\t}\n\n\treturn &provisioner.X509Options{\n\t\tAllowedNames:       allow,\n\t\tDeniedNames:        deny,\n\t\tAllowWildcardNames: p.AllowWildcardNames,\n\t}\n}\n",
    "source_file": "modules/caddypki/acmeserver/policy.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage acmeserver\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\tweakrand \"math/rand\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"regexp\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/go-chi/chi/v5\"\n\t\"github.com/smallstep/certificates/acme\"\n\t\"github.com/smallstep/certificates/acme/api\"\n\tacmeNoSQL \"github.com/smallstep/certificates/acme/db/nosql\"\n\t\"github.com/smallstep/certificates/authority\"\n\t\"github.com/smallstep/certificates/authority/provisioner\"\n\t\"github.com/smallstep/certificates/db\"\n\t\"github.com/smallstep/nosql\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddypki\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Handler{})\n}\n\n// Handler is an ACME server handler.\ntype Handler struct {\n\t// The ID of the CA to use for signing. This refers to\n\t// the ID given to the CA in the `pki` app. If omitted,\n\t// the default ID is \"local\".\n\tCA string `json:\"ca,omitempty\"`\n\n\t// The lifetime for issued certificates\n\tLifetime caddy.Duration `json:\"lifetime,omitempty\"`\n\n\t// The hostname or IP address by which ACME clients\n\t// will access the server. This is used to populate\n\t// the ACME directory endpoint. If not set, the Host\n\t// header of the request will be used.\n\t// COMPATIBILITY NOTE / TODO: This property may go away in the\n\t// future. Do not rely on this property long-term; check release notes.\n\tHost string `json:\"host,omitempty\"`\n\n\t// The path prefix under which to serve all ACME\n\t// endpoints. All other requests will not be served\n\t// by this handler and will be passed through to\n\t// the next one. Default: \"/acme/\".\n\t// COMPATIBILITY NOTE / TODO: This property may go away in the\n\t// future, as it is currently only required due to\n\t// limitations in the underlying library. Do not rely\n\t// on this property long-term; check release notes.\n\tPathPrefix string `json:\"path_prefix,omitempty\"`\n\n\t// If true, the CA's root will be the issuer instead of\n\t// the intermediate. This is NOT recommended and should\n\t// only be used when devices/clients do not properly\n\t// validate certificate chains. EXPERIMENTAL: Might be\n\t// changed or removed in the future.\n\tSignWithRoot bool `json:\"sign_with_root,omitempty\"`\n\n\t// The addresses of DNS resolvers to use when looking up\n\t// the TXT records for solving DNS challenges.\n\t// It accepts [network addresses](/docs/conventions#network-addresses)\n\t// with port range of only 1. If the host is an IP address,\n\t// it will be dialed directly to resolve the upstream server.\n\t// If the host is not an IP address, the addresses are resolved\n\t// using the [name resolution convention](https://golang.org/pkg/net/#hdr-Name_Resolution)\n\t// of the Go standard library. If the array contains more\n\t// than 1 resolver address, one is chosen at random.\n\tResolvers []string `json:\"resolvers,omitempty\"`\n\n\t// Specify the set of enabled ACME challenges. An empty or absent value\n\t// means all challenges are enabled. Accepted values are:\n\t// \"http-01\", \"dns-01\", \"tls-alpn-01\"\n\tChallenges ACMEChallenges `json:\"challenges,omitempty\" `\n\n\t// The policy to use for issuing certificates\n\tPolicy *Policy `json:\"policy,omitempty\"`\n\n\tlogger    *zap.Logger\n\tresolvers []caddy.NetworkAddress\n\tctx       caddy.Context\n\n\tacmeDB        acme.DB\n\tacmeAuth      *authority.Authority\n\tacmeClient    acme.Client\n\tacmeLinker    acme.Linker\n\tacmeEndpoints http.Handler\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Handler) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.acme_server\",\n\t\tNew: func() caddy.Module { return new(Handler) },\n\t}\n}\n\n// Provision sets up the ACME server handler.\nfunc (ash *Handler) Provision(ctx caddy.Context) error {\n\tash.ctx = ctx\n\tash.logger = ctx.Logger()\n\n\t// set some defaults\n\tif ash.CA == \"\" {\n\t\tash.CA = caddypki.DefaultCAID\n\t}\n\tif ash.PathPrefix == \"\" {\n\t\tash.PathPrefix = defaultPathPrefix\n\t}\n\tif ash.Lifetime == 0 {\n\t\tash.Lifetime = caddy.Duration(12 * time.Hour)\n\t}\n\tif len(ash.Challenges) > 0 {\n\t\tif err := ash.Challenges.validate(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\t// get a reference to the configured CA\n\tappModule, err := ctx.App(\"pki\")\n\tif err != nil {\n\t\treturn err\n\t}\n\tpkiApp := appModule.(*caddypki.PKI)\n\tca, err := pkiApp.GetCA(ctx, ash.CA)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// make sure leaf cert lifetime is less than the intermediate cert lifetime. this check only\n\t// applies for caddy-managed intermediate certificates\n\tif ca.Intermediate == nil && ash.Lifetime >= ca.IntermediateLifetime {\n\t\treturn fmt.Errorf(\"certificate lifetime (%s) should be less than intermediate certificate lifetime (%s)\", time.Duration(ash.Lifetime), time.Duration(ca.IntermediateLifetime))\n\t}\n\n\tdatabase, err := ash.openDatabase()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tauthorityConfig := caddypki.AuthorityConfig{\n\t\tSignWithRoot: ash.SignWithRoot,\n\t\tAuthConfig: &authority.AuthConfig{\n\t\t\tProvisioners: provisioner.List{\n\t\t\t\t&provisioner.ACME{\n\t\t\t\t\tName:       ash.CA,\n\t\t\t\t\tChallenges: ash.Challenges.toSmallstepType(),\n\t\t\t\t\tOptions: &provisioner.Options{\n\t\t\t\t\t\tX509: ash.Policy.normalizeRules(),\n\t\t\t\t\t},\n\t\t\t\t\tType: provisioner.TypeACME.String(),\n\t\t\t\t\tClaims: &provisioner.Claims{\n\t\t\t\t\t\tMinTLSDur:     &provisioner.Duration{Duration: 5 * time.Minute},\n\t\t\t\t\t\tMaxTLSDur:     &provisioner.Duration{Duration: 24 * time.Hour * 365},\n\t\t\t\t\t\tDefaultTLSDur: &provisioner.Duration{Duration: time.Duration(ash.Lifetime)},\n\t\t\t\t\t},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t\tDB: database,\n\t}\n\n\tash.acmeAuth, err = ca.NewAuthority(authorityConfig)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tash.acmeDB, err = acmeNoSQL.New(ash.acmeAuth.GetDatabase().(nosql.DB))\n\tif err != nil {\n\t\treturn fmt.Errorf(\"configuring ACME DB: %v\", err)\n\t}\n\n\tash.acmeClient, err = ash.makeClient()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tash.acmeLinker = acme.NewLinker(\n\t\tash.Host,\n\t\tstrings.Trim(ash.PathPrefix, \"/\"),\n\t)\n\n\t// extract its http.Handler so we can use it directly\n\tr := chi.NewRouter()\n\tr.Route(ash.PathPrefix, func(r chi.Router) {\n\t\tapi.Route(r)\n\t})\n\tash.acmeEndpoints = r\n\n\treturn nil\n}\n\nfunc (ash Handler) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\tif strings.HasPrefix(r.URL.Path, ash.PathPrefix) {\n\t\tacmeCtx := acme.NewContext(\n\t\t\tr.Context(),\n\t\t\tash.acmeDB,\n\t\t\tash.acmeClient,\n\t\t\tash.acmeLinker,\n\t\t\tnil,\n\t\t)\n\t\tacmeCtx = authority.NewContext(acmeCtx, ash.acmeAuth)\n\t\tr = r.WithContext(acmeCtx)\n\n\t\tash.acmeEndpoints.ServeHTTP(w, r)\n\t\treturn nil\n\t}\n\treturn next.ServeHTTP(w, r)\n}\n\nfunc (ash Handler) getDatabaseKey() string {\n\tkey := ash.CA\n\tkey = strings.ToLower(key)\n\tkey = strings.TrimSpace(key)\n\treturn keyCleaner.ReplaceAllLiteralString(key, \"\")\n}\n\n// Cleanup implements caddy.CleanerUpper and closes any idle databases.\nfunc (ash Handler) Cleanup() error {\n\tkey := ash.getDatabaseKey()\n\tdeleted, err := databasePool.Delete(key)\n\tif deleted {\n\t\tif c := ash.logger.Check(zapcore.DebugLevel, \"unloading unused CA database\"); c != nil {\n\t\t\tc.Write(zap.String(\"db_key\", key))\n\t\t}\n\t}\n\tif err != nil {\n\t\tif c := ash.logger.Check(zapcore.ErrorLevel, \"closing CA database\"); c != nil {\n\t\t\tc.Write(zap.String(\"db_key\", key), zap.Error(err))\n\t\t}\n\t}\n\treturn err\n}\n\nfunc (ash Handler) openDatabase() (*db.AuthDB, error) {\n\tkey := ash.getDatabaseKey()\n\tdatabase, loaded, err := databasePool.LoadOrNew(key, func() (caddy.Destructor, error) {\n\t\tdbFolder := filepath.Join(caddy.AppDataDir(), \"acme_server\", key)\n\t\tdbPath := filepath.Join(dbFolder, \"db\")\n\n\t\terr := os.MkdirAll(dbFolder, 0o755)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"making folder for CA database: %v\", err)\n\t\t}\n\n\t\tdbConfig := &db.Config{\n\t\t\tType:       \"bbolt\",\n\t\t\tDataSource: dbPath,\n\t\t}\n\t\tdatabase, err := db.New(dbConfig)\n\t\treturn databaseCloser{&database}, err\n\t})\n\n\tif loaded {\n\t\tif c := ash.logger.Check(zapcore.DebugLevel, \"loaded preexisting CA database\"); c != nil {\n\t\t\tc.Write(zap.String(\"db_key\", key))\n\t\t}\n\t}\n\n\treturn database.(databaseCloser).DB, err\n}\n\n// makeClient creates an ACME client which will use a custom\n// resolver instead of net.DefaultResolver.\nfunc (ash Handler) makeClient() (acme.Client, error) {\n\tfor _, v := range ash.Resolvers {\n\t\taddr, err := caddy.ParseNetworkAddressWithDefaults(v, \"udp\", 53)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif addr.PortRangeSize() != 1 {\n\t\t\treturn nil, fmt.Errorf(\"resolver address must have exactly one address; cannot call %v\", addr)\n\t\t}\n\t\tash.resolvers = append(ash.resolvers, addr)\n\t}\n\n\tvar resolver *net.Resolver\n\tif len(ash.resolvers) != 0 {\n\t\tdialer := &net.Dialer{\n\t\t\tTimeout: 2 * time.Second,\n\t\t}\n\t\tresolver = &net.Resolver{\n\t\t\tPreferGo: true,\n\t\t\tDial: func(ctx context.Context, network, address string) (net.Conn, error) {\n\t\t\t\t//nolint:gosec\n\t\t\t\taddr := ash.resolvers[weakrand.Intn(len(ash.resolvers))]\n\t\t\t\treturn dialer.DialContext(ctx, addr.Network, addr.JoinHostPort(0))\n\t\t\t},\n\t\t}\n\t} else {\n\t\tresolver = net.DefaultResolver\n\t}\n\n\treturn resolverClient{\n\t\tClient:   acme.NewClient(),\n\t\tresolver: resolver,\n\t\tctx:      ash.ctx,\n\t}, nil\n}\n\ntype resolverClient struct {\n\tacme.Client\n\n\tresolver *net.Resolver\n\tctx      context.Context\n}\n\nfunc (c resolverClient) LookupTxt(name string) ([]string, error) {\n\treturn c.resolver.LookupTXT(c.ctx, name)\n}\n\nconst defaultPathPrefix = \"/acme/\"\n\nvar (\n\tkeyCleaner   = regexp.MustCompile(`[^\\w.-_]`)\n\tdatabasePool = caddy.NewUsagePool()\n)\n\ntype databaseCloser struct {\n\tDB *db.AuthDB\n}\n\nfunc (closer databaseCloser) Destruct() error {\n\treturn (*closer.DB).Shutdown()\n}\n\n// Interface guards\nvar (\n\t_ caddyhttp.MiddlewareHandler = (*Handler)(nil)\n\t_ caddy.Provisioner           = (*Handler)(nil)\n)\n",
    "source_file": "modules/caddypki/acmeserver/acmeserver.go",
    "chunk_type": "code"
  },
  {
    "content": "package acmeserver\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"strings\"\n\n\t\"github.com/smallstep/certificates/authority/provisioner\"\n)\n\n// ACMEChallenge is an opaque string that represents supported ACME challenges.\ntype ACMEChallenge string\n\nconst (\n\tHTTP_01     ACMEChallenge = \"http-01\"\n\tDNS_01      ACMEChallenge = \"dns-01\"\n\tTLS_ALPN_01 ACMEChallenge = \"tls-alpn-01\"\n)\n\n// validate checks if the given challenge is supported.\nfunc (c ACMEChallenge) validate() error {\n\tswitch c {\n\tcase HTTP_01, DNS_01, TLS_ALPN_01:\n\t\treturn nil\n\tdefault:\n\t\treturn fmt.Errorf(\"acme challenge %q is not supported\", c)\n\t}\n}\n\n// The unmarshaller first marshals the value into a string. Then it\n// trims any space around it and lowercase it for normaliztion. The\n// method does not and should not validate the value within accepted enums.\nfunc (c *ACMEChallenge) UnmarshalJSON(b []byte) error {\n\tvar s string\n\tif err := json.Unmarshal(b, &s); err != nil {\n\t\treturn err\n\t}\n\t*c = ACMEChallenge(strings.ToLower(strings.TrimSpace(s)))\n\treturn nil\n}\n\n// String returns a string representation of the challenge.\nfunc (c ACMEChallenge) String() string {\n\treturn strings.ToLower(string(c))\n}\n\n// ACMEChallenges is a list of ACME challenges.\ntype ACMEChallenges []ACMEChallenge\n\n// validate checks if the given challenges are supported.\nfunc (c ACMEChallenges) validate() error {\n\tfor _, ch := range c {\n\t\tif err := ch.validate(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (c ACMEChallenges) toSmallstepType() []provisioner.ACMEChallenge {\n\tif len(c) == 0 {\n\t\treturn nil\n\t}\n\tac := make([]provisioner.ACMEChallenge, len(c))\n\tfor i, ch := range c {\n\t\tac[i] = provisioner.ACMEChallenge(ch)\n\t}\n\treturn ac\n}\n\nfunc stringToChallenges(chs []string) ACMEChallenges {\n\tchallenges := make(ACMEChallenges, len(chs))\n\tfor i, ch := range chs {\n\t\tchallenges[i] = ACMEChallenge(ch)\n\t}\n\treturn challenges\n}\n",
    "source_file": "modules/caddypki/acmeserver/challenges.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage acmeserver\n\nimport (\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddypki\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterDirective(\"acme_server\", parseACMEServer)\n}\n\n// parseACMEServer sets up an ACME server handler from Caddyfile tokens.\n//\n//\tacme_server [<matcher>] {\n//\t\tca        <id>\n//\t\tlifetime  <duration>\n//\t\tresolvers <addresses...>\n//\t\tchallenges <challenges...>\n//\t\tallow_wildcard_names\n//\t\tallow {\n//\t\t\tdomains <domains...>\n//\t\t\tip_ranges <addresses...>\n//\t\t}\n//\t\tdeny {\n//\t\t\tdomains <domains...>\n//\t\t\tip_ranges <addresses...>\n//\t\t}\n//\t\tsign_with_root\n//\t}\nfunc parseACMEServer(h httpcaddyfile.Helper) ([]httpcaddyfile.ConfigValue, error) {\n\th.Next() // consume directive name\n\tmatcherSet, err := h.ExtractMatcherSet()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\th.Next() // consume the directive name again (matcher parsing resets)\n\n\t// no inline args allowed\n\tif h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\tvar acmeServer Handler\n\tvar ca *caddypki.CA\n\n\tfor h.NextBlock(0) {\n\t\tswitch h.Val() {\n\t\tcase \"ca\":\n\t\t\tif !h.AllArgs(&acmeServer.CA) {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tif ca == nil {\n\t\t\t\tca = new(caddypki.CA)\n\t\t\t}\n\t\t\tca.ID = acmeServer.CA\n\t\tcase \"lifetime\":\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(h.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tacmeServer.Lifetime = caddy.Duration(dur)\n\t\tcase \"resolvers\":\n\t\t\tacmeServer.Resolvers = h.RemainingArgs()\n\t\t\tif len(acmeServer.Resolvers) == 0 {\n\t\t\t\treturn nil, h.Errf(\"must specify at least one resolver address\")\n\t\t\t}\n\t\tcase \"challenges\":\n\t\t\tacmeServer.Challenges = append(acmeServer.Challenges, stringToChallenges(h.RemainingArgs())...)\n\t\tcase \"allow_wildcard_names\":\n\t\t\tif acmeServer.Policy == nil {\n\t\t\t\tacmeServer.Policy = &Policy{}\n\t\t\t}\n\t\t\tacmeServer.Policy.AllowWildcardNames = true\n\t\tcase \"allow\":\n\t\t\tr := &RuleSet{}\n\t\t\tfor nesting := h.Nesting(); h.NextBlock(nesting); {\n\t\t\t\tif h.CountRemainingArgs() == 0 {\n\t\t\t\t\treturn nil, h.ArgErr() // TODO:\n\t\t\t\t}\n\t\t\t\tswitch h.Val() {\n\t\t\t\tcase \"domains\":\n\t\t\t\t\tr.Domains = append(r.Domains, h.RemainingArgs()...)\n\t\t\t\tcase \"ip_ranges\":\n\t\t\t\t\tr.IPRanges = append(r.IPRanges, h.RemainingArgs()...)\n\t\t\t\tdefault:\n\t\t\t\t\treturn nil, h.Errf(\"unrecognized 'allow' subdirective: %s\", h.Val())\n\t\t\t\t}\n\t\t\t}\n\t\t\tif acmeServer.Policy == nil {\n\t\t\t\tacmeServer.Policy = &Policy{}\n\t\t\t}\n\t\t\tacmeServer.Policy.Allow = r\n\t\tcase \"deny\":\n\t\t\tr := &RuleSet{}\n\t\t\tfor nesting := h.Nesting(); h.NextBlock(nesting); {\n\t\t\t\tif h.CountRemainingArgs() == 0 {\n\t\t\t\t\treturn nil, h.ArgErr() // TODO:\n\t\t\t\t}\n\t\t\t\tswitch h.Val() {\n\t\t\t\tcase \"domains\":\n\t\t\t\t\tr.Domains = append(r.Domains, h.RemainingArgs()...)\n\t\t\t\tcase \"ip_ranges\":\n\t\t\t\t\tr.IPRanges = append(r.IPRanges, h.RemainingArgs()...)\n\t\t\t\tdefault:\n\t\t\t\t\treturn nil, h.Errf(\"unrecognized 'deny' subdirective: %s\", h.Val())\n\t\t\t\t}\n\t\t\t}\n\t\t\tif acmeServer.Policy == nil {\n\t\t\t\tacmeServer.Policy = &Policy{}\n\t\t\t}\n\t\t\tacmeServer.Policy.Deny = r\n\t\tcase \"sign_with_root\":\n\t\t\tif h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tacmeServer.SignWithRoot = true\n\t\tdefault:\n\t\t\treturn nil, h.Errf(\"unrecognized ACME server directive: %s\", h.Val())\n\t\t}\n\t}\n\n\tconfigVals := h.NewRoute(matcherSet, acmeServer)\n\n\tif ca == nil {\n\t\treturn configVals, nil\n\t}\n\n\treturn append(configVals, httpcaddyfile.ConfigValue{\n\t\tClass: \"pki.ca\",\n\t\tValue: ca,\n\t}), nil\n}\n",
    "source_file": "modules/caddypki/acmeserver/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "package network\n\nimport (\n\t\"errors\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(ProxyFromURL{})\n\tcaddy.RegisterModule(ProxyFromNone{})\n}\n\n// The \"url\" proxy source uses the defined URL as the proxy\ntype ProxyFromURL struct {\n\tURL string `json:\"url\"`\n\n\tctx    caddy.Context\n\tlogger *zap.Logger\n}\n\n// CaddyModule implements Module.\nfunc (p ProxyFromURL) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID: \"caddy.network_proxy.url\",\n\t\tNew: func() caddy.Module {\n\t\t\treturn &ProxyFromURL{}\n\t\t},\n\t}\n}\n\nfunc (p *ProxyFromURL) Provision(ctx caddy.Context) error {\n\tp.ctx = ctx\n\tp.logger = ctx.Logger()\n\treturn nil\n}\n\n// Validate implements Validator.\nfunc (p ProxyFromURL) Validate() error {\n\tif _, err := url.Parse(p.URL); err != nil {\n\t\treturn err\n\t}\n\treturn nil\n}\n\n// ProxyFunc implements ProxyFuncProducer.\nfunc (p ProxyFromURL) ProxyFunc() func(*http.Request) (*url.URL, error) {\n\tif strings.Contains(p.URL, \"{\") && strings.Contains(p.URL, \"}\") {\n\t\t// courtesy of @ImpostorKeanu: https://github.com/caddyserver/caddy/pull/6397\n\t\treturn func(r *http.Request) (*url.URL, error) {\n\t\t\t// retrieve the replacer from context.\n\t\t\trepl, ok := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\t\t\tif !ok {\n\t\t\t\terr := errors.New(\"failed to obtain replacer from request\")\n\t\t\t\tp.logger.Error(err.Error())\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\t// apply placeholders to the value\n\t\t\t// note: h.ForwardProxyURL should never be empty at this point\n\t\t\ts := repl.ReplaceAll(p.URL, \"\")\n\t\t\tif s == \"\" {\n\t\t\t\tp.logger.Error(\"network_proxy URL was empty after applying placeholders\",\n\t\t\t\t\tzap.String(\"initial_value\", p.URL),\n\t\t\t\t\tzap.String(\"final_value\", s),\n\t\t\t\t\tzap.String(\"hint\", \"check for invalid placeholders\"))\n\t\t\t\treturn nil, errors.New(\"empty value for network_proxy URL\")\n\t\t\t}\n\n\t\t\t// parse the url\n\t\t\tpUrl, err := url.Parse(s)\n\t\t\tif err != nil {\n\t\t\t\tp.logger.Warn(\"failed to derive transport proxy from network_proxy URL\")\n\t\t\t\tpUrl = nil\n\t\t\t} else if pUrl.Host == \"\" || strings.Split(\"\", pUrl.Host)[0] == \":\" {\n\t\t\t\t// url.Parse does not return an error on these values:\n\t\t\t\t//\n\t\t\t\t// - http://:80\n\t\t\t\t//   - pUrl.Host == \":80\"\n\t\t\t\t// - /some/path\n\t\t\t\t//   - pUrl.Host == \"\"\n\t\t\t\t//\n\t\t\t\t// Super edge cases, but humans are human.\n\t\t\t\terr = errors.New(\"supplied network_proxy URL is missing a host value\")\n\t\t\t\tpUrl = nil\n\t\t\t} else {\n\t\t\t\tp.logger.Debug(\"setting transport proxy url\", zap.String(\"url\", s))\n\t\t\t}\n\n\t\t\treturn pUrl, err\n\t\t}\n\t}\n\treturn func(r *http.Request) (*url.URL, error) {\n\t\treturn url.Parse(p.URL)\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (p *ProxyFromURL) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next()\n\td.Next()\n\tp.URL = d.Val()\n\treturn nil\n}\n\n// The \"none\" proxy source module disables the use of network proxy.\ntype ProxyFromNone struct{}\n\nfunc (p ProxyFromNone) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID: \"caddy.network_proxy.none\",\n\t\tNew: func() caddy.Module {\n\t\t\treturn &ProxyFromNone{}\n\t\t},\n\t}\n}\n\n// UnmarshalCaddyfile implements caddyfile.Unmarshaler.\nfunc (p ProxyFromNone) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\treturn nil\n}\n\n// ProxyFunc implements ProxyFuncProducer.\nfunc (p ProxyFromNone) ProxyFunc() func(*http.Request) (*url.URL, error) {\n\treturn nil\n}\n\nvar (\n\t_ caddy.Module            = ProxyFromURL{}\n\t_ caddy.Provisioner       = (*ProxyFromURL)(nil)\n\t_ caddy.Validator         = ProxyFromURL{}\n\t_ caddy.ProxyFuncProducer = ProxyFromURL{}\n\t_ caddyfile.Unmarshaler   = (*ProxyFromURL)(nil)\n\n\t_ caddy.Module            = ProxyFromNone{}\n\t_ caddy.ProxyFuncProducer = ProxyFromNone{}\n\t_ caddyfile.Unmarshaler   = ProxyFromNone{}\n)\n",
    "source_file": "modules/internal/network/networkproxy.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage standardstek\n\nimport (\n\t\"log\"\n\t\"runtime/debug\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(standardSTEKProvider{})\n}\n\ntype standardSTEKProvider struct {\n\tstekConfig *caddytls.SessionTicketService\n\ttimer      *time.Timer\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (standardSTEKProvider) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"tls.stek.standard\",\n\t\tNew: func() caddy.Module { return new(standardSTEKProvider) },\n\t}\n}\n\n// Initialize sets the configuration for s and returns the starting keys.\nfunc (s *standardSTEKProvider) Initialize(config *caddytls.SessionTicketService) ([][32]byte, error) {\n\t// keep a reference to the config; we'll need it when rotating keys\n\ts.stekConfig = config\n\n\titvl := time.Duration(s.stekConfig.RotationInterval)\n\n\tmutex.Lock()\n\tdefer mutex.Unlock()\n\n\t// if this is our first rotation or we are overdue\n\t// for one, perform a rotation immediately; otherwise,\n\t// we assume that the keys are non-empty and fresh\n\tsince := time.Since(lastRotation)\n\tif lastRotation.IsZero() || since > itvl {\n\t\tvar err error\n\t\tkeys, err = s.stekConfig.RotateSTEKs(keys)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tsince = 0 // since this is overdue or is the first rotation, use full interval\n\t\tlastRotation = time.Now()\n\t}\n\n\t// create timer for the remaining time on the interval;\n\t// this timer is cleaned up only when Next() returns\n\ts.timer = time.NewTimer(itvl - since)\n\n\treturn keys, nil\n}\n\n// Next returns a channel which transmits the latest session ticket keys.\nfunc (s *standardSTEKProvider) Next(doneChan <-chan struct{}) <-chan [][32]byte {\n\tkeysChan := make(chan [][32]byte)\n\tgo s.rotate(doneChan, keysChan)\n\treturn keysChan\n}\n\n// rotate rotates keys on a regular basis, sending each updated set of\n// keys down keysChan, until doneChan is closed.\nfunc (s *standardSTEKProvider) rotate(doneChan <-chan struct{}, keysChan chan<- [][32]byte) {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tlog.Printf(\"[PANIC] standard STEK rotation: %v\\n%s\", err, debug.Stack())\n\t\t}\n\t}()\n\tfor {\n\t\tselect {\n\t\tcase now := <-s.timer.C:\n\t\t\t// copy the slice header to avoid races\n\t\t\tmutex.RLock()\n\t\t\tkeysCopy := keys\n\t\t\tmutex.RUnlock()\n\n\t\t\t// generate a new key, rotating old ones\n\t\t\tvar err error\n\t\t\tkeysCopy, err = s.stekConfig.RotateSTEKs(keysCopy)\n\t\t\tif err != nil {\n\t\t\t\t// TODO: improve this handling\n\t\t\t\tlog.Printf(\"[ERROR] Generating STEK: %v\", err)\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// replace keys slice with updated value and\n\t\t\t// record the timestamp of rotation\n\t\t\tmutex.Lock()\n\t\t\tkeys = keysCopy\n\t\t\tlastRotation = now\n\t\t\tmutex.Unlock()\n\n\t\t\t// send the updated keys to the service\n\t\t\tkeysChan <- keysCopy\n\n\t\t\t// timer channel is already drained, so reset directly (see godoc)\n\t\t\ts.timer.Reset(time.Duration(s.stekConfig.RotationInterval))\n\n\t\tcase <-doneChan:\n\t\t\t// again, see godocs for why timer is stopped this way\n\t\t\tif !s.timer.Stop() {\n\t\t\t\t<-s.timer.C\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t}\n}\n\nvar (\n\tlastRotation time.Time\n\tkeys         [][32]byte\n\tmutex        sync.RWMutex // protects keys and lastRotation\n)\n\n// Interface guard\nvar _ caddytls.STEKProvider = (*standardSTEKProvider)(nil)\n",
    "source_file": "modules/caddytls/standardstek/stek.go",
    "chunk_type": "code"
  },
  {
    "content": "package tracing\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"sync\"\n\n\tsdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n)\n\n// globalTracerProvider stores global tracer provider and is responsible for graceful shutdown when nobody is using it.\nvar globalTracerProvider = &tracerProvider{}\n\ntype tracerProvider struct {\n\tmu                     sync.Mutex\n\ttracerProvider         *sdktrace.TracerProvider\n\ttracerProvidersCounter int\n}\n\n// getTracerProvider create or return an existing global TracerProvider\nfunc (t *tracerProvider) getTracerProvider(opts ...sdktrace.TracerProviderOption) *sdktrace.TracerProvider {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\n\tt.tracerProvidersCounter++\n\n\tif t.tracerProvider == nil {\n\t\tt.tracerProvider = sdktrace.NewTracerProvider(\n\t\t\topts...,\n\t\t)\n\t}\n\n\treturn t.tracerProvider\n}\n\n// cleanupTracerProvider gracefully shutdown a TracerProvider\nfunc (t *tracerProvider) cleanupTracerProvider(logger *zap.Logger) error {\n\tt.mu.Lock()\n\tdefer t.mu.Unlock()\n\n\tif t.tracerProvidersCounter > 0 {\n\t\tt.tracerProvidersCounter--\n\t}\n\n\tif t.tracerProvidersCounter == 0 {\n\t\tif t.tracerProvider != nil {\n\t\t\t// tracerProvider.ForceFlush SHOULD be invoked according to https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/sdk.md#forceflush\n\t\t\tif err := t.tracerProvider.ForceFlush(context.Background()); err != nil {\n\t\t\t\tif c := logger.Check(zapcore.ErrorLevel, \"forcing flush\"); c != nil {\n\t\t\t\t\tc.Write(zap.Error(err))\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// tracerProvider.Shutdown MUST be invoked according to https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/sdk.md#shutdown\n\t\t\tif err := t.tracerProvider.Shutdown(context.Background()); err != nil {\n\t\t\t\treturn fmt.Errorf(\"tracerProvider shutdown error: %w\", err)\n\t\t\t}\n\t\t}\n\n\t\tt.tracerProvider = nil\n\t}\n\n\treturn nil\n}\n",
    "source_file": "modules/caddyhttp/tracing/tracerprovider.go",
    "chunk_type": "code"
  },
  {
    "content": "package tracing\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"go.opentelemetry.io/contrib/instrumentation/net/http/otelhttp\"\n\t\"go.opentelemetry.io/contrib/propagators/autoprop\"\n\t\"go.opentelemetry.io/otel/exporters/otlp/otlptrace/otlptracegrpc\"\n\t\"go.opentelemetry.io/otel/propagation\"\n\t\"go.opentelemetry.io/otel/sdk/resource\"\n\tsdktrace \"go.opentelemetry.io/otel/sdk/trace\"\n\tsemconv \"go.opentelemetry.io/otel/semconv/v1.17.0\"\n\t\"go.opentelemetry.io/otel/trace\"\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nconst (\n\twebEngineName                = \"Caddy\"\n\tdefaultSpanName              = \"handler\"\n\tnextCallCtxKey  caddy.CtxKey = \"nextCall\"\n)\n\n// nextCall store the next handler, and the error value return on calling it (if any)\ntype nextCall struct {\n\tnext caddyhttp.Handler\n\terr  error\n}\n\n// openTelemetryWrapper is responsible for the tracing injection, extraction and propagation.\ntype openTelemetryWrapper struct {\n\tpropagators propagation.TextMapPropagator\n\n\thandler http.Handler\n\n\tspanName string\n}\n\n// newOpenTelemetryWrapper is responsible for the openTelemetryWrapper initialization using provided configuration.\nfunc newOpenTelemetryWrapper(\n\tctx context.Context,\n\tspanName string,\n) (openTelemetryWrapper, error) {\n\tif spanName == \"\" {\n\t\tspanName = defaultSpanName\n\t}\n\n\tot := openTelemetryWrapper{\n\t\tspanName: spanName,\n\t}\n\n\tversion, _ := caddy.Version()\n\tres, err := ot.newResource(webEngineName, version)\n\tif err != nil {\n\t\treturn ot, fmt.Errorf(\"creating resource error: %w\", err)\n\t}\n\n\ttraceExporter, err := otlptracegrpc.New(ctx)\n\tif err != nil {\n\t\treturn ot, fmt.Errorf(\"creating trace exporter error: %w\", err)\n\t}\n\n\tot.propagators = autoprop.NewTextMapPropagator()\n\n\ttracerProvider := globalTracerProvider.getTracerProvider(\n\t\tsdktrace.WithBatcher(traceExporter),\n\t\tsdktrace.WithResource(res),\n\t)\n\n\tot.handler = otelhttp.NewHandler(http.HandlerFunc(ot.serveHTTP),\n\t\tot.spanName,\n\t\totelhttp.WithTracerProvider(tracerProvider),\n\t\totelhttp.WithPropagators(ot.propagators),\n\t\totelhttp.WithSpanNameFormatter(ot.spanNameFormatter),\n\t)\n\n\treturn ot, nil\n}\n\n// serveHTTP injects a tracing context and call the next handler.\nfunc (ot *openTelemetryWrapper) serveHTTP(w http.ResponseWriter, r *http.Request) {\n\tctx := r.Context()\n\tot.propagators.Inject(ctx, propagation.HeaderCarrier(r.Header))\n\tspanCtx := trace.SpanContextFromContext(ctx)\n\tif spanCtx.IsValid() {\n\t\ttraceID := spanCtx.TraceID().String()\n\t\tspanID := spanCtx.SpanID().String()\n\t\t// Add a trace_id placeholder, accessible via `{http.vars.trace_id}`.\n\t\tcaddyhttp.SetVar(ctx, \"trace_id\", traceID)\n\t\t// Add a span_id placeholder, accessible via `{http.vars.span_id}`.\n\t\tcaddyhttp.SetVar(ctx, \"span_id\", spanID)\n\t\t// Add the traceID and spanID to the log fields for the request.\n\t\tif extra, ok := ctx.Value(caddyhttp.ExtraLogFieldsCtxKey).(*caddyhttp.ExtraLogFields); ok {\n\t\t\textra.Add(zap.String(\"traceID\", traceID))\n\t\t\textra.Add(zap.String(\"spanID\", spanID))\n\t\t}\n\t}\n\tnext := ctx.Value(nextCallCtxKey).(*nextCall)\n\tnext.err = next.next.ServeHTTP(w, r)\n}\n\n// ServeHTTP propagates call to the by wrapped by `otelhttp` next handler.\nfunc (ot *openTelemetryWrapper) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\tn := &nextCall{\n\t\tnext: next,\n\t\terr:  nil,\n\t}\n\tot.handler.ServeHTTP(w, r.WithContext(context.WithValue(r.Context(), nextCallCtxKey, n)))\n\n\treturn n.err\n}\n\n// cleanup flush all remaining data and shutdown a tracerProvider\nfunc (ot *openTelemetryWrapper) cleanup(logger *zap.Logger) error {\n\treturn globalTracerProvider.cleanupTracerProvider(logger)\n}\n\n// newResource creates a resource that describe current handler instance and merge it with a default attributes value.\nfunc (ot *openTelemetryWrapper) newResource(\n\twebEngineName,\n\twebEngineVersion string,\n) (*resource.Resource, error) {\n\treturn resource.Merge(resource.Default(), resource.NewSchemaless(\n\t\tsemconv.WebEngineName(webEngineName),\n\t\tsemconv.WebEngineVersion(webEngineVersion),\n\t))\n}\n\n// spanNameFormatter performs the replacement of placeholders in the span name\nfunc (ot *openTelemetryWrapper) spanNameFormatter(operation string, r *http.Request) string {\n\treturn r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer).ReplaceAll(operation, \"\")\n}\n",
    "source_file": "modules/caddyhttp/tracing/tracer.go",
    "chunk_type": "code"
  },
  {
    "content": "package tracing\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Tracing{})\n\thttpcaddyfile.RegisterHandlerDirective(\"tracing\", parseCaddyfile)\n}\n\n// Tracing implements an HTTP handler that adds support for distributed tracing,\n// using OpenTelemetry. This module is responsible for the injection and\n// propagation of the trace context. Configure this module via environment\n// variables (see https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/sdk-environment-variables.md).\n// Some values can be overwritten in the configuration file.\ntype Tracing struct {\n\t// SpanName is a span name. It should follow the naming guidelines here:\n\t// https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/api.md#span\n\tSpanName string `json:\"span\"`\n\n\t// otel implements opentelemetry related logic.\n\totel openTelemetryWrapper\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Tracing) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.tracing\",\n\t\tNew: func() caddy.Module { return new(Tracing) },\n\t}\n}\n\n// Provision implements caddy.Provisioner.\nfunc (ot *Tracing) Provision(ctx caddy.Context) error {\n\tot.logger = ctx.Logger()\n\n\tvar err error\n\tot.otel, err = newOpenTelemetryWrapper(ctx, ot.SpanName)\n\n\treturn err\n}\n\n// Cleanup implements caddy.CleanerUpper and closes any idle connections. It\n// calls Shutdown method for a trace provider https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/sdk.md#shutdown.\nfunc (ot *Tracing) Cleanup() error {\n\tif err := ot.otel.cleanup(ot.logger); err != nil {\n\t\treturn fmt.Errorf(\"tracerProvider shutdown: %w\", err)\n\t}\n\treturn nil\n}\n\n// ServeHTTP implements caddyhttp.MiddlewareHandler.\nfunc (ot *Tracing) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\treturn ot.otel.ServeHTTP(w, r, next)\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens. Syntax:\n//\n//\ttracing {\n//\t    [span <span_name>]\n//\t}\nfunc (ot *Tracing) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\tsetParameter := func(d *caddyfile.Dispenser, val *string) error {\n\t\tif d.NextArg() {\n\t\t\t*val = d.Val()\n\t\t} else {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t\tif d.NextArg() {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t\treturn nil\n\t}\n\n\t// paramsMap is a mapping between \"string\" parameter from the Caddyfile and its destination within the module\n\tparamsMap := map[string]*string{\n\t\t\"span\": &ot.SpanName,\n\t}\n\n\td.Next() // consume directive name\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tif dst, ok := paramsMap[d.Val()]; ok {\n\t\t\tif err := setParameter(d, dst); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t} else {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc parseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\tvar m Tracing\n\terr := m.UnmarshalCaddyfile(h.Dispenser)\n\treturn &m, err\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*Tracing)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*Tracing)(nil)\n\t_ caddyfile.Unmarshaler       = (*Tracing)(nil)\n)\n",
    "source_file": "modules/caddyhttp/tracing/module.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage rewrite\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"regexp\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Rewrite{})\n}\n\n// Rewrite is a middleware which can rewrite/mutate HTTP requests.\n//\n// The Method and URI properties are \"setters\" (the request URI\n// will be overwritten with the given values). Other properties are\n// \"modifiers\" (they modify existing values in a differentiable\n// way). It is atypical to combine the use of setters and\n// modifiers in a single rewrite.\n//\n// To ensure consistent behavior, prefix and suffix stripping is\n// performed in the URL-decoded (unescaped, normalized) space by\n// default except for the specific bytes where an escape sequence\n// is used in the prefix or suffix pattern.\n//\n// For all modifiers, paths are cleaned before being modified so that\n// multiple, consecutive slashes are collapsed into a single slash,\n// and dot elements are resolved and removed. In the special case\n// of a prefix, suffix, or substring containing \"//\" (repeated slashes),\n// slashes will not be merged while cleaning the path so that\n// the rewrite can be interpreted literally.\ntype Rewrite struct {\n\t// Changes the request's HTTP verb.\n\tMethod string `json:\"method,omitempty\"`\n\n\t// Changes the request's URI, which consists of path and query string.\n\t// Only components of the URI that are specified will be changed.\n\t// For example, a value of \"/foo.html\" or \"foo.html\" will only change\n\t// the path and will preserve any existing query string. Similarly, a\n\t// value of \"?a=b\" will only change the query string and will not affect\n\t// the path. Both can also be changed: \"/foo?a=b\" - this sets both the\n\t// path and query string at the same time.\n\t//\n\t// You can also use placeholders. For example, to preserve the existing\n\t// query string, you might use: \"?{http.request.uri.query}&a=b\". Any\n\t// key-value pairs you add to the query string will not overwrite\n\t// existing values (individual pairs are append-only).\n\t//\n\t// To clear the query string, explicitly set an empty one: \"?\"\n\tURI string `json:\"uri,omitempty\"`\n\n\t// Strips the given prefix from the beginning of the URI path.\n\t// The prefix should be written in normalized (unescaped) form,\n\t// but if an escaping (`%xx`) is used, the path will be required\n\t// to have that same escape at that position in order to match.\n\tStripPathPrefix string `json:\"strip_path_prefix,omitempty\"`\n\n\t// Strips the given suffix from the end of the URI path.\n\t// The suffix should be written in normalized (unescaped) form,\n\t// but if an escaping (`%xx`) is used, the path will be required\n\t// to have that same escape at that position in order to match.\n\tStripPathSuffix string `json:\"strip_path_suffix,omitempty\"`\n\n\t// Performs substring replacements on the URI.\n\tURISubstring []substrReplacer `json:\"uri_substring,omitempty\"`\n\n\t// Performs regular expression replacements on the URI path.\n\tPathRegexp []*regexReplacer `json:\"path_regexp,omitempty\"`\n\n\t// Mutates the query string of the URI.\n\tQuery *queryOps `json:\"query,omitempty\"`\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Rewrite) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.rewrite\",\n\t\tNew: func() caddy.Module { return new(Rewrite) },\n\t}\n}\n\n// Provision sets up rewr.\nfunc (rewr *Rewrite) Provision(ctx caddy.Context) error {\n\trewr.logger = ctx.Logger()\n\n\tfor i, rep := range rewr.PathRegexp {\n\t\tif rep.Find == \"\" {\n\t\t\treturn fmt.Errorf(\"path_regexp find cannot be empty\")\n\t\t}\n\t\tre, err := regexp.Compile(rep.Find)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"compiling regular expression %d: %v\", i, err)\n\t\t}\n\t\trep.re = re\n\t}\n\tif rewr.Query != nil {\n\t\tfor _, replacementOp := range rewr.Query.Replace {\n\t\t\terr := replacementOp.Provision(ctx)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"compiling regular expression %s in query rewrite replace operation: %v\", replacementOp.SearchRegexp, err)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (rewr Rewrite) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tconst message = \"rewrote request\"\n\n\tc := rewr.logger.Check(zap.DebugLevel, message)\n\tif c == nil {\n\t\trewr.Rewrite(r, repl)\n\t\treturn next.ServeHTTP(w, r)\n\t}\n\n\tchanged := rewr.Rewrite(r, repl)\n\n\tif changed {\n\t\tc.Write(\n\t\t\tzap.Object(\"request\", caddyhttp.LoggableHTTPRequest{Request: r}),\n\t\t\tzap.String(\"method\", r.Method),\n\t\t\tzap.String(\"uri\", r.RequestURI),\n\t\t)\n\t}\n\n\treturn next.ServeHTTP(w, r)\n}\n\n// rewrite performs the rewrites on r using repl, which should\n// have been obtained from r, but is passed in for efficiency.\n// It returns true if any changes were made to r.\nfunc (rewr Rewrite) Rewrite(r *http.Request, repl *caddy.Replacer) bool {\n\toldMethod := r.Method\n\toldURI := r.RequestURI\n\n\t// method\n\tif rewr.Method != \"\" {\n\t\tr.Method = strings.ToUpper(repl.ReplaceAll(rewr.Method, \"\"))\n\t}\n\n\t// uri (path, query string and... fragment, because why not)\n\tif uri := rewr.URI; uri != \"\" {\n\t\t// find the bounds of each part of the URI that exist\n\t\tpathStart, qsStart, fragStart := -1, -1, -1\n\t\tpathEnd, qsEnd := -1, -1\n\tloop:\n\t\tfor i, ch := range uri {\n\t\t\tswitch {\n\t\t\tcase ch == '?' && qsStart < 0:\n\t\t\t\tpathEnd, qsStart = i, i+1\n\t\t\tcase ch == '#' && fragStart < 0: // everything after fragment is fragment (very clear in RFC 3986 section 4.2)\n\t\t\t\tif qsStart < 0 {\n\t\t\t\t\tpathEnd = i\n\t\t\t\t} else {\n\t\t\t\t\tqsEnd = i\n\t\t\t\t}\n\t\t\t\tfragStart = i + 1\n\t\t\t\tbreak loop\n\t\t\tcase pathStart < 0 && qsStart < 0:\n\t\t\t\tpathStart = i\n\t\t\t}\n\t\t}\n\t\tif pathStart >= 0 && pathEnd < 0 {\n\t\t\tpathEnd = len(uri)\n\t\t}\n\t\tif qsStart >= 0 && qsEnd < 0 {\n\t\t\tqsEnd = len(uri)\n\t\t}\n\n\t\t// isolate the three main components of the URI\n\t\tvar path, query, frag string\n\t\tif pathStart > -1 {\n\t\t\tpath = uri[pathStart:pathEnd]\n\t\t}\n\t\tif qsStart > -1 {\n\t\t\tquery = uri[qsStart:qsEnd]\n\t\t}\n\t\tif fragStart > -1 {\n\t\t\tfrag = uri[fragStart:]\n\t\t}\n\n\t\t// build components which are specified, and store them\n\t\t// in a temporary variable so that they all read the\n\t\t// same version of the URI\n\t\tvar newPath, newQuery, newFrag string\n\n\t\tif path != \"\" {\n\t\t\t// replace the `path` placeholder to escaped path\n\t\t\tpathPlaceholder := \"{http.request.uri.path}\"\n\t\t\tif strings.Contains(path, pathPlaceholder) {\n\t\t\t\tpath = strings.ReplaceAll(path, pathPlaceholder, r.URL.EscapedPath())\n\t\t\t}\n\n\t\t\tnewPath = repl.ReplaceAll(path, \"\")\n\t\t}\n\n\t\t// before continuing, we need to check if a query string\n\t\t// snuck into the path component during replacements\n\t\tif before, after, found := strings.Cut(newPath, \"?\"); found {\n\t\t\t// recompute; new path contains a query string\n\t\t\tvar injectedQuery string\n\t\t\tnewPath, injectedQuery = before, after\n\t\t\t// don't overwrite explicitly-configured query string\n\t\t\tif query == \"\" {\n\t\t\t\tquery = injectedQuery\n\t\t\t}\n\t\t}\n\n\t\tif query != \"\" {\n\t\t\tnewQuery = buildQueryString(query, repl)\n\t\t}\n\t\tif frag != \"\" {\n\t\t\tnewFrag = repl.ReplaceAll(frag, \"\")\n\t\t}\n\n\t\t// update the URI with the new components\n\t\t// only after building them\n\t\tif pathStart >= 0 {\n\t\t\tif path, err := url.PathUnescape(newPath); err != nil {\n\t\t\t\tr.URL.Path = newPath\n\t\t\t} else {\n\t\t\t\tr.URL.Path = path\n\t\t\t}\n\t\t}\n\t\tif qsStart >= 0 {\n\t\t\tr.URL.RawQuery = newQuery\n\t\t}\n\t\tif fragStart >= 0 {\n\t\t\tr.URL.Fragment = newFrag\n\t\t}\n\t}\n\n\t// strip path prefix or suffix\n\tif rewr.StripPathPrefix != \"\" {\n\t\tprefix := repl.ReplaceAll(rewr.StripPathPrefix, \"\")\n\t\tif !strings.HasPrefix(prefix, \"/\") {\n\t\t\tprefix = \"/\" + prefix\n\t\t}\n\t\tmergeSlashes := !strings.Contains(prefix, \"//\")\n\t\tchangePath(r, func(escapedPath string) string {\n\t\t\tescapedPath = caddyhttp.CleanPath(escapedPath, mergeSlashes)\n\t\t\treturn trimPathPrefix(escapedPath, prefix)\n\t\t})\n\t}\n\tif rewr.StripPathSuffix != \"\" {\n\t\tsuffix := repl.ReplaceAll(rewr.StripPathSuffix, \"\")\n\t\tmergeSlashes := !strings.Contains(suffix, \"//\")\n\t\tchangePath(r, func(escapedPath string) string {\n\t\t\tescapedPath = caddyhttp.CleanPath(escapedPath, mergeSlashes)\n\t\t\treturn reverse(trimPathPrefix(reverse(escapedPath), reverse(suffix)))\n\t\t})\n\t}\n\n\t// substring replacements in URI\n\tfor _, rep := range rewr.URISubstring {\n\t\trep.do(r, repl)\n\t}\n\n\t// regular expression replacements on the path\n\tfor _, rep := range rewr.PathRegexp {\n\t\trep.do(r, repl)\n\t}\n\n\t// apply query operations\n\tif rewr.Query != nil {\n\t\trewr.Query.do(r, repl)\n\t}\n\n\t// update the encoded copy of the URI\n\tr.RequestURI = r.URL.RequestURI()\n\n\t// return true if anything changed\n\treturn r.Method != oldMethod || r.RequestURI != oldURI\n}\n\n// buildQueryString takes an input query string and\n// performs replacements on each component, returning\n// the resulting query string. This function appends\n// duplicate keys rather than replaces.\nfunc buildQueryString(qs string, repl *caddy.Replacer) string {\n\tvar sb strings.Builder\n\n\t// first component must be key, which is the same\n\t// as if we just wrote a value in previous iteration\n\twroteVal := true\n\n\tfor len(qs) > 0 {\n\t\t// determine the end of this component, which will be at\n\t\t// the next equal sign or ampersand, whichever comes first\n\t\tnextEq, nextAmp := strings.Index(qs, \"=\"), strings.Index(qs, \"&\")\n\t\tampIsNext := nextAmp >= 0 && (nextAmp < nextEq || nextEq < 0)\n\t\tend := len(qs) // assume no delimiter remains...\n\t\tif ampIsNext {\n\t\t\tend = nextAmp // ...unless ampersand is first...\n\t\t} else if nextEq >= 0 && (nextEq < nextAmp || nextAmp < 0) {\n\t\t\tend = nextEq // ...or unless equal is first.\n\t\t}\n\n\t\t// consume the component and write the result\n\t\tcomp := qs[:end]\n\t\tcomp, _ = repl.ReplaceFunc(comp, func(name string, val any) (any, error) {\n\t\t\tif name == \"http.request.uri.query\" && wroteVal {\n\t\t\t\treturn val, nil // already escaped\n\t\t\t}\n\t\t\tvar valStr string\n\t\t\tswitch v := val.(type) {\n\t\t\tcase string:\n\t\t\t\tvalStr = v\n\t\t\tcase fmt.Stringer:\n\t\t\t\tvalStr = v.String()\n\t\t\tcase int:\n\t\t\t\tvalStr = strconv.Itoa(v)\n\t\t\tdefault:\n\t\t\t\tvalStr = fmt.Sprintf(\"%+v\", v)\n\t\t\t}\n\t\t\treturn url.QueryEscape(valStr), nil\n\t\t})\n\t\tif end < len(qs) {\n\t\t\tend++ // consume delimiter\n\t\t}\n\t\tqs = qs[end:]\n\n\t\t// if previous iteration wrote a value,\n\t\t// that means we are writing a key\n\t\tif wroteVal {\n\t\t\tif sb.Len() > 0 && len(comp) > 0 {\n\t\t\t\tsb.WriteRune('&')\n\t\t\t}\n\t\t} else {\n\t\t\tsb.WriteRune('=')\n\t\t}\n\t\tsb.WriteString(comp)\n\n\t\t// remember for the next iteration that we just wrote a value,\n\t\t// which means the next iteration MUST write a key\n\t\twroteVal = ampIsNext\n\t}\n\n\treturn sb.String()\n}\n\n// trimPathPrefix is like strings.TrimPrefix, but customized for advanced URI\n// path prefix matching. The string prefix will be trimmed from the beginning\n// of escapedPath if escapedPath starts with prefix. Rather than a naive 1:1\n// comparison of each byte to determine if escapedPath starts with prefix,\n// both strings are iterated in lock-step, and if prefix has a '%' encoding\n// at a particular position, escapedPath must also have the same encoding\n// representation for that character. In other words, if the prefix string\n// uses the escaped form for a character, escapedPath must literally use the\n// same escape at that position. Otherwise, all character comparisons are\n// performed in normalized/unescaped space.\nfunc trimPathPrefix(escapedPath, prefix string) string {\n\tvar iPath, iPrefix int\n\tfor iPath < len(escapedPath) && iPrefix < len(prefix) {\n\t\tprefixCh := prefix[iPrefix]\n\t\tch := string(escapedPath[iPath])\n\n\t\tif ch == \"%\" && prefixCh != '%' && len(escapedPath) >= iPath+3 {\n\t\t\tvar err error\n\t\t\tch, err = url.PathUnescape(escapedPath[iPath : iPath+3])\n\t\t\tif err != nil {\n\t\t\t\t// should be impossible unless EscapedPath() is returning invalid values!\n\t\t\t\treturn escapedPath\n\t\t\t}\n\t\t\tiPath += 2\n\t\t}\n\n\t\t// prefix comparisons are case-insensitive to consistency with\n\t\t// path matcher, which is case-insensitive for good reasons\n\t\tif !strings.EqualFold(ch, string(prefixCh)) {\n\t\t\treturn escapedPath\n\t\t}\n\n\t\tiPath++\n\t\tiPrefix++\n\t}\n\n\t// if we iterated through the entire prefix, we found it, so trim it\n\tif iPath >= len(prefix) {\n\t\treturn escapedPath[iPath:]\n\t}\n\n\t// otherwise we did not find the prefix\n\treturn escapedPath\n}\n\nfunc reverse(s string) string {\n\tr := []rune(s)\n\tfor i, j := 0, len(r)-1; i < len(r)/2; i, j = i+1, j-1 {\n\t\tr[i], r[j] = r[j], r[i]\n\t}\n\treturn string(r)\n}\n\n// substrReplacer describes either a simple and fast substring replacement.\ntype substrReplacer struct {\n\t// A substring to find. Supports placeholders.\n\tFind string `json:\"find,omitempty\"`\n\n\t// The substring to replace with. Supports placeholders.\n\tReplace string `json:\"replace,omitempty\"`\n\n\t// Maximum number of replacements per string.\n\t// Set to <= 0 for no limit (default).\n\tLimit int `json:\"limit,omitempty\"`\n}\n\n// do performs the substring replacement on r.\nfunc (rep substrReplacer) do(r *http.Request, repl *caddy.Replacer) {\n\tif rep.Find == \"\" {\n\t\treturn\n\t}\n\n\tlim := rep.Limit\n\tif lim == 0 {\n\t\tlim = -1\n\t}\n\n\tfind := repl.ReplaceAll(rep.Find, \"\")\n\treplace := repl.ReplaceAll(rep.Replace, \"\")\n\n\tmergeSlashes := !strings.Contains(rep.Find, \"//\")\n\n\tchangePath(r, func(pathOrRawPath string) string {\n\t\treturn strings.Replace(caddyhttp.CleanPath(pathOrRawPath, mergeSlashes), find, replace, lim)\n\t})\n\n\tr.URL.RawQuery = strings.Replace(r.URL.RawQuery, find, replace, lim)\n}\n\n// regexReplacer describes a replacement using a regular expression.\ntype regexReplacer struct {\n\t// The regular expression to find.\n\tFind string `json:\"find,omitempty\"`\n\n\t// The substring to replace with. Supports placeholders and\n\t// regular expression capture groups.\n\tReplace string `json:\"replace,omitempty\"`\n\n\tre *regexp.Regexp\n}\n\nfunc (rep regexReplacer) do(r *http.Request, repl *caddy.Replacer) {\n\tif rep.Find == \"\" || rep.re == nil {\n\t\treturn\n\t}\n\treplace := repl.ReplaceAll(rep.Replace, \"\")\n\tchangePath(r, func(pathOrRawPath string) string {\n\t\treturn rep.re.ReplaceAllString(pathOrRawPath, replace)\n\t})\n}\n\nfunc changePath(req *http.Request, newVal func(pathOrRawPath string) string) {\n\treq.URL.RawPath = newVal(req.URL.EscapedPath())\n\tif p, err := url.PathUnescape(req.URL.RawPath); err == nil && p != \"\" {\n\t\treq.URL.Path = p\n\t} else {\n\t\treq.URL.Path = newVal(req.URL.Path)\n\t}\n\t// RawPath is only set if it's different from the normalized Path (std lib)\n\tif req.URL.RawPath == req.URL.Path {\n\t\treq.URL.RawPath = \"\"\n\t}\n}\n\n// queryOps describes the operations to perform on query keys: add, set, rename and delete.\ntype queryOps struct {\n\t// Renames a query key from Key to Val, without affecting the value.\n\tRename []queryOpsArguments `json:\"rename,omitempty\"`\n\n\t// Sets query parameters; overwrites a query key with the given value.\n\tSet []queryOpsArguments `json:\"set,omitempty\"`\n\n\t// Adds query parameters; does not overwrite an existing query field,\n\t// and only appends an additional value for that key if any already exist.\n\tAdd []queryOpsArguments `json:\"add,omitempty\"`\n\n\t// Replaces query parameters.\n\tReplace []*queryOpsReplacement `json:\"replace,omitempty\"`\n\n\t// Deletes a given query key by name.\n\tDelete []string `json:\"delete,omitempty\"`\n}\n\n// Provision compiles the query replace operation regex.\nfunc (replacement *queryOpsReplacement) Provision(_ caddy.Context) error {\n\tif replacement.SearchRegexp != \"\" {\n\t\tre, err := regexp.Compile(replacement.SearchRegexp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"replacement for query field '%s': %v\", replacement.Key, err)\n\t\t}\n\t\treplacement.re = re\n\t}\n\treturn nil\n}\n\nfunc (q *queryOps) do(r *http.Request, repl *caddy.Replacer) {\n\tquery := r.URL.Query()\n\tfor _, renameParam := range q.Rename {\n\t\tkey := repl.ReplaceAll(renameParam.Key, \"\")\n\t\tval := repl.ReplaceAll(renameParam.Val, \"\")\n\t\tif key == \"\" || val == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tquery[val] = query[key]\n\t\tdelete(query, key)\n\t}\n\n\tfor _, setParam := range q.Set {\n\t\tkey := repl.ReplaceAll(setParam.Key, \"\")\n\t\tif key == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tval := repl.ReplaceAll(setParam.Val, \"\")\n\t\tquery[key] = []string{val}\n\t}\n\n\tfor _, addParam := range q.Add {\n\t\tkey := repl.ReplaceAll(addParam.Key, \"\")\n\t\tif key == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tval := repl.ReplaceAll(addParam.Val, \"\")\n\t\tquery[key] = append(query[key], val)\n\t}\n\n\tfor _, replaceParam := range q.Replace {\n\t\tkey := repl.ReplaceAll(replaceParam.Key, \"\")\n\t\tsearch := repl.ReplaceKnown(replaceParam.Search, \"\")\n\t\treplace := repl.ReplaceKnown(replaceParam.Replace, \"\")\n\n\t\t// replace all query keys...\n\t\tif key == \"*\" {\n\t\t\tfor fieldName, vals := range query {\n\t\t\t\tfor i := range vals {\n\t\t\t\t\tif replaceParam.re != nil {\n\t\t\t\t\t\tquery[fieldName][i] = replaceParam.re.ReplaceAllString(query[fieldName][i], replace)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tquery[fieldName][i] = strings.ReplaceAll(query[fieldName][i], search, replace)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tfor fieldName, vals := range query {\n\t\t\tfor i := range vals {\n\t\t\t\tif replaceParam.re != nil {\n\t\t\t\t\tquery[fieldName][i] = replaceParam.re.ReplaceAllString(query[fieldName][i], replace)\n\t\t\t\t} else {\n\t\t\t\t\tquery[fieldName][i] = strings.ReplaceAll(query[fieldName][i], search, replace)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, deleteParam := range q.Delete {\n\t\tparam := repl.ReplaceAll(deleteParam, \"\")\n\t\tif param == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tdelete(query, param)\n\t}\n\n\tr.URL.RawQuery = query.Encode()\n}\n\ntype queryOpsArguments struct {\n\t// A key in the query string. Note that query string keys may appear multiple times.\n\tKey string `json:\"key,omitempty\"`\n\n\t// The value for the given operation; for add and set, this is\n\t// simply the value of the query, and for rename this is the\n\t// query key to rename to.\n\tVal string `json:\"val,omitempty\"`\n}\n\ntype queryOpsReplacement struct {\n\t// The key to replace in the query string.\n\tKey string `json:\"key,omitempty\"`\n\n\t// The substring to search for.\n\tSearch string `json:\"search,omitempty\"`\n\n\t// The regular expression to search with.\n\tSearchRegexp string `json:\"search_regexp,omitempty\"`\n\n\t// The string with which to replace matches.\n\tReplace string `json:\"replace,omitempty\"`\n\n\tre *regexp.Regexp\n}\n\n// Interface guard\nvar _ caddyhttp.MiddlewareHandler = (*Rewrite)(nil)\n",
    "source_file": "modules/caddyhttp/rewrite/rewrite.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage rewrite\n\nimport (\n\t\"encoding/json\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterDirective(\"rewrite\", parseCaddyfileRewrite)\n\thttpcaddyfile.RegisterHandlerDirective(\"method\", parseCaddyfileMethod)\n\thttpcaddyfile.RegisterHandlerDirective(\"uri\", parseCaddyfileURI)\n\thttpcaddyfile.RegisterDirective(\"handle_path\", parseCaddyfileHandlePath)\n}\n\n// parseCaddyfileRewrite sets up a basic rewrite handler from Caddyfile tokens. Syntax:\n//\n//\trewrite [<matcher>] <to>\n//\n// Only URI components which are given in <to> will be set in the resulting URI.\n// See the docs for the rewrite handler for more information.\nfunc parseCaddyfileRewrite(h httpcaddyfile.Helper) ([]httpcaddyfile.ConfigValue, error) {\n\th.Next() // consume directive name\n\n\t// count the tokens to determine what to do\n\targsCount := h.CountRemainingArgs()\n\tif argsCount == 0 {\n\t\treturn nil, h.Errf(\"too few arguments; must have at least a rewrite URI\")\n\t}\n\tif argsCount > 2 {\n\t\treturn nil, h.Errf(\"too many arguments; should only be a matcher and a URI\")\n\t}\n\n\t// with only one arg, assume it's a rewrite URI with no matcher token\n\tif argsCount == 1 {\n\t\tif !h.NextArg() {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\t\treturn h.NewRoute(nil, Rewrite{URI: h.Val()}), nil\n\t}\n\n\t// parse the matcher token into a matcher set\n\tuserMatcherSet, err := h.ExtractMatcherSet()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\th.Next() // consume directive name again, matcher parsing does a reset\n\th.Next() // advance to the rewrite URI\n\n\treturn h.NewRoute(userMatcherSet, Rewrite{URI: h.Val()}), nil\n}\n\n// parseCaddyfileMethod sets up a basic method rewrite handler from Caddyfile tokens. Syntax:\n//\n//\tmethod [<matcher>] <method>\nfunc parseCaddyfileMethod(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\tif !h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\tif h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\treturn Rewrite{Method: h.Val()}, nil\n}\n\n// parseCaddyfileURI sets up a handler for manipulating (but not \"rewriting\") the\n// URI from Caddyfile tokens. Syntax:\n//\n//\turi [<matcher>] strip_prefix|strip_suffix|replace|path_regexp <target> [<replacement> [<limit>]]\n//\n// If strip_prefix or strip_suffix are used, then <target> will be stripped\n// only if it is the beginning or the end, respectively, of the URI path. If\n// replace is used, then <target> will be replaced with <replacement> across\n// the whole URI, up to <limit> times (or unlimited if unspecified). If\n// path_regexp is used, then regular expression replacements will be performed\n// on the path portion of the URI (and a limit cannot be set).\nfunc parseCaddyfileURI(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\n\targs := h.RemainingArgs()\n\tif len(args) < 1 {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\tvar rewr Rewrite\n\n\tswitch args[0] {\n\tcase \"strip_prefix\":\n\t\tif len(args) != 2 {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\t\trewr.StripPathPrefix = args[1]\n\n\tcase \"strip_suffix\":\n\t\tif len(args) != 2 {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\t\trewr.StripPathSuffix = args[1]\n\n\tcase \"replace\":\n\t\tvar find, replace, lim string\n\t\tswitch len(args) {\n\t\tcase 4:\n\t\t\tlim = args[3]\n\t\t\tfallthrough\n\t\tcase 3:\n\t\t\tfind = args[1]\n\t\t\treplace = args[2]\n\t\tdefault:\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\n\t\tvar limInt int\n\t\tif lim != \"\" {\n\t\t\tvar err error\n\t\t\tlimInt, err = strconv.Atoi(lim)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, h.Errf(\"limit must be an integer; invalid: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\trewr.URISubstring = append(rewr.URISubstring, substrReplacer{\n\t\t\tFind:    find,\n\t\t\tReplace: replace,\n\t\t\tLimit:   limInt,\n\t\t})\n\n\tcase \"path_regexp\":\n\t\tif len(args) != 3 {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\t\tfind, replace := args[1], args[2]\n\t\trewr.PathRegexp = append(rewr.PathRegexp, &regexReplacer{\n\t\t\tFind:    find,\n\t\t\tReplace: replace,\n\t\t})\n\n\tcase \"query\":\n\t\tif len(args) > 4 {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\t\trewr.Query = &queryOps{}\n\t\tvar hasArgs bool\n\t\tif len(args) > 1 {\n\t\t\thasArgs = true\n\t\t\terr := applyQueryOps(h, rewr.Query, args[1:])\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\n\t\tfor h.NextBlock(0) {\n\t\t\tif hasArgs {\n\t\t\t\treturn nil, h.Err(\"Cannot specify uri query rewrites in both argument and block\")\n\t\t\t}\n\t\t\tqueryArgs := []string{h.Val()}\n\t\t\tqueryArgs = append(queryArgs, h.RemainingArgs()...)\n\t\t\terr := applyQueryOps(h, rewr.Query, queryArgs)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t}\n\n\tdefault:\n\t\treturn nil, h.Errf(\"unrecognized URI manipulation '%s'\", args[0])\n\t}\n\treturn rewr, nil\n}\n\nfunc applyQueryOps(h httpcaddyfile.Helper, qo *queryOps, args []string) error {\n\tkey := args[0]\n\tswitch {\n\tcase strings.HasPrefix(key, \"-\"):\n\t\tif len(args) != 1 {\n\t\t\treturn h.ArgErr()\n\t\t}\n\t\tqo.Delete = append(qo.Delete, strings.TrimLeft(key, \"-\"))\n\n\tcase strings.HasPrefix(key, \"+\"):\n\t\tif len(args) != 2 {\n\t\t\treturn h.ArgErr()\n\t\t}\n\t\tparam := strings.TrimLeft(key, \"+\")\n\t\tqo.Add = append(qo.Add, queryOpsArguments{Key: param, Val: args[1]})\n\n\tcase strings.Contains(key, \">\"):\n\t\tif len(args) != 1 {\n\t\t\treturn h.ArgErr()\n\t\t}\n\t\trenameValKey := strings.Split(key, \">\")\n\t\tqo.Rename = append(qo.Rename, queryOpsArguments{Key: renameValKey[0], Val: renameValKey[1]})\n\n\tcase len(args) == 3:\n\t\tqo.Replace = append(qo.Replace, &queryOpsReplacement{Key: key, SearchRegexp: args[1], Replace: args[2]})\n\n\tdefault:\n\t\tif len(args) != 2 {\n\t\t\treturn h.ArgErr()\n\t\t}\n\t\tqo.Set = append(qo.Set, queryOpsArguments{Key: key, Val: args[1]})\n\t}\n\treturn nil\n}\n\n// parseCaddyfileHandlePath parses the handle_path directive. Syntax:\n//\n//\thandle_path [<matcher>] {\n//\t    <directives...>\n//\t}\n//\n// Only path matchers (with a `/` prefix) are supported as this is a shortcut\n// for the handle directive with a strip_prefix rewrite.\nfunc parseCaddyfileHandlePath(h httpcaddyfile.Helper) ([]httpcaddyfile.ConfigValue, error) {\n\th.Next() // consume directive name\n\n\t// there must be a path matcher\n\tif !h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\t// read the prefix to strip\n\tpath := h.Val()\n\tif !strings.HasPrefix(path, \"/\") {\n\t\treturn nil, h.Errf(\"path matcher must begin with '/', got %s\", path)\n\t}\n\n\t// we only want to strip what comes before the '/' if\n\t// the user specified it (e.g. /api/* should only strip /api)\n\tvar stripPath string\n\tif strings.HasSuffix(path, \"/*\") {\n\t\tstripPath = path[:len(path)-2]\n\t} else if strings.HasSuffix(path, \"*\") {\n\t\tstripPath = path[:len(path)-1]\n\t} else {\n\t\tstripPath = path\n\t}\n\n\t// the ParseSegmentAsSubroute function expects the cursor\n\t// to be at the token just before the block opening,\n\t// so we need to rewind because we already read past it\n\th.Reset()\n\th.Next()\n\n\t// parse the block contents as a subroute handler\n\thandler, err := httpcaddyfile.ParseSegmentAsSubroute(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsubroute, ok := handler.(*caddyhttp.Subroute)\n\tif !ok {\n\t\treturn nil, h.Errf(\"segment was not parsed as a subroute\")\n\t}\n\n\t// make a matcher on the path and everything below it\n\tpathMatcher := caddy.ModuleMap{\n\t\t\"path\": h.JSON(caddyhttp.MatchPath{path}),\n\t}\n\n\t// build a route with a rewrite handler to strip the path prefix\n\troute := caddyhttp.Route{\n\t\tHandlersRaw: []json.RawMessage{\n\t\t\tcaddyconfig.JSONModuleObject(Rewrite{\n\t\t\t\tStripPathPrefix: stripPath,\n\t\t\t}, \"handler\", \"rewrite\", nil),\n\t\t},\n\t}\n\n\t// prepend the route to the subroute\n\tsubroute.Routes = append([]caddyhttp.Route{route}, subroute.Routes...)\n\n\t// build and return a route from the subroute\n\treturn h.NewRoute(pathMatcher, subroute), nil\n}\n",
    "source_file": "modules/caddyhttp/rewrite/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "package proxyprotocol\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"strings\"\n\n\tgoproxy \"github.com/pires/go-proxyproto\"\n)\n\ntype Policy int\n\n// as defined in: https://pkg.go.dev/github.com/pires/go-proxyproto@v0.7.0#Policy\nconst (\n\t// IGNORE address from PROXY header, but accept connection\n\tPolicyIGNORE Policy = iota\n\t// USE address from PROXY header\n\tPolicyUSE\n\t// REJECT connection when PROXY header is sent\n\t// Note: even though the first read on the connection returns an error if\n\t// a PROXY header is present, subsequent reads do not. It is the task of\n\t// the code using the connection to handle that case properly.\n\tPolicyREJECT\n\t// REQUIRE connection to send PROXY header, reject if not present\n\t// Note: even though the first read on the connection returns an error if\n\t// a PROXY header is not present, subsequent reads do not. It is the task\n\t// of the code using the connection to handle that case properly.\n\tPolicyREQUIRE\n\t// SKIP accepts a connection without requiring the PROXY header\n\t// Note: an example usage can be found in the SkipProxyHeaderForCIDR\n\t// function.\n\tPolicySKIP\n)\n\nvar policyToGoProxyPolicy = map[Policy]goproxy.Policy{\n\tPolicyUSE:     goproxy.USE,\n\tPolicyIGNORE:  goproxy.IGNORE,\n\tPolicyREJECT:  goproxy.REJECT,\n\tPolicyREQUIRE: goproxy.REQUIRE,\n\tPolicySKIP:    goproxy.SKIP,\n}\n\nvar policyMap = map[Policy]string{\n\tPolicyUSE:     \"USE\",\n\tPolicyIGNORE:  \"IGNORE\",\n\tPolicyREJECT:  \"REJECT\",\n\tPolicyREQUIRE: \"REQUIRE\",\n\tPolicySKIP:    \"SKIP\",\n}\n\nvar policyMapRev = map[string]Policy{\n\t\"USE\":     PolicyUSE,\n\t\"IGNORE\":  PolicyIGNORE,\n\t\"REJECT\":  PolicyREJECT,\n\t\"REQUIRE\": PolicyREQUIRE,\n\t\"SKIP\":    PolicySKIP,\n}\n\n// MarshalText implements the text marshaller method.\nfunc (x Policy) MarshalText() ([]byte, error) {\n\treturn []byte(policyMap[x]), nil\n}\n\n// UnmarshalText implements the text unmarshaller method.\nfunc (x *Policy) UnmarshalText(text []byte) error {\n\tname := string(text)\n\ttmp, err := parsePolicy(name)\n\tif err != nil {\n\t\treturn err\n\t}\n\t*x = tmp\n\treturn nil\n}\n\nfunc parsePolicy(name string) (Policy, error) {\n\tif x, ok := policyMapRev[strings.ToUpper(name)]; ok {\n\t\treturn x, nil\n\t}\n\treturn Policy(0), fmt.Errorf(\"%s is %w\", name, errInvalidPolicy)\n}\n\nvar errInvalidPolicy = errors.New(\"invalid policy\")\n",
    "source_file": "modules/caddyhttp/proxyprotocol/policy.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage proxyprotocol\n\nimport (\n\t\"net\"\n\t\"net/netip\"\n\t\"time\"\n\n\tgoproxy \"github.com/pires/go-proxyproto\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// ListenerWrapper provides PROXY protocol support to Caddy by implementing\n// the caddy.ListenerWrapper interface. If a connection is received via Unix\n// socket, it's trusted. Otherwise, it's checked against the Allow/Deny lists,\n// then it's handled by the FallbackPolicy.\n//\n// It must be loaded before the `tls` listener because the PROXY protocol\n// encapsulates the TLS data.\n//\n// Credit goes to https://github.com/mastercactapus/caddy2-proxyprotocol for having\n// initially implemented this as a plugin.\ntype ListenerWrapper struct {\n\t// Timeout specifies an optional maximum time for\n\t// the PROXY header to be received.\n\t// If zero, timeout is disabled. Default is 5s.\n\tTimeout caddy.Duration `json:\"timeout,omitempty\"`\n\n\t// Allow is an optional list of CIDR ranges to\n\t// allow/require PROXY headers from.\n\tAllow []string `json:\"allow,omitempty\"`\n\tallow []netip.Prefix\n\n\t// Deny is an optional list of CIDR ranges to\n\t// deny PROXY headers from.\n\tDeny []string `json:\"deny,omitempty\"`\n\tdeny []netip.Prefix\n\n\t// FallbackPolicy specifies the policy to use if the downstream\n\t// IP address is not in the Allow list nor is in the Deny list.\n\t//\n\t// NOTE: The generated docs which describe the value of this\n\t// field is wrong because of how this type unmarshals JSON in a\n\t// custom way. The field expects a string, not a number.\n\t//\n\t// Accepted values are: IGNORE, USE, REJECT, REQUIRE, SKIP\n\t//\n\t// - IGNORE: address from PROXY header, but accept connection\n\t//\n\t// - USE: address from PROXY header\n\t//\n\t// - REJECT: connection when PROXY header is sent\n\t//   Note: even though the first read on the connection returns an error if\n\t//   a PROXY header is present, subsequent reads do not. It is the task of\n\t//   the code using the connection to handle that case properly.\n\t//\n\t// - REQUIRE: connection to send PROXY header, reject if not present\n\t//   Note: even though the first read on the connection returns an error if\n\t//   a PROXY header is not present, subsequent reads do not. It is the task\n\t//   of the code using the connection to handle that case properly.\n\t//\n\t// - SKIP: accepts a connection without requiring the PROXY header.\n\t//   Note: an example usage can be found in the SkipProxyHeaderForCIDR\n\t//   function.\n\t//\n\t// Default: IGNORE\n\t//\n\t// Policy definitions are here: https://pkg.go.dev/github.com/pires/go-proxyproto@v0.7.0#Policy\n\tFallbackPolicy Policy `json:\"fallback_policy,omitempty\"`\n\n\tpolicy goproxy.ConnPolicyFunc\n}\n\n// Provision sets up the listener wrapper.\nfunc (pp *ListenerWrapper) Provision(ctx caddy.Context) error {\n\tfor _, cidr := range pp.Allow {\n\t\tipnet, err := netip.ParsePrefix(cidr)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tpp.allow = append(pp.allow, ipnet)\n\t}\n\tfor _, cidr := range pp.Deny {\n\t\tipnet, err := netip.ParsePrefix(cidr)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tpp.deny = append(pp.deny, ipnet)\n\t}\n\n\tpp.policy = func(options goproxy.ConnPolicyOptions) (goproxy.Policy, error) {\n\t\t// trust unix sockets\n\t\tif network := options.Upstream.Network(); caddy.IsUnixNetwork(network) || caddy.IsFdNetwork(network) {\n\t\t\treturn goproxy.USE, nil\n\t\t}\n\t\tret := pp.FallbackPolicy\n\t\thost, _, err := net.SplitHostPort(options.Upstream.String())\n\t\tif err != nil {\n\t\t\treturn goproxy.REJECT, err\n\t\t}\n\n\t\tip, err := netip.ParseAddr(host)\n\t\tif err != nil {\n\t\t\treturn goproxy.REJECT, err\n\t\t}\n\t\tfor _, ipnet := range pp.deny {\n\t\t\tif ipnet.Contains(ip) {\n\t\t\t\treturn goproxy.REJECT, nil\n\t\t\t}\n\t\t}\n\t\tfor _, ipnet := range pp.allow {\n\t\t\tif ipnet.Contains(ip) {\n\t\t\t\tret = PolicyUSE\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\treturn policyToGoProxyPolicy[ret], nil\n\t}\n\treturn nil\n}\n\n// WrapListener adds PROXY protocol support to the listener.\nfunc (pp *ListenerWrapper) WrapListener(l net.Listener) net.Listener {\n\tpl := &goproxy.Listener{\n\t\tListener:          l,\n\t\tReadHeaderTimeout: time.Duration(pp.Timeout),\n\t}\n\tpl.ConnPolicy = pp.policy\n\treturn pl\n}\n",
    "source_file": "modules/caddyhttp/proxyprotocol/listenerwrapper.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage proxyprotocol\n\nimport (\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(ListenerWrapper{})\n}\n\nfunc (ListenerWrapper) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"caddy.listeners.proxy_protocol\",\n\t\tNew: func() caddy.Module { return new(ListenerWrapper) },\n\t}\n}\n\n// UnmarshalCaddyfile sets up the listener Listenerwrapper from Caddyfile tokens. Syntax:\n//\n//\tproxy_protocol {\n//\t\ttimeout <duration>\n//\t\tallow <IPs...>\n//\t\tdeny <IPs...>\n//\t\tfallback_policy <policy>\n//\t}\nfunc (w *ListenerWrapper) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume wrapper name\n\n\t// No same-line options are supported\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"parsing proxy_protocol timeout duration: %v\", err)\n\t\t\t}\n\t\t\tw.Timeout = caddy.Duration(dur)\n\n\t\tcase \"allow\":\n\t\t\tw.Allow = append(w.Allow, d.RemainingArgs()...)\n\t\tcase \"deny\":\n\t\t\tw.Deny = append(w.Deny, d.RemainingArgs()...)\n\t\tcase \"fallback_policy\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tp, err := parsePolicy(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.WrapErr(err)\n\t\t\t}\n\t\t\tw.FallbackPolicy = p\n\t\tdefault:\n\t\t\treturn d.ArgErr()\n\t\t}\n\t}\n\treturn nil\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner     = (*ListenerWrapper)(nil)\n\t_ caddy.Module          = (*ListenerWrapper)(nil)\n\t_ caddy.ListenerWrapper = (*ListenerWrapper)(nil)\n\t_ caddyfile.Unmarshaler = (*ListenerWrapper)(nil)\n)\n",
    "source_file": "modules/caddyhttp/proxyprotocol/module.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage intercept\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Intercept{})\n\thttpcaddyfile.RegisterHandlerDirective(\"intercept\", parseCaddyfile)\n}\n\n// Intercept is a middleware that intercepts then replaces or modifies the original response.\n// It can, for instance, be used to implement X-Sendfile/X-Accel-Redirect-like features\n// when using modules like FrankenPHP or Caddy Snake.\n//\n// EXPERIMENTAL: Subject to change or removal.\ntype Intercept struct {\n\t// List of handlers and their associated matchers to evaluate\n\t// after successful response generation.\n\t// The first handler that matches the original response will\n\t// be invoked. The original response body will not be\n\t// written to the client;\n\t// it is up to the handler to finish handling the response.\n\t//\n\t// Three new placeholders are available in this handler chain:\n\t// - `{http.intercept.status_code}` The status code from the response\n\t// - `{http.intercept.header.*}` The headers from the response\n\tHandleResponse []caddyhttp.ResponseHandler `json:\"handle_response,omitempty\"`\n\n\t// Holds the named response matchers from the Caddyfile while adapting\n\tresponseMatchers map[string]caddyhttp.ResponseMatcher\n\n\t// Holds the handle_response Caddyfile tokens while adapting\n\thandleResponseSegments []*caddyfile.Dispenser\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\n//\n// EXPERIMENTAL: Subject to change or removal.\nfunc (Intercept) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.intercept\",\n\t\tNew: func() caddy.Module { return new(Intercept) },\n\t}\n}\n\n// Provision ensures that i is set up properly before use.\n//\n// EXPERIMENTAL: Subject to change or removal.\nfunc (irh *Intercept) Provision(ctx caddy.Context) error {\n\t// set up any response routes\n\tfor i, rh := range irh.HandleResponse {\n\t\terr := rh.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning response handler %d: %w\", i, err)\n\t\t}\n\t}\n\n\tirh.logger = ctx.Logger()\n\n\treturn nil\n}\n\nvar bufPool = sync.Pool{\n\tNew: func() any {\n\t\treturn new(bytes.Buffer)\n\t},\n}\n\n// TODO: handle status code replacement\n//\n// EXPERIMENTAL: Subject to change or removal.\ntype interceptedResponseHandler struct {\n\tcaddyhttp.ResponseRecorder\n\treplacer     *caddy.Replacer\n\thandler      caddyhttp.ResponseHandler\n\thandlerIndex int\n\tstatusCode   int\n}\n\n// EXPERIMENTAL: Subject to change or removal.\nfunc (irh interceptedResponseHandler) WriteHeader(statusCode int) {\n\tif irh.statusCode != 0 && (statusCode < 100 || statusCode >= 200) {\n\t\tirh.ResponseRecorder.WriteHeader(irh.statusCode)\n\n\t\treturn\n\t}\n\n\tirh.ResponseRecorder.WriteHeader(statusCode)\n}\n\n// EXPERIMENTAL: Subject to change or removal.\nfunc (irh interceptedResponseHandler) Unwrap() http.ResponseWriter {\n\treturn irh.ResponseRecorder\n}\n\n// EXPERIMENTAL: Subject to change or removal.\nfunc (ir Intercept) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\tbuf := bufPool.Get().(*bytes.Buffer)\n\tbuf.Reset()\n\tdefer bufPool.Put(buf)\n\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\trec := interceptedResponseHandler{replacer: repl}\n\trec.ResponseRecorder = caddyhttp.NewResponseRecorder(w, buf, func(status int, header http.Header) bool {\n\t\t// see if any response handler is configured for this original response\n\t\tfor i, rh := range ir.HandleResponse {\n\t\t\tif rh.Match != nil && !rh.Match.Match(status, header) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\trec.handler = rh\n\t\t\trec.handlerIndex = i\n\n\t\t\t// if configured to only change the status code,\n\t\t\t// do that then stream\n\t\t\tif statusCodeStr := rh.StatusCode.String(); statusCodeStr != \"\" {\n\t\t\t\tsc, err := strconv.Atoi(repl.ReplaceAll(statusCodeStr, \"\"))\n\t\t\t\tif err != nil {\n\t\t\t\t\trec.statusCode = http.StatusInternalServerError\n\t\t\t\t} else {\n\t\t\t\t\trec.statusCode = sc\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn rec.statusCode == 0\n\t\t}\n\n\t\treturn false\n\t})\n\n\tif err := next.ServeHTTP(rec, r); err != nil {\n\t\treturn err\n\t}\n\tif !rec.Buffered() {\n\t\treturn nil\n\t}\n\n\t// set up the replacer so that parts of the original response can be\n\t// used for routing decisions\n\tfor field, value := range rec.Header() {\n\t\trepl.Set(\"http.intercept.header.\"+field, strings.Join(value, \",\"))\n\t}\n\trepl.Set(\"http.intercept.status_code\", rec.Status())\n\n\tif c := ir.logger.Check(zapcore.DebugLevel, \"handling response\"); c != nil {\n\t\tc.Write(zap.Int(\"handler\", rec.handlerIndex))\n\t}\n\n\t// pass the request through the response handler routes\n\treturn rec.handler.Routes.Compile(next).ServeHTTP(w, r)\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens. Syntax:\n//\n//\tintercept [<matcher>] {\n//\t    # intercept original responses\n//\t    @name {\n//\t        status <code...>\n//\t        header <field> [<value>]\n//\t    }\n//\t    replace_status [<matcher>] <status_code>\n//\t    handle_response [<matcher>] {\n//\t        <directives...>\n//\t    }\n//\t}\n//\n// The FinalizeUnmarshalCaddyfile method should be called after this\n// to finalize parsing of \"handle_response\" blocks, if possible.\n//\n// EXPERIMENTAL: Subject to change or removal.\nfunc (i *Intercept) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// collect the response matchers defined as subdirectives\n\t// prefixed with \"@\" for use with \"handle_response\" blocks\n\ti.responseMatchers = make(map[string]caddyhttp.ResponseMatcher)\n\n\td.Next() // consume the directive name\n\tfor d.NextBlock(0) {\n\t\t// if the subdirective has an \"@\" prefix then we\n\t\t// parse it as a response matcher for use with \"handle_response\"\n\t\tif strings.HasPrefix(d.Val(), matcherPrefix) {\n\t\t\terr := caddyhttp.ParseNamedResponseMatcher(d.NewFromNextSegment(), i.responseMatchers)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tswitch d.Val() {\n\t\tcase \"handle_response\":\n\t\t\t// delegate the parsing of handle_response to the caller,\n\t\t\t// since we need the httpcaddyfile.Helper to parse subroutes.\n\t\t\t// See h.FinalizeUnmarshalCaddyfile\n\t\t\ti.handleResponseSegments = append(i.handleResponseSegments, d.NewFromNextSegment())\n\n\t\tcase \"replace_status\":\n\t\t\targs := d.RemainingArgs()\n\t\t\tif len(args) != 1 && len(args) != 2 {\n\t\t\t\treturn d.Errf(\"must have one or two arguments: an optional response matcher, and a status code\")\n\t\t\t}\n\n\t\t\tresponseHandler := caddyhttp.ResponseHandler{}\n\n\t\t\tif len(args) == 2 {\n\t\t\t\tif !strings.HasPrefix(args[0], matcherPrefix) {\n\t\t\t\t\treturn d.Errf(\"must use a named response matcher, starting with '@'\")\n\t\t\t\t}\n\t\t\t\tfoundMatcher, ok := i.responseMatchers[args[0]]\n\t\t\t\tif !ok {\n\t\t\t\t\treturn d.Errf(\"no named response matcher defined with name '%s'\", args[0][1:])\n\t\t\t\t}\n\t\t\t\tresponseHandler.Match = &foundMatcher\n\t\t\t\tresponseHandler.StatusCode = caddyhttp.WeakString(args[1])\n\t\t\t} else if len(args) == 1 {\n\t\t\t\tresponseHandler.StatusCode = caddyhttp.WeakString(args[0])\n\t\t\t}\n\n\t\t\t// make sure there's no block, cause it doesn't make sense\n\t\t\tif nesting := d.Nesting(); d.NextBlock(nesting) {\n\t\t\t\treturn d.Errf(\"cannot define routes for 'replace_status', use 'handle_response' instead.\")\n\t\t\t}\n\n\t\t\ti.HandleResponse = append(\n\t\t\t\ti.HandleResponse,\n\t\t\t\tresponseHandler,\n\t\t\t)\n\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective %s\", d.Val())\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// FinalizeUnmarshalCaddyfile finalizes the Caddyfile parsing which\n// requires having an httpcaddyfile.Helper to function, to parse subroutes.\n//\n// EXPERIMENTAL: Subject to change or removal.\nfunc (i *Intercept) FinalizeUnmarshalCaddyfile(helper httpcaddyfile.Helper) error {\n\tfor _, d := range i.handleResponseSegments {\n\t\t// consume the \"handle_response\" token\n\t\td.Next()\n\t\targs := d.RemainingArgs()\n\n\t\t// TODO: Remove this check at some point in the future\n\t\tif len(args) == 2 {\n\t\t\treturn d.Errf(\"configuring 'handle_response' for status code replacement is no longer supported. Use 'replace_status' instead.\")\n\t\t}\n\n\t\tif len(args) > 1 {\n\t\t\treturn d.Errf(\"too many arguments for 'handle_response': %s\", args)\n\t\t}\n\n\t\tvar matcher *caddyhttp.ResponseMatcher\n\t\tif len(args) == 1 {\n\t\t\t// the first arg should always be a matcher.\n\t\t\tif !strings.HasPrefix(args[0], matcherPrefix) {\n\t\t\t\treturn d.Errf(\"must use a named response matcher, starting with '@'\")\n\t\t\t}\n\n\t\t\tfoundMatcher, ok := i.responseMatchers[args[0]]\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"no named response matcher defined with name '%s'\", args[0][1:])\n\t\t\t}\n\t\t\tmatcher = &foundMatcher\n\t\t}\n\n\t\t// parse the block as routes\n\t\thandler, err := httpcaddyfile.ParseSegmentAsSubroute(helper.WithDispenser(d.NewFromNextSegment()))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsubroute, ok := handler.(*caddyhttp.Subroute)\n\t\tif !ok {\n\t\t\treturn helper.Errf(\"segment was not parsed as a subroute\")\n\t\t}\n\t\ti.HandleResponse = append(\n\t\t\ti.HandleResponse,\n\t\t\tcaddyhttp.ResponseHandler{\n\t\t\t\tMatch:  matcher,\n\t\t\t\tRoutes: subroute.Routes,\n\t\t\t},\n\t\t)\n\t}\n\n\t// move the handle_response entries without a matcher to the end.\n\t// we can't use sort.SliceStable because it will reorder the rest of the\n\t// entries which may be undesirable because we don't have a good\n\t// heuristic to use for sorting.\n\twithoutMatchers := []caddyhttp.ResponseHandler{}\n\twithMatchers := []caddyhttp.ResponseHandler{}\n\tfor _, hr := range i.HandleResponse {\n\t\tif hr.Match == nil {\n\t\t\twithoutMatchers = append(withoutMatchers, hr)\n\t\t} else {\n\t\t\twithMatchers = append(withMatchers, hr)\n\t\t}\n\t}\n\ti.HandleResponse = append(withMatchers, withoutMatchers...)\n\n\t// clean up the bits we only needed for adapting\n\ti.handleResponseSegments = nil\n\ti.responseMatchers = nil\n\n\treturn nil\n}\n\nconst matcherPrefix = \"@\"\n\nfunc parseCaddyfile(helper httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\tvar ir Intercept\n\tif err := ir.UnmarshalCaddyfile(helper.Dispenser); err != nil {\n\t\treturn nil, err\n\t}\n\n\tif err := ir.FinalizeUnmarshalCaddyfile(helper); err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn ir, nil\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*Intercept)(nil)\n\t_ caddyfile.Unmarshaler       = (*Intercept)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*Intercept)(nil)\n)\n",
    "source_file": "modules/caddyhttp/intercept/intercept.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Package encode implements an encoder middleware for Caddy. The initial\n// enhancements related to Accept-Encoding, minimum content length, and\n// buffer/writer pools were adapted from https://github.com/xi2/httpgzip\n// then modified heavily to accommodate modular encoders and fix bugs.\n// Code borrowed from that repository is Copyright (c) 2015 The Httpgzip Authors.\npackage encode\n\nimport (\n\t\"fmt\"\n\t\"io\"\n\t\"math\"\n\t\"net/http\"\n\t\"slices\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Encode{})\n}\n\n// Encode is a middleware which can encode responses.\ntype Encode struct {\n\t// Selection of compression algorithms to choose from. The best one\n\t// will be chosen based on the client's Accept-Encoding header.\n\tEncodingsRaw caddy.ModuleMap `json:\"encodings,omitempty\" caddy:\"namespace=http.encoders\"`\n\n\t// If the client has no strong preference, choose these encodings in order.\n\tPrefer []string `json:\"prefer,omitempty\"`\n\n\t// Only encode responses that are at least this many bytes long.\n\tMinLength int `json:\"minimum_length,omitempty\"`\n\n\t// Only encode responses that match against this ResponseMmatcher.\n\t// The default is a collection of text-based Content-Type headers.\n\tMatcher *caddyhttp.ResponseMatcher `json:\"match,omitempty\"`\n\n\twriterPools map[string]*sync.Pool // TODO: these pools do not get reused through config reloads...\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Encode) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.encode\",\n\t\tNew: func() caddy.Module { return new(Encode) },\n\t}\n}\n\n// Provision provisions enc.\nfunc (enc *Encode) Provision(ctx caddy.Context) error {\n\tmods, err := ctx.LoadModule(enc, \"EncodingsRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading encoder modules: %v\", err)\n\t}\n\tfor modName, modIface := range mods.(map[string]any) {\n\t\terr = enc.addEncoding(modIface.(Encoding))\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"adding encoding %s: %v\", modName, err)\n\t\t}\n\t}\n\tif enc.MinLength == 0 {\n\t\tenc.MinLength = defaultMinLength\n\t}\n\n\tif enc.Matcher == nil {\n\t\t// common text-based content types\n\t\t// list based on https://developers.cloudflare.com/speed/optimization/content/brotli/content-compression/#compression-between-cloudflare-and-website-visitors\n\t\tenc.Matcher = &caddyhttp.ResponseMatcher{\n\t\t\tHeaders: http.Header{\n\t\t\t\t\"Content-Type\": []string{\n\t\t\t\t\t\"application/atom+xml*\",\n\t\t\t\t\t\"application/eot*\",\n\t\t\t\t\t\"application/font*\",\n\t\t\t\t\t\"application/geo+json*\",\n\t\t\t\t\t\"application/graphql+json*\",\n\t\t\t\t\t\"application/javascript*\",\n\t\t\t\t\t\"application/json*\",\n\t\t\t\t\t\"application/ld+json*\",\n\t\t\t\t\t\"application/manifest+json*\",\n\t\t\t\t\t\"application/opentype*\",\n\t\t\t\t\t\"application/otf*\",\n\t\t\t\t\t\"application/rss+xml*\",\n\t\t\t\t\t\"application/truetype*\",\n\t\t\t\t\t\"application/ttf*\",\n\t\t\t\t\t\"application/vnd.api+json*\",\n\t\t\t\t\t\"application/vnd.ms-fontobject*\",\n\t\t\t\t\t\"application/wasm*\",\n\t\t\t\t\t\"application/x-httpd-cgi*\",\n\t\t\t\t\t\"application/x-javascript*\",\n\t\t\t\t\t\"application/x-opentype*\",\n\t\t\t\t\t\"application/x-otf*\",\n\t\t\t\t\t\"application/x-perl*\",\n\t\t\t\t\t\"application/x-protobuf*\",\n\t\t\t\t\t\"application/x-ttf*\",\n\t\t\t\t\t\"application/xhtml+xml*\",\n\t\t\t\t\t\"application/xml*\",\n\t\t\t\t\t\"font/ttf*\",\n\t\t\t\t\t\"font/otf*\",\n\t\t\t\t\t\"image/svg+xml*\",\n\t\t\t\t\t\"image/vnd.microsoft.icon*\",\n\t\t\t\t\t\"image/x-icon*\",\n\t\t\t\t\t\"multipart/bag*\",\n\t\t\t\t\t\"multipart/mixed*\",\n\t\t\t\t\t\"text/*\",\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// Validate ensures that enc's configuration is valid.\nfunc (enc *Encode) Validate() error {\n\tcheck := make(map[string]bool)\n\tfor _, encName := range enc.Prefer {\n\t\tif _, ok := enc.writerPools[encName]; !ok {\n\t\t\treturn fmt.Errorf(\"encoding %s not enabled\", encName)\n\t\t}\n\n\t\tif _, ok := check[encName]; ok {\n\t\t\treturn fmt.Errorf(\"encoding %s is duplicated in prefer\", encName)\n\t\t}\n\t\tcheck[encName] = true\n\t}\n\n\treturn nil\n}\n\nfunc isEncodeAllowed(h http.Header) bool {\n\treturn !strings.Contains(h.Get(\"Cache-Control\"), \"no-transform\")\n}\n\nfunc (enc *Encode) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\tif isEncodeAllowed(r.Header) {\n\t\tfor _, encName := range AcceptedEncodings(r, enc.Prefer) {\n\t\t\tif _, ok := enc.writerPools[encName]; !ok {\n\t\t\t\tcontinue // encoding not offered\n\t\t\t}\n\t\t\tw = enc.openResponseWriter(encName, w, r.Method == http.MethodConnect)\n\t\t\tdefer w.(*responseWriter).Close()\n\n\t\t\t// to comply with RFC 9110 section 8.8.3(.3), we modify the Etag when encoding\n\t\t\t// by appending a hyphen and the encoder name; the problem is, the client will\n\t\t\t// send back that Etag in a If-None-Match header, but upstream handlers that set\n\t\t\t// the Etag in the first place don't know that we appended to their Etag! so here\n\t\t\t// we have to strip our addition so the upstream handlers can still honor client\n\t\t\t// caches without knowing about our changes...\n\t\t\tif etag := r.Header.Get(\"If-None-Match\"); etag != \"\" && !strings.HasPrefix(etag, \"W/\") {\n\t\t\t\tourSuffix := \"-\" + encName + `\"`\n\t\t\t\tif strings.HasSuffix(etag, ourSuffix) {\n\t\t\t\t\tetag = strings.TrimSuffix(etag, ourSuffix) + `\"`\n\t\t\t\t\tr.Header.Set(\"If-None-Match\", etag)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tbreak\n\t\t}\n\t}\n\treturn next.ServeHTTP(w, r)\n}\n\nfunc (enc *Encode) addEncoding(e Encoding) error {\n\tae := e.AcceptEncoding()\n\tif ae == \"\" {\n\t\treturn fmt.Errorf(\"encoder does not specify an Accept-Encoding value\")\n\t}\n\tif _, ok := enc.writerPools[ae]; ok {\n\t\treturn fmt.Errorf(\"encoder already added: %s\", ae)\n\t}\n\tif enc.writerPools == nil {\n\t\tenc.writerPools = make(map[string]*sync.Pool)\n\t}\n\tenc.writerPools[ae] = &sync.Pool{\n\t\tNew: func() any {\n\t\t\treturn e.NewEncoder()\n\t\t},\n\t}\n\treturn nil\n}\n\n// openResponseWriter creates a new response writer that may (or may not)\n// encode the response with encodingName. The returned response writer MUST\n// be closed after the handler completes.\nfunc (enc *Encode) openResponseWriter(encodingName string, w http.ResponseWriter, isConnect bool) *responseWriter {\n\tvar rw responseWriter\n\treturn enc.initResponseWriter(&rw, encodingName, w, isConnect)\n}\n\n// initResponseWriter initializes the responseWriter instance\n// allocated in openResponseWriter, enabling mid-stack inlining.\nfunc (enc *Encode) initResponseWriter(rw *responseWriter, encodingName string, wrappedRW http.ResponseWriter, isConnect bool) *responseWriter {\n\tif rww, ok := wrappedRW.(*caddyhttp.ResponseWriterWrapper); ok {\n\t\trw.ResponseWriter = rww\n\t} else {\n\t\trw.ResponseWriter = &caddyhttp.ResponseWriterWrapper{ResponseWriter: wrappedRW}\n\t}\n\trw.encodingName = encodingName\n\trw.config = enc\n\trw.isConnect = isConnect\n\n\treturn rw\n}\n\n// responseWriter writes to an underlying response writer\n// using the encoding represented by encodingName and\n// configured by config.\ntype responseWriter struct {\n\thttp.ResponseWriter\n\tencodingName string\n\tw            Encoder\n\tconfig       *Encode\n\tstatusCode   int\n\twroteHeader  bool\n\tisConnect    bool\n}\n\n// WriteHeader stores the status to write when the time comes\n// to actually write the header.\nfunc (rw *responseWriter) WriteHeader(status int) {\n\trw.statusCode = status\n\n\t// See #5849 and RFC 9110 section 15.4.5 (https://www.rfc-editor.org/rfc/rfc9110.html#section-15.4.5) - 304\n\t// Not Modified must have certain headers set as if it was a 200 response, and according to the issue\n\t// we would miss the Vary header in this case when compression was also enabled; note that we set this\n\t// header in the responseWriter.init() method but that is only called if we are writing a response body\n\tif status == http.StatusNotModified && !hasVaryValue(rw.Header(), \"Accept-Encoding\") {\n\t\trw.Header().Add(\"Vary\", \"Accept-Encoding\")\n\t}\n\n\t// write status immediately if status is 2xx and the request is CONNECT\n\t// since it means the response is successful.\n\t// see: https://github.com/caddyserver/caddy/issues/6733#issuecomment-2525058845\n\tif rw.isConnect && 200 <= status && status <= 299 {\n\t\trw.ResponseWriter.WriteHeader(status)\n\t\trw.wroteHeader = true\n\t}\n\n\t// write status immediately when status code is informational\n\t// see: https://caddy.community/t/disappear-103-early-hints-response-with-encode-enable-caddy-v2-7-6/23081/5\n\tif 100 <= status && status <= 199 {\n\t\trw.ResponseWriter.WriteHeader(status)\n\t}\n}\n\n// Match determines, if encoding should be done based on the ResponseMatcher.\nfunc (enc *Encode) Match(rw *responseWriter) bool {\n\treturn enc.Matcher.Match(rw.statusCode, rw.Header())\n}\n\n// FlushError is an alternative Flush returning an error. It delays the actual Flush of the underlying\n// ResponseWriterWrapper until headers were written.\nfunc (rw *responseWriter) FlushError() error {\n\t// WriteHeader wasn't called and is a CONNECT request, treat it as a success.\n\t// otherwise, wait until header is written.\n\tif rw.isConnect && !rw.wroteHeader && rw.statusCode == 0 {\n\t\trw.WriteHeader(http.StatusOK)\n\t}\n\n\tif !rw.wroteHeader {\n\t\t// flushing the underlying ResponseWriter will write header and status code,\n\t\t// but we need to delay that until we can determine if we must encode and\n\t\t// therefore add the Content-Encoding header; this happens in the first call\n\t\t// to rw.Write (see bug in #4314)\n\t\treturn nil\n\t}\n\t// also flushes the encoder, if any\n\t// see: https://github.com/jjiang-stripe/caddy-slow-gzip\n\tif rw.w != nil {\n\t\terr := rw.w.Flush()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\t//nolint:bodyclose\n\treturn http.NewResponseController(rw.ResponseWriter).Flush()\n}\n\n// Write writes to the response. If the response qualifies,\n// it is encoded using the encoder, which is initialized\n// if not done so already.\nfunc (rw *responseWriter) Write(p []byte) (int, error) {\n\t// ignore zero data writes, probably head request\n\tif len(p) == 0 {\n\t\treturn 0, nil\n\t}\n\n\t// WriteHeader wasn't called and is a CONNECT request, treat it as a success.\n\t// otherwise, determine if the response should be compressed.\n\tif rw.isConnect && !rw.wroteHeader && rw.statusCode == 0 {\n\t\trw.WriteHeader(http.StatusOK)\n\t}\n\n\t// sniff content-type and determine content-length\n\tif !rw.wroteHeader && rw.config.MinLength > 0 {\n\t\tvar gtMinLength bool\n\t\tif len(p) > rw.config.MinLength {\n\t\t\tgtMinLength = true\n\t\t} else if cl, err := strconv.Atoi(rw.Header().Get(\"Content-Length\")); err == nil && cl > rw.config.MinLength {\n\t\t\tgtMinLength = true\n\t\t}\n\n\t\tif gtMinLength {\n\t\t\tif rw.Header().Get(\"Content-Type\") == \"\" {\n\t\t\t\trw.Header().Set(\"Content-Type\", http.DetectContentType(p))\n\t\t\t}\n\t\t\trw.init()\n\t\t}\n\t}\n\n\t// before we write to the response, we need to make\n\t// sure the header is written exactly once; we do\n\t// that by checking if a status code has been set,\n\t// and if so, that means we haven't written the\n\t// header OR the default status code will be written\n\t// by the standard library\n\tif !rw.wroteHeader {\n\t\tif rw.statusCode != 0 {\n\t\t\trw.ResponseWriter.WriteHeader(rw.statusCode)\n\t\t}\n\t\trw.wroteHeader = true\n\t}\n\n\tif rw.w != nil {\n\t\treturn rw.w.Write(p)\n\t} else {\n\t\treturn rw.ResponseWriter.Write(p)\n\t}\n}\n\n// used to mask ReadFrom method\ntype writerOnly struct {\n\tio.Writer\n}\n\n// copied from stdlib\nconst sniffLen = 512\n\n// ReadFrom will try to use sendfile to copy from the reader to the response writer.\n// It's only used if the response writer implements io.ReaderFrom and the data can't be compressed.\n// It's based on stdlin http1.1 response writer implementation.\n// https://github.com/golang/go/blob/f4e3ec3dbe3b8e04a058d266adf8e048bab563f2/src/net/http/server.go#L586\nfunc (rw *responseWriter) ReadFrom(r io.Reader) (int64, error) {\n\trf, ok := rw.ResponseWriter.(io.ReaderFrom)\n\t// sendfile can't be used anyway\n\tif !ok {\n\t\t// mask ReadFrom to avoid infinite recursion\n\t\treturn io.Copy(writerOnly{rw}, r)\n\t}\n\n\tvar ns int64\n\t// try to sniff the content type and determine if the response should be compressed\n\tif !rw.wroteHeader && rw.config.MinLength > 0 {\n\t\tvar (\n\t\t\terr error\n\t\t\tbuf [sniffLen]byte\n\t\t)\n\t\t// mask ReadFrom to let Write determine if the response should be compressed\n\t\tns, err = io.CopyBuffer(writerOnly{rw}, io.LimitReader(r, sniffLen), buf[:])\n\t\tif err != nil || ns < sniffLen {\n\t\t\treturn ns, err\n\t\t}\n\t}\n\n\t// the response will be compressed, no sendfile support\n\tif rw.w != nil {\n\t\tnr, err := io.Copy(rw.w, r)\n\t\treturn nr + ns, err\n\t}\n\tnr, err := rf.ReadFrom(r)\n\treturn nr + ns, err\n}\n\n// Close writes any remaining buffered response and\n// deallocates any active resources.\nfunc (rw *responseWriter) Close() error {\n\t// didn't write, probably head request\n\tif !rw.wroteHeader {\n\t\tcl, err := strconv.Atoi(rw.Header().Get(\"Content-Length\"))\n\t\tif err == nil && cl > rw.config.MinLength {\n\t\t\trw.init()\n\t\t}\n\n\t\t// issue #5059, don't write status code if not set explicitly.\n\t\tif rw.statusCode != 0 {\n\t\t\trw.ResponseWriter.WriteHeader(rw.statusCode)\n\t\t}\n\t\trw.wroteHeader = true\n\t}\n\n\tvar err error\n\tif rw.w != nil {\n\t\terr = rw.w.Close()\n\t\trw.w.Reset(nil)\n\t\trw.config.writerPools[rw.encodingName].Put(rw.w)\n\t\trw.w = nil\n\t}\n\treturn err\n}\n\n// Unwrap returns the underlying ResponseWriter.\nfunc (rw *responseWriter) Unwrap() http.ResponseWriter {\n\treturn rw.ResponseWriter\n}\n\n// init should be called before we write a response, if rw.buf has contents.\nfunc (rw *responseWriter) init() {\n\thdr := rw.Header()\n\tif hdr.Get(\"Content-Encoding\") == \"\" && isEncodeAllowed(hdr) &&\n\t\trw.config.Match(rw) {\n\t\trw.w = rw.config.writerPools[rw.encodingName].Get().(Encoder)\n\t\trw.w.Reset(rw.ResponseWriter)\n\t\thdr.Del(\"Content-Length\") // https://github.com/golang/go/issues/14975\n\t\thdr.Set(\"Content-Encoding\", rw.encodingName)\n\t\tif !hasVaryValue(hdr, \"Accept-Encoding\") {\n\t\t\thdr.Add(\"Vary\", \"Accept-Encoding\")\n\t\t}\n\t\thdr.Del(\"Accept-Ranges\") // we don't know ranges for dynamically-encoded content\n\n\t\t// strong ETags need to be distinct depending on the encoding (\"selected representation\")\n\t\t// see RFC 9110 section 8.8.3.3:\n\t\t// https://www.rfc-editor.org/rfc/rfc9110.html#name-example-entity-tags-varying\n\t\t// I don't know a great way to do this... how about appending? That's a neat trick!\n\t\t// (We have to strip the value we append from If-None-Match headers before\n\t\t// sending subsequent requests back upstream, however, since upstream handlers\n\t\t// don't know about our appending to their Etag since they've already done their work)\n\t\tif etag := hdr.Get(\"Etag\"); etag != \"\" && !strings.HasPrefix(etag, \"W/\") {\n\t\t\tetag = fmt.Sprintf(`%s-%s\"`, strings.TrimSuffix(etag, `\"`), rw.encodingName)\n\t\t\thdr.Set(\"Etag\", etag)\n\t\t}\n\t}\n}\n\nfunc hasVaryValue(hdr http.Header, target string) bool {\n\tfor _, vary := range hdr.Values(\"Vary\") {\n\t\tvals := strings.Split(vary, \",\")\n\t\tfor _, val := range vals {\n\t\t\tif strings.EqualFold(strings.TrimSpace(val), target) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}\n\n// AcceptedEncodings returns the list of encodings that the\n// client supports, in descending order of preference.\n// The client preference via q-factor and the server\n// preference via Prefer setting are taken into account. If\n// the Sec-WebSocket-Key header is present then non-identity\n// encodings are not considered. See\n// http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html.\nfunc AcceptedEncodings(r *http.Request, preferredOrder []string) []string {\n\tacceptEncHeader := r.Header.Get(\"Accept-Encoding\")\n\twebsocketKey := r.Header.Get(\"Sec-WebSocket-Key\")\n\tif acceptEncHeader == \"\" {\n\t\treturn []string{}\n\t}\n\n\tprefs := []encodingPreference{}\n\n\tfor _, accepted := range strings.Split(acceptEncHeader, \",\") {\n\t\tparts := strings.Split(accepted, \";\")\n\t\tencName := strings.ToLower(strings.TrimSpace(parts[0]))\n\n\t\t// determine q-factor\n\t\tqFactor := 1.0\n\t\tif len(parts) > 1 {\n\t\t\tqFactorStr := strings.ToLower(strings.TrimSpace(parts[1]))\n\t\t\tif strings.HasPrefix(qFactorStr, \"q=\") {\n\t\t\t\tif qFactorFloat, err := strconv.ParseFloat(qFactorStr[2:], 32); err == nil {\n\t\t\t\t\tif qFactorFloat >= 0 && qFactorFloat <= 1 {\n\t\t\t\t\t\tqFactor = qFactorFloat\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// encodings with q-factor of 0 are not accepted;\n\t\t// use a small threshold to account for float precision\n\t\tif qFactor < 0.00001 {\n\t\t\tcontinue\n\t\t}\n\n\t\t// don't encode WebSocket handshakes\n\t\tif websocketKey != \"\" && encName != \"identity\" {\n\t\t\tcontinue\n\t\t}\n\n\t\t// set server preference\n\t\tprefOrder := slices.Index(preferredOrder, encName)\n\t\tif prefOrder > -1 {\n\t\t\tprefOrder = len(preferredOrder) - prefOrder\n\t\t}\n\n\t\tprefs = append(prefs, encodingPreference{\n\t\t\tencoding:    encName,\n\t\t\tq:           qFactor,\n\t\t\tpreferOrder: prefOrder,\n\t\t})\n\t}\n\n\t// sort preferences by descending q-factor first, then by preferOrder\n\tsort.Slice(prefs, func(i, j int) bool {\n\t\tif math.Abs(prefs[i].q-prefs[j].q) < 0.00001 {\n\t\t\treturn prefs[i].preferOrder > prefs[j].preferOrder\n\t\t}\n\t\treturn prefs[i].q > prefs[j].q\n\t})\n\n\tprefEncNames := make([]string, len(prefs))\n\tfor i := range prefs {\n\t\tprefEncNames[i] = prefs[i].encoding\n\t}\n\n\treturn prefEncNames\n}\n\n// encodingPreference pairs an encoding with its q-factor.\ntype encodingPreference struct {\n\tencoding    string\n\tq           float64\n\tpreferOrder int\n}\n\n// Encoder is a type which can encode a stream of data.\ntype Encoder interface {\n\tio.WriteCloser\n\tReset(io.Writer)\n\tFlush() error // encoder by default buffers data to maximize compressing rate\n}\n\n// Encoding is a type which can create encoders of its kind\n// and return the name used in the Accept-Encoding header.\ntype Encoding interface {\n\tAcceptEncoding() string\n\tNewEncoder() Encoder\n}\n\n// Precompressed is a type which returns filename suffix of precompressed\n// file and Accept-Encoding header to use when serving this file.\ntype Precompressed interface {\n\tAcceptEncoding() string\n\tSuffix() string\n}\n\n// defaultMinLength is the minimum length at which to compress content.\nconst defaultMinLength = 512\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*Encode)(nil)\n\t_ caddy.Validator             = (*Encode)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*Encode)(nil)\n)\n",
    "source_file": "modules/caddyhttp/encode/encode.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage encode\n\nimport (\n\t\"strconv\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterHandlerDirective(\"encode\", parseCaddyfile)\n}\n\nfunc parseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\tenc := new(Encode)\n\terr := enc.UnmarshalCaddyfile(h.Dispenser)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn enc, nil\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens. Syntax:\n//\n//\tencode [<matcher>] <formats...> {\n//\t    gzip           [<level>]\n//\t    zstd\n//\t    minimum_length <length>\n//\t    # response matcher block\n//\t    match {\n//\t        status <code...>\n//\t        header <field> [<value>]\n//\t    }\n//\t    # or response matcher single line syntax\n//\t    match [header <field> [<value>]] | [status <code...>]\n//\t}\n//\n// Specifying the formats on the first line will use those formats' defaults.\nfunc (enc *Encode) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume directive name\n\n\tprefer := []string{}\n\tremainingArgs := d.RemainingArgs()\n\n\tresponseMatchers := make(map[string]caddyhttp.ResponseMatcher)\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"minimum_length\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tminLength, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tenc.MinLength = minLength\n\t\tcase \"match\":\n\t\t\terr := caddyhttp.ParseNamedResponseMatcher(d.NewFromNextSegment(), responseMatchers)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tmatcher := responseMatchers[\"match\"]\n\t\t\tenc.Matcher = &matcher\n\t\tdefault:\n\t\t\tname := d.Val()\n\t\t\tmodID := \"http.encoders.\" + name\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tencoding, ok := unm.(Encoding)\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"module %s is not an HTTP encoding; is %T\", modID, unm)\n\t\t\t}\n\t\t\tif enc.EncodingsRaw == nil {\n\t\t\t\tenc.EncodingsRaw = make(caddy.ModuleMap)\n\t\t\t}\n\t\t\tenc.EncodingsRaw[name] = caddyconfig.JSON(encoding, nil)\n\t\t\tprefer = append(prefer, name)\n\t\t}\n\t}\n\n\tif len(prefer) == 0 && len(remainingArgs) == 0 {\n\t\tremainingArgs = []string{\"zstd\", \"gzip\"}\n\t}\n\n\tfor _, arg := range remainingArgs {\n\t\tmod, err := caddy.GetModule(\"http.encoders.\" + arg)\n\t\tif err != nil {\n\t\t\treturn d.Errf(\"finding encoder module '%s': %v\", mod, err)\n\t\t}\n\t\tencoding, ok := mod.New().(Encoding)\n\t\tif !ok {\n\t\t\treturn d.Errf(\"module %s is not an HTTP encoding\", mod)\n\t\t}\n\t\tif enc.EncodingsRaw == nil {\n\t\t\tenc.EncodingsRaw = make(caddy.ModuleMap)\n\t\t}\n\t\tenc.EncodingsRaw[arg] = caddyconfig.JSON(encoding, nil)\n\t\tprefer = append(prefer, arg)\n\t}\n\n\t// use the order in which the encoders were defined.\n\tenc.Prefer = prefer\n\n\treturn nil\n}\n\n// Interface guard\nvar _ caddyfile.Unmarshaler = (*Encode)(nil)\n",
    "source_file": "modules/caddyhttp/encode/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"context\"\n\t\"crypto/tls\"\n\t\"crypto/x509\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"fmt\"\n\tweakrand \"math/rand\"\n\t\"net\"\n\t\"net/http\"\n\t\"os\"\n\t\"reflect\"\n\t\"slices\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/pires/go-proxyproto\"\n\t\"github.com/quic-go/quic-go/http3\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\t\"golang.org/x/net/http2\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n\t\"github.com/caddyserver/caddy/v2/modules/internal/network\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(HTTPTransport{})\n}\n\n// HTTPTransport is essentially a configuration wrapper for http.Transport.\n// It defines a JSON structure useful when configuring the HTTP transport\n// for Caddy's reverse proxy. It builds its http.Transport at Provision.\ntype HTTPTransport struct {\n\t// TODO: It's possible that other transports (like fastcgi) might be\n\t// able to borrow/use at least some of these config fields; if so,\n\t// maybe move them into a type called CommonTransport and embed it?\n\n\t// Configures the DNS resolver used to resolve the IP address of upstream hostnames.\n\tResolver *UpstreamResolver `json:\"resolver,omitempty\"`\n\n\t// Configures TLS to the upstream. Setting this to an empty struct\n\t// is sufficient to enable TLS with reasonable defaults.\n\tTLS *TLSConfig `json:\"tls,omitempty\"`\n\n\t// Configures HTTP Keep-Alive (enabled by default). Should only be\n\t// necessary if rigorous testing has shown that tuning this helps\n\t// improve performance.\n\tKeepAlive *KeepAlive `json:\"keep_alive,omitempty\"`\n\n\t// Whether to enable compression to upstream. Default: true\n\tCompression *bool `json:\"compression,omitempty\"`\n\n\t// Maximum number of connections per host. Default: 0 (no limit)\n\tMaxConnsPerHost int `json:\"max_conns_per_host,omitempty\"`\n\n\t// If non-empty, which PROXY protocol version to send when\n\t// connecting to an upstream. Default: off.\n\tProxyProtocol string `json:\"proxy_protocol,omitempty\"`\n\n\t// URL to the server that the HTTP transport will use to proxy\n\t// requests to the upstream. See http.Transport.Proxy for\n\t// information regarding supported protocols. This value takes\n\t// precedence over `HTTP_PROXY`, etc.\n\t//\n\t// Providing a value to this parameter results in\n\t// requests flowing through the reverse_proxy in the following\n\t// way:\n\t//\n\t// User Agent ->\n\t//  reverse_proxy ->\n\t//  forward_proxy_url -> upstream\n\t//\n\t// Default: http.ProxyFromEnvironment\n\t// DEPRECATED: Use NetworkProxyRaw|`network_proxy` instead. Subject to removal.\n\tForwardProxyURL string `json:\"forward_proxy_url,omitempty\"`\n\n\t// How long to wait before timing out trying to connect to\n\t// an upstream. Default: `3s`.\n\tDialTimeout caddy.Duration `json:\"dial_timeout,omitempty\"`\n\n\t// How long to wait before spawning an RFC 6555 Fast Fallback\n\t// connection. A negative value disables this. Default: `300ms`.\n\tFallbackDelay caddy.Duration `json:\"dial_fallback_delay,omitempty\"`\n\n\t// How long to wait for reading response headers from server. Default: No timeout.\n\tResponseHeaderTimeout caddy.Duration `json:\"response_header_timeout,omitempty\"`\n\n\t// The length of time to wait for a server's first response\n\t// headers after fully writing the request headers if the\n\t// request has a header \"Expect: 100-continue\". Default: No timeout.\n\tExpectContinueTimeout caddy.Duration `json:\"expect_continue_timeout,omitempty\"`\n\n\t// The maximum bytes to read from response headers. Default: `10MiB`.\n\tMaxResponseHeaderSize int64 `json:\"max_response_header_size,omitempty\"`\n\n\t// The size of the write buffer in bytes. Default: `4KiB`.\n\tWriteBufferSize int `json:\"write_buffer_size,omitempty\"`\n\n\t// The size of the read buffer in bytes. Default: `4KiB`.\n\tReadBufferSize int `json:\"read_buffer_size,omitempty\"`\n\n\t// The maximum time to wait for next read from backend. Default: no timeout.\n\tReadTimeout caddy.Duration `json:\"read_timeout,omitempty\"`\n\n\t// The maximum time to wait for next write to backend. Default: no timeout.\n\tWriteTimeout caddy.Duration `json:\"write_timeout,omitempty\"`\n\n\t// The versions of HTTP to support. As a special case, \"h2c\"\n\t// can be specified to use H2C (HTTP/2 over Cleartext) to the\n\t// upstream (this feature is experimental and subject to\n\t// change or removal). Default: [\"1.1\", \"2\"]\n\t//\n\t// EXPERIMENTAL: \"3\" enables HTTP/3, but it must be the only\n\t// version specified if enabled. Additionally, HTTPS must be\n\t// enabled to the upstream as HTTP/3 requires TLS. Subject\n\t// to change or removal while experimental.\n\tVersions []string `json:\"versions,omitempty\"`\n\n\t// Specify the address to bind to when connecting to an upstream. In other words,\n\t// it is the address the upstream sees as the remote address.\n\tLocalAddress string `json:\"local_address,omitempty\"`\n\n\t// The pre-configured underlying HTTP transport.\n\tTransport *http.Transport `json:\"-\"`\n\n\t// The module that provides the network (forward) proxy\n\t// URL that the HTTP transport will use to proxy\n\t// requests to the upstream. See [http.Transport.Proxy](https://pkg.go.dev/net/http#Transport.Proxy)\n\t// for information regarding supported protocols.\n\t//\n\t// Providing a value to this parameter results in requests\n\t// flowing through the reverse_proxy in the following way:\n\t//\n\t// User Agent ->\n\t//  reverse_proxy ->\n\t//  [proxy provided by the module] -> upstream\n\t//\n\t// If nil, defaults to reading the `HTTP_PROXY`,\n\t// `HTTPS_PROXY`, and `NO_PROXY` environment variables.\n\tNetworkProxyRaw json.RawMessage `json:\"network_proxy,omitempty\" caddy:\"namespace=caddy.network_proxy inline_key=from\"`\n\n\th2cTransport *http2.Transport\n\th3Transport  *http3.Transport // TODO: EXPERIMENTAL (May 2024)\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (HTTPTransport) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.transport.http\",\n\t\tNew: func() caddy.Module { return new(HTTPTransport) },\n\t}\n}\n\n// Provision sets up h.Transport with a *http.Transport\n// that is ready to use.\nfunc (h *HTTPTransport) Provision(ctx caddy.Context) error {\n\tif len(h.Versions) == 0 {\n\t\th.Versions = []string{\"1.1\", \"2\"}\n\t}\n\n\trt, err := h.NewTransport(ctx)\n\tif err != nil {\n\t\treturn err\n\t}\n\th.Transport = rt\n\n\treturn nil\n}\n\n// NewTransport builds a standard-lib-compatible http.Transport value from h.\nfunc (h *HTTPTransport) NewTransport(caddyCtx caddy.Context) (*http.Transport, error) {\n\t// Set keep-alive defaults if it wasn't otherwise configured\n\tif h.KeepAlive == nil {\n\t\th.KeepAlive = &KeepAlive{\n\t\t\tProbeInterval:       caddy.Duration(30 * time.Second),\n\t\t\tIdleConnTimeout:     caddy.Duration(2 * time.Minute),\n\t\t\tMaxIdleConnsPerHost: 32, // seems about optimal, see #2805\n\t\t}\n\t}\n\n\t// Set a relatively short default dial timeout.\n\t// This is helpful to make load-balancer retries more speedy.\n\tif h.DialTimeout == 0 {\n\t\th.DialTimeout = caddy.Duration(3 * time.Second)\n\t}\n\n\tdialer := &net.Dialer{\n\t\tTimeout:       time.Duration(h.DialTimeout),\n\t\tFallbackDelay: time.Duration(h.FallbackDelay),\n\t}\n\n\tif h.LocalAddress != \"\" {\n\t\tnetaddr, err := caddy.ParseNetworkAddressWithDefaults(h.LocalAddress, \"tcp\", 0)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif netaddr.PortRangeSize() > 1 {\n\t\t\treturn nil, fmt.Errorf(\"local_address must be a single address, not a port range\")\n\t\t}\n\t\tswitch netaddr.Network {\n\t\tcase \"tcp\", \"tcp4\", \"tcp6\":\n\t\t\tdialer.LocalAddr, err = net.ResolveTCPAddr(netaddr.Network, netaddr.JoinHostPort(0))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\tcase \"unix\", \"unixgram\", \"unixpacket\":\n\t\t\tdialer.LocalAddr, err = net.ResolveUnixAddr(netaddr.Network, netaddr.JoinHostPort(0))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\tcase \"udp\", \"udp4\", \"udp6\":\n\t\t\treturn nil, fmt.Errorf(\"local_address must be a TCP address, not a UDP address\")\n\t\tdefault:\n\t\t\treturn nil, fmt.Errorf(\"unsupported network\")\n\t\t}\n\t}\n\tif h.Resolver != nil {\n\t\terr := h.Resolver.ParseAddresses()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\td := &net.Dialer{\n\t\t\tTimeout:       time.Duration(h.DialTimeout),\n\t\t\tFallbackDelay: time.Duration(h.FallbackDelay),\n\t\t}\n\t\tdialer.Resolver = &net.Resolver{\n\t\t\tPreferGo: true,\n\t\t\tDial: func(ctx context.Context, _, _ string) (net.Conn, error) {\n\t\t\t\t//nolint:gosec\n\t\t\t\taddr := h.Resolver.netAddrs[weakrand.Intn(len(h.Resolver.netAddrs))]\n\t\t\t\treturn d.DialContext(ctx, addr.Network, addr.JoinHostPort(0))\n\t\t\t},\n\t\t}\n\t}\n\n\tdialContext := func(ctx context.Context, network, address string) (net.Conn, error) {\n\t\t// For unix socket upstreams, we need to recover the dial info from\n\t\t// the request's context, because the Host on the request's URL\n\t\t// will have been modified by directing the request, overwriting\n\t\t// the unix socket filename.\n\t\t// Also, we need to avoid overwriting the address at this point\n\t\t// when not necessary, because http.ProxyFromEnvironment may have\n\t\t// modified the address according to the user's env proxy config.\n\t\tif dialInfo, ok := GetDialInfo(ctx); ok {\n\t\t\tif strings.HasPrefix(dialInfo.Network, \"unix\") {\n\t\t\t\tnetwork = dialInfo.Network\n\t\t\t\taddress = dialInfo.Address\n\t\t\t}\n\t\t}\n\n\t\tconn, err := dialer.DialContext(ctx, network, address)\n\t\tif err != nil {\n\t\t\t// identify this error as one that occurred during\n\t\t\t// dialing, which can be important when trying to\n\t\t\t// decide whether to retry a request\n\t\t\treturn nil, DialError{err}\n\t\t}\n\n\t\tif h.ProxyProtocol != \"\" {\n\t\t\tproxyProtocolInfo, ok := caddyhttp.GetVar(ctx, proxyProtocolInfoVarKey).(ProxyProtocolInfo)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"failed to get proxy protocol info from context\")\n\t\t\t}\n\t\t\tvar proxyv byte\n\t\t\tswitch h.ProxyProtocol {\n\t\t\tcase \"v1\":\n\t\t\t\tproxyv = 1\n\t\t\tcase \"v2\":\n\t\t\t\tproxyv = 2\n\t\t\tdefault:\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected proxy protocol version\")\n\t\t\t}\n\n\t\t\t// The src and dst have to be of the same address family. As we don't know the original\n\t\t\t// dst address (it's kind of impossible to know) and this address is generally of very\n\t\t\t// little interest, we just set it to all zeros.\n\t\t\tvar destAddr net.Addr\n\t\t\tswitch {\n\t\t\tcase proxyProtocolInfo.AddrPort.Addr().Is4():\n\t\t\t\tdestAddr = &net.TCPAddr{\n\t\t\t\t\tIP: net.IPv4zero,\n\t\t\t\t}\n\t\t\tcase proxyProtocolInfo.AddrPort.Addr().Is6():\n\t\t\t\tdestAddr = &net.TCPAddr{\n\t\t\t\t\tIP: net.IPv6zero,\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected remote addr type in proxy protocol info\")\n\t\t\t}\n\t\t\tsourceAddr := &net.TCPAddr{\n\t\t\t\tIP:   proxyProtocolInfo.AddrPort.Addr().AsSlice(),\n\t\t\t\tPort: int(proxyProtocolInfo.AddrPort.Port()),\n\t\t\t\tZone: proxyProtocolInfo.AddrPort.Addr().Zone(),\n\t\t\t}\n\t\t\theader := proxyproto.HeaderProxyFromAddrs(proxyv, sourceAddr, destAddr)\n\n\t\t\t// retain the log message structure\n\t\t\tswitch h.ProxyProtocol {\n\t\t\tcase \"v1\":\n\t\t\t\tcaddyCtx.Logger().Debug(\"sending proxy protocol header v1\", zap.Any(\"header\", header))\n\t\t\tcase \"v2\":\n\t\t\t\tcaddyCtx.Logger().Debug(\"sending proxy protocol header v2\", zap.Any(\"header\", header))\n\t\t\t}\n\n\t\t\t_, err = header.WriteTo(conn)\n\t\t\tif err != nil {\n\t\t\t\t// identify this error as one that occurred during\n\t\t\t\t// dialing, which can be important when trying to\n\t\t\t\t// decide whether to retry a request\n\t\t\t\treturn nil, DialError{err}\n\t\t\t}\n\t\t}\n\n\t\t// if read/write timeouts are configured and this is a TCP connection,\n\t\t// enforce the timeouts by wrapping the connection with our own type\n\t\tif tcpConn, ok := conn.(*net.TCPConn); ok && (h.ReadTimeout > 0 || h.WriteTimeout > 0) {\n\t\t\tconn = &tcpRWTimeoutConn{\n\t\t\t\tTCPConn:      tcpConn,\n\t\t\t\treadTimeout:  time.Duration(h.ReadTimeout),\n\t\t\t\twriteTimeout: time.Duration(h.WriteTimeout),\n\t\t\t\tlogger:       caddyCtx.Logger(),\n\t\t\t}\n\t\t}\n\n\t\treturn conn, nil\n\t}\n\n\t// negotiate any HTTP/SOCKS proxy for the HTTP transport\n\tproxy := http.ProxyFromEnvironment\n\tif h.ForwardProxyURL != \"\" {\n\t\tcaddyCtx.Logger().Warn(\"forward_proxy_url is deprecated; use network_proxy instead\")\n\t\tu := network.ProxyFromURL{URL: h.ForwardProxyURL}\n\t\th.NetworkProxyRaw = caddyconfig.JSONModuleObject(u, \"from\", \"url\", nil)\n\t}\n\tif len(h.NetworkProxyRaw) != 0 {\n\t\tproxyMod, err := caddyCtx.LoadModule(h, \"NetworkProxyRaw\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to load network_proxy module: %v\", err)\n\t\t}\n\t\tif m, ok := proxyMod.(caddy.ProxyFuncProducer); ok {\n\t\t\tproxy = m.ProxyFunc()\n\t\t} else {\n\t\t\treturn nil, fmt.Errorf(\"network_proxy module is not `(func(*http.Request) (*url.URL, error))``\")\n\t\t}\n\t}\n\n\trt := &http.Transport{\n\t\tProxy:                  proxy,\n\t\tDialContext:            dialContext,\n\t\tMaxConnsPerHost:        h.MaxConnsPerHost,\n\t\tResponseHeaderTimeout:  time.Duration(h.ResponseHeaderTimeout),\n\t\tExpectContinueTimeout:  time.Duration(h.ExpectContinueTimeout),\n\t\tMaxResponseHeaderBytes: h.MaxResponseHeaderSize,\n\t\tWriteBufferSize:        h.WriteBufferSize,\n\t\tReadBufferSize:         h.ReadBufferSize,\n\t}\n\n\tif h.TLS != nil {\n\t\trt.TLSHandshakeTimeout = time.Duration(h.TLS.HandshakeTimeout)\n\t\tvar err error\n\t\trt.TLSClientConfig, err = h.TLS.MakeTLSClientConfig(caddyCtx)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"making TLS client config: %v\", err)\n\t\t}\n\n\t\t// servername has a placeholder, so we need to replace it\n\t\tif strings.Contains(h.TLS.ServerName, \"{\") {\n\t\t\trt.DialTLSContext = func(ctx context.Context, network, addr string) (net.Conn, error) {\n\t\t\t\t// reuses the dialer from above to establish a plaintext connection\n\t\t\t\tconn, err := dialContext(ctx, network, addr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\n\t\t\t\t// but add our own handshake logic\n\t\t\t\trepl := ctx.Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\t\t\t\ttlsConfig := rt.TLSClientConfig.Clone()\n\t\t\t\ttlsConfig.ServerName = repl.ReplaceAll(tlsConfig.ServerName, \"\")\n\t\t\t\ttlsConn := tls.Client(conn, tlsConfig)\n\n\t\t\t\t// complete the handshake before returning the connection\n\t\t\t\tif rt.TLSHandshakeTimeout != 0 {\n\t\t\t\t\tvar cancel context.CancelFunc\n\t\t\t\t\tctx, cancel = context.WithTimeout(ctx, rt.TLSHandshakeTimeout)\n\t\t\t\t\tdefer cancel()\n\t\t\t\t}\n\t\t\t\terr = tlsConn.HandshakeContext(ctx)\n\t\t\t\tif err != nil {\n\t\t\t\t\t_ = tlsConn.Close()\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\treturn tlsConn, nil\n\t\t\t}\n\t\t}\n\t}\n\n\tif h.KeepAlive != nil {\n\t\tdialer.KeepAlive = time.Duration(h.KeepAlive.ProbeInterval)\n\t\tif h.KeepAlive.Enabled != nil {\n\t\t\trt.DisableKeepAlives = !*h.KeepAlive.Enabled\n\t\t}\n\t\trt.MaxIdleConns = h.KeepAlive.MaxIdleConns\n\t\trt.MaxIdleConnsPerHost = h.KeepAlive.MaxIdleConnsPerHost\n\t\trt.IdleConnTimeout = time.Duration(h.KeepAlive.IdleConnTimeout)\n\t}\n\n\t// The proxy protocol header can only be sent once right after opening the connection.\n\t// So single connection must not be used for multiple requests, which can potentially\n\t// come from different clients.\n\tif !rt.DisableKeepAlives && h.ProxyProtocol != \"\" {\n\t\tcaddyCtx.Logger().Warn(\"disabling keepalives, they are incompatible with using PROXY protocol\")\n\t\trt.DisableKeepAlives = true\n\t}\n\n\tif h.Compression != nil {\n\t\trt.DisableCompression = !*h.Compression\n\t}\n\n\tif slices.Contains(h.Versions, \"2\") {\n\t\tif err := http2.ConfigureTransport(rt); err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// configure HTTP/3 transport if enabled; however, this does not\n\t// automatically fall back to lower versions like most web browsers\n\t// do (that'd add latency and complexity, besides, we expect that\n\t// site owners  control the backends), so it must be exclusive\n\tif len(h.Versions) == 1 && h.Versions[0] == \"3\" {\n\t\th.h3Transport = new(http3.Transport)\n\t\tif h.TLS != nil {\n\t\t\tvar err error\n\t\t\th.h3Transport.TLSClientConfig, err = h.TLS.MakeTLSClientConfig(caddyCtx)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"making TLS client config for HTTP/3 transport: %v\", err)\n\t\t\t}\n\t\t}\n\t} else if len(h.Versions) > 1 && slices.Contains(h.Versions, \"3\") {\n\t\treturn nil, fmt.Errorf(\"if HTTP/3 is enabled to the upstream, no other HTTP versions are supported\")\n\t}\n\n\t// if h2c is enabled, configure its transport (std lib http.Transport\n\t// does not \"HTTP/2 over cleartext TCP\")\n\tif slices.Contains(h.Versions, \"h2c\") {\n\t\t// crafting our own http2.Transport doesn't allow us to utilize\n\t\t// most of the customizations/preferences on the http.Transport,\n\t\t// because, for some reason, only http2.ConfigureTransport()\n\t\t// is allowed to set the unexported field that refers to a base\n\t\t// http.Transport config; oh well\n\t\th2t := &http2.Transport{\n\t\t\t// kind of a hack, but for plaintext/H2C requests, pretend to dial TLS\n\t\t\tDialTLSContext: func(ctx context.Context, network, address string, _ *tls.Config) (net.Conn, error) {\n\t\t\t\treturn dialContext(ctx, network, address)\n\t\t\t},\n\t\t\tAllowHTTP: true,\n\t\t}\n\t\tif h.Compression != nil {\n\t\t\th2t.DisableCompression = !*h.Compression\n\t\t}\n\t\th.h2cTransport = h2t\n\t}\n\n\treturn rt, nil\n}\n\n// RoundTrip implements http.RoundTripper.\nfunc (h *HTTPTransport) RoundTrip(req *http.Request) (*http.Response, error) {\n\th.SetScheme(req)\n\n\t// use HTTP/3 if enabled (TODO: This is EXPERIMENTAL)\n\tif h.h3Transport != nil {\n\t\treturn h.h3Transport.RoundTrip(req)\n\t}\n\n\t// if H2C (\"HTTP/2 over cleartext\") is enabled and the upstream request is\n\t// HTTP without TLS, use the alternate H2C-capable transport instead\n\tif req.URL.Scheme == \"http\" && h.h2cTransport != nil {\n\t\t// There is no dedicated DisableKeepAlives field in *http2.Transport.\n\t\t// This is an alternative way to disable keep-alive.\n\t\treq.Close = h.Transport.DisableKeepAlives\n\t\treturn h.h2cTransport.RoundTrip(req)\n\t}\n\n\treturn h.Transport.RoundTrip(req)\n}\n\n// SetScheme ensures that the outbound request req\n// has the scheme set in its URL; the underlying\n// http.Transport requires a scheme to be set.\n//\n// This method may be used by other transport modules\n// that wrap/use this one.\nfunc (h *HTTPTransport) SetScheme(req *http.Request) {\n\tif req.URL.Scheme != \"\" {\n\t\treturn\n\t}\n\tif h.shouldUseTLS(req) {\n\t\treq.URL.Scheme = \"https\"\n\t} else {\n\t\treq.URL.Scheme = \"http\"\n\t}\n}\n\n// shouldUseTLS returns true if TLS should be used for req.\nfunc (h *HTTPTransport) shouldUseTLS(req *http.Request) bool {\n\tif h.TLS == nil {\n\t\treturn false\n\t}\n\n\tport := req.URL.Port()\n\treturn !slices.Contains(h.TLS.ExceptPorts, port)\n}\n\n// TLSEnabled returns true if TLS is enabled.\nfunc (h HTTPTransport) TLSEnabled() bool {\n\treturn h.TLS != nil\n}\n\n// EnableTLS enables TLS on the transport.\nfunc (h *HTTPTransport) EnableTLS(base *TLSConfig) error {\n\th.TLS = base\n\treturn nil\n}\n\n// Cleanup implements caddy.CleanerUpper and closes any idle connections.\nfunc (h HTTPTransport) Cleanup() error {\n\tif h.Transport == nil {\n\t\treturn nil\n\t}\n\th.Transport.CloseIdleConnections()\n\treturn nil\n}\n\n// TLSConfig holds configuration related to the TLS configuration for the\n// transport/client.\ntype TLSConfig struct {\n\t// Certificate authority module which provides the certificate pool of trusted certificates\n\tCARaw json.RawMessage `json:\"ca,omitempty\" caddy:\"namespace=tls.ca_pool.source inline_key=provider\"`\n\n\t// Deprecated: Use the `ca` field with the `tls.ca_pool.source.inline` module instead.\n\t// Optional list of base64-encoded DER-encoded CA certificates to trust.\n\tRootCAPool []string `json:\"root_ca_pool,omitempty\"`\n\n\t// Deprecated: Use the `ca` field with the `tls.ca_pool.source.file` module instead.\n\t// List of PEM-encoded CA certificate files to add to the same trust\n\t// store as RootCAPool (or root_ca_pool in the JSON).\n\tRootCAPEMFiles []string `json:\"root_ca_pem_files,omitempty\"`\n\n\t// PEM-encoded client certificate filename to present to servers.\n\tClientCertificateFile string `json:\"client_certificate_file,omitempty\"`\n\n\t// PEM-encoded key to use with the client certificate.\n\tClientCertificateKeyFile string `json:\"client_certificate_key_file,omitempty\"`\n\n\t// If specified, Caddy will use and automate a client certificate\n\t// with this subject name.\n\tClientCertificateAutomate string `json:\"client_certificate_automate,omitempty\"`\n\n\t// If true, TLS verification of server certificates will be disabled.\n\t// This is insecure and may be removed in the future. Do not use this\n\t// option except in testing or local development environments.\n\tInsecureSkipVerify bool `json:\"insecure_skip_verify,omitempty\"`\n\n\t// The duration to allow a TLS handshake to a server. Default: No timeout.\n\tHandshakeTimeout caddy.Duration `json:\"handshake_timeout,omitempty\"`\n\n\t// The server name used when verifying the certificate received in the TLS\n\t// handshake. By default, this will use the upstream address' host part.\n\t// You only need to override this if your upstream address does not match the\n\t// certificate the upstream is likely to use. For example if the upstream\n\t// address is an IP address, then you would need to configure this to the\n\t// hostname being served by the upstream server. Currently, this does not\n\t// support placeholders because the TLS config is not provisioned on each\n\t// connection, so a static value must be used.\n\tServerName string `json:\"server_name,omitempty\"`\n\n\t// TLS renegotiation level. TLS renegotiation is the act of performing\n\t// subsequent handshakes on a connection after the first.\n\t// The level can be:\n\t//  - \"never\": (the default) disables renegotiation.\n\t//  - \"once\": allows a remote server to request renegotiation once per connection.\n\t//  - \"freely\": allows a remote server to repeatedly request renegotiation.\n\tRenegotiation string `json:\"renegotiation,omitempty\"`\n\n\t// Skip TLS ports specifies a list of upstream ports on which TLS should not be\n\t// attempted even if it is configured. Handy when using dynamic upstreams that\n\t// return HTTP and HTTPS endpoints too.\n\t// When specified, TLS will automatically be configured on the transport.\n\t// The value can be a list of any valid tcp port numbers, default empty.\n\tExceptPorts []string `json:\"except_ports,omitempty\"`\n\n\t// The list of elliptic curves to support. Caddy's\n\t// defaults are modern and secure.\n\tCurves []string `json:\"curves,omitempty\"`\n}\n\n// MakeTLSClientConfig returns a tls.Config usable by a client to a backend.\n// If there is no custom TLS configuration, a nil config may be returned.\nfunc (t *TLSConfig) MakeTLSClientConfig(ctx caddy.Context) (*tls.Config, error) {\n\tcfg := new(tls.Config)\n\n\t// client auth\n\tif t.ClientCertificateFile != \"\" && t.ClientCertificateKeyFile == \"\" {\n\t\treturn nil, fmt.Errorf(\"client_certificate_file specified without client_certificate_key_file\")\n\t}\n\tif t.ClientCertificateFile == \"\" && t.ClientCertificateKeyFile != \"\" {\n\t\treturn nil, fmt.Errorf(\"client_certificate_key_file specified without client_certificate_file\")\n\t}\n\tif t.ClientCertificateFile != \"\" && t.ClientCertificateKeyFile != \"\" {\n\t\tcert, err := tls.LoadX509KeyPair(t.ClientCertificateFile, t.ClientCertificateKeyFile)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"loading client certificate key pair: %v\", err)\n\t\t}\n\t\tcfg.Certificates = []tls.Certificate{cert}\n\t}\n\tif t.ClientCertificateAutomate != \"\" {\n\t\t// TODO: use or enable ctx.IdentityCredentials() ...\n\t\ttlsAppIface, err := ctx.App(\"tls\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"getting tls app: %v\", err)\n\t\t}\n\t\ttlsApp := tlsAppIface.(*caddytls.TLS)\n\t\terr = tlsApp.Manage(map[string]struct{}{t.ClientCertificateAutomate: {}})\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"managing client certificate: %v\", err)\n\t\t}\n\t\tcfg.GetClientCertificate = func(cri *tls.CertificateRequestInfo) (*tls.Certificate, error) {\n\t\t\tcerts := caddytls.AllMatchingCertificates(t.ClientCertificateAutomate)\n\t\t\tvar err error\n\t\t\tfor _, cert := range certs {\n\t\t\t\tcertCertificate := cert.Certificate // avoid taking address of iteration variable (gosec warning)\n\t\t\t\terr = cri.SupportsCertificate(&certCertificate)\n\t\t\t\tif err == nil {\n\t\t\t\t\treturn &cert.Certificate, nil\n\t\t\t\t}\n\t\t\t}\n\t\t\tif err == nil {\n\t\t\t\terr = fmt.Errorf(\"no client certificate found for automate name: %s\", t.ClientCertificateAutomate)\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\t// trusted root CAs\n\tif len(t.RootCAPool) > 0 || len(t.RootCAPEMFiles) > 0 {\n\t\tctx.Logger().Warn(\"root_ca_pool and root_ca_pem_files are deprecated. Use one of the tls.ca_pool.source modules instead\")\n\t\trootPool := x509.NewCertPool()\n\t\tfor _, encodedCACert := range t.RootCAPool {\n\t\t\tcaCert, err := decodeBase64DERCert(encodedCACert)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"parsing CA certificate: %v\", err)\n\t\t\t}\n\t\t\trootPool.AddCert(caCert)\n\t\t}\n\t\tfor _, pemFile := range t.RootCAPEMFiles {\n\t\t\tpemData, err := os.ReadFile(pemFile)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"failed reading ca cert: %v\", err)\n\t\t\t}\n\t\t\trootPool.AppendCertsFromPEM(pemData)\n\t\t}\n\t\tcfg.RootCAs = rootPool\n\t}\n\n\tif t.CARaw != nil {\n\t\tif len(t.RootCAPool) > 0 || len(t.RootCAPEMFiles) > 0 {\n\t\t\treturn nil, fmt.Errorf(\"conflicting config for Root CA pool\")\n\t\t}\n\t\tcaRaw, err := ctx.LoadModule(t, \"CARaw\")\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"failed to load ca module: %v\", err)\n\t\t}\n\t\tca, ok := caRaw.(caddytls.CA)\n\t\tif !ok {\n\t\t\treturn nil, fmt.Errorf(\"CA module '%s' is not a certificate pool provider\", ca)\n\t\t}\n\t\tcfg.RootCAs = ca.CertPool()\n\t}\n\n\t// Renegotiation\n\tswitch t.Renegotiation {\n\tcase \"never\", \"\":\n\t\tcfg.Renegotiation = tls.RenegotiateNever\n\tcase \"once\":\n\t\tcfg.Renegotiation = tls.RenegotiateOnceAsClient\n\tcase \"freely\":\n\t\tcfg.Renegotiation = tls.RenegotiateFreelyAsClient\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"invalid TLS renegotiation level: %v\", t.Renegotiation)\n\t}\n\n\t// override for the server name used verify the TLS handshake\n\tcfg.ServerName = t.ServerName\n\n\t// throw all security out the window\n\tcfg.InsecureSkipVerify = t.InsecureSkipVerify\n\n\tcurvesAdded := make(map[tls.CurveID]struct{})\n\tfor _, curveName := range t.Curves {\n\t\tcurveID := caddytls.SupportedCurves[curveName]\n\t\tif _, ok := curvesAdded[curveID]; !ok {\n\t\t\tcurvesAdded[curveID] = struct{}{}\n\t\t\tcfg.CurvePreferences = append(cfg.CurvePreferences, curveID)\n\t\t}\n\t}\n\n\t// only return a config if it's not empty\n\tif reflect.DeepEqual(cfg, new(tls.Config)) {\n\t\treturn nil, nil\n\t}\n\n\treturn cfg, nil\n}\n\n// KeepAlive holds configuration pertaining to HTTP Keep-Alive.\ntype KeepAlive struct {\n\t// Whether HTTP Keep-Alive is enabled. Default: `true`\n\tEnabled *bool `json:\"enabled,omitempty\"`\n\n\t// How often to probe for liveness. Default: `30s`.\n\tProbeInterval caddy.Duration `json:\"probe_interval,omitempty\"`\n\n\t// Maximum number of idle connections. Default: `0`, which means no limit.\n\tMaxIdleConns int `json:\"max_idle_conns,omitempty\"`\n\n\t// Maximum number of idle connections per host. Default: `32`.\n\tMaxIdleConnsPerHost int `json:\"max_idle_conns_per_host,omitempty\"`\n\n\t// How long connections should be kept alive when idle. Default: `2m`.\n\tIdleConnTimeout caddy.Duration `json:\"idle_timeout,omitempty\"`\n}\n\n// tcpRWTimeoutConn enforces read/write timeouts for a TCP connection.\n// If it fails to set deadlines, the error is logged but does not abort\n// the read/write attempt (ignoring the error is consistent with what\n// the standard library does: https://github.com/golang/go/blob/c5da4fb7ac5cb7434b41fc9a1df3bee66c7f1a4d/src/net/http/server.go#L981-L986)\ntype tcpRWTimeoutConn struct {\n\t*net.TCPConn\n\treadTimeout, writeTimeout time.Duration\n\tlogger                    *zap.Logger\n}\n\nfunc (c *tcpRWTimeoutConn) Read(b []byte) (int, error) {\n\tif c.readTimeout > 0 {\n\t\terr := c.TCPConn.SetReadDeadline(time.Now().Add(c.readTimeout))\n\t\tif err != nil {\n\t\t\tif ce := c.logger.Check(zapcore.ErrorLevel, \"failed to set read deadline\"); ce != nil {\n\t\t\t\tce.Write(zap.Error(err))\n\t\t\t}\n\t\t}\n\t}\n\treturn c.TCPConn.Read(b)\n}\n\nfunc (c *tcpRWTimeoutConn) Write(b []byte) (int, error) {\n\tif c.writeTimeout > 0 {\n\t\terr := c.TCPConn.SetWriteDeadline(time.Now().Add(c.writeTimeout))\n\t\tif err != nil {\n\t\t\tif ce := c.logger.Check(zapcore.ErrorLevel, \"failed to set write deadline\"); ce != nil {\n\t\t\t\tce.Write(zap.Error(err))\n\t\t\t}\n\t\t}\n\t}\n\treturn c.TCPConn.Write(b)\n}\n\n// decodeBase64DERCert base64-decodes, then DER-decodes, certStr.\nfunc decodeBase64DERCert(certStr string) (*x509.Certificate, error) {\n\t// decode base64\n\tderBytes, err := base64.StdEncoding.DecodeString(certStr)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// parse the DER-encoded certificate\n\treturn x509.ParseCertificate(derBytes)\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner  = (*HTTPTransport)(nil)\n\t_ http.RoundTripper  = (*HTTPTransport)(nil)\n\t_ caddy.CleanerUpper = (*HTTPTransport)(nil)\n\t_ TLSTransport       = (*HTTPTransport)(nil)\n)\n",
    "source_file": "modules/caddyhttp/reverseproxy/httptransport.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/spf13/cobra\"\n\t\"go.uber.org/zap\"\n\n\tcaddycmd \"github.com/caddyserver/caddy/v2/cmd\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/headers\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\nfunc init() {\n\tcaddycmd.RegisterCommand(caddycmd.Command{\n\t\tName:  \"reverse-proxy\",\n\t\tUsage: `[--from <addr>] [--to <addr>] [--change-host-header] [--insecure] [--internal-certs] [--disable-redirects] [--header-up \"Field: value\"] [--header-down \"Field: value\"] [--access-log] [--debug]`,\n\t\tShort: \"A quick and production-ready reverse proxy\",\n\t\tLong: `\nA simple but production-ready reverse proxy. Useful for quick deployments,\ndemos, and development.\n\nSimply shuttles HTTP(S) traffic from the --from address to the --to address.\nMultiple --to addresses may be specified by repeating the flag.\n\nUnless otherwise specified in the addresses, the --from address will be\nassumed to be HTTPS if a hostname is given, and the --to address will be\nassumed to be HTTP.\n\nIf the --from address has a host or IP, Caddy will attempt to serve the\nproxy over HTTPS with a certificate (unless overridden by the HTTP scheme\nor port).\n\nIf serving HTTPS: \n  --disable-redirects can be used to avoid binding to the HTTP port.\n  --internal-certs can be used to force issuance certs using the internal\n    CA instead of attempting to issue a public certificate.\n\nFor proxying:\n  --header-up can be used to set a request header to send to the upstream.\n  --header-down can be used to set a response header to send back to the client.\n  --change-host-header sets the Host header on the request to the address\n    of the upstream, instead of defaulting to the incoming Host header.\n\tThis is a shortcut for --header-up \"Host: {http.reverse_proxy.upstream.hostport}\".\n  --insecure disables TLS verification with the upstream. WARNING: THIS\n    DISABLES SECURITY BY NOT VERIFYING THE UPSTREAM'S CERTIFICATE.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"from\", \"f\", \"localhost\", \"Address on which to receive traffic\")\n\t\t\tcmd.Flags().StringSliceP(\"to\", \"t\", []string{}, \"Upstream address(es) to which traffic should be sent\")\n\t\t\tcmd.Flags().BoolP(\"change-host-header\", \"c\", false, \"Set upstream Host header to address of upstream\")\n\t\t\tcmd.Flags().BoolP(\"insecure\", \"\", false, \"Disable TLS verification (WARNING: DISABLES SECURITY BY NOT VERIFYING TLS CERTIFICATES!)\")\n\t\t\tcmd.Flags().BoolP(\"disable-redirects\", \"r\", false, \"Disable HTTP->HTTPS redirects\")\n\t\t\tcmd.Flags().BoolP(\"internal-certs\", \"i\", false, \"Use internal CA for issuing certs\")\n\t\t\tcmd.Flags().StringSliceP(\"header-up\", \"H\", []string{}, \"Set a request header to send to the upstream (format: \\\"Field: value\\\")\")\n\t\t\tcmd.Flags().StringSliceP(\"header-down\", \"d\", []string{}, \"Set a response header to send back to the client (format: \\\"Field: value\\\")\")\n\t\t\tcmd.Flags().BoolP(\"access-log\", \"\", false, \"Enable the access log\")\n\t\t\tcmd.Flags().BoolP(\"debug\", \"v\", false, \"Enable verbose debug logs\")\n\t\t\tcmd.RunE = caddycmd.WrapCommandFuncForCobra(cmdReverseProxy)\n\t\t},\n\t})\n}\n\nfunc cmdReverseProxy(fs caddycmd.Flags) (int, error) {\n\tcaddy.TrapSignals()\n\n\tfrom := fs.String(\"from\")\n\tchangeHost := fs.Bool(\"change-host-header\")\n\tinsecure := fs.Bool(\"insecure\")\n\tdisableRedir := fs.Bool(\"disable-redirects\")\n\tinternalCerts := fs.Bool(\"internal-certs\")\n\taccessLog := fs.Bool(\"access-log\")\n\tdebug := fs.Bool(\"debug\")\n\n\thttpPort := strconv.Itoa(caddyhttp.DefaultHTTPPort)\n\thttpsPort := strconv.Itoa(caddyhttp.DefaultHTTPSPort)\n\n\tto, err := fs.GetStringSlice(\"to\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid to flag: %v\", err)\n\t}\n\tif len(to) == 0 {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"--to is required\")\n\t}\n\n\t// set up the downstream address; assume missing information from given parts\n\tfromAddr, err := httpcaddyfile.ParseAddress(from)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid downstream address %s: %v\", from, err)\n\t}\n\tif fromAddr.Path != \"\" {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"paths are not allowed: %s\", from)\n\t}\n\tif fromAddr.Scheme == \"\" {\n\t\tif fromAddr.Port == httpPort || fromAddr.Host == \"\" {\n\t\t\tfromAddr.Scheme = \"http\"\n\t\t} else {\n\t\t\tfromAddr.Scheme = \"https\"\n\t\t}\n\t}\n\tif fromAddr.Port == \"\" {\n\t\tswitch fromAddr.Scheme {\n\t\tcase \"http\":\n\t\t\tfromAddr.Port = httpPort\n\t\tcase \"https\":\n\t\t\tfromAddr.Port = httpsPort\n\t\t}\n\t}\n\n\t// set up the upstream address; assume missing information from given parts\n\t// mixing schemes isn't supported, so use first defined (if available)\n\ttoAddresses := make([]string, len(to))\n\tvar toScheme string\n\tfor i, toLoc := range to {\n\t\taddr, err := parseUpstreamDialAddress(toLoc)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid upstream address %s: %v\", toLoc, err)\n\t\t}\n\t\tif addr.scheme != \"\" && toScheme == \"\" {\n\t\t\ttoScheme = addr.scheme\n\t\t}\n\t\ttoAddresses[i] = addr.dialAddr()\n\t}\n\n\t// proceed to build the handler and server\n\tht := HTTPTransport{}\n\tif toScheme == \"https\" {\n\t\tht.TLS = new(TLSConfig)\n\t\tif insecure {\n\t\t\tht.TLS.InsecureSkipVerify = true\n\t\t}\n\t}\n\n\tupstreamPool := UpstreamPool{}\n\tfor _, toAddr := range toAddresses {\n\t\tparsedAddr, err := caddy.ParseNetworkAddress(toAddr)\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid upstream address %s: %v\", toAddr, err)\n\t\t}\n\n\t\tif parsedAddr.StartPort == 0 && parsedAddr.EndPort == 0 {\n\t\t\t// unix networks don't have ports\n\t\t\tupstreamPool = append(upstreamPool, &Upstream{\n\t\t\t\tDial: toAddr,\n\t\t\t})\n\t\t} else {\n\t\t\t// expand a port range into multiple upstreams\n\t\t\tfor i := parsedAddr.StartPort; i <= parsedAddr.EndPort; i++ {\n\t\t\t\tupstreamPool = append(upstreamPool, &Upstream{\n\t\t\t\t\tDial: caddy.JoinNetworkAddress(\"\", parsedAddr.Host, fmt.Sprint(i)),\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\thandler := Handler{\n\t\tTransportRaw: caddyconfig.JSONModuleObject(ht, \"protocol\", \"http\", nil),\n\t\tUpstreams:    upstreamPool,\n\t}\n\n\t// set up header_up\n\theaderUp, err := fs.GetStringSlice(\"header-up\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid header flag: %v\", err)\n\t}\n\tif len(headerUp) > 0 {\n\t\treqHdr := make(http.Header)\n\t\tfor i, h := range headerUp {\n\t\t\tkey, val, found := strings.Cut(h, \":\")\n\t\t\tkey, val = strings.TrimSpace(key), strings.TrimSpace(val)\n\t\t\tif !found || key == \"\" || val == \"\" {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"header-up %d: invalid format \\\"%s\\\" (expecting \\\"Field: value\\\")\", i, h)\n\t\t\t}\n\t\t\treqHdr.Set(key, val)\n\t\t}\n\t\thandler.Headers = &headers.Handler{\n\t\t\tRequest: &headers.HeaderOps{\n\t\t\t\tSet: reqHdr,\n\t\t\t},\n\t\t}\n\t}\n\n\t// set up header_down\n\theaderDown, err := fs.GetStringSlice(\"header-down\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid header flag: %v\", err)\n\t}\n\tif len(headerDown) > 0 {\n\t\trespHdr := make(http.Header)\n\t\tfor i, h := range headerDown {\n\t\t\tkey, val, found := strings.Cut(h, \":\")\n\t\t\tkey, val = strings.TrimSpace(key), strings.TrimSpace(val)\n\t\t\tif !found || key == \"\" || val == \"\" {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"header-down %d: invalid format \\\"%s\\\" (expecting \\\"Field: value\\\")\", i, h)\n\t\t\t}\n\t\t\trespHdr.Set(key, val)\n\t\t}\n\t\tif handler.Headers == nil {\n\t\t\thandler.Headers = &headers.Handler{}\n\t\t}\n\t\thandler.Headers.Response = &headers.RespHeaderOps{\n\t\t\tHeaderOps: &headers.HeaderOps{\n\t\t\t\tSet: respHdr,\n\t\t\t},\n\t\t}\n\t}\n\n\tif changeHost {\n\t\tif handler.Headers == nil {\n\t\t\thandler.Headers = new(headers.Handler)\n\t\t}\n\t\tif handler.Headers.Request == nil {\n\t\t\thandler.Headers.Request = new(headers.HeaderOps)\n\t\t}\n\t\tif handler.Headers.Request.Set == nil {\n\t\t\thandler.Headers.Request.Set = http.Header{}\n\t\t}\n\t\thandler.Headers.Request.Set.Set(\"Host\", \"{http.reverse_proxy.upstream.hostport}\")\n\t}\n\n\troute := caddyhttp.Route{\n\t\tHandlersRaw: []json.RawMessage{\n\t\t\tcaddyconfig.JSONModuleObject(handler, \"handler\", \"reverse_proxy\", nil),\n\t\t},\n\t}\n\tif fromAddr.Host != \"\" {\n\t\troute.MatcherSetsRaw = []caddy.ModuleMap{\n\t\t\t{\n\t\t\t\t\"host\": caddyconfig.JSON(caddyhttp.MatchHost{fromAddr.Host}, nil),\n\t\t\t},\n\t\t}\n\t}\n\n\tserver := &caddyhttp.Server{\n\t\tRoutes: caddyhttp.RouteList{route},\n\t\tListen: []string{\":\" + fromAddr.Port},\n\t}\n\tif accessLog {\n\t\tserver.Logs = &caddyhttp.ServerLogConfig{}\n\t}\n\n\tif fromAddr.Scheme == \"http\" {\n\t\tserver.AutoHTTPS = &caddyhttp.AutoHTTPSConfig{Disabled: true}\n\t} else if disableRedir {\n\t\tserver.AutoHTTPS = &caddyhttp.AutoHTTPSConfig{DisableRedir: true}\n\t}\n\n\thttpApp := caddyhttp.App{\n\t\tServers: map[string]*caddyhttp.Server{\"proxy\": server},\n\t}\n\n\tappsRaw := caddy.ModuleMap{\n\t\t\"http\": caddyconfig.JSON(httpApp, nil),\n\t}\n\tif internalCerts && fromAddr.Host != \"\" {\n\t\ttlsApp := caddytls.TLS{\n\t\t\tAutomation: &caddytls.AutomationConfig{\n\t\t\t\tPolicies: []*caddytls.AutomationPolicy{{\n\t\t\t\t\tSubjectsRaw: []string{fromAddr.Host},\n\t\t\t\t\tIssuersRaw:  []json.RawMessage{json.RawMessage(`{\"module\":\"internal\"}`)},\n\t\t\t\t}},\n\t\t\t},\n\t\t}\n\t\tappsRaw[\"tls\"] = caddyconfig.JSON(tlsApp, nil)\n\t}\n\n\tvar false bool\n\tcfg := &caddy.Config{\n\t\tAdmin: &caddy.AdminConfig{\n\t\t\tDisabled: true,\n\t\t\tConfig: &caddy.ConfigSettings{\n\t\t\t\tPersist: &false,\n\t\t\t},\n\t\t},\n\t\tAppsRaw: appsRaw,\n\t}\n\n\tif debug {\n\t\tcfg.Logging = &caddy.Logging{\n\t\t\tLogs: map[string]*caddy.CustomLog{\n\t\t\t\t\"default\": {BaseLog: caddy.BaseLog{Level: zap.DebugLevel.CapitalString()}},\n\t\t\t},\n\t\t}\n\t}\n\n\terr = caddy.Run(cfg)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tcaddy.Log().Info(\"caddy proxying\", zap.String(\"from\", fromAddr.String()), zap.Strings(\"to\", toAddresses))\n\tif len(toAddresses) > 1 {\n\t\tcaddy.Log().Info(\"using default load balancing policy\", zap.String(\"policy\", \"random\"))\n\t}\n\n\tselect {}\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/command.go",
    "chunk_type": "code"
  },
  {
    "content": "package reverseproxy\n\nimport (\n\t\"errors\"\n\t\"runtime/debug\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/prometheus/client_golang/prometheus\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nvar reverseProxyMetrics = struct {\n\tonce             sync.Once\n\tupstreamsHealthy *prometheus.GaugeVec\n\tlogger           *zap.Logger\n}{}\n\nfunc initReverseProxyMetrics(handler *Handler, registry *prometheus.Registry) {\n\tconst ns, sub = \"caddy\", \"reverse_proxy\"\n\n\tupstreamsLabels := []string{\"upstream\"}\n\treverseProxyMetrics.once.Do(func() {\n\t\treverseProxyMetrics.upstreamsHealthy = prometheus.NewGaugeVec(prometheus.GaugeOpts{\n\t\t\tNamespace: ns,\n\t\t\tSubsystem: sub,\n\t\t\tName:      \"upstreams_healthy\",\n\t\t\tHelp:      \"Health status of reverse proxy upstreams.\",\n\t\t}, upstreamsLabels)\n\t})\n\n\t// duplicate registration could happen if multiple sites with reverse proxy are configured; so ignore the error because\n\t// there's no good way to capture having multiple sites with reverse proxy. If this happens, the metrics will be\n\t// registered twice, but the second registration will be ignored.\n\tif err := registry.Register(reverseProxyMetrics.upstreamsHealthy); err != nil &&\n\t\t!errors.Is(err, prometheus.AlreadyRegisteredError{\n\t\t\tExistingCollector: reverseProxyMetrics.upstreamsHealthy,\n\t\t\tNewCollector:      reverseProxyMetrics.upstreamsHealthy,\n\t\t}) {\n\t\tpanic(err)\n\t}\n\n\treverseProxyMetrics.logger = handler.logger.Named(\"reverse_proxy.metrics\")\n}\n\ntype metricsUpstreamsHealthyUpdater struct {\n\thandler *Handler\n}\n\nfunc newMetricsUpstreamsHealthyUpdater(handler *Handler, ctx caddy.Context) *metricsUpstreamsHealthyUpdater {\n\tinitReverseProxyMetrics(handler, ctx.GetMetricsRegistry())\n\treverseProxyMetrics.upstreamsHealthy.Reset()\n\n\treturn &metricsUpstreamsHealthyUpdater{handler}\n}\n\nfunc (m *metricsUpstreamsHealthyUpdater) init() {\n\tgo func() {\n\t\tdefer func() {\n\t\t\tif err := recover(); err != nil {\n\t\t\t\tif c := reverseProxyMetrics.logger.Check(zapcore.ErrorLevel, \"upstreams healthy metrics updater panicked\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.Any(\"error\", err),\n\t\t\t\t\t\tzap.ByteString(\"stack\", debug.Stack()),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\n\t\tm.update()\n\n\t\tticker := time.NewTicker(10 * time.Second)\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase <-ticker.C:\n\t\t\t\tm.update()\n\t\t\tcase <-m.handler.ctx.Done():\n\t\t\t\tticker.Stop()\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}()\n}\n\nfunc (m *metricsUpstreamsHealthyUpdater) update() {\n\tfor _, upstream := range m.handler.Upstreams {\n\t\tlabels := prometheus.Labels{\"upstream\": upstream.Dial}\n\n\t\tgaugeValue := 0.0\n\t\tif upstream.Healthy() {\n\t\t\tgaugeValue = 1.0\n\t\t}\n\n\t\treverseProxyMetrics.upstreamsHealthy.With(labels).Set(gaugeValue)\n\t}\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/metrics.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\tweakrand \"math/rand\"\n\t\"net\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync/atomic\"\n\t\"time\"\n\n\t\"github.com/cespare/xxhash/v2\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(RandomSelection{})\n\tcaddy.RegisterModule(RandomChoiceSelection{})\n\tcaddy.RegisterModule(LeastConnSelection{})\n\tcaddy.RegisterModule(RoundRobinSelection{})\n\tcaddy.RegisterModule(WeightedRoundRobinSelection{})\n\tcaddy.RegisterModule(FirstSelection{})\n\tcaddy.RegisterModule(IPHashSelection{})\n\tcaddy.RegisterModule(ClientIPHashSelection{})\n\tcaddy.RegisterModule(URIHashSelection{})\n\tcaddy.RegisterModule(QueryHashSelection{})\n\tcaddy.RegisterModule(HeaderHashSelection{})\n\tcaddy.RegisterModule(CookieHashSelection{})\n}\n\n// RandomSelection is a policy that selects\n// an available host at random.\ntype RandomSelection struct{}\n\n// CaddyModule returns the Caddy module information.\nfunc (RandomSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.random\",\n\t\tNew: func() caddy.Module { return new(RandomSelection) },\n\t}\n}\n\n// Select returns an available host, if any.\nfunc (r RandomSelection) Select(pool UpstreamPool, request *http.Request, _ http.ResponseWriter) *Upstream {\n\treturn selectRandomHost(pool)\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (r *RandomSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\treturn nil\n}\n\n// WeightedRoundRobinSelection is a policy that selects\n// a host based on weighted round-robin ordering.\ntype WeightedRoundRobinSelection struct {\n\t// The weight of each upstream in order,\n\t// corresponding with the list of upstreams configured.\n\tWeights     []int `json:\"weights,omitempty\"`\n\tindex       uint32\n\ttotalWeight int\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (WeightedRoundRobinSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID: \"http.reverse_proxy.selection_policies.weighted_round_robin\",\n\t\tNew: func() caddy.Module {\n\t\t\treturn new(WeightedRoundRobinSelection)\n\t\t},\n\t}\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (r *WeightedRoundRobinSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\n\targs := d.RemainingArgs()\n\tif len(args) == 0 {\n\t\treturn d.ArgErr()\n\t}\n\n\tfor _, weight := range args {\n\t\tweightInt, err := strconv.Atoi(weight)\n\t\tif err != nil {\n\t\t\treturn d.Errf(\"invalid weight value '%s': %v\", weight, err)\n\t\t}\n\t\tif weightInt < 0 {\n\t\t\treturn d.Errf(\"invalid weight value '%s': weight should be non-negative\", weight)\n\t\t}\n\t\tr.Weights = append(r.Weights, weightInt)\n\t}\n\treturn nil\n}\n\n// Provision sets up r.\nfunc (r *WeightedRoundRobinSelection) Provision(ctx caddy.Context) error {\n\tfor _, weight := range r.Weights {\n\t\tr.totalWeight += weight\n\t}\n\treturn nil\n}\n\n// Select returns an available host, if any.\nfunc (r *WeightedRoundRobinSelection) Select(pool UpstreamPool, _ *http.Request, _ http.ResponseWriter) *Upstream {\n\tif len(pool) == 0 {\n\t\treturn nil\n\t}\n\tif len(r.Weights) < 2 {\n\t\treturn pool[0]\n\t}\n\tvar index, totalWeight int\n\tvar weights []int\n\n\tfor _, w := range r.Weights {\n\t\tif w > 0 {\n\t\t\tweights = append(weights, w)\n\t\t}\n\t}\n\tcurrentWeight := int(atomic.AddUint32(&r.index, 1)) % r.totalWeight\n\tfor i, weight := range weights {\n\t\ttotalWeight += weight\n\t\tif currentWeight < totalWeight {\n\t\t\tindex = i\n\t\t\tbreak\n\t\t}\n\t}\n\n\tupstreams := make([]*Upstream, 0, len(weights))\n\tfor i, upstream := range pool {\n\t\tif !upstream.Available() || r.Weights[i] == 0 {\n\t\t\tcontinue\n\t\t}\n\t\tupstreams = append(upstreams, upstream)\n\t\tif len(upstreams) == cap(upstreams) {\n\t\t\tbreak\n\t\t}\n\t}\n\tif len(upstreams) == 0 {\n\t\treturn nil\n\t}\n\treturn upstreams[index%len(upstreams)]\n}\n\n// RandomChoiceSelection is a policy that selects\n// two or more available hosts at random, then\n// chooses the one with the least load.\ntype RandomChoiceSelection struct {\n\t// The size of the sub-pool created from the larger upstream pool. The default value\n\t// is 2 and the maximum at selection time is the size of the upstream pool.\n\tChoose int `json:\"choose,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (RandomChoiceSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.random_choose\",\n\t\tNew: func() caddy.Module { return new(RandomChoiceSelection) },\n\t}\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (r *RandomChoiceSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\n\tif !d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\tchooseStr := d.Val()\n\tchoose, err := strconv.Atoi(chooseStr)\n\tif err != nil {\n\t\treturn d.Errf(\"invalid choice value '%s': %v\", chooseStr, err)\n\t}\n\tr.Choose = choose\n\treturn nil\n}\n\n// Provision sets up r.\nfunc (r *RandomChoiceSelection) Provision(ctx caddy.Context) error {\n\tif r.Choose == 0 {\n\t\tr.Choose = 2\n\t}\n\treturn nil\n}\n\n// Validate ensures that r's configuration is valid.\nfunc (r RandomChoiceSelection) Validate() error {\n\tif r.Choose < 2 {\n\t\treturn fmt.Errorf(\"choose must be at least 2\")\n\t}\n\treturn nil\n}\n\n// Select returns an available host, if any.\nfunc (r RandomChoiceSelection) Select(pool UpstreamPool, _ *http.Request, _ http.ResponseWriter) *Upstream {\n\tk := min(r.Choose, len(pool))\n\tchoices := make([]*Upstream, k)\n\tfor i, upstream := range pool {\n\t\tif !upstream.Available() {\n\t\t\tcontinue\n\t\t}\n\t\tj := weakrand.Intn(i + 1) //nolint:gosec\n\t\tif j < k {\n\t\t\tchoices[j] = upstream\n\t\t}\n\t}\n\treturn leastRequests(choices)\n}\n\n// LeastConnSelection is a policy that selects the\n// host with the least active requests. If multiple\n// hosts have the same fewest number, one is chosen\n// randomly. The term \"conn\" or \"connection\" is used\n// in this policy name due to its similar meaning in\n// other software, but our load balancer actually\n// counts active requests rather than connections,\n// since these days requests are multiplexed onto\n// shared connections.\ntype LeastConnSelection struct{}\n\n// CaddyModule returns the Caddy module information.\nfunc (LeastConnSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.least_conn\",\n\t\tNew: func() caddy.Module { return new(LeastConnSelection) },\n\t}\n}\n\n// Select selects the up host with the least number of connections in the\n// pool. If more than one host has the same least number of connections,\n// one of the hosts is chosen at random.\nfunc (LeastConnSelection) Select(pool UpstreamPool, _ *http.Request, _ http.ResponseWriter) *Upstream {\n\tvar bestHost *Upstream\n\tvar count int\n\tleastReqs := -1\n\n\tfor _, host := range pool {\n\t\tif !host.Available() {\n\t\t\tcontinue\n\t\t}\n\t\tnumReqs := host.NumRequests()\n\t\tif leastReqs == -1 || numReqs < leastReqs {\n\t\t\tleastReqs = numReqs\n\t\t\tcount = 0\n\t\t}\n\n\t\t// among hosts with same least connections, perform a reservoir\n\t\t// sample: https://en.wikipedia.org/wiki/Reservoir_sampling\n\t\tif numReqs == leastReqs {\n\t\t\tcount++\n\t\t\tif count == 1 || (weakrand.Int()%count) == 0 { //nolint:gosec\n\t\t\t\tbestHost = host\n\t\t\t}\n\t\t}\n\t}\n\n\treturn bestHost\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (r *LeastConnSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\treturn nil\n}\n\n// RoundRobinSelection is a policy that selects\n// a host based on round-robin ordering.\ntype RoundRobinSelection struct {\n\trobin uint32\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (RoundRobinSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.round_robin\",\n\t\tNew: func() caddy.Module { return new(RoundRobinSelection) },\n\t}\n}\n\n// Select returns an available host, if any.\nfunc (r *RoundRobinSelection) Select(pool UpstreamPool, _ *http.Request, _ http.ResponseWriter) *Upstream {\n\tn := uint32(len(pool))\n\tif n == 0 {\n\t\treturn nil\n\t}\n\tfor i := uint32(0); i < n; i++ {\n\t\trobin := atomic.AddUint32(&r.robin, 1)\n\t\thost := pool[robin%n]\n\t\tif host.Available() {\n\t\t\treturn host\n\t\t}\n\t}\n\treturn nil\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (r *RoundRobinSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\treturn nil\n}\n\n// FirstSelection is a policy that selects\n// the first available host.\ntype FirstSelection struct{}\n\n// CaddyModule returns the Caddy module information.\nfunc (FirstSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.first\",\n\t\tNew: func() caddy.Module { return new(FirstSelection) },\n\t}\n}\n\n// Select returns an available host, if any.\nfunc (FirstSelection) Select(pool UpstreamPool, _ *http.Request, _ http.ResponseWriter) *Upstream {\n\tfor _, host := range pool {\n\t\tif host.Available() {\n\t\t\treturn host\n\t\t}\n\t}\n\treturn nil\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (r *FirstSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\treturn nil\n}\n\n// IPHashSelection is a policy that selects a host\n// based on hashing the remote IP of the request.\ntype IPHashSelection struct{}\n\n// CaddyModule returns the Caddy module information.\nfunc (IPHashSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.ip_hash\",\n\t\tNew: func() caddy.Module { return new(IPHashSelection) },\n\t}\n}\n\n// Select returns an available host, if any.\nfunc (IPHashSelection) Select(pool UpstreamPool, req *http.Request, _ http.ResponseWriter) *Upstream {\n\tclientIP, _, err := net.SplitHostPort(req.RemoteAddr)\n\tif err != nil {\n\t\tclientIP = req.RemoteAddr\n\t}\n\treturn hostByHashing(pool, clientIP)\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (r *IPHashSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\treturn nil\n}\n\n// ClientIPHashSelection is a policy that selects a host\n// based on hashing the client IP of the request, as determined\n// by the HTTP app's trusted proxies settings.\ntype ClientIPHashSelection struct{}\n\n// CaddyModule returns the Caddy module information.\nfunc (ClientIPHashSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.client_ip_hash\",\n\t\tNew: func() caddy.Module { return new(ClientIPHashSelection) },\n\t}\n}\n\n// Select returns an available host, if any.\nfunc (ClientIPHashSelection) Select(pool UpstreamPool, req *http.Request, _ http.ResponseWriter) *Upstream {\n\taddress := caddyhttp.GetVar(req.Context(), caddyhttp.ClientIPVarKey).(string)\n\tclientIP, _, err := net.SplitHostPort(address)\n\tif err != nil {\n\t\tclientIP = address // no port\n\t}\n\treturn hostByHashing(pool, clientIP)\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (r *ClientIPHashSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\treturn nil\n}\n\n// URIHashSelection is a policy that selects a\n// host by hashing the request URI.\ntype URIHashSelection struct{}\n\n// CaddyModule returns the Caddy module information.\nfunc (URIHashSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.uri_hash\",\n\t\tNew: func() caddy.Module { return new(URIHashSelection) },\n\t}\n}\n\n// Select returns an available host, if any.\nfunc (URIHashSelection) Select(pool UpstreamPool, req *http.Request, _ http.ResponseWriter) *Upstream {\n\treturn hostByHashing(pool, req.RequestURI)\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (r *URIHashSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\treturn nil\n}\n\n// QueryHashSelection is a policy that selects\n// a host based on a given request query parameter.\ntype QueryHashSelection struct {\n\t// The query key whose value is to be hashed and used for upstream selection.\n\tKey string `json:\"key,omitempty\"`\n\n\t// The fallback policy to use if the query key is not present. Defaults to `random`.\n\tFallbackRaw json.RawMessage `json:\"fallback,omitempty\" caddy:\"namespace=http.reverse_proxy.selection_policies inline_key=policy\"`\n\tfallback    Selector\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (QueryHashSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.query\",\n\t\tNew: func() caddy.Module { return new(QueryHashSelection) },\n\t}\n}\n\n// Provision sets up the module.\nfunc (s *QueryHashSelection) Provision(ctx caddy.Context) error {\n\tif s.Key == \"\" {\n\t\treturn fmt.Errorf(\"query key is required\")\n\t}\n\tif s.FallbackRaw == nil {\n\t\ts.FallbackRaw = caddyconfig.JSONModuleObject(RandomSelection{}, \"policy\", \"random\", nil)\n\t}\n\tmod, err := ctx.LoadModule(s, \"FallbackRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading fallback selection policy: %s\", err)\n\t}\n\ts.fallback = mod.(Selector)\n\treturn nil\n}\n\n// Select returns an available host, if any.\nfunc (s QueryHashSelection) Select(pool UpstreamPool, req *http.Request, _ http.ResponseWriter) *Upstream {\n\t// Since the query may have multiple values for the same key,\n\t// we'll join them to avoid a problem where the user can control\n\t// the upstream that the request goes to by sending multiple values\n\t// for the same key, when the upstream only considers the first value.\n\t// Keep in mind that a client changing the order of the values may\n\t// affect which upstream is selected, but this is a semantically\n\t// different request, because the order of the values is significant.\n\tvals := strings.Join(req.URL.Query()[s.Key], \",\")\n\tif vals == \"\" {\n\t\treturn s.fallback.Select(pool, req, nil)\n\t}\n\treturn hostByHashing(pool, vals)\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (s *QueryHashSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\n\tif !d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\ts.Key = d.Val()\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"fallback\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif s.FallbackRaw != nil {\n\t\t\t\treturn d.Err(\"fallback selection policy already specified\")\n\t\t\t}\n\t\t\tmod, err := loadFallbackPolicy(d)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\ts.FallbackRaw = mod\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized option '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\n// HeaderHashSelection is a policy that selects\n// a host based on a given request header.\ntype HeaderHashSelection struct {\n\t// The HTTP header field whose value is to be hashed and used for upstream selection.\n\tField string `json:\"field,omitempty\"`\n\n\t// The fallback policy to use if the header is not present. Defaults to `random`.\n\tFallbackRaw json.RawMessage `json:\"fallback,omitempty\" caddy:\"namespace=http.reverse_proxy.selection_policies inline_key=policy\"`\n\tfallback    Selector\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (HeaderHashSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.header\",\n\t\tNew: func() caddy.Module { return new(HeaderHashSelection) },\n\t}\n}\n\n// Provision sets up the module.\nfunc (s *HeaderHashSelection) Provision(ctx caddy.Context) error {\n\tif s.Field == \"\" {\n\t\treturn fmt.Errorf(\"header field is required\")\n\t}\n\tif s.FallbackRaw == nil {\n\t\ts.FallbackRaw = caddyconfig.JSONModuleObject(RandomSelection{}, \"policy\", \"random\", nil)\n\t}\n\tmod, err := ctx.LoadModule(s, \"FallbackRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading fallback selection policy: %s\", err)\n\t}\n\ts.fallback = mod.(Selector)\n\treturn nil\n}\n\n// Select returns an available host, if any.\nfunc (s HeaderHashSelection) Select(pool UpstreamPool, req *http.Request, _ http.ResponseWriter) *Upstream {\n\t// The Host header should be obtained from the req.Host field\n\t// since net/http removes it from the header map.\n\tif s.Field == \"Host\" && req.Host != \"\" {\n\t\treturn hostByHashing(pool, req.Host)\n\t}\n\n\tval := req.Header.Get(s.Field)\n\tif val == \"\" {\n\t\treturn s.fallback.Select(pool, req, nil)\n\t}\n\treturn hostByHashing(pool, val)\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens.\nfunc (s *HeaderHashSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume policy name\n\n\tif !d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\ts.Field = d.Val()\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"fallback\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif s.FallbackRaw != nil {\n\t\t\t\treturn d.Err(\"fallback selection policy already specified\")\n\t\t\t}\n\t\t\tmod, err := loadFallbackPolicy(d)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\ts.FallbackRaw = mod\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized option '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\n// CookieHashSelection is a policy that selects\n// a host based on a given cookie name.\ntype CookieHashSelection struct {\n\t// The HTTP cookie name whose value is to be hashed and used for upstream selection.\n\tName string `json:\"name,omitempty\"`\n\t// Secret to hash (Hmac256) chosen upstream in cookie\n\tSecret string `json:\"secret,omitempty\"`\n\t// The cookie's Max-Age before it expires. Default is no expiry.\n\tMaxAge caddy.Duration `json:\"max_age,omitempty\"`\n\n\t// The fallback policy to use if the cookie is not present. Defaults to `random`.\n\tFallbackRaw json.RawMessage `json:\"fallback,omitempty\" caddy:\"namespace=http.reverse_proxy.selection_policies inline_key=policy\"`\n\tfallback    Selector\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (CookieHashSelection) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.selection_policies.cookie\",\n\t\tNew: func() caddy.Module { return new(CookieHashSelection) },\n\t}\n}\n\n// Provision sets up the module.\nfunc (s *CookieHashSelection) Provision(ctx caddy.Context) error {\n\tif s.Name == \"\" {\n\t\ts.Name = \"lb\"\n\t}\n\tif s.FallbackRaw == nil {\n\t\ts.FallbackRaw = caddyconfig.JSONModuleObject(RandomSelection{}, \"policy\", \"random\", nil)\n\t}\n\tmod, err := ctx.LoadModule(s, \"FallbackRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading fallback selection policy: %s\", err)\n\t}\n\ts.fallback = mod.(Selector)\n\treturn nil\n}\n\n// Select returns an available host, if any.\nfunc (s CookieHashSelection) Select(pool UpstreamPool, req *http.Request, w http.ResponseWriter) *Upstream {\n\t// selects a new Host using the fallback policy (typically random)\n\t// and write a sticky session cookie to the response.\n\tselectNewHost := func() *Upstream {\n\t\tupstream := s.fallback.Select(pool, req, w)\n\t\tif upstream == nil {\n\t\t\treturn nil\n\t\t}\n\t\tsha, err := hashCookie(s.Secret, upstream.Dial)\n\t\tif err != nil {\n\t\t\treturn upstream\n\t\t}\n\t\tcookie := &http.Cookie{\n\t\t\tName:   s.Name,\n\t\t\tValue:  sha,\n\t\t\tPath:   \"/\",\n\t\t\tSecure: false,\n\t\t}\n\t\tisProxyHttps := false\n\t\tif trusted, ok := caddyhttp.GetVar(req.Context(), caddyhttp.TrustedProxyVarKey).(bool); ok && trusted {\n\t\t\txfp, xfpOk, _ := lastHeaderValue(req.Header, \"X-Forwarded-Proto\")\n\t\t\tisProxyHttps = xfpOk && xfp == \"https\"\n\t\t}\n\t\tif req.TLS != nil || isProxyHttps {\n\t\t\tcookie.Secure = true\n\t\t\tcookie.SameSite = http.SameSiteNoneMode\n\t\t}\n\t\tif s.MaxAge > 0 {\n\t\t\tcookie.MaxAge = int(time.Duration(s.MaxAge).Seconds())\n\t\t}\n\t\thttp.SetCookie(w, cookie)\n\t\treturn upstream\n\t}\n\n\tcookie, err := req.Cookie(s.Name)\n\t// If there's no cookie, select a host using the fallback policy\n\tif err != nil || cookie == nil {\n\t\treturn selectNewHost()\n\t}\n\t// If the cookie is present, loop over the available upstreams until we find a match\n\tcookieValue := cookie.Value\n\tfor _, upstream := range pool {\n\t\tif !upstream.Available() {\n\t\t\tcontinue\n\t\t}\n\t\tsha, err := hashCookie(s.Secret, upstream.Dial)\n\t\tif err == nil && sha == cookieValue {\n\t\t\treturn upstream\n\t\t}\n\t}\n\t// If there is no matching host, select a host using the fallback policy\n\treturn selectNewHost()\n}\n\n// UnmarshalCaddyfile sets up the module from Caddyfile tokens. Syntax:\n//\n//\tlb_policy cookie [<name> [<secret>]] {\n//\t\tfallback <policy>\n//\t\tmax_age <duration>\n//\t}\n//\n// By default name is `lb`\nfunc (s *CookieHashSelection) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\targs := d.RemainingArgs()\n\tswitch len(args) {\n\tcase 1:\n\tcase 2:\n\t\ts.Name = args[1]\n\tcase 3:\n\t\ts.Name = args[1]\n\t\ts.Secret = args[2]\n\tdefault:\n\t\treturn d.ArgErr()\n\t}\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"fallback\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif s.FallbackRaw != nil {\n\t\t\t\treturn d.Err(\"fallback selection policy already specified\")\n\t\t\t}\n\t\t\tmod, err := loadFallbackPolicy(d)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\ts.FallbackRaw = mod\n\t\tcase \"max_age\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif s.MaxAge != 0 {\n\t\t\t\treturn d.Err(\"cookie max_age already specified\")\n\t\t\t}\n\t\t\tmaxAge, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid duration: %s\", d.Val())\n\t\t\t}\n\t\t\tif maxAge <= 0 {\n\t\t\t\treturn d.Errf(\"invalid duration: %s, max_age should be non-zero and positive\", d.Val())\n\t\t\t}\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\ts.MaxAge = caddy.Duration(maxAge)\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized option '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\n// hashCookie hashes (HMAC 256) some data with the secret\nfunc hashCookie(secret string, data string) (string, error) {\n\th := hmac.New(sha256.New, []byte(secret))\n\t_, err := h.Write([]byte(data))\n\tif err != nil {\n\t\treturn \"\", err\n\t}\n\treturn hex.EncodeToString(h.Sum(nil)), nil\n}\n\n// selectRandomHost returns a random available host\nfunc selectRandomHost(pool []*Upstream) *Upstream {\n\t// use reservoir sampling because the number of available\n\t// hosts isn't known: https://en.wikipedia.org/wiki/Reservoir_sampling\n\tvar randomHost *Upstream\n\tvar count int\n\tfor _, upstream := range pool {\n\t\tif !upstream.Available() {\n\t\t\tcontinue\n\t\t}\n\t\t// (n % 1 == 0) holds for all n, therefore a\n\t\t// upstream will always be chosen if there is at\n\t\t// least one available\n\t\tcount++\n\t\tif (weakrand.Int() % count) == 0 { //nolint:gosec\n\t\t\trandomHost = upstream\n\t\t}\n\t}\n\treturn randomHost\n}\n\n// leastRequests returns the host with the\n// least number of active requests to it.\n// If more than one host has the same\n// least number of active requests, then\n// one of those is chosen at random.\nfunc leastRequests(upstreams []*Upstream) *Upstream {\n\tif len(upstreams) == 0 {\n\t\treturn nil\n\t}\n\tvar best []*Upstream\n\tbestReqs := -1\n\tfor _, upstream := range upstreams {\n\t\tif upstream == nil {\n\t\t\tcontinue\n\t\t}\n\t\treqs := upstream.NumRequests()\n\t\tif reqs == 0 {\n\t\t\treturn upstream\n\t\t}\n\t\t// If bestReqs was just initialized to -1\n\t\t// we need to append upstream also\n\t\tif reqs <= bestReqs || bestReqs == -1 {\n\t\t\tbestReqs = reqs\n\t\t\tbest = append(best, upstream)\n\t\t}\n\t}\n\tif len(best) == 0 {\n\t\treturn nil\n\t}\n\tif len(best) == 1 {\n\t\treturn best[0]\n\t}\n\treturn best[weakrand.Intn(len(best))] //nolint:gosec\n}\n\n// hostByHashing returns an available host from pool based on a hashable string s.\nfunc hostByHashing(pool []*Upstream, s string) *Upstream {\n\t// Highest Random Weight (HRW, or \"Rendezvous\") hashing,\n\t// guarantees stability when the list of upstreams changes;\n\t// see https://medium.com/i0exception/rendezvous-hashing-8c00e2fb58b0,\n\t// https://randorithms.com/2020/12/26/rendezvous-hashing.html,\n\t// and https://en.wikipedia.org/wiki/Rendezvous_hashing.\n\tvar highestHash uint64\n\tvar upstream *Upstream\n\tfor _, up := range pool {\n\t\tif !up.Available() {\n\t\t\tcontinue\n\t\t}\n\t\th := hash(up.String() + s) // important to hash key and server together\n\t\tif h > highestHash {\n\t\t\thighestHash = h\n\t\t\tupstream = up\n\t\t}\n\t}\n\treturn upstream\n}\n\n// hash calculates a fast hash based on s.\nfunc hash(s string) uint64 {\n\th := xxhash.New()\n\t_, _ = h.Write([]byte(s))\n\treturn h.Sum64()\n}\n\nfunc loadFallbackPolicy(d *caddyfile.Dispenser) (json.RawMessage, error) {\n\tname := d.Val()\n\tmodID := \"http.reverse_proxy.selection_policies.\" + name\n\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsel, ok := unm.(Selector)\n\tif !ok {\n\t\treturn nil, d.Errf(\"module %s (%T) is not a reverseproxy.Selector\", modID, unm)\n\t}\n\treturn caddyconfig.JSONModuleObject(sel, \"policy\", name, nil), nil\n}\n\n// Interface guards\nvar (\n\t_ Selector = (*RandomSelection)(nil)\n\t_ Selector = (*RandomChoiceSelection)(nil)\n\t_ Selector = (*LeastConnSelection)(nil)\n\t_ Selector = (*RoundRobinSelection)(nil)\n\t_ Selector = (*WeightedRoundRobinSelection)(nil)\n\t_ Selector = (*FirstSelection)(nil)\n\t_ Selector = (*IPHashSelection)(nil)\n\t_ Selector = (*ClientIPHashSelection)(nil)\n\t_ Selector = (*URIHashSelection)(nil)\n\t_ Selector = (*QueryHashSelection)(nil)\n\t_ Selector = (*HeaderHashSelection)(nil)\n\t_ Selector = (*CookieHashSelection)(nil)\n\n\t_ caddy.Validator = (*RandomChoiceSelection)(nil)\n\n\t_ caddy.Provisioner = (*RandomChoiceSelection)(nil)\n\t_ caddy.Provisioner = (*WeightedRoundRobinSelection)(nil)\n\n\t_ caddyfile.Unmarshaler = (*RandomChoiceSelection)(nil)\n\t_ caddyfile.Unmarshaler = (*WeightedRoundRobinSelection)(nil)\n)\n",
    "source_file": "modules/caddyhttp/reverseproxy/selectionpolicies.go",
    "chunk_type": "code"
  },
  {
    "content": "package reverseproxy\n\nimport (\n\t\"context\"\n\t\"encoding/json\"\n\t\"fmt\"\n\tweakrand \"math/rand\"\n\t\"net\"\n\t\"net/http\"\n\t\"strconv\"\n\t\"sync\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(SRVUpstreams{})\n\tcaddy.RegisterModule(AUpstreams{})\n\tcaddy.RegisterModule(MultiUpstreams{})\n}\n\n// SRVUpstreams provides upstreams from SRV lookups.\n// The lookup DNS name can be configured either by\n// its individual parts (that is, specifying the\n// service, protocol, and name separately) to form\n// the standard \"_service._proto.name\" domain, or\n// the domain can be specified directly in name by\n// leaving service and proto empty. See RFC 2782.\n//\n// Lookups are cached and refreshed at the configured\n// refresh interval.\n//\n// Returned upstreams are sorted by priority and weight.\ntype SRVUpstreams struct {\n\t// The service label.\n\tService string `json:\"service,omitempty\"`\n\n\t// The protocol label; either tcp or udp.\n\tProto string `json:\"proto,omitempty\"`\n\n\t// The name label; or, if service and proto are\n\t// empty, the entire domain name to look up.\n\tName string `json:\"name,omitempty\"`\n\n\t// The interval at which to refresh the SRV lookup.\n\t// Results are cached between lookups. Default: 1m\n\tRefresh caddy.Duration `json:\"refresh,omitempty\"`\n\n\t// If > 0 and there is an error with the lookup,\n\t// continue to use the cached results for up to\n\t// this long before trying again, (even though they\n\t// are stale) instead of returning an error to the\n\t// client. Default: 0s.\n\tGracePeriod caddy.Duration `json:\"grace_period,omitempty\"`\n\n\t// Configures the DNS resolver used to resolve the\n\t// SRV address to SRV records.\n\tResolver *UpstreamResolver `json:\"resolver,omitempty\"`\n\n\t// If Resolver is configured, how long to wait before\n\t// timing out trying to connect to the DNS server.\n\tDialTimeout caddy.Duration `json:\"dial_timeout,omitempty\"`\n\n\t// If Resolver is configured, how long to wait before\n\t// spawning an RFC 6555 Fast Fallback connection.\n\t// A negative value disables this.\n\tFallbackDelay caddy.Duration `json:\"dial_fallback_delay,omitempty\"`\n\n\tresolver *net.Resolver\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (SRVUpstreams) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.upstreams.srv\",\n\t\tNew: func() caddy.Module { return new(SRVUpstreams) },\n\t}\n}\n\nfunc (su *SRVUpstreams) Provision(ctx caddy.Context) error {\n\tsu.logger = ctx.Logger()\n\tif su.Refresh == 0 {\n\t\tsu.Refresh = caddy.Duration(time.Minute)\n\t}\n\n\tif su.Resolver != nil {\n\t\terr := su.Resolver.ParseAddresses()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\td := &net.Dialer{\n\t\t\tTimeout:       time.Duration(su.DialTimeout),\n\t\t\tFallbackDelay: time.Duration(su.FallbackDelay),\n\t\t}\n\t\tsu.resolver = &net.Resolver{\n\t\t\tPreferGo: true,\n\t\t\tDial: func(ctx context.Context, _, _ string) (net.Conn, error) {\n\t\t\t\t//nolint:gosec\n\t\t\t\taddr := su.Resolver.netAddrs[weakrand.Intn(len(su.Resolver.netAddrs))]\n\t\t\t\treturn d.DialContext(ctx, addr.Network, addr.JoinHostPort(0))\n\t\t\t},\n\t\t}\n\t}\n\tif su.resolver == nil {\n\t\tsu.resolver = net.DefaultResolver\n\t}\n\n\treturn nil\n}\n\nfunc (su SRVUpstreams) GetUpstreams(r *http.Request) ([]*Upstream, error) {\n\tsuAddr, service, proto, name := su.expandedAddr(r)\n\n\t// first, use a cheap read-lock to return a cached result quickly\n\tsrvsMu.RLock()\n\tcached := srvs[suAddr]\n\tsrvsMu.RUnlock()\n\tif cached.isFresh() {\n\t\treturn allNew(cached.upstreams), nil\n\t}\n\n\t// otherwise, obtain a write-lock to update the cached value\n\tsrvsMu.Lock()\n\tdefer srvsMu.Unlock()\n\n\t// check to see if it's still stale, since we're now in a different\n\t// lock from when we first checked freshness; another goroutine might\n\t// have refreshed it in the meantime before we re-obtained our lock\n\tcached = srvs[suAddr]\n\tif cached.isFresh() {\n\t\treturn allNew(cached.upstreams), nil\n\t}\n\n\tif c := su.logger.Check(zapcore.DebugLevel, \"refreshing SRV upstreams\"); c != nil {\n\t\tc.Write(\n\t\t\tzap.String(\"service\", service),\n\t\t\tzap.String(\"proto\", proto),\n\t\t\tzap.String(\"name\", name),\n\t\t)\n\t}\n\n\t_, records, err := su.resolver.LookupSRV(r.Context(), service, proto, name)\n\tif err != nil {\n\t\t// From LookupSRV docs: \"If the response contains invalid names, those records are filtered\n\t\t// out and an error will be returned alongside the remaining results, if any.\" Thus, we\n\t\t// only return an error if no records were also returned.\n\t\tif len(records) == 0 {\n\t\t\tif su.GracePeriod > 0 {\n\t\t\t\tif c := su.logger.Check(zapcore.ErrorLevel, \"SRV lookup failed; using previously cached\"); c != nil {\n\t\t\t\t\tc.Write(zap.Error(err))\n\t\t\t\t}\n\t\t\t\tcached.freshness = time.Now().Add(time.Duration(su.GracePeriod) - time.Duration(su.Refresh))\n\t\t\t\tsrvs[suAddr] = cached\n\t\t\t\treturn allNew(cached.upstreams), nil\n\t\t\t}\n\t\t\treturn nil, err\n\t\t}\n\t\tif c := su.logger.Check(zapcore.WarnLevel, \"SRV records filtered\"); c != nil {\n\t\t\tc.Write(zap.Error(err))\n\t\t}\n\t}\n\n\tupstreams := make([]Upstream, len(records))\n\tfor i, rec := range records {\n\t\tif c := su.logger.Check(zapcore.DebugLevel, \"discovered SRV record\"); c != nil {\n\t\t\tc.Write(\n\t\t\t\tzap.String(\"target\", rec.Target),\n\t\t\t\tzap.Uint16(\"port\", rec.Port),\n\t\t\t\tzap.Uint16(\"priority\", rec.Priority),\n\t\t\t\tzap.Uint16(\"weight\", rec.Weight),\n\t\t\t)\n\t\t}\n\t\taddr := net.JoinHostPort(rec.Target, strconv.Itoa(int(rec.Port)))\n\t\tupstreams[i] = Upstream{Dial: addr}\n\t}\n\n\t// before adding a new one to the cache (as opposed to replacing stale one), make room if cache is full\n\tif cached.freshness.IsZero() && len(srvs) >= 100 {\n\t\tfor randomKey := range srvs {\n\t\t\tdelete(srvs, randomKey)\n\t\t\tbreak\n\t\t}\n\t}\n\n\tsrvs[suAddr] = srvLookup{\n\t\tsrvUpstreams: su,\n\t\tfreshness:    time.Now(),\n\t\tupstreams:    upstreams,\n\t}\n\n\treturn allNew(upstreams), nil\n}\n\nfunc (su SRVUpstreams) String() string {\n\tif su.Service == \"\" && su.Proto == \"\" {\n\t\treturn su.Name\n\t}\n\treturn su.formattedAddr(su.Service, su.Proto, su.Name)\n}\n\n// expandedAddr expands placeholders in the configured SRV domain labels.\n// The return values are: addr, the RFC 2782 representation of the SRV domain;\n// service, the service; proto, the protocol; and name, the name.\n// If su.Service and su.Proto are empty, name will be returned as addr instead.\nfunc (su SRVUpstreams) expandedAddr(r *http.Request) (addr, service, proto, name string) {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tname = repl.ReplaceAll(su.Name, \"\")\n\tif su.Service == \"\" && su.Proto == \"\" {\n\t\taddr = name\n\t\treturn\n\t}\n\tservice = repl.ReplaceAll(su.Service, \"\")\n\tproto = repl.ReplaceAll(su.Proto, \"\")\n\taddr = su.formattedAddr(service, proto, name)\n\treturn\n}\n\n// formattedAddr the RFC 2782 representation of the SRV domain, in\n// the form \"_service._proto.name\".\nfunc (SRVUpstreams) formattedAddr(service, proto, name string) string {\n\treturn fmt.Sprintf(\"_%s._%s.%s\", service, proto, name)\n}\n\ntype srvLookup struct {\n\tsrvUpstreams SRVUpstreams\n\tfreshness    time.Time\n\tupstreams    []Upstream\n}\n\nfunc (sl srvLookup) isFresh() bool {\n\treturn time.Since(sl.freshness) < time.Duration(sl.srvUpstreams.Refresh)\n}\n\ntype IPVersions struct {\n\tIPv4 *bool `json:\"ipv4,omitempty\"`\n\tIPv6 *bool `json:\"ipv6,omitempty\"`\n}\n\nfunc resolveIpVersion(versions *IPVersions) string {\n\tresolveIpv4 := versions == nil || (versions.IPv4 == nil && versions.IPv6 == nil) || (versions.IPv4 != nil && *versions.IPv4)\n\tresolveIpv6 := versions == nil || (versions.IPv6 == nil && versions.IPv4 == nil) || (versions.IPv6 != nil && *versions.IPv6)\n\tswitch {\n\tcase resolveIpv4 && !resolveIpv6:\n\t\treturn \"ip4\"\n\tcase !resolveIpv4 && resolveIpv6:\n\t\treturn \"ip6\"\n\tdefault:\n\t\treturn \"ip\"\n\t}\n}\n\n// AUpstreams provides upstreams from A/AAAA lookups.\n// Results are cached and refreshed at the configured\n// refresh interval.\ntype AUpstreams struct {\n\t// The domain name to look up.\n\tName string `json:\"name,omitempty\"`\n\n\t// The port to use with the upstreams. Default: 80\n\tPort string `json:\"port,omitempty\"`\n\n\t// The interval at which to refresh the A lookup.\n\t// Results are cached between lookups. Default: 1m\n\tRefresh caddy.Duration `json:\"refresh,omitempty\"`\n\n\t// Configures the DNS resolver used to resolve the\n\t// domain name to A records.\n\tResolver *UpstreamResolver `json:\"resolver,omitempty\"`\n\n\t// If Resolver is configured, how long to wait before\n\t// timing out trying to connect to the DNS server.\n\tDialTimeout caddy.Duration `json:\"dial_timeout,omitempty\"`\n\n\t// If Resolver is configured, how long to wait before\n\t// spawning an RFC 6555 Fast Fallback connection.\n\t// A negative value disables this.\n\tFallbackDelay caddy.Duration `json:\"dial_fallback_delay,omitempty\"`\n\n\t// The IP versions to resolve for. By default, both\n\t// \"ipv4\" and \"ipv6\" will be enabled, which\n\t// correspond to A and AAAA records respectively.\n\tVersions *IPVersions `json:\"versions,omitempty\"`\n\n\tresolver *net.Resolver\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (AUpstreams) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.upstreams.a\",\n\t\tNew: func() caddy.Module { return new(AUpstreams) },\n\t}\n}\n\nfunc (au *AUpstreams) Provision(ctx caddy.Context) error {\n\tau.logger = ctx.Logger()\n\tif au.Refresh == 0 {\n\t\tau.Refresh = caddy.Duration(time.Minute)\n\t}\n\tif au.Port == \"\" {\n\t\tau.Port = \"80\"\n\t}\n\n\tif au.Resolver != nil {\n\t\terr := au.Resolver.ParseAddresses()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\td := &net.Dialer{\n\t\t\tTimeout:       time.Duration(au.DialTimeout),\n\t\t\tFallbackDelay: time.Duration(au.FallbackDelay),\n\t\t}\n\t\tau.resolver = &net.Resolver{\n\t\t\tPreferGo: true,\n\t\t\tDial: func(ctx context.Context, _, _ string) (net.Conn, error) {\n\t\t\t\t//nolint:gosec\n\t\t\t\taddr := au.Resolver.netAddrs[weakrand.Intn(len(au.Resolver.netAddrs))]\n\t\t\t\treturn d.DialContext(ctx, addr.Network, addr.JoinHostPort(0))\n\t\t\t},\n\t\t}\n\t}\n\tif au.resolver == nil {\n\t\tau.resolver = net.DefaultResolver\n\t}\n\n\treturn nil\n}\n\nfunc (au AUpstreams) GetUpstreams(r *http.Request) ([]*Upstream, error) {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\t// Map ipVersion early, so we can use it as part of the cache-key.\n\t// This should be fairly inexpensive and comes and the upside of\n\t// allowing the same dynamic upstream (name + port combination)\n\t// to be used multiple times with different ip versions.\n\t//\n\t// It also forced a cache-miss if a previously cached dynamic\n\t// upstream changes its ip version, e.g. after a config reload,\n\t// while keeping the cache-invalidation as simple as it currently is.\n\tipVersion := resolveIpVersion(au.Versions)\n\n\tauStr := repl.ReplaceAll(au.String()+ipVersion, \"\")\n\n\t// first, use a cheap read-lock to return a cached result quickly\n\taAaaaMu.RLock()\n\tcached := aAaaa[auStr]\n\taAaaaMu.RUnlock()\n\tif cached.isFresh() {\n\t\treturn allNew(cached.upstreams), nil\n\t}\n\n\t// otherwise, obtain a write-lock to update the cached value\n\taAaaaMu.Lock()\n\tdefer aAaaaMu.Unlock()\n\n\t// check to see if it's still stale, since we're now in a different\n\t// lock from when we first checked freshness; another goroutine might\n\t// have refreshed it in the meantime before we re-obtained our lock\n\tcached = aAaaa[auStr]\n\tif cached.isFresh() {\n\t\treturn allNew(cached.upstreams), nil\n\t}\n\n\tname := repl.ReplaceAll(au.Name, \"\")\n\tport := repl.ReplaceAll(au.Port, \"\")\n\n\tif c := au.logger.Check(zapcore.DebugLevel, \"refreshing A upstreams\"); c != nil {\n\t\tc.Write(\n\t\t\tzap.String(\"version\", ipVersion),\n\t\t\tzap.String(\"name\", name),\n\t\t\tzap.String(\"port\", port),\n\t\t)\n\t}\n\n\tips, err := au.resolver.LookupIP(r.Context(), ipVersion, name)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tupstreams := make([]Upstream, len(ips))\n\tfor i, ip := range ips {\n\t\tif c := au.logger.Check(zapcore.DebugLevel, \"discovered A record\"); c != nil {\n\t\t\tc.Write(zap.String(\"ip\", ip.String()))\n\t\t}\n\t\tupstreams[i] = Upstream{\n\t\t\tDial: net.JoinHostPort(ip.String(), port),\n\t\t}\n\t}\n\n\t// before adding a new one to the cache (as opposed to replacing stale one), make room if cache is full\n\tif cached.freshness.IsZero() && len(aAaaa) >= 100 {\n\t\tfor randomKey := range aAaaa {\n\t\t\tdelete(aAaaa, randomKey)\n\t\t\tbreak\n\t\t}\n\t}\n\n\taAaaa[auStr] = aLookup{\n\t\taUpstreams: au,\n\t\tfreshness:  time.Now(),\n\t\tupstreams:  upstreams,\n\t}\n\n\treturn allNew(upstreams), nil\n}\n\nfunc (au AUpstreams) String() string { return net.JoinHostPort(au.Name, au.Port) }\n\ntype aLookup struct {\n\taUpstreams AUpstreams\n\tfreshness  time.Time\n\tupstreams  []Upstream\n}\n\nfunc (al aLookup) isFresh() bool {\n\treturn time.Since(al.freshness) < time.Duration(al.aUpstreams.Refresh)\n}\n\n// MultiUpstreams is a single dynamic upstream source that\n// aggregates the results of multiple dynamic upstream sources.\n// All configured sources will be queried in order, with their\n// results appended to the end of the list. Errors returned\n// from individual sources will be logged and the next source\n// will continue to be invoked.\n//\n// This module makes it easy to implement redundant cluster\n// failovers, especially in conjunction with the `first` load\n// balancing policy: if the first source returns an error or\n// no upstreams, the second source's upstreams will be used\n// naturally.\ntype MultiUpstreams struct {\n\t// The list of upstream source modules to get upstreams from.\n\t// They will be queried in order, with their results appended\n\t// in the order they are returned.\n\tSourcesRaw []json.RawMessage `json:\"sources,omitempty\" caddy:\"namespace=http.reverse_proxy.upstreams inline_key=source\"`\n\tsources    []UpstreamSource\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MultiUpstreams) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.upstreams.multi\",\n\t\tNew: func() caddy.Module { return new(MultiUpstreams) },\n\t}\n}\n\nfunc (mu *MultiUpstreams) Provision(ctx caddy.Context) error {\n\tmu.logger = ctx.Logger()\n\n\tif mu.SourcesRaw != nil {\n\t\tmod, err := ctx.LoadModule(mu, \"SourcesRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading upstream source modules: %v\", err)\n\t\t}\n\t\tfor _, src := range mod.([]any) {\n\t\t\tmu.sources = append(mu.sources, src.(UpstreamSource))\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (mu MultiUpstreams) GetUpstreams(r *http.Request) ([]*Upstream, error) {\n\tvar upstreams []*Upstream\n\n\tfor i, src := range mu.sources {\n\t\tselect {\n\t\tcase <-r.Context().Done():\n\t\t\treturn upstreams, context.Canceled\n\t\tdefault:\n\t\t}\n\n\t\tup, err := src.GetUpstreams(r)\n\t\tif err != nil {\n\t\t\tif c := mu.logger.Check(zapcore.ErrorLevel, \"upstream source returned error\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.Int(\"source_idx\", i),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t}\n\t\t} else if len(up) == 0 {\n\t\t\tif c := mu.logger.Check(zapcore.WarnLevel, \"upstream source returned 0 upstreams\"); c != nil {\n\t\t\t\tc.Write(zap.Int(\"source_idx\", i))\n\t\t\t}\n\t\t} else {\n\t\t\tupstreams = append(upstreams, up...)\n\t\t}\n\t}\n\n\treturn upstreams, nil\n}\n\n// UpstreamResolver holds the set of addresses of DNS resolvers of\n// upstream addresses\ntype UpstreamResolver struct {\n\t// The addresses of DNS resolvers to use when looking up the addresses of proxy upstreams.\n\t// It accepts [network addresses](/docs/conventions#network-addresses)\n\t// with port range of only 1. If the host is an IP address, it will be dialed directly to resolve the upstream server.\n\t// If the host is not an IP address, the addresses are resolved using the [name resolution convention](https://golang.org/pkg/net/#hdr-Name_Resolution) of the Go standard library.\n\t// If the array contains more than 1 resolver address, one is chosen at random.\n\tAddresses []string `json:\"addresses,omitempty\"`\n\tnetAddrs  []caddy.NetworkAddress\n}\n\n// ParseAddresses parses all the configured network addresses\n// and ensures they're ready to be used.\nfunc (u *UpstreamResolver) ParseAddresses() error {\n\tfor _, v := range u.Addresses {\n\t\taddr, err := caddy.ParseNetworkAddressWithDefaults(v, \"udp\", 53)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tif addr.PortRangeSize() != 1 {\n\t\t\treturn fmt.Errorf(\"resolver address must have exactly one address; cannot call %v\", addr)\n\t\t}\n\t\tu.netAddrs = append(u.netAddrs, addr)\n\t}\n\treturn nil\n}\n\nfunc allNew(upstreams []Upstream) []*Upstream {\n\tresults := make([]*Upstream, len(upstreams))\n\tfor i := range upstreams {\n\t\tresults[i] = &Upstream{Dial: upstreams[i].Dial}\n\t}\n\treturn results\n}\n\nvar (\n\tsrvs   = make(map[string]srvLookup)\n\tsrvsMu sync.RWMutex\n\n\taAaaa   = make(map[string]aLookup)\n\taAaaaMu sync.RWMutex\n)\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner = (*SRVUpstreams)(nil)\n\t_ UpstreamSource    = (*SRVUpstreams)(nil)\n\t_ caddy.Provisioner = (*AUpstreams)(nil)\n\t_ UpstreamSource    = (*AUpstreams)(nil)\n)\n",
    "source_file": "modules/caddyhttp/reverseproxy/upstreams.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"net/netip\"\n\t\"strconv\"\n\t\"sync/atomic\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\n// UpstreamPool is a collection of upstreams.\ntype UpstreamPool []*Upstream\n\n// Upstream bridges this proxy's configuration to the\n// state of the backend host it is correlated with.\n// Upstream values must not be copied.\ntype Upstream struct {\n\t*Host `json:\"-\"`\n\n\t// The [network address](/docs/conventions#network-addresses)\n\t// to dial to connect to the upstream. Must represent precisely\n\t// one socket (i.e. no port ranges). A valid network address\n\t// either has a host and port or is a unix socket address.\n\t//\n\t// Placeholders may be used to make the upstream dynamic, but be\n\t// aware of the health check implications of this: a single\n\t// upstream that represents numerous (perhaps arbitrary) backends\n\t// can be considered down if one or enough of the arbitrary\n\t// backends is down. Also be aware of open proxy vulnerabilities.\n\tDial string `json:\"dial,omitempty\"`\n\n\t// The maximum number of simultaneous requests to allow to\n\t// this upstream. If set, overrides the global passive health\n\t// check UnhealthyRequestCount value.\n\tMaxRequests int `json:\"max_requests,omitempty\"`\n\n\t// TODO: This could be really useful, to bind requests\n\t// with certain properties to specific backends\n\t// HeaderAffinity string\n\t// IPAffinity     string\n\n\tactiveHealthCheckPort     int\n\tactiveHealthCheckUpstream string\n\thealthCheckPolicy         *PassiveHealthChecks\n\tcb                        CircuitBreaker\n\tunhealthy                 int32 // accessed atomically; status from active health checker\n}\n\n// (pointer receiver necessary to avoid a race condition, since\n// copying the Upstream reads the 'unhealthy' field which is\n// accessed atomically)\nfunc (u *Upstream) String() string { return u.Dial }\n\n// Available returns true if the remote host\n// is available to receive requests. This is\n// the method that should be used by selection\n// policies, etc. to determine if a backend\n// should be able to be sent a request.\nfunc (u *Upstream) Available() bool {\n\treturn u.Healthy() && !u.Full()\n}\n\n// Healthy returns true if the remote host\n// is currently known to be healthy or \"up\".\n// It consults the circuit breaker, if any.\nfunc (u *Upstream) Healthy() bool {\n\thealthy := u.healthy()\n\tif healthy && u.healthCheckPolicy != nil {\n\t\thealthy = u.Host.Fails() < u.healthCheckPolicy.MaxFails\n\t}\n\tif healthy && u.cb != nil {\n\t\thealthy = u.cb.OK()\n\t}\n\treturn healthy\n}\n\n// Full returns true if the remote host\n// cannot receive more requests at this time.\nfunc (u *Upstream) Full() bool {\n\treturn u.MaxRequests > 0 && u.Host.NumRequests() >= u.MaxRequests\n}\n\n// fillDialInfo returns a filled DialInfo for upstream u, using the request\n// context. Note that the returned value is not a pointer.\nfunc (u *Upstream) fillDialInfo(repl *caddy.Replacer) (DialInfo, error) {\n\tvar addr caddy.NetworkAddress\n\n\t// use provided dial address\n\tvar err error\n\tdial := repl.ReplaceAll(u.Dial, \"\")\n\taddr, err = caddy.ParseNetworkAddress(dial)\n\tif err != nil {\n\t\treturn DialInfo{}, fmt.Errorf(\"upstream %s: invalid dial address %s: %v\", u.Dial, dial, err)\n\t}\n\tif numPorts := addr.PortRangeSize(); numPorts != 1 {\n\t\treturn DialInfo{}, fmt.Errorf(\"upstream %s: dial address must represent precisely one socket: %s represents %d\",\n\t\t\tu.Dial, dial, numPorts)\n\t}\n\n\treturn DialInfo{\n\t\tUpstream: u,\n\t\tNetwork:  addr.Network,\n\t\tAddress:  addr.JoinHostPort(0),\n\t\tHost:     addr.Host,\n\t\tPort:     strconv.Itoa(int(addr.StartPort)),\n\t}, nil\n}\n\nfunc (u *Upstream) fillHost() {\n\thost := new(Host)\n\texistingHost, loaded := hosts.LoadOrStore(u.String(), host)\n\tif loaded {\n\t\thost = existingHost.(*Host)\n\t}\n\tu.Host = host\n}\n\n// Host is the basic, in-memory representation of the state of a remote host.\n// Its fields are accessed atomically and Host values must not be copied.\ntype Host struct {\n\tnumRequests  int64 // must be 64-bit aligned on 32-bit systems (see https://golang.org/pkg/sync/atomic/#pkg-note-BUG)\n\tfails        int64\n\tactivePasses int64\n\tactiveFails  int64\n}\n\n// NumRequests returns the number of active requests to the upstream.\nfunc (h *Host) NumRequests() int {\n\treturn int(atomic.LoadInt64(&h.numRequests))\n}\n\n// Fails returns the number of recent failures with the upstream.\nfunc (h *Host) Fails() int {\n\treturn int(atomic.LoadInt64(&h.fails))\n}\n\n// activeHealthPasses returns the number of consecutive active health check passes with the upstream.\nfunc (h *Host) activeHealthPasses() int {\n\treturn int(atomic.LoadInt64(&h.activePasses))\n}\n\n// activeHealthFails returns the number of consecutive active health check failures with the upstream.\nfunc (h *Host) activeHealthFails() int {\n\treturn int(atomic.LoadInt64(&h.activeFails))\n}\n\n// countRequest mutates the active request count by\n// delta. It returns an error if the adjustment fails.\nfunc (h *Host) countRequest(delta int) error {\n\tresult := atomic.AddInt64(&h.numRequests, int64(delta))\n\tif result < 0 {\n\t\treturn fmt.Errorf(\"count below 0: %d\", result)\n\t}\n\treturn nil\n}\n\n// countFail mutates the recent failures count by\n// delta. It returns an error if the adjustment fails.\nfunc (h *Host) countFail(delta int) error {\n\tresult := atomic.AddInt64(&h.fails, int64(delta))\n\tif result < 0 {\n\t\treturn fmt.Errorf(\"count below 0: %d\", result)\n\t}\n\treturn nil\n}\n\n// countHealthPass mutates the recent passes count by\n// delta. It returns an error if the adjustment fails.\nfunc (h *Host) countHealthPass(delta int) error {\n\tresult := atomic.AddInt64(&h.activePasses, int64(delta))\n\tif result < 0 {\n\t\treturn fmt.Errorf(\"count below 0: %d\", result)\n\t}\n\treturn nil\n}\n\n// countHealthFail mutates the recent failures count by\n// delta. It returns an error if the adjustment fails.\nfunc (h *Host) countHealthFail(delta int) error {\n\tresult := atomic.AddInt64(&h.activeFails, int64(delta))\n\tif result < 0 {\n\t\treturn fmt.Errorf(\"count below 0: %d\", result)\n\t}\n\treturn nil\n}\n\n// resetHealth resets the health check counters.\nfunc (h *Host) resetHealth() {\n\tatomic.StoreInt64(&h.activePasses, 0)\n\tatomic.StoreInt64(&h.activeFails, 0)\n}\n\n// healthy returns true if the upstream is not actively marked as unhealthy.\n// (This returns the status only from the \"active\" health checks.)\nfunc (u *Upstream) healthy() bool {\n\treturn atomic.LoadInt32(&u.unhealthy) == 0\n}\n\n// SetHealthy sets the upstream has healthy or unhealthy\n// and returns true if the new value is different. This\n// sets the status only for the \"active\" health checks.\nfunc (u *Upstream) setHealthy(healthy bool) bool {\n\tvar unhealthy, compare int32 = 1, 0\n\tif healthy {\n\t\tunhealthy, compare = 0, 1\n\t}\n\treturn atomic.CompareAndSwapInt32(&u.unhealthy, compare, unhealthy)\n}\n\n// DialInfo contains information needed to dial a\n// connection to an upstream host. This information\n// may be different than that which is represented\n// in a URL (for example, unix sockets don't have\n// a host that can be represented in a URL, but\n// they certainly have a network name and address).\ntype DialInfo struct {\n\t// Upstream is the Upstream associated with\n\t// this DialInfo. It may be nil.\n\tUpstream *Upstream\n\n\t// The network to use. This should be one of\n\t// the values that is accepted by net.Dial:\n\t// https://golang.org/pkg/net/#Dial\n\tNetwork string\n\n\t// The address to dial. Follows the same\n\t// semantics and rules as net.Dial.\n\tAddress string\n\n\t// Host and Port are components of Address.\n\tHost, Port string\n}\n\n// String returns the Caddy network address form\n// by joining the network and address with a\n// forward slash.\nfunc (di DialInfo) String() string {\n\treturn caddy.JoinNetworkAddress(di.Network, di.Host, di.Port)\n}\n\n// GetDialInfo gets the upstream dialing info out of the context,\n// and returns true if there was a valid value; false otherwise.\nfunc GetDialInfo(ctx context.Context) (DialInfo, bool) {\n\tdialInfo, ok := caddyhttp.GetVar(ctx, dialInfoVarKey).(DialInfo)\n\treturn dialInfo, ok\n}\n\n// hosts is the global repository for hosts that are\n// currently in use by active configuration(s). This\n// allows the state of remote hosts to be preserved\n// through config reloads.\nvar hosts = caddy.NewUsagePool()\n\n// dialInfoVarKey is the key used for the variable that holds\n// the dial info for the upstream connection.\nconst dialInfoVarKey = \"reverse_proxy.dial_info\"\n\n// proxyProtocolInfoVarKey is the key used for the variable that holds\n// the proxy protocol info for the upstream connection.\nconst proxyProtocolInfoVarKey = \"reverse_proxy.proxy_protocol_info\"\n\n// ProxyProtocolInfo contains information needed to write proxy protocol to a\n// connection to an upstream host.\ntype ProxyProtocolInfo struct {\n\tAddrPort netip.AddrPort\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/hosts.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Most of the code in this file was initially borrowed from the Go\n// standard library and modified; It had this copyright notice:\n// Copyright 2021 The Go Authors. All rights reserved.\n// Use of this source code is governed by a BSD-style\n// license that can be found in the LICENSE file.\n\n// Original source, copied because the package was marked internal:\n// https://github.com/golang/go/blob/5c489514bc5e61ad9b5b07bd7d8ec65d66a0512a/src/net/http/internal/ascii/print.go\n\npackage reverseproxy\n\n// asciiEqualFold is strings.EqualFold, ASCII only. It reports whether s and t\n// are equal, ASCII-case-insensitively.\nfunc asciiEqualFold(s, t string) bool {\n\tif len(s) != len(t) {\n\t\treturn false\n\t}\n\tfor i := 0; i < len(s); i++ {\n\t\tif asciiLower(s[i]) != asciiLower(t[i]) {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// asciiLower returns the ASCII lowercase version of b.\nfunc asciiLower(b byte) byte {\n\tif 'A' <= b && b <= 'Z' {\n\t\treturn b + ('a' - 'A')\n\t}\n\treturn b\n}\n\n// asciiIsPrint returns whether s is ASCII and printable according to\n// https://tools.ietf.org/html/rfc20#section-4.2.\nfunc asciiIsPrint(s string) bool {\n\tfor i := 0; i < len(s); i++ {\n\t\tif s[i] < ' ' || s[i] > '~' {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/ascii.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/url\"\n\t\"regexp\"\n\t\"runtime/debug\"\n\t\"slices\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\n// HealthChecks configures active and passive health checks.\ntype HealthChecks struct {\n\t// Active health checks run in the background on a timer. To\n\t// minimally enable active health checks, set either path or\n\t// port (or both). Note that active health check status\n\t// (healthy/unhealthy) is stored per-proxy-handler, not\n\t// globally; this allows different handlers to use different\n\t// criteria to decide what defines a healthy backend.\n\t//\n\t// Active health checks do not run for dynamic upstreams.\n\tActive *ActiveHealthChecks `json:\"active,omitempty\"`\n\n\t// Passive health checks monitor proxied requests for errors or timeouts.\n\t// To minimally enable passive health checks, specify at least an empty\n\t// config object with fail_duration > 0. Passive health check state is\n\t// shared (stored globally), so a failure from one handler will be counted\n\t// by all handlers; but the tolerances or standards for what defines\n\t// healthy/unhealthy backends is configured per-proxy-handler.\n\t//\n\t// Passive health checks technically do operate on dynamic upstreams,\n\t// but are only effective for very busy proxies where the list of\n\t// upstreams is mostly stable. This is because the shared/global\n\t// state of upstreams is cleaned up when the upstreams are no longer\n\t// used. Since dynamic upstreams are allocated dynamically at each\n\t// request (specifically, each iteration of the proxy loop per request),\n\t// they are also cleaned up after every request. Thus, if there is a\n\t// moment when no requests are actively referring to a particular\n\t// upstream host, the passive health check state will be reset because\n\t// it will be garbage-collected. It is usually better for the dynamic\n\t// upstream module to only return healthy, available backends instead.\n\tPassive *PassiveHealthChecks `json:\"passive,omitempty\"`\n}\n\n// ActiveHealthChecks holds configuration related to active\n// health checks (that is, health checks which occur in a\n// background goroutine independently).\ntype ActiveHealthChecks struct {\n\t// Deprecated: Use 'uri' instead. This field will be removed. TODO: remove this field\n\tPath string `json:\"path,omitempty\"`\n\n\t// The URI (path and query) to use for health checks\n\tURI string `json:\"uri,omitempty\"`\n\n\t// The host:port to use (if different from the upstream's dial address)\n\t// for health checks. This should be used in tandem with `health_header` and\n\t// `{http.reverse_proxy.active.target_upstream}`. This can be helpful when\n\t// creating an intermediate service to do a more thorough health check.\n\t// If upstream is set, the active health check port is ignored.\n\tUpstream string `json:\"upstream,omitempty\"`\n\n\t// The port to use (if different from the upstream's dial\n\t// address) for health checks. If active upstream is set,\n\t// this value is ignored.\n\tPort int `json:\"port,omitempty\"`\n\n\t// HTTP headers to set on health check requests.\n\tHeaders http.Header `json:\"headers,omitempty\"`\n\n\t// The HTTP method to use for health checks (default \"GET\").\n\tMethod string `json:\"method,omitempty\"`\n\n\t// The body to send with the health check request.\n\tBody string `json:\"body,omitempty\"`\n\n\t// Whether to follow HTTP redirects in response to active health checks (default off).\n\tFollowRedirects bool `json:\"follow_redirects,omitempty\"`\n\n\t// How frequently to perform active health checks (default 30s).\n\tInterval caddy.Duration `json:\"interval,omitempty\"`\n\n\t// How long to wait for a response from a backend before\n\t// considering it unhealthy (default 5s).\n\tTimeout caddy.Duration `json:\"timeout,omitempty\"`\n\n\t// Number of consecutive health check passes before marking\n\t// a previously unhealthy backend as healthy again (default 1).\n\tPasses int `json:\"passes,omitempty\"`\n\n\t// Number of consecutive health check failures before marking\n\t// a previously healthy backend as unhealthy (default 1).\n\tFails int `json:\"fails,omitempty\"`\n\n\t// The maximum response body to download from the backend\n\t// during a health check.\n\tMaxSize int64 `json:\"max_size,omitempty\"`\n\n\t// The HTTP status code to expect from a healthy backend.\n\tExpectStatus int `json:\"expect_status,omitempty\"`\n\n\t// A regular expression against which to match the response\n\t// body of a healthy backend.\n\tExpectBody string `json:\"expect_body,omitempty\"`\n\n\turi        *url.URL\n\thttpClient *http.Client\n\tbodyRegexp *regexp.Regexp\n\tlogger     *zap.Logger\n}\n\n// Provision ensures that a is set up properly before use.\nfunc (a *ActiveHealthChecks) Provision(ctx caddy.Context, h *Handler) error {\n\tif !a.IsEnabled() {\n\t\treturn nil\n\t}\n\n\t// Canonicalize the header keys ahead of time, since\n\t// JSON unmarshaled headers may be incorrect\n\tcleaned := http.Header{}\n\tfor key, hdrs := range a.Headers {\n\t\tfor _, val := range hdrs {\n\t\t\tcleaned.Add(key, val)\n\t\t}\n\t}\n\ta.Headers = cleaned\n\n\t// If Method is not set, default to GET\n\tif a.Method == \"\" {\n\t\ta.Method = http.MethodGet\n\t}\n\n\th.HealthChecks.Active.logger = h.logger.Named(\"health_checker.active\")\n\n\ttimeout := time.Duration(a.Timeout)\n\tif timeout == 0 {\n\t\ttimeout = 5 * time.Second\n\t}\n\n\tif a.Path != \"\" {\n\t\ta.logger.Warn(\"the 'path' option is deprecated, please use 'uri' instead!\")\n\t}\n\n\t// parse the URI string (supports path and query)\n\tif a.URI != \"\" {\n\t\tparsedURI, err := url.Parse(a.URI)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\ta.uri = parsedURI\n\t}\n\n\ta.httpClient = &http.Client{\n\t\tTimeout:   timeout,\n\t\tTransport: h.Transport,\n\t\tCheckRedirect: func(req *http.Request, via []*http.Request) error {\n\t\t\tif !a.FollowRedirects {\n\t\t\t\treturn http.ErrUseLastResponse\n\t\t\t}\n\t\t\treturn nil\n\t\t},\n\t}\n\n\tfor _, upstream := range h.Upstreams {\n\t\t// if there's an alternative upstream for health-check provided in the config,\n\t\t// then use it, otherwise use the upstream's dial address. if upstream is used,\n\t\t// then the port is ignored.\n\t\tif a.Upstream != \"\" {\n\t\t\tupstream.activeHealthCheckUpstream = a.Upstream\n\t\t} else if a.Port != 0 {\n\t\t\t// if there's an alternative port for health-check provided in the config,\n\t\t\t// then use it, otherwise use the port of upstream.\n\t\t\tupstream.activeHealthCheckPort = a.Port\n\t\t}\n\t}\n\n\tif a.Interval == 0 {\n\t\ta.Interval = caddy.Duration(30 * time.Second)\n\t}\n\n\tif a.ExpectBody != \"\" {\n\t\tvar err error\n\t\ta.bodyRegexp, err = regexp.Compile(a.ExpectBody)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"expect_body: compiling regular expression: %v\", err)\n\t\t}\n\t}\n\n\tif a.Passes < 1 {\n\t\ta.Passes = 1\n\t}\n\n\tif a.Fails < 1 {\n\t\ta.Fails = 1\n\t}\n\n\treturn nil\n}\n\n// IsEnabled checks if the active health checks have\n// the minimum config necessary to be enabled.\nfunc (a *ActiveHealthChecks) IsEnabled() bool {\n\treturn a.Path != \"\" || a.URI != \"\" || a.Port != 0\n}\n\n// PassiveHealthChecks holds configuration related to passive\n// health checks (that is, health checks which occur during\n// the normal flow of request proxying).\ntype PassiveHealthChecks struct {\n\t// How long to remember a failed request to a backend. A duration > 0\n\t// enables passive health checking. Default is 0.\n\tFailDuration caddy.Duration `json:\"fail_duration,omitempty\"`\n\n\t// The number of failed requests within the FailDuration window to\n\t// consider a backend as \"down\". Must be >= 1; default is 1. Requires\n\t// that FailDuration be > 0.\n\tMaxFails int `json:\"max_fails,omitempty\"`\n\n\t// Limits the number of simultaneous requests to a backend by\n\t// marking the backend as \"down\" if it has this many concurrent\n\t// requests or more.\n\tUnhealthyRequestCount int `json:\"unhealthy_request_count,omitempty\"`\n\n\t// Count the request as failed if the response comes back with\n\t// one of these status codes.\n\tUnhealthyStatus []int `json:\"unhealthy_status,omitempty\"`\n\n\t// Count the request as failed if the response takes at least this\n\t// long to receive.\n\tUnhealthyLatency caddy.Duration `json:\"unhealthy_latency,omitempty\"`\n\n\tlogger *zap.Logger\n}\n\n// CircuitBreaker is a type that can act as an early-warning\n// system for the health checker when backends are getting\n// overloaded. This interface is still experimental and is\n// subject to change.\ntype CircuitBreaker interface {\n\tOK() bool\n\tRecordMetric(statusCode int, latency time.Duration)\n}\n\n// activeHealthChecker runs active health checks on a\n// regular basis and blocks until\n// h.HealthChecks.Active.stopChan is closed.\nfunc (h *Handler) activeHealthChecker() {\n\tdefer func() {\n\t\tif err := recover(); err != nil {\n\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"active health checker panicked\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.Any(\"error\", err),\n\t\t\t\t\tzap.ByteString(\"stack\", debug.Stack()),\n\t\t\t\t)\n\t\t\t}\n\t\t}\n\t}()\n\tticker := time.NewTicker(time.Duration(h.HealthChecks.Active.Interval))\n\th.doActiveHealthCheckForAllHosts()\n\tfor {\n\t\tselect {\n\t\tcase <-ticker.C:\n\t\t\th.doActiveHealthCheckForAllHosts()\n\t\tcase <-h.ctx.Done():\n\t\t\tticker.Stop()\n\t\t\treturn\n\t\t}\n\t}\n}\n\n// doActiveHealthCheckForAllHosts immediately performs a\n// health checks for all upstream hosts configured by h.\nfunc (h *Handler) doActiveHealthCheckForAllHosts() {\n\tfor _, upstream := range h.Upstreams {\n\t\tgo func(upstream *Upstream) {\n\t\t\tdefer func() {\n\t\t\t\tif err := recover(); err != nil {\n\t\t\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"active health checker panicked\"); c != nil {\n\t\t\t\t\t\tc.Write(\n\t\t\t\t\t\t\tzap.Any(\"error\", err),\n\t\t\t\t\t\t\tzap.ByteString(\"stack\", debug.Stack()),\n\t\t\t\t\t\t)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}()\n\n\t\t\trepl := caddy.NewReplacer()\n\n\t\t\tnetworkAddr, err := repl.ReplaceOrErr(upstream.Dial, true, true)\n\t\t\tif err != nil {\n\t\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"invalid use of placeholders in dial address for active health checks\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.String(\"address\", networkAddr),\n\t\t\t\t\t\tzap.Error(err),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t\taddr, err := caddy.ParseNetworkAddress(networkAddr)\n\t\t\tif err != nil {\n\t\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"bad network address\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.String(\"address\", networkAddr),\n\t\t\t\t\t\tzap.Error(err),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t\tif hcp := uint(upstream.activeHealthCheckPort); hcp != 0 {\n\t\t\t\tif addr.IsUnixNetwork() || addr.IsFdNetwork() {\n\t\t\t\t\taddr.Network = \"tcp\" // I guess we just assume TCP since we are using a port??\n\t\t\t\t}\n\t\t\t\taddr.StartPort, addr.EndPort = hcp, hcp\n\t\t\t}\n\t\t\tif addr.PortRangeSize() != 1 {\n\t\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"multiple addresses (upstream must map to only one address)\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.String(\"address\", networkAddr),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\treturn\n\t\t\t}\n\t\t\thostAddr := addr.JoinHostPort(0)\n\t\t\tif addr.IsUnixNetwork() || addr.IsFdNetwork() {\n\t\t\t\t// this will be used as the Host portion of a http.Request URL, and\n\t\t\t\t// paths to socket files would produce an error when creating URL,\n\t\t\t\t// so use a fake Host value instead; unix sockets are usually local\n\t\t\t\thostAddr = \"localhost\"\n\t\t\t}\n\n\t\t\t// Fill in the dial info for the upstream\n\t\t\t// If the upstream is set, use that instead\n\t\t\tdialInfoUpstream := upstream\n\t\t\tif h.HealthChecks.Active.Upstream != \"\" {\n\t\t\t\tdialInfoUpstream = &Upstream{\n\t\t\t\t\tDial: h.HealthChecks.Active.Upstream,\n\t\t\t\t}\n\t\t\t}\n\t\t\tdialInfo, _ := dialInfoUpstream.fillDialInfo(repl)\n\n\t\t\terr = h.doActiveHealthCheck(dialInfo, hostAddr, networkAddr, upstream)\n\t\t\tif err != nil {\n\t\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"active health check failed\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.String(\"address\", hostAddr),\n\t\t\t\t\t\tzap.Error(err),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t}\n\t\t}(upstream)\n\t}\n}\n\n// doActiveHealthCheck performs a health check to upstream which\n// can be reached at address hostAddr. The actual address for\n// the request will be built according to active health checker\n// config. The health status of the host will be updated\n// according to whether it passes the health check. An error is\n// returned only if the health check fails to occur or if marking\n// the host's health status fails.\nfunc (h *Handler) doActiveHealthCheck(dialInfo DialInfo, hostAddr string, networkAddr string, upstream *Upstream) error {\n\t// create the URL for the request that acts as a health check\n\tu := &url.URL{\n\t\tScheme: \"http\",\n\t\tHost:   hostAddr,\n\t}\n\n\t// split the host and port if possible, override the port if configured\n\thost, port, err := net.SplitHostPort(hostAddr)\n\tif err != nil {\n\t\thost = hostAddr\n\t}\n\n\t// ignore active health check port if active upstream is provided as the\n\t// active upstream already contains the replacement port\n\tif h.HealthChecks.Active.Upstream != \"\" {\n\t\tu.Host = h.HealthChecks.Active.Upstream\n\t} else if h.HealthChecks.Active.Port != 0 {\n\t\tport := strconv.Itoa(h.HealthChecks.Active.Port)\n\t\tu.Host = net.JoinHostPort(host, port)\n\t}\n\n\t// this is kind of a hacky way to know if we should use HTTPS, but whatever\n\tif tt, ok := h.Transport.(TLSTransport); ok && tt.TLSEnabled() {\n\t\tu.Scheme = \"https\"\n\n\t\t// if the port is in the except list, flip back to HTTP\n\t\tif ht, ok := h.Transport.(*HTTPTransport); ok && slices.Contains(ht.TLS.ExceptPorts, port) {\n\t\t\tu.Scheme = \"http\"\n\t\t}\n\t}\n\n\t// if we have a provisioned uri, use that, otherwise use\n\t// the deprecated Path option\n\tif h.HealthChecks.Active.uri != nil {\n\t\tu.Path = h.HealthChecks.Active.uri.Path\n\t\tu.RawQuery = h.HealthChecks.Active.uri.RawQuery\n\t} else {\n\t\tu.Path = h.HealthChecks.Active.Path\n\t}\n\n\t// replacer used for both body and headers. Only globals (env vars, system info, etc.) are available\n\trepl := caddy.NewReplacer()\n\n\t// if body is provided, create a reader for it, otherwise nil\n\tvar requestBody io.Reader\n\tif h.HealthChecks.Active.Body != \"\" {\n\t\t// set body, using replacer\n\t\trequestBody = strings.NewReader(repl.ReplaceAll(h.HealthChecks.Active.Body, \"\"))\n\t}\n\n\t// attach dialing information to this request, as well as context values that\n\t// may be expected by handlers of this request\n\tctx := h.ctx.Context\n\tctx = context.WithValue(ctx, caddy.ReplacerCtxKey, caddy.NewReplacer())\n\tctx = context.WithValue(ctx, caddyhttp.VarsCtxKey, map[string]any{\n\t\tdialInfoVarKey: dialInfo,\n\t})\n\treq, err := http.NewRequestWithContext(ctx, h.HealthChecks.Active.Method, u.String(), requestBody)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"making request: %v\", err)\n\t}\n\tctx = context.WithValue(ctx, caddyhttp.OriginalRequestCtxKey, *req)\n\treq = req.WithContext(ctx)\n\n\t// set headers, using replacer\n\trepl.Set(\"http.reverse_proxy.active.target_upstream\", networkAddr)\n\tfor key, vals := range h.HealthChecks.Active.Headers {\n\t\tkey = repl.ReplaceAll(key, \"\")\n\t\tif key == \"Host\" {\n\t\t\treq.Host = repl.ReplaceAll(h.HealthChecks.Active.Headers.Get(key), \"\")\n\t\t\tcontinue\n\t\t}\n\t\tfor _, val := range vals {\n\t\t\treq.Header.Add(key, repl.ReplaceKnown(val, \"\"))\n\t\t}\n\t}\n\n\tmarkUnhealthy := func() {\n\t\t// increment failures and then check if it has reached the threshold to mark unhealthy\n\t\terr := upstream.Host.countHealthFail(1)\n\t\tif err != nil {\n\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"could not count active health failure\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.String(\"host\", upstream.Dial),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tif upstream.Host.activeHealthFails() >= h.HealthChecks.Active.Fails {\n\t\t\t// dispatch an event that the host newly became unhealthy\n\t\t\tif upstream.setHealthy(false) {\n\t\t\t\th.events.Emit(h.ctx, \"unhealthy\", map[string]any{\"host\": hostAddr})\n\t\t\t\tupstream.Host.resetHealth()\n\t\t\t}\n\t\t}\n\t}\n\n\tmarkHealthy := func() {\n\t\t// increment passes and then check if it has reached the threshold to be healthy\n\t\terr := upstream.countHealthPass(1)\n\t\tif err != nil {\n\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"could not count active health pass\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.String(\"host\", upstream.Dial),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tif upstream.Host.activeHealthPasses() >= h.HealthChecks.Active.Passes {\n\t\t\tif upstream.setHealthy(true) {\n\t\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.InfoLevel, \"host is up\"); c != nil {\n\t\t\t\t\tc.Write(zap.String(\"host\", hostAddr))\n\t\t\t\t}\n\t\t\t\th.events.Emit(h.ctx, \"healthy\", map[string]any{\"host\": hostAddr})\n\t\t\t\tupstream.Host.resetHealth()\n\t\t\t}\n\t\t}\n\t}\n\n\t// do the request, being careful to tame the response body\n\tresp, err := h.HealthChecks.Active.httpClient.Do(req)\n\tif err != nil {\n\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.InfoLevel, \"HTTP request failed\"); c != nil {\n\t\t\tc.Write(\n\t\t\t\tzap.String(\"host\", hostAddr),\n\t\t\t\tzap.Error(err),\n\t\t\t)\n\t\t}\n\t\tmarkUnhealthy()\n\t\treturn nil\n\t}\n\tvar body io.Reader = resp.Body\n\tif h.HealthChecks.Active.MaxSize > 0 {\n\t\tbody = io.LimitReader(body, h.HealthChecks.Active.MaxSize)\n\t}\n\tdefer func() {\n\t\t// drain any remaining body so connection could be re-used\n\t\t_, _ = io.Copy(io.Discard, body)\n\t\tresp.Body.Close()\n\t}()\n\n\t// if status code is outside criteria, mark down\n\tif h.HealthChecks.Active.ExpectStatus > 0 {\n\t\tif !caddyhttp.StatusCodeMatches(resp.StatusCode, h.HealthChecks.Active.ExpectStatus) {\n\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.InfoLevel, \"unexpected status code\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.Int(\"status_code\", resp.StatusCode),\n\t\t\t\t\tzap.String(\"host\", hostAddr),\n\t\t\t\t)\n\t\t\t}\n\t\t\tmarkUnhealthy()\n\t\t\treturn nil\n\t\t}\n\t} else if resp.StatusCode < 200 || resp.StatusCode >= 300 {\n\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.InfoLevel, \"status code out of tolerances\"); c != nil {\n\t\t\tc.Write(\n\t\t\t\tzap.Int(\"status_code\", resp.StatusCode),\n\t\t\t\tzap.String(\"host\", hostAddr),\n\t\t\t)\n\t\t}\n\t\tmarkUnhealthy()\n\t\treturn nil\n\t}\n\n\t// if body does not match regex, mark down\n\tif h.HealthChecks.Active.bodyRegexp != nil {\n\t\tbodyBytes, err := io.ReadAll(body)\n\t\tif err != nil {\n\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.InfoLevel, \"failed to read response body\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.String(\"host\", hostAddr),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t}\n\t\t\tmarkUnhealthy()\n\t\t\treturn nil\n\t\t}\n\t\tif !h.HealthChecks.Active.bodyRegexp.Match(bodyBytes) {\n\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.InfoLevel, \"response body failed expectations\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.String(\"host\", hostAddr),\n\t\t\t\t)\n\t\t\t}\n\t\t\tmarkUnhealthy()\n\t\t\treturn nil\n\t\t}\n\t}\n\n\t// passed health check parameters, so mark as healthy\n\tmarkHealthy()\n\n\treturn nil\n}\n\n// countFailure is used with passive health checks. It\n// remembers 1 failure for upstream for the configured\n// duration. If passive health checks are disabled or\n// failure expiry is 0, this is a no-op.\nfunc (h *Handler) countFailure(upstream *Upstream) {\n\t// only count failures if passive health checking is enabled\n\t// and if failures are configured have a non-zero expiry\n\tif h.HealthChecks == nil || h.HealthChecks.Passive == nil {\n\t\treturn\n\t}\n\tfailDuration := time.Duration(h.HealthChecks.Passive.FailDuration)\n\tif failDuration == 0 {\n\t\treturn\n\t}\n\n\t// count failure immediately\n\terr := upstream.Host.countFail(1)\n\tif err != nil {\n\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"could not count failure\"); c != nil {\n\t\t\tc.Write(\n\t\t\t\tzap.String(\"host\", upstream.Dial),\n\t\t\t\tzap.Error(err),\n\t\t\t)\n\t\t}\n\t\treturn\n\t}\n\n\t// forget it later\n\tgo func(host *Host, failDuration time.Duration) {\n\t\tdefer func() {\n\t\t\tif err := recover(); err != nil {\n\t\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"passive health check failure forgetter panicked\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.Any(\"error\", err),\n\t\t\t\t\t\tzap.ByteString(\"stack\", debug.Stack()),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t}\n\t\t}()\n\t\ttimer := time.NewTimer(failDuration)\n\t\tselect {\n\t\tcase <-h.ctx.Done():\n\t\t\tif !timer.Stop() {\n\t\t\t\t<-timer.C\n\t\t\t}\n\t\tcase <-timer.C:\n\t\t}\n\t\terr := host.countFail(-1)\n\t\tif err != nil {\n\t\t\tif c := h.HealthChecks.Active.logger.Check(zapcore.ErrorLevel, \"could not forget failure\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.String(\"host\", upstream.Dial),\n\t\t\t\t\tzap.Error(err),\n\t\t\t\t)\n\t\t\t}\n\t\t}\n\t}(upstream.Host, failDuration)\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/healthchecks.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(adminUpstreams{})\n}\n\n// adminUpstreams is a module that provides the\n// /reverse_proxy/upstreams endpoint for the Caddy admin\n// API. This allows for checking the health of configured\n// reverse proxy upstreams in the pool.\ntype adminUpstreams struct{}\n\n// upstreamStatus holds the status of a particular upstream\ntype upstreamStatus struct {\n\tAddress     string `json:\"address\"`\n\tNumRequests int    `json:\"num_requests\"`\n\tFails       int    `json:\"fails\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (adminUpstreams) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"admin.api.reverse_proxy\",\n\t\tNew: func() caddy.Module { return new(adminUpstreams) },\n\t}\n}\n\n// Routes returns a route for the /reverse_proxy/upstreams endpoint.\nfunc (al adminUpstreams) Routes() []caddy.AdminRoute {\n\treturn []caddy.AdminRoute{\n\t\t{\n\t\t\tPattern: \"/reverse_proxy/upstreams\",\n\t\t\tHandler: caddy.AdminHandlerFunc(al.handleUpstreams),\n\t\t},\n\t}\n}\n\n// handleUpstreams reports the status of the reverse proxy\n// upstream pool.\nfunc (adminUpstreams) handleUpstreams(w http.ResponseWriter, r *http.Request) error {\n\tif r.Method != http.MethodGet {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusMethodNotAllowed,\n\t\t\tErr:        fmt.Errorf(\"method not allowed\"),\n\t\t}\n\t}\n\n\t// Prep for a JSON response\n\tw.Header().Set(\"Content-Type\", \"application/json\")\n\tenc := json.NewEncoder(w)\n\n\t// Collect the results to respond with\n\tresults := []upstreamStatus{}\n\n\t// Iterate over the upstream pool (needs to be fast)\n\tvar rangeErr error\n\thosts.Range(func(key, val any) bool {\n\t\taddress, ok := key.(string)\n\t\tif !ok {\n\t\t\trangeErr = caddy.APIError{\n\t\t\t\tHTTPStatus: http.StatusInternalServerError,\n\t\t\t\tErr:        fmt.Errorf(\"could not type assert upstream address\"),\n\t\t\t}\n\t\t\treturn false\n\t\t}\n\n\t\tupstream, ok := val.(*Host)\n\t\tif !ok {\n\t\t\trangeErr = caddy.APIError{\n\t\t\t\tHTTPStatus: http.StatusInternalServerError,\n\t\t\t\tErr:        fmt.Errorf(\"could not type assert upstream struct\"),\n\t\t\t}\n\t\t\treturn false\n\t\t}\n\n\t\tresults = append(results, upstreamStatus{\n\t\t\tAddress:     address,\n\t\t\tNumRequests: upstream.NumRequests(),\n\t\t\tFails:       upstream.Fails(),\n\t\t})\n\t\treturn true\n\t})\n\n\t// If an error happened during the range, return it\n\tif rangeErr != nil {\n\t\treturn rangeErr\n\t}\n\n\terr := enc.Encode(results)\n\tif err != nil {\n\t\treturn caddy.APIError{\n\t\t\tHTTPStatus: http.StatusInternalServerError,\n\t\t\tErr:        err,\n\t\t}\n\t}\n\n\treturn nil\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/admin.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"strconv\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(CopyResponseHandler{})\n\tcaddy.RegisterModule(CopyResponseHeadersHandler{})\n}\n\n// CopyResponseHandler is a special HTTP handler which may\n// only be used within reverse_proxy's handle_response routes,\n// to copy the proxy response. EXPERIMENTAL, subject to change.\ntype CopyResponseHandler struct {\n\t// To write the upstream response's body but with a different\n\t// status code, set this field to the desired status code.\n\tStatusCode caddyhttp.WeakString `json:\"status_code,omitempty\"`\n\n\tctx caddy.Context\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (CopyResponseHandler) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.copy_response\",\n\t\tNew: func() caddy.Module { return new(CopyResponseHandler) },\n\t}\n}\n\n// Provision ensures that h is set up properly before use.\nfunc (h *CopyResponseHandler) Provision(ctx caddy.Context) error {\n\th.ctx = ctx\n\treturn nil\n}\n\n// ServeHTTP implements the Handler interface.\nfunc (h CopyResponseHandler) ServeHTTP(rw http.ResponseWriter, req *http.Request, _ caddyhttp.Handler) error {\n\trepl := req.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\thrc, ok := req.Context().Value(proxyHandleResponseContextCtxKey).(*handleResponseContext)\n\n\t// don't allow this to be used outside of handle_response routes\n\tif !ok {\n\t\treturn caddyhttp.Error(http.StatusInternalServerError,\n\t\t\tfmt.Errorf(\"cannot use 'copy_response' outside of reverse_proxy's handle_response routes\"))\n\t}\n\n\t// allow a custom status code to be written; otherwise the\n\t// status code from the upstream response is written\n\tif codeStr := h.StatusCode.String(); codeStr != \"\" {\n\t\tintVal, err := strconv.Atoi(repl.ReplaceAll(codeStr, \"\"))\n\t\tif err != nil {\n\t\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t\t}\n\t\thrc.response.StatusCode = intVal\n\t}\n\n\t// make sure the reverse_proxy handler doesn't try to call\n\t// finalizeResponse again after we've already done it here.\n\thrc.isFinalized = true\n\n\t// write the response\n\treturn hrc.handler.finalizeResponse(rw, req, hrc.response, repl, hrc.start, hrc.logger)\n}\n\n// CopyResponseHeadersHandler is a special HTTP handler which may\n// only be used within reverse_proxy's handle_response routes,\n// to copy headers from the proxy response. EXPERIMENTAL;\n// subject to change.\ntype CopyResponseHeadersHandler struct {\n\t// A list of header fields to copy from the response.\n\t// Cannot be defined at the same time as Exclude.\n\tInclude []string `json:\"include,omitempty\"`\n\n\t// A list of header fields to skip copying from the response.\n\t// Cannot be defined at the same time as Include.\n\tExclude []string `json:\"exclude,omitempty\"`\n\n\tincludeMap map[string]struct{}\n\texcludeMap map[string]struct{}\n\tctx        caddy.Context\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (CopyResponseHeadersHandler) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.copy_response_headers\",\n\t\tNew: func() caddy.Module { return new(CopyResponseHeadersHandler) },\n\t}\n}\n\n// Validate ensures the h's configuration is valid.\nfunc (h *CopyResponseHeadersHandler) Validate() error {\n\tif len(h.Exclude) > 0 && len(h.Include) > 0 {\n\t\treturn fmt.Errorf(\"cannot define both 'exclude' and 'include' lists at the same time\")\n\t}\n\n\treturn nil\n}\n\n// Provision ensures that h is set up properly before use.\nfunc (h *CopyResponseHeadersHandler) Provision(ctx caddy.Context) error {\n\th.ctx = ctx\n\n\t// Optimize the include list by converting it to a map\n\tif len(h.Include) > 0 {\n\t\th.includeMap = map[string]struct{}{}\n\t}\n\tfor _, field := range h.Include {\n\t\th.includeMap[http.CanonicalHeaderKey(field)] = struct{}{}\n\t}\n\n\t// Optimize the exclude list by converting it to a map\n\tif len(h.Exclude) > 0 {\n\t\th.excludeMap = map[string]struct{}{}\n\t}\n\tfor _, field := range h.Exclude {\n\t\th.excludeMap[http.CanonicalHeaderKey(field)] = struct{}{}\n\t}\n\n\treturn nil\n}\n\n// ServeHTTP implements the Handler interface.\nfunc (h CopyResponseHeadersHandler) ServeHTTP(rw http.ResponseWriter, req *http.Request, next caddyhttp.Handler) error {\n\thrc, ok := req.Context().Value(proxyHandleResponseContextCtxKey).(*handleResponseContext)\n\n\t// don't allow this to be used outside of handle_response routes\n\tif !ok {\n\t\treturn caddyhttp.Error(http.StatusInternalServerError,\n\t\t\tfmt.Errorf(\"cannot use 'copy_response_headers' outside of reverse_proxy's handle_response routes\"))\n\t}\n\n\tfor field, values := range hrc.response.Header {\n\t\t// Check the include list first, skip\n\t\t// the header if it's _not_ in this list.\n\t\tif len(h.includeMap) > 0 {\n\t\t\tif _, ok := h.includeMap[field]; !ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// Then, check the exclude list, skip\n\t\t// the header if it _is_ in this list.\n\t\tif len(h.excludeMap) > 0 {\n\t\t\tif _, ok := h.excludeMap[field]; ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\t// Copy all the values for the header.\n\t\tfor _, value := range values {\n\t\t\trw.Header().Add(field, value)\n\t\t}\n\t}\n\n\treturn next.ServeHTTP(rw, req)\n}\n\n// Interface guards\nvar (\n\t_ caddyhttp.MiddlewareHandler = (*CopyResponseHandler)(nil)\n\t_ caddyfile.Unmarshaler       = (*CopyResponseHandler)(nil)\n\t_ caddy.Provisioner           = (*CopyResponseHandler)(nil)\n\n\t_ caddyhttp.MiddlewareHandler = (*CopyResponseHeadersHandler)(nil)\n\t_ caddyfile.Unmarshaler       = (*CopyResponseHeadersHandler)(nil)\n\t_ caddy.Provisioner           = (*CopyResponseHeadersHandler)(nil)\n\t_ caddy.Validator             = (*CopyResponseHeadersHandler)(nil)\n)\n",
    "source_file": "modules/caddyhttp/reverseproxy/copyresponse.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/rand\"\n\t\"encoding/base64\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/httptrace\"\n\t\"net/netip\"\n\t\"net/textproto\"\n\t\"net/url\"\n\t\"strconv\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\t\"golang.org/x/net/http/httpguts\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyevents\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/headers\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/rewrite\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Handler{})\n}\n\n// Handler implements a highly configurable and production-ready reverse proxy.\n//\n// Upon proxying, this module sets the following placeholders (which can be used\n// both within and after this handler; for example, in response headers):\n//\n// Placeholder | Description\n// ------------|-------------\n// `{http.reverse_proxy.upstream.address}` | The full address to the upstream as given in the config\n// `{http.reverse_proxy.upstream.hostport}` | The host:port of the upstream\n// `{http.reverse_proxy.upstream.host}` | The host of the upstream\n// `{http.reverse_proxy.upstream.port}` | The port of the upstream\n// `{http.reverse_proxy.upstream.requests}` | The approximate current number of requests to the upstream\n// `{http.reverse_proxy.upstream.max_requests}` | The maximum approximate number of requests allowed to the upstream\n// `{http.reverse_proxy.upstream.fails}` | The number of recent failed requests to the upstream\n// `{http.reverse_proxy.upstream.latency}` | How long it took the proxy upstream to write the response header.\n// `{http.reverse_proxy.upstream.latency_ms}` | Same as 'latency', but in milliseconds.\n// `{http.reverse_proxy.upstream.duration}` | Time spent proxying to the upstream, including writing response body to client.\n// `{http.reverse_proxy.upstream.duration_ms}` | Same as 'upstream.duration', but in milliseconds.\n// `{http.reverse_proxy.duration}` | Total time spent proxying, including selecting an upstream, retries, and writing response.\n// `{http.reverse_proxy.duration_ms}` | Same as 'duration', but in milliseconds.\n// `{http.reverse_proxy.retries}` | The number of retries actually performed to communicate with an upstream.\ntype Handler struct {\n\t// Configures the method of transport for the proxy. A transport\n\t// is what performs the actual \"round trip\" to the backend.\n\t// The default transport is plaintext HTTP.\n\tTransportRaw json.RawMessage `json:\"transport,omitempty\" caddy:\"namespace=http.reverse_proxy.transport inline_key=protocol\"`\n\n\t// A circuit breaker may be used to relieve pressure on a backend\n\t// that is beginning to exhibit symptoms of stress or latency.\n\t// By default, there is no circuit breaker.\n\tCBRaw json.RawMessage `json:\"circuit_breaker,omitempty\" caddy:\"namespace=http.reverse_proxy.circuit_breakers inline_key=type\"`\n\n\t// Load balancing distributes load/requests between backends.\n\tLoadBalancing *LoadBalancing `json:\"load_balancing,omitempty\"`\n\n\t// Health checks update the status of backends, whether they are\n\t// up or down. Down backends will not be proxied to.\n\tHealthChecks *HealthChecks `json:\"health_checks,omitempty\"`\n\n\t// Upstreams is the static list of backends to proxy to.\n\tUpstreams UpstreamPool `json:\"upstreams,omitempty\"`\n\n\t// A module for retrieving the list of upstreams dynamically. Dynamic\n\t// upstreams are retrieved at every iteration of the proxy loop for\n\t// each request (i.e. before every proxy attempt within every request).\n\t// Active health checks do not work on dynamic upstreams, and passive\n\t// health checks are only effective on dynamic upstreams if the proxy\n\t// server is busy enough that concurrent requests to the same backends\n\t// are continuous. Instead of health checks for dynamic upstreams, it\n\t// is recommended that the dynamic upstream module only return available\n\t// backends in the first place.\n\tDynamicUpstreamsRaw json.RawMessage `json:\"dynamic_upstreams,omitempty\" caddy:\"namespace=http.reverse_proxy.upstreams inline_key=source\"`\n\n\t// Adjusts how often to flush the response buffer. By default,\n\t// no periodic flushing is done. A negative value disables\n\t// response buffering, and flushes immediately after each\n\t// write to the client. This option is ignored when the upstream's\n\t// response is recognized as a streaming response, or if its\n\t// content length is -1; for such responses, writes are flushed\n\t// to the client immediately.\n\tFlushInterval caddy.Duration `json:\"flush_interval,omitempty\"`\n\n\t// A list of IP ranges (supports CIDR notation) from which\n\t// X-Forwarded-* header values should be trusted. By default,\n\t// no proxies are trusted, so existing values will be ignored\n\t// when setting these headers. If the proxy is trusted, then\n\t// existing values will be used when constructing the final\n\t// header values.\n\tTrustedProxies []string `json:\"trusted_proxies,omitempty\"`\n\n\t// Headers manipulates headers between Caddy and the backend.\n\t// By default, all headers are passed-thru without changes,\n\t// with the exceptions of special hop-by-hop headers.\n\t//\n\t// X-Forwarded-For, X-Forwarded-Proto and X-Forwarded-Host\n\t// are also set implicitly.\n\tHeaders *headers.Handler `json:\"headers,omitempty\"`\n\n\t// If nonzero, the entire request body up to this size will be read\n\t// and buffered in memory before being proxied to the backend. This\n\t// should be avoided if at all possible for performance reasons, but\n\t// could be useful if the backend is intolerant of read latency or\n\t// chunked encodings.\n\tRequestBuffers int64 `json:\"request_buffers,omitempty\"`\n\n\t// If nonzero, the entire response body up to this size will be read\n\t// and buffered in memory before being proxied to the client. This\n\t// should be avoided if at all possible for performance reasons, but\n\t// could be useful if the backend has tighter memory constraints.\n\tResponseBuffers int64 `json:\"response_buffers,omitempty\"`\n\n\t// If nonzero, streaming requests such as WebSockets will be\n\t// forcibly closed at the end of the timeout. Default: no timeout.\n\tStreamTimeout caddy.Duration `json:\"stream_timeout,omitempty\"`\n\n\t// If nonzero, streaming requests such as WebSockets will not be\n\t// closed when the proxy config is unloaded, and instead the stream\n\t// will remain open until the delay is complete. In other words,\n\t// enabling this prevents streams from closing when Caddy's config\n\t// is reloaded. Enabling this may be a good idea to avoid a thundering\n\t// herd of reconnecting clients which had their connections closed\n\t// by the previous config closing. Default: no delay.\n\tStreamCloseDelay caddy.Duration `json:\"stream_close_delay,omitempty\"`\n\n\t// If configured, rewrites the copy of the upstream request.\n\t// Allows changing the request method and URI (path and query).\n\t// Since the rewrite is applied to the copy, it does not persist\n\t// past the reverse proxy handler.\n\t// If the method is changed to `GET` or `HEAD`, the request body\n\t// will not be copied to the backend. This allows a later request\n\t// handler -- either in a `handle_response` route, or after -- to\n\t// read the body.\n\t// By default, no rewrite is performed, and the method and URI\n\t// from the incoming request is used as-is for proxying.\n\tRewrite *rewrite.Rewrite `json:\"rewrite,omitempty\"`\n\n\t// List of handlers and their associated matchers to evaluate\n\t// after successful roundtrips. The first handler that matches\n\t// the response from a backend will be invoked. The response\n\t// body from the backend will not be written to the client;\n\t// it is up to the handler to finish handling the response.\n\t// If passive health checks are enabled, any errors from the\n\t// handler chain will not affect the health status of the\n\t// backend.\n\t//\n\t// Three new placeholders are available in this handler chain:\n\t// - `{http.reverse_proxy.status_code}` The status code from the response\n\t// - `{http.reverse_proxy.status_text}` The status text from the response\n\t// - `{http.reverse_proxy.header.*}` The headers from the response\n\tHandleResponse []caddyhttp.ResponseHandler `json:\"handle_response,omitempty\"`\n\n\t// If set, the proxy will write very detailed logs about its\n\t// inner workings. Enable this only when debugging, as it\n\t// will produce a lot of output.\n\t//\n\t// EXPERIMENTAL: This feature is subject to change or removal.\n\tVerboseLogs bool `json:\"verbose_logs,omitempty\"`\n\n\tTransport        http.RoundTripper `json:\"-\"`\n\tCB               CircuitBreaker    `json:\"-\"`\n\tDynamicUpstreams UpstreamSource    `json:\"-\"`\n\n\t// Holds the parsed CIDR ranges from TrustedProxies\n\ttrustedProxies []netip.Prefix\n\n\t// Holds the named response matchers from the Caddyfile while adapting\n\tresponseMatchers map[string]caddyhttp.ResponseMatcher\n\n\t// Holds the handle_response Caddyfile tokens while adapting\n\thandleResponseSegments []*caddyfile.Dispenser\n\n\t// Stores upgraded requests (hijacked connections) for proper cleanup\n\tconnections           map[io.ReadWriteCloser]openConnection\n\tconnectionsCloseTimer *time.Timer\n\tconnectionsMu         *sync.Mutex\n\n\tctx    caddy.Context\n\tlogger *zap.Logger\n\tevents *caddyevents.App\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Handler) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.reverse_proxy\",\n\t\tNew: func() caddy.Module { return new(Handler) },\n\t}\n}\n\n// Provision ensures that h is set up properly before use.\nfunc (h *Handler) Provision(ctx caddy.Context) error {\n\teventAppIface, err := ctx.App(\"events\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"getting events app: %v\", err)\n\t}\n\th.events = eventAppIface.(*caddyevents.App)\n\th.ctx = ctx\n\th.logger = ctx.Logger()\n\th.connections = make(map[io.ReadWriteCloser]openConnection)\n\th.connectionsMu = new(sync.Mutex)\n\n\t// warn about unsafe buffering config\n\tif h.RequestBuffers == -1 || h.ResponseBuffers == -1 {\n\t\th.logger.Warn(\"UNLIMITED BUFFERING: buffering is enabled without any cap on buffer size, which can result in OOM crashes\")\n\t}\n\n\t// start by loading modules\n\tif h.TransportRaw != nil {\n\t\tmod, err := ctx.LoadModule(h, \"TransportRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading transport: %v\", err)\n\t\t}\n\t\th.Transport = mod.(http.RoundTripper)\n\t\t// enable request buffering for fastcgi if not configured\n\t\t// This is because most fastcgi servers are php-fpm that require the content length to be set to read the body, golang\n\t\t// std has fastcgi implementation that doesn't need this value to process the body, but we can safely assume that's\n\t\t// not used.\n\t\t// http3 requests have a negative content length for GET and HEAD requests, if that header is not sent.\n\t\t// see: https://github.com/caddyserver/caddy/issues/6678#issuecomment-2472224182\n\t\t// Though it appears even if CONTENT_LENGTH is invalid, php-fpm can handle just fine if the body is empty (no Stdin records sent).\n\t\t// php-fpm will hang if there is any data in the body though, https://github.com/caddyserver/caddy/issues/5420#issuecomment-2415943516\n\n\t\t// TODO: better default buffering for fastcgi requests without content length, in theory a value of 1 should be enough, make it bigger anyway\n\t\tif module, ok := h.Transport.(caddy.Module); ok && module.CaddyModule().ID.Name() == \"fastcgi\" && h.RequestBuffers == 0 {\n\t\t\th.RequestBuffers = 4096\n\t\t}\n\t}\n\tif h.LoadBalancing != nil && h.LoadBalancing.SelectionPolicyRaw != nil {\n\t\tmod, err := ctx.LoadModule(h.LoadBalancing, \"SelectionPolicyRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading load balancing selection policy: %s\", err)\n\t\t}\n\t\th.LoadBalancing.SelectionPolicy = mod.(Selector)\n\t}\n\tif h.CBRaw != nil {\n\t\tmod, err := ctx.LoadModule(h, \"CBRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading circuit breaker: %s\", err)\n\t\t}\n\t\th.CB = mod.(CircuitBreaker)\n\t}\n\tif h.DynamicUpstreamsRaw != nil {\n\t\tmod, err := ctx.LoadModule(h, \"DynamicUpstreamsRaw\")\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"loading upstream source module: %v\", err)\n\t\t}\n\t\th.DynamicUpstreams = mod.(UpstreamSource)\n\t}\n\n\t// parse trusted proxy CIDRs ahead of time\n\tfor _, str := range h.TrustedProxies {\n\t\tif strings.Contains(str, \"/\") {\n\t\t\tipNet, err := netip.ParsePrefix(str)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"parsing CIDR expression: '%s': %v\", str, err)\n\t\t\t}\n\t\t\th.trustedProxies = append(h.trustedProxies, ipNet)\n\t\t} else {\n\t\t\tipAddr, err := netip.ParseAddr(str)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"invalid IP address: '%s': %v\", str, err)\n\t\t\t}\n\t\t\tipNew := netip.PrefixFrom(ipAddr, ipAddr.BitLen())\n\t\t\th.trustedProxies = append(h.trustedProxies, ipNew)\n\t\t}\n\t}\n\n\t// ensure any embedded headers handler module gets provisioned\n\t// (see https://caddy.community/t/set-cookie-manipulation-in-reverse-proxy/7666?u=matt\n\t// for what happens if we forget to provision it)\n\tif h.Headers != nil {\n\t\terr := h.Headers.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning embedded headers handler: %v\", err)\n\t\t}\n\t}\n\n\tif h.Rewrite != nil {\n\t\terr := h.Rewrite.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning rewrite: %v\", err)\n\t\t}\n\t}\n\n\t// set up transport\n\tif h.Transport == nil {\n\t\tt := &HTTPTransport{}\n\t\terr := t.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning default transport: %v\", err)\n\t\t}\n\t\th.Transport = t\n\t}\n\n\t// set up load balancing\n\tif h.LoadBalancing == nil {\n\t\th.LoadBalancing = new(LoadBalancing)\n\t}\n\tif h.LoadBalancing.SelectionPolicy == nil {\n\t\th.LoadBalancing.SelectionPolicy = RandomSelection{}\n\t}\n\tif h.LoadBalancing.TryDuration > 0 && h.LoadBalancing.TryInterval == 0 {\n\t\t// a non-zero try_duration with a zero try_interval\n\t\t// will always spin the CPU for try_duration if the\n\t\t// upstream is local or low-latency; avoid that by\n\t\t// defaulting to a sane wait period between attempts\n\t\th.LoadBalancing.TryInterval = caddy.Duration(250 * time.Millisecond)\n\t}\n\tlbMatcherSets, err := ctx.LoadModule(h.LoadBalancing, \"RetryMatchRaw\")\n\tif err != nil {\n\t\treturn err\n\t}\n\terr = h.LoadBalancing.RetryMatch.FromInterface(lbMatcherSets)\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// set up upstreams\n\tfor _, u := range h.Upstreams {\n\t\th.provisionUpstream(u)\n\t}\n\n\tif h.HealthChecks != nil {\n\t\t// set defaults on passive health checks, if necessary\n\t\tif h.HealthChecks.Passive != nil {\n\t\t\th.HealthChecks.Passive.logger = h.logger.Named(\"health_checker.passive\")\n\t\t\tif h.HealthChecks.Passive.MaxFails == 0 {\n\t\t\t\th.HealthChecks.Passive.MaxFails = 1\n\t\t\t}\n\t\t}\n\n\t\t// if active health checks are enabled, configure them and start a worker\n\t\tif h.HealthChecks.Active != nil {\n\t\t\terr := h.HealthChecks.Active.Provision(ctx, h)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\tif h.HealthChecks.Active.IsEnabled() {\n\t\t\t\tgo h.activeHealthChecker()\n\t\t\t}\n\t\t}\n\t}\n\n\t// set up any response routes\n\tfor i, rh := range h.HandleResponse {\n\t\terr := rh.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning response handler %d: %v\", i, err)\n\t\t}\n\t}\n\n\tupstreamHealthyUpdater := newMetricsUpstreamsHealthyUpdater(h, ctx)\n\tupstreamHealthyUpdater.init()\n\n\treturn nil\n}\n\n// Cleanup cleans up the resources made by h.\nfunc (h *Handler) Cleanup() error {\n\terr := h.cleanupConnections()\n\n\t// remove hosts from our config from the pool\n\tfor _, upstream := range h.Upstreams {\n\t\t_, _ = hosts.Delete(upstream.String())\n\t}\n\n\treturn err\n}\n\nfunc (h *Handler) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\t// prepare the request for proxying; this is needed only once\n\tclonedReq, err := h.prepareRequest(r, repl)\n\tif err != nil {\n\t\treturn caddyhttp.Error(http.StatusInternalServerError,\n\t\t\tfmt.Errorf(\"preparing request for upstream round-trip: %v\", err))\n\t}\n\t// websocket over http2, assuming backend doesn't support this, the request will be modified to http1.1 upgrade\n\t// TODO: once we can reliably detect backend support this, it can be removed for those backends\n\tif r.ProtoMajor == 2 && r.Method == http.MethodConnect && r.Header.Get(\":protocol\") == \"websocket\" {\n\t\tclonedReq.Header.Del(\":protocol\")\n\t\t// keep the body for later use. http1.1 upgrade uses http.NoBody\n\t\tcaddyhttp.SetVar(clonedReq.Context(), \"h2_websocket_body\", clonedReq.Body)\n\t\tclonedReq.Body = http.NoBody\n\t\tclonedReq.Method = http.MethodGet\n\t\tclonedReq.Header.Set(\"Upgrade\", \"websocket\")\n\t\tclonedReq.Header.Set(\"Connection\", \"Upgrade\")\n\t\tkey := make([]byte, 16)\n\t\t_, randErr := rand.Read(key)\n\t\tif randErr != nil {\n\t\t\treturn randErr\n\t\t}\n\t\tclonedReq.Header[\"Sec-WebSocket-Key\"] = []string{base64.StdEncoding.EncodeToString(key)}\n\t}\n\n\t// we will need the original headers and Host value if\n\t// header operations are configured; this is so that each\n\t// retry can apply the modifications, because placeholders\n\t// may be used which depend on the selected upstream for\n\t// their values\n\treqHost := clonedReq.Host\n\treqHeader := clonedReq.Header\n\n\tstart := time.Now()\n\tdefer func() {\n\t\t// total proxying duration, including time spent on LB and retries\n\t\trepl.Set(\"http.reverse_proxy.duration\", time.Since(start))\n\t\trepl.Set(\"http.reverse_proxy.duration_ms\", time.Since(start).Seconds()*1e3) // multiply seconds to preserve decimal (see #4666)\n\t}()\n\n\t// in the proxy loop, each iteration is an attempt to proxy the request,\n\t// and because we may retry some number of times, carry over the error\n\t// from previous tries because of the nuances of load balancing & retries\n\tvar proxyErr error\n\tvar retries int\n\tfor {\n\t\t// if the request body was buffered (and only the entire body, hence no body\n\t\t// set to read from after the buffer), make reading from the body idempotent\n\t\t// and reusable, so if a backend partially or fully reads the body but then\n\t\t// produces an error, the request can be repeated to the next backend with\n\t\t// the full body (retries should only happen for idempotent requests) (see #6259)\n\t\tif reqBodyBuf, ok := r.Body.(bodyReadCloser); ok && reqBodyBuf.body == nil {\n\t\t\tr.Body = io.NopCloser(bytes.NewReader(reqBodyBuf.buf.Bytes()))\n\t\t}\n\n\t\tvar done bool\n\t\tdone, proxyErr = h.proxyLoopIteration(clonedReq, r, w, proxyErr, start, retries, repl, reqHeader, reqHost, next)\n\t\tif done {\n\t\t\tbreak\n\t\t}\n\t\tif h.VerboseLogs {\n\t\t\tvar lbWait time.Duration\n\t\t\tif h.LoadBalancing != nil {\n\t\t\t\tlbWait = time.Duration(h.LoadBalancing.TryInterval)\n\t\t\t}\n\t\t\tif c := h.logger.Check(zapcore.DebugLevel, \"retrying\"); c != nil {\n\t\t\t\tc.Write(zap.Error(proxyErr), zap.Duration(\"after\", lbWait))\n\t\t\t}\n\t\t}\n\t\tretries++\n\t}\n\n\t// number of retries actually performed\n\trepl.Set(\"http.reverse_proxy.retries\", retries)\n\n\tif proxyErr != nil {\n\t\treturn statusError(proxyErr)\n\t}\n\n\treturn nil\n}\n\n// proxyLoopIteration implements an iteration of the proxy loop. Despite the enormous amount of local state\n// that has to be passed in, we brought this into its own method so that we could run defer more easily.\n// It returns true when the loop is done and should break; false otherwise. The error value returned should\n// be assigned to the proxyErr value for the next iteration of the loop (or the error handled after break).\nfunc (h *Handler) proxyLoopIteration(r *http.Request, origReq *http.Request, w http.ResponseWriter, proxyErr error, start time.Time, retries int,\n\trepl *caddy.Replacer, reqHeader http.Header, reqHost string, next caddyhttp.Handler,\n) (bool, error) {\n\t// get the updated list of upstreams\n\tupstreams := h.Upstreams\n\tif h.DynamicUpstreams != nil {\n\t\tdUpstreams, err := h.DynamicUpstreams.GetUpstreams(r)\n\t\tif err != nil {\n\t\t\tif c := h.logger.Check(zapcore.ErrorLevel, \"failed getting dynamic upstreams; falling back to static upstreams\"); c != nil {\n\t\t\t\tc.Write(zap.Error(err))\n\t\t\t}\n\t\t} else {\n\t\t\tupstreams = dUpstreams\n\t\t\tfor _, dUp := range dUpstreams {\n\t\t\t\th.provisionUpstream(dUp)\n\t\t\t}\n\t\t\tif c := h.logger.Check(zapcore.DebugLevel, \"provisioned dynamic upstreams\"); c != nil {\n\t\t\t\tc.Write(zap.Int(\"count\", len(dUpstreams)))\n\t\t\t}\n\t\t\tdefer func() {\n\t\t\t\t// these upstreams are dynamic, so they are only used for this iteration\n\t\t\t\t// of the proxy loop; be sure to let them go away when we're done with them\n\t\t\t\tfor _, upstream := range dUpstreams {\n\t\t\t\t\t_, _ = hosts.Delete(upstream.String())\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t}\n\n\t// choose an available upstream\n\tupstream := h.LoadBalancing.SelectionPolicy.Select(upstreams, r, w)\n\tif upstream == nil {\n\t\tif proxyErr == nil {\n\t\t\tproxyErr = caddyhttp.Error(http.StatusServiceUnavailable, errNoUpstream)\n\t\t}\n\t\tif !h.LoadBalancing.tryAgain(h.ctx, start, retries, proxyErr, r, h.logger) {\n\t\t\treturn true, proxyErr\n\t\t}\n\t\treturn false, proxyErr\n\t}\n\n\t// the dial address may vary per-request if placeholders are\n\t// used, so perform those replacements here; the resulting\n\t// DialInfo struct should have valid network address syntax\n\tdialInfo, err := upstream.fillDialInfo(repl)\n\tif err != nil {\n\t\treturn true, fmt.Errorf(\"making dial info: %v\", err)\n\t}\n\n\tif c := h.logger.Check(zapcore.DebugLevel, \"selected upstream\"); c != nil {\n\t\tc.Write(\n\t\t\tzap.String(\"dial\", dialInfo.Address),\n\t\t\tzap.Int(\"total_upstreams\", len(upstreams)),\n\t\t)\n\t}\n\n\t// attach to the request information about how to dial the upstream;\n\t// this is necessary because the information cannot be sufficiently\n\t// or satisfactorily represented in a URL\n\tcaddyhttp.SetVar(r.Context(), dialInfoVarKey, dialInfo)\n\n\t// set placeholders with information about this upstream\n\trepl.Set(\"http.reverse_proxy.upstream.address\", dialInfo.String())\n\trepl.Set(\"http.reverse_proxy.upstream.hostport\", dialInfo.Address)\n\trepl.Set(\"http.reverse_proxy.upstream.host\", dialInfo.Host)\n\trepl.Set(\"http.reverse_proxy.upstream.port\", dialInfo.Port)\n\trepl.Set(\"http.reverse_proxy.upstream.requests\", upstream.Host.NumRequests())\n\trepl.Set(\"http.reverse_proxy.upstream.max_requests\", upstream.MaxRequests)\n\trepl.Set(\"http.reverse_proxy.upstream.fails\", upstream.Host.Fails())\n\n\t// mutate request headers according to this upstream;\n\t// because we're in a retry loop, we have to copy\n\t// headers (and the r.Host value) from the original\n\t// so that each retry is identical to the first\n\tif h.Headers != nil && h.Headers.Request != nil {\n\t\tr.Header = make(http.Header)\n\t\tcopyHeader(r.Header, reqHeader)\n\t\tr.Host = reqHost\n\t\th.Headers.Request.ApplyToRequest(r)\n\t}\n\n\t// proxy the request to that upstream\n\tproxyErr = h.reverseProxy(w, r, origReq, repl, dialInfo, next)\n\tif proxyErr == nil || errors.Is(proxyErr, context.Canceled) {\n\t\t// context.Canceled happens when the downstream client\n\t\t// cancels the request, which is not our failure\n\t\treturn true, nil\n\t}\n\n\t// if the roundtrip was successful, don't retry the request or\n\t// ding the health status of the upstream (an error can still\n\t// occur after the roundtrip if, for example, a response handler\n\t// after the roundtrip returns an error)\n\tif succ, ok := proxyErr.(roundtripSucceededError); ok {\n\t\treturn true, succ.error\n\t}\n\n\t// remember this failure (if enabled)\n\th.countFailure(upstream)\n\n\t// if we've tried long enough, break\n\tif !h.LoadBalancing.tryAgain(h.ctx, start, retries, proxyErr, r, h.logger) {\n\t\treturn true, proxyErr\n\t}\n\n\treturn false, proxyErr\n}\n\n// Mapping of the canonical form of the headers, to the RFC 6455 form,\n// i.e. `WebSocket` with uppercase 'S'.\nvar websocketHeaderMapping = map[string]string{\n\t\"Sec-Websocket-Accept\":     \"Sec-WebSocket-Accept\",\n\t\"Sec-Websocket-Extensions\": \"Sec-WebSocket-Extensions\",\n\t\"Sec-Websocket-Key\":        \"Sec-WebSocket-Key\",\n\t\"Sec-Websocket-Protocol\":   \"Sec-WebSocket-Protocol\",\n\t\"Sec-Websocket-Version\":    \"Sec-WebSocket-Version\",\n}\n\n// normalizeWebsocketHeaders ensures we use the standard casing as per\n// RFC 6455, i.e. `WebSocket` with uppercase 'S'. Most servers don't\n// care about this difference (read headers case insensitively), but\n// some do, so this maximizes compatibility with upstreams.\n// See https://github.com/caddyserver/caddy/pull/6621\nfunc normalizeWebsocketHeaders(header http.Header) {\n\tfor k, rk := range websocketHeaderMapping {\n\t\tif v, ok := header[k]; ok {\n\t\t\tdelete(header, k)\n\t\t\theader[rk] = v\n\t\t}\n\t}\n}\n\n// prepareRequest clones req so that it can be safely modified without\n// changing the original request or introducing data races. It then\n// modifies it so that it is ready to be proxied, except for directing\n// to a specific upstream. This method adjusts headers and other relevant\n// properties of the cloned request and should be done just once (before\n// proxying) regardless of proxy retries. This assumes that no mutations\n// of the cloned request are performed by h during or after proxying.\nfunc (h Handler) prepareRequest(req *http.Request, repl *caddy.Replacer) (*http.Request, error) {\n\treq = cloneRequest(req)\n\n\t// if enabled, perform rewrites on the cloned request; if\n\t// the method is GET or HEAD, prevent the request body\n\t// from being copied to the upstream\n\tif h.Rewrite != nil {\n\t\tchanged := h.Rewrite.Rewrite(req, repl)\n\t\tif changed && (h.Rewrite.Method == \"GET\" || h.Rewrite.Method == \"HEAD\") {\n\t\t\treq.ContentLength = 0\n\t\t\treq.Body = nil\n\t\t}\n\t}\n\n\t// if enabled, buffer client request; this should only be\n\t// enabled if the upstream requires it and does not work\n\t// with \"slow clients\" (gunicorn, etc.) - this obviously\n\t// has a perf overhead and makes the proxy at risk of\n\t// exhausting memory and more susceptible to slowloris\n\t// attacks, so it is strongly recommended to only use this\n\t// feature if absolutely required, if read timeouts are\n\t// set, and if body size is limited\n\tif h.RequestBuffers != 0 && req.Body != nil {\n\t\tvar readBytes int64\n\t\treq.Body, readBytes = h.bufferedBody(req.Body, h.RequestBuffers)\n\t\t// set Content-Length when body is fully buffered\n\t\tif b, ok := req.Body.(bodyReadCloser); ok && b.body == nil {\n\t\t\treq.ContentLength = readBytes\n\t\t\treq.Header.Set(\"Content-Length\", strconv.FormatInt(req.ContentLength, 10))\n\t\t}\n\t}\n\n\tif req.ContentLength == 0 {\n\t\treq.Body = nil // Issue golang/go#16036: nil Body for http.Transport retries\n\t}\n\n\treq.Close = false\n\n\t// if User-Agent is not set by client, then explicitly\n\t// disable it so it's not set to default value by std lib\n\tif _, ok := req.Header[\"User-Agent\"]; !ok {\n\t\treq.Header.Set(\"User-Agent\", \"\")\n\t}\n\n\t// Indicate if request has been conveyed in early data.\n\t// RFC 8470: \"An intermediary that forwards a request prior to the\n\t// completion of the TLS handshake with its client MUST send it with\n\t// the Early-Data header field set to \u201c1\u201d (i.e., it adds it if not\n\t// present in the request). An intermediary MUST use the Early-Data\n\t// header field if the request might have been subject to a replay and\n\t// might already have been forwarded by it or another instance\n\t// (see Section 6.2).\"\n\tif req.TLS != nil && !req.TLS.HandshakeComplete {\n\t\treq.Header.Set(\"Early-Data\", \"1\")\n\t}\n\n\treqUpgradeType := upgradeType(req.Header)\n\tremoveConnectionHeaders(req.Header)\n\n\t// Remove hop-by-hop headers to the backend. Especially\n\t// important is \"Connection\" because we want a persistent\n\t// connection, regardless of what the client sent to us.\n\t// Issue golang/go#46313: don't skip if field is empty.\n\tfor _, h := range hopHeaders {\n\t\t// Issue golang/go#21096: tell backend applications that care about trailer support\n\t\t// that we support trailers. (We do, but we don't go out of our way to\n\t\t// advertise that unless the incoming client request thought it was worth\n\t\t// mentioning.)\n\t\tif h == \"Te\" && httpguts.HeaderValuesContainsToken(req.Header[\"Te\"], \"trailers\") {\n\t\t\treq.Header.Set(\"Te\", \"trailers\")\n\t\t\tcontinue\n\t\t}\n\t\treq.Header.Del(h)\n\t}\n\n\t// After stripping all the hop-by-hop connection headers above, add back any\n\t// necessary for protocol upgrades, such as for websockets.\n\tif reqUpgradeType != \"\" {\n\t\treq.Header.Set(\"Connection\", \"Upgrade\")\n\t\treq.Header.Set(\"Upgrade\", reqUpgradeType)\n\t\tnormalizeWebsocketHeaders(req.Header)\n\t}\n\n\t// Set up the PROXY protocol info\n\taddress := caddyhttp.GetVar(req.Context(), caddyhttp.ClientIPVarKey).(string)\n\taddrPort, err := netip.ParseAddrPort(address)\n\tif err != nil {\n\t\t// OK; probably didn't have a port\n\t\taddr, err := netip.ParseAddr(address)\n\t\tif err != nil {\n\t\t\t// Doesn't seem like a valid ip address at all\n\t\t} else {\n\t\t\t// Ok, only the port was missing\n\t\t\taddrPort = netip.AddrPortFrom(addr, 0)\n\t\t}\n\t}\n\tproxyProtocolInfo := ProxyProtocolInfo{AddrPort: addrPort}\n\tcaddyhttp.SetVar(req.Context(), proxyProtocolInfoVarKey, proxyProtocolInfo)\n\n\t// Add the supported X-Forwarded-* headers\n\terr = h.addForwardedHeaders(req)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// Via header(s)\n\treq.Header.Add(\"Via\", fmt.Sprintf(\"%d.%d Caddy\", req.ProtoMajor, req.ProtoMinor))\n\n\treturn req, nil\n}\n\n// addForwardedHeaders adds the de-facto standard X-Forwarded-*\n// headers to the request before it is sent upstream.\n//\n// These headers are security sensitive, so care is taken to only\n// use existing values for these headers from the incoming request\n// if the client IP is trusted (i.e. coming from a trusted proxy\n// sitting in front of this server). If the request didn't have\n// the headers at all, then they will be added with the values\n// that we can glean from the request.\nfunc (h Handler) addForwardedHeaders(req *http.Request) error {\n\t// Parse the remote IP, ignore the error as non-fatal,\n\t// but the remote IP is required to continue, so we\n\t// just return early. This should probably never happen\n\t// though, unless some other module manipulated the request's\n\t// remote address and used an invalid value.\n\tclientIP, _, err := net.SplitHostPort(req.RemoteAddr)\n\tif err != nil {\n\t\t// Remove the `X-Forwarded-*` headers to avoid upstreams\n\t\t// potentially trusting a header that came from the client\n\t\treq.Header.Del(\"X-Forwarded-For\")\n\t\treq.Header.Del(\"X-Forwarded-Proto\")\n\t\treq.Header.Del(\"X-Forwarded-Host\")\n\t\treturn nil\n\t}\n\n\t// Client IP may contain a zone if IPv6, so we need\n\t// to pull that out before parsing the IP\n\tclientIP, _, _ = strings.Cut(clientIP, \"%\")\n\tipAddr, err := netip.ParseAddr(clientIP)\n\tif err != nil {\n\t\treturn fmt.Errorf(\"invalid IP address: '%s': %v\", clientIP, err)\n\t}\n\n\t// Check if the client is a trusted proxy\n\ttrusted := caddyhttp.GetVar(req.Context(), caddyhttp.TrustedProxyVarKey).(bool)\n\tfor _, ipRange := range h.trustedProxies {\n\t\tif ipRange.Contains(ipAddr) {\n\t\t\ttrusted = true\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// If we aren't the first proxy, and the proxy is trusted,\n\t// retain prior X-Forwarded-For information as a comma+space\n\t// separated list and fold multiple headers into one.\n\tclientXFF := clientIP\n\tprior, ok, omit := allHeaderValues(req.Header, \"X-Forwarded-For\")\n\tif trusted && ok && prior != \"\" {\n\t\tclientXFF = prior + \", \" + clientXFF\n\t}\n\tif !omit {\n\t\treq.Header.Set(\"X-Forwarded-For\", clientXFF)\n\t}\n\n\t// Set X-Forwarded-Proto; many backend apps expect this,\n\t// so that they can properly craft URLs with the right\n\t// scheme to match the original request\n\tproto := \"https\"\n\tif req.TLS == nil {\n\t\tproto = \"http\"\n\t}\n\tprior, ok, omit = lastHeaderValue(req.Header, \"X-Forwarded-Proto\")\n\tif trusted && ok && prior != \"\" {\n\t\tproto = prior\n\t}\n\tif !omit {\n\t\treq.Header.Set(\"X-Forwarded-Proto\", proto)\n\t}\n\n\t// Set X-Forwarded-Host; often this is redundant because\n\t// we pass through the request Host as-is, but in situations\n\t// where we proxy over HTTPS, the user may need to override\n\t// Host themselves, so it's helpful to send the original too.\n\thost := req.Host\n\tprior, ok, omit = lastHeaderValue(req.Header, \"X-Forwarded-Host\")\n\tif trusted && ok && prior != \"\" {\n\t\thost = prior\n\t}\n\tif !omit {\n\t\treq.Header.Set(\"X-Forwarded-Host\", host)\n\t}\n\n\treturn nil\n}\n\n// reverseProxy performs a round-trip to the given backend and processes the response with the client.\n// (This method is mostly the beginning of what was borrowed from the net/http/httputil package in the\n// Go standard library which was used as the foundation.)\nfunc (h *Handler) reverseProxy(rw http.ResponseWriter, req *http.Request, origReq *http.Request, repl *caddy.Replacer, di DialInfo, next caddyhttp.Handler) error {\n\t_ = di.Upstream.Host.countRequest(1)\n\t//nolint:errcheck\n\tdefer di.Upstream.Host.countRequest(-1)\n\n\t// point the request to this upstream\n\th.directRequest(req, di)\n\n\tserver := req.Context().Value(caddyhttp.ServerCtxKey).(*caddyhttp.Server)\n\tshouldLogCredentials := server.Logs != nil && server.Logs.ShouldLogCredentials\n\n\t// Forward 1xx status codes, backported from https://github.com/golang/go/pull/53164\n\tvar (\n\t\troundTripMutex sync.Mutex\n\t\troundTripDone  bool\n\t)\n\ttrace := &httptrace.ClientTrace{\n\t\tGot1xxResponse: func(code int, header textproto.MIMEHeader) error {\n\t\t\troundTripMutex.Lock()\n\t\t\tdefer roundTripMutex.Unlock()\n\t\t\tif roundTripDone {\n\t\t\t\t// If RoundTrip has returned, don't try to further modify\n\t\t\t\t// the ResponseWriter's header map.\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th := rw.Header()\n\t\t\tcopyHeader(h, http.Header(header))\n\t\t\trw.WriteHeader(code)\n\n\t\t\t// Clear headers coming from the backend\n\t\t\t// (it's not automatically done by ResponseWriter.WriteHeader() for 1xx responses)\n\t\t\tclear(h)\n\n\t\t\treturn nil\n\t\t},\n\t}\n\treq = req.WithContext(httptrace.WithClientTrace(req.Context(), trace))\n\n\t// do the round-trip\n\tstart := time.Now()\n\tres, err := h.Transport.RoundTrip(req)\n\tduration := time.Since(start)\n\n\t// record that the round trip is done for the 1xx response handler\n\troundTripMutex.Lock()\n\troundTripDone = true\n\troundTripMutex.Unlock()\n\n\t// emit debug log with values we know are safe,\n\t// or if there is no error, emit fuller log entry\n\tlogger := h.logger.With(\n\t\tzap.String(\"upstream\", di.Upstream.String()),\n\t\tzap.Duration(\"duration\", duration),\n\t\tzap.Object(\"request\", caddyhttp.LoggableHTTPRequest{\n\t\t\tRequest:              req,\n\t\t\tShouldLogCredentials: shouldLogCredentials,\n\t\t}),\n\t)\n\n\tconst logMessage = \"upstream roundtrip\"\n\n\tif err != nil {\n\t\tif c := logger.Check(zapcore.DebugLevel, logMessage); c != nil {\n\t\t\tc.Write(zap.Error(err))\n\t\t}\n\t\treturn err\n\t}\n\tif c := logger.Check(zapcore.DebugLevel, logMessage); c != nil {\n\t\tc.Write(\n\t\t\tzap.Object(\"headers\", caddyhttp.LoggableHTTPHeader{\n\t\t\t\tHeader:               res.Header,\n\t\t\t\tShouldLogCredentials: shouldLogCredentials,\n\t\t\t}),\n\t\t\tzap.Int(\"status\", res.StatusCode),\n\t\t)\n\t}\n\n\t// duration until upstream wrote response headers (roundtrip duration)\n\trepl.Set(\"http.reverse_proxy.upstream.latency\", duration)\n\trepl.Set(\"http.reverse_proxy.upstream.latency_ms\", duration.Seconds()*1e3) // multiply seconds to preserve decimal (see #4666)\n\n\t// update circuit breaker on current conditions\n\tif di.Upstream.cb != nil {\n\t\tdi.Upstream.cb.RecordMetric(res.StatusCode, duration)\n\t}\n\n\t// perform passive health checks (if enabled)\n\tif h.HealthChecks != nil && h.HealthChecks.Passive != nil {\n\t\t// strike if the status code matches one that is \"bad\"\n\t\tfor _, badStatus := range h.HealthChecks.Passive.UnhealthyStatus {\n\t\t\tif caddyhttp.StatusCodeMatches(res.StatusCode, badStatus) {\n\t\t\t\th.countFailure(di.Upstream)\n\t\t\t}\n\t\t}\n\n\t\t// strike if the roundtrip took too long\n\t\tif h.HealthChecks.Passive.UnhealthyLatency > 0 &&\n\t\t\tduration >= time.Duration(h.HealthChecks.Passive.UnhealthyLatency) {\n\t\t\th.countFailure(di.Upstream)\n\t\t}\n\t}\n\n\t// if enabled, buffer the response body\n\tif h.ResponseBuffers != 0 {\n\t\tres.Body, _ = h.bufferedBody(res.Body, h.ResponseBuffers)\n\t}\n\n\t// see if any response handler is configured for this response from the backend\n\tfor i, rh := range h.HandleResponse {\n\t\tif rh.Match != nil && !rh.Match.Match(res.StatusCode, res.Header) {\n\t\t\tcontinue\n\t\t}\n\n\t\t// if configured to only change the status code,\n\t\t// do that then continue regular proxy response\n\t\tif statusCodeStr := rh.StatusCode.String(); statusCodeStr != \"\" {\n\t\t\tstatusCode, err := strconv.Atoi(repl.ReplaceAll(statusCodeStr, \"\"))\n\t\t\tif err != nil {\n\t\t\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t\t\t}\n\t\t\tif statusCode != 0 {\n\t\t\t\tres.StatusCode = statusCode\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\n\t\t// set up the replacer so that parts of the original response can be\n\t\t// used for routing decisions\n\t\tfor field, value := range res.Header {\n\t\t\trepl.Set(\"http.reverse_proxy.header.\"+field, strings.Join(value, \",\"))\n\t\t}\n\t\trepl.Set(\"http.reverse_proxy.status_code\", res.StatusCode)\n\t\trepl.Set(\"http.reverse_proxy.status_text\", res.Status)\n\n\t\tif c := logger.Check(zapcore.DebugLevel, \"handling response\"); c != nil {\n\t\t\tc.Write(zap.Int(\"handler\", i))\n\t\t}\n\n\t\t// we make some data available via request context to child routes\n\t\t// so that they may inherit some options and functions from the\n\t\t// handler, and be able to copy the response.\n\t\t// we use the original request here, so that any routes from 'next'\n\t\t// see the original request rather than the proxy cloned request.\n\t\thrc := &handleResponseContext{\n\t\t\thandler:  h,\n\t\t\tresponse: res,\n\t\t\tstart:    start,\n\t\t\tlogger:   logger,\n\t\t}\n\t\tctx := origReq.Context()\n\t\tctx = context.WithValue(ctx, proxyHandleResponseContextCtxKey, hrc)\n\n\t\t// pass the request through the response handler routes\n\t\trouteErr := rh.Routes.Compile(next).ServeHTTP(rw, origReq.WithContext(ctx))\n\n\t\t// close the response body afterwards, since we don't need it anymore;\n\t\t// either a route had 'copy_response' which already consumed the body,\n\t\t// or some other terminal handler ran which doesn't need the response\n\t\t// body after that point (e.g. 'file_server' for X-Accel-Redirect flow),\n\t\t// or we fell through to subsequent handlers past this proxy\n\t\t// (e.g. forward auth's 2xx response flow).\n\t\tif !hrc.isFinalized {\n\t\t\tres.Body.Close()\n\t\t}\n\n\t\t// wrap any route error in roundtripSucceededError so caller knows that\n\t\t// the roundtrip was successful and to not retry\n\t\tif routeErr != nil {\n\t\t\treturn roundtripSucceededError{routeErr}\n\t\t}\n\n\t\t// we're done handling the response, and we don't want to\n\t\t// fall through to the default finalize/copy behaviour\n\t\treturn nil\n\t}\n\n\t// copy the response body and headers back to the upstream client\n\treturn h.finalizeResponse(rw, req, res, repl, start, logger)\n}\n\n// finalizeResponse prepares and copies the response.\nfunc (h *Handler) finalizeResponse(\n\trw http.ResponseWriter,\n\treq *http.Request,\n\tres *http.Response,\n\trepl *caddy.Replacer,\n\tstart time.Time,\n\tlogger *zap.Logger,\n) error {\n\t// deal with 101 Switching Protocols responses: (WebSocket, h2c, etc)\n\tif res.StatusCode == http.StatusSwitchingProtocols {\n\t\tvar wg sync.WaitGroup\n\t\th.handleUpgradeResponse(logger, &wg, rw, req, res)\n\t\twg.Wait()\n\t\treturn nil\n\t}\n\n\tremoveConnectionHeaders(res.Header)\n\n\tfor _, h := range hopHeaders {\n\t\tres.Header.Del(h)\n\t}\n\n\t// delete our Server header and use Via instead (see #6275)\n\trw.Header().Del(\"Server\")\n\tvar protoPrefix string\n\tif !strings.HasPrefix(strings.ToUpper(res.Proto), \"HTTP/\") {\n\t\tprotoPrefix = res.Proto[:strings.Index(res.Proto, \"/\")+1]\n\t}\n\trw.Header().Add(\"Via\", fmt.Sprintf(\"%s%d.%d Caddy\", protoPrefix, res.ProtoMajor, res.ProtoMinor))\n\n\t// apply any response header operations\n\tif h.Headers != nil && h.Headers.Response != nil {\n\t\tif h.Headers.Response.Require == nil ||\n\t\t\th.Headers.Response.Require.Match(res.StatusCode, res.Header) {\n\t\t\th.Headers.Response.ApplyTo(res.Header, repl)\n\t\t}\n\t}\n\n\tcopyHeader(rw.Header(), res.Header)\n\n\t// The \"Trailer\" header isn't included in the Transport's response,\n\t// at least for *http.Transport. Build it up from Trailer.\n\tannouncedTrailers := len(res.Trailer)\n\tif announcedTrailers > 0 {\n\t\ttrailerKeys := make([]string, 0, len(res.Trailer))\n\t\tfor k := range res.Trailer {\n\t\t\ttrailerKeys = append(trailerKeys, k)\n\t\t}\n\t\trw.Header().Add(\"Trailer\", strings.Join(trailerKeys, \", \"))\n\t}\n\n\trw.WriteHeader(res.StatusCode)\n\tif h.VerboseLogs {\n\t\tlogger.Debug(\"wrote header\")\n\t}\n\n\terr := h.copyResponse(rw, res.Body, h.flushInterval(req, res), logger)\n\terrClose := res.Body.Close() // close now, instead of defer, to populate res.Trailer\n\tif h.VerboseLogs || errClose != nil {\n\t\tif c := logger.Check(zapcore.DebugLevel, \"closed response body from upstream\"); c != nil {\n\t\t\tc.Write(zap.Error(errClose))\n\t\t}\n\t}\n\tif err != nil {\n\t\t// we're streaming the response and we've already written headers, so\n\t\t// there's nothing an error handler can do to recover at this point;\n\t\t// we'll just log the error and abort the stream here and panic just as\n\t\t// the standard lib's proxy to propagate the stream error.\n\t\t// see issue https://github.com/caddyserver/caddy/issues/5951\n\t\tif c := logger.Check(zapcore.WarnLevel, \"aborting with incomplete response\"); c != nil {\n\t\t\tc.Write(zap.Error(err))\n\t\t}\n\t\t// no extra logging from stdlib\n\t\tpanic(http.ErrAbortHandler)\n\t}\n\n\tif len(res.Trailer) > 0 {\n\t\t// Force chunking if we saw a response trailer.\n\t\t// This prevents net/http from calculating the length for short\n\t\t// bodies and adding a Content-Length.\n\t\t//nolint:bodyclose\n\t\thttp.NewResponseController(rw).Flush()\n\t}\n\n\t// total duration spent proxying, including writing response body\n\trepl.Set(\"http.reverse_proxy.upstream.duration\", time.Since(start))\n\trepl.Set(\"http.reverse_proxy.upstream.duration_ms\", time.Since(start).Seconds()*1e3)\n\n\tif len(res.Trailer) == announcedTrailers {\n\t\tcopyHeader(rw.Header(), res.Trailer)\n\t\treturn nil\n\t}\n\n\tfor k, vv := range res.Trailer {\n\t\tk = http.TrailerPrefix + k\n\t\tfor _, v := range vv {\n\t\t\trw.Header().Add(k, v)\n\t\t}\n\t}\n\n\tif h.VerboseLogs {\n\t\tlogger.Debug(\"response finalized\")\n\t}\n\n\treturn nil\n}\n\n// tryAgain takes the time that the handler was initially invoked,\n// the amount of retries already performed, as well as any error\n// currently obtained, and the request being tried, and returns\n// true if another attempt should be made at proxying the request.\n// If true is returned, it has already blocked long enough before\n// the next retry (i.e. no more sleeping is needed). If false is\n// returned, the handler should stop trying to proxy the request.\nfunc (lb LoadBalancing) tryAgain(ctx caddy.Context, start time.Time, retries int, proxyErr error, req *http.Request, logger *zap.Logger) bool {\n\t// no retries are configured\n\tif lb.TryDuration == 0 && lb.Retries == 0 {\n\t\treturn false\n\t}\n\n\t// if we've tried long enough, break\n\tif lb.TryDuration > 0 && time.Since(start) >= time.Duration(lb.TryDuration) {\n\t\treturn false\n\t}\n\n\t// if we've reached the retry limit, break\n\tif lb.Retries > 0 && retries >= lb.Retries {\n\t\treturn false\n\t}\n\n\t// if the error occurred while dialing (i.e. a connection\n\t// could not even be established to the upstream), then it\n\t// should be safe to retry, since without a connection, no\n\t// HTTP request can be transmitted; but if the error is not\n\t// specifically a dialer error, we need to be careful\n\tif proxyErr != nil {\n\t\t_, isDialError := proxyErr.(DialError)\n\t\therr, isHandlerError := proxyErr.(caddyhttp.HandlerError)\n\n\t\t// if the error occurred after a connection was established,\n\t\t// we have to assume the upstream received the request, and\n\t\t// retries need to be carefully decided, because some requests\n\t\t// are not idempotent\n\t\tif !isDialError && (!isHandlerError || !errors.Is(herr, errNoUpstream)) {\n\t\t\tif lb.RetryMatch == nil && req.Method != \"GET\" {\n\t\t\t\t// by default, don't retry requests if they aren't GET\n\t\t\t\treturn false\n\t\t\t}\n\n\t\t\tmatch, err := lb.RetryMatch.AnyMatchWithError(req)\n\t\t\tif err != nil {\n\t\t\t\tlogger.Error(\"error matching request for retry\", zap.Error(err))\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif !match {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\n\t// fast path; if the interval is zero, we don't need to wait\n\tif lb.TryInterval == 0 {\n\t\treturn true\n\t}\n\n\t// otherwise, wait and try the next available host\n\ttimer := time.NewTimer(time.Duration(lb.TryInterval))\n\tselect {\n\tcase <-timer.C:\n\t\treturn true\n\tcase <-ctx.Done():\n\t\tif !timer.Stop() {\n\t\t\t// if the timer has been stopped then read from the channel\n\t\t\t<-timer.C\n\t\t}\n\t\treturn false\n\t}\n}\n\n// directRequest modifies only req.URL so that it points to the upstream\n// in the given DialInfo. It must modify ONLY the request URL.\nfunc (Handler) directRequest(req *http.Request, di DialInfo) {\n\t// we need a host, so set the upstream's host address\n\treqHost := di.Address\n\n\t// if the port equates to the scheme, strip the port because\n\t// it's weird to make a request like http://example.com:80/.\n\tif (req.URL.Scheme == \"http\" && di.Port == \"80\") ||\n\t\t(req.URL.Scheme == \"https\" && di.Port == \"443\") {\n\t\treqHost = di.Host\n\t}\n\n\treq.URL.Host = reqHost\n}\n\nfunc (h Handler) provisionUpstream(upstream *Upstream) {\n\t// create or get the host representation for this upstream\n\tupstream.fillHost()\n\n\t// give it the circuit breaker, if any\n\tupstream.cb = h.CB\n\n\t// if the passive health checker has a non-zero UnhealthyRequestCount\n\t// but the upstream has no MaxRequests set (they are the same thing,\n\t// but the passive health checker is a default value for upstreams\n\t// without MaxRequests), copy the value into this upstream, since the\n\t// value in the upstream (MaxRequests) is what is used during\n\t// availability checks\n\tif h.HealthChecks != nil &&\n\t\th.HealthChecks.Passive != nil &&\n\t\th.HealthChecks.Passive.UnhealthyRequestCount > 0 &&\n\t\tupstream.MaxRequests == 0 {\n\t\tupstream.MaxRequests = h.HealthChecks.Passive.UnhealthyRequestCount\n\t}\n\n\t// upstreams need independent access to the passive\n\t// health check policy because passive health checks\n\t// run without access to h.\n\tif h.HealthChecks != nil {\n\t\tupstream.healthCheckPolicy = h.HealthChecks.Passive\n\t}\n}\n\n// bufferedBody reads originalBody into a buffer with maximum size of limit (-1 for unlimited),\n// then returns a reader for the buffer along with how many bytes were buffered. Always close\n// the return value when done with it, just like if it was the original body! If limit is 0\n// (which it shouldn't be), this function returns its input; i.e. is a no-op, for safety.\n// Otherwise, it returns bodyReadCloser, the original body will be closed and body will be nil\n// if it's explicitly configured to buffer all or EOF is reached when reading.\n// TODO: the error during reading is discarded if the limit is negative, should the error be propagated\n// to upstream/downstream?\nfunc (h Handler) bufferedBody(originalBody io.ReadCloser, limit int64) (io.ReadCloser, int64) {\n\tif limit == 0 {\n\t\treturn originalBody, 0\n\t}\n\tvar written int64\n\tbuf := bufPool.Get().(*bytes.Buffer)\n\tbuf.Reset()\n\tif limit > 0 {\n\t\tvar err error\n\t\twritten, err = io.CopyN(buf, originalBody, limit)\n\t\tif (err != nil && err != io.EOF) || written == limit {\n\t\t\treturn bodyReadCloser{\n\t\t\t\tReader: io.MultiReader(buf, originalBody),\n\t\t\t\tbuf:    buf,\n\t\t\t\tbody:   originalBody,\n\t\t\t}, written\n\t\t}\n\t} else {\n\t\twritten, _ = io.Copy(buf, originalBody)\n\t}\n\toriginalBody.Close() // no point in keeping it open\n\treturn bodyReadCloser{\n\t\tReader: buf,\n\t\tbuf:    buf,\n\t}, written\n}\n\n// cloneRequest makes a semi-deep clone of origReq.\n//\n// Most of this code is borrowed from the Go stdlib reverse proxy,\n// but we make a shallow-ish clone the request (deep clone only\n// the headers and URL) so we can avoid manipulating the original\n// request when using it to proxy upstream. This prevents request\n// corruption and data races.\nfunc cloneRequest(origReq *http.Request) *http.Request {\n\treq := new(http.Request)\n\t*req = *origReq\n\tif origReq.URL != nil {\n\t\tnewURL := new(url.URL)\n\t\t*newURL = *origReq.URL\n\t\tif origReq.URL.User != nil {\n\t\t\tnewURL.User = new(url.Userinfo)\n\t\t\t*newURL.User = *origReq.URL.User\n\t\t}\n\t\t// sanitize the request URL; we expect it to not contain the\n\t\t// scheme and host since those should be determined by r.TLS\n\t\t// and r.Host respectively, but some clients may include it\n\t\t// in the request-line, which is technically valid in HTTP,\n\t\t// but breaks reverseproxy behaviour, overriding how the\n\t\t// dialer will behave. See #4237 for context.\n\t\tnewURL.Scheme = \"\"\n\t\tnewURL.Host = \"\"\n\t\treq.URL = newURL\n\t}\n\tif origReq.Header != nil {\n\t\treq.Header = origReq.Header.Clone()\n\t}\n\tif origReq.Trailer != nil {\n\t\treq.Trailer = origReq.Trailer.Clone()\n\t}\n\treturn req\n}\n\nfunc copyHeader(dst, src http.Header) {\n\tfor k, vv := range src {\n\t\tfor _, v := range vv {\n\t\t\tdst.Add(k, v)\n\t\t}\n\t}\n}\n\n// allHeaderValues gets all values for a given header field,\n// joined by a comma and space if more than one is set. If the\n// header field is nil, then the omit is true, meaning some\n// earlier logic in the server wanted to prevent this header from\n// getting written at all. If the header is empty, then ok is\n// false. Callers should still check that the value is not empty\n// (the header field may be set but have an empty value).\nfunc allHeaderValues(h http.Header, field string) (value string, ok bool, omit bool) {\n\tvalues, ok := h[http.CanonicalHeaderKey(field)]\n\tif ok && values == nil {\n\t\treturn \"\", true, true\n\t}\n\tif len(values) == 0 {\n\t\treturn \"\", false, false\n\t}\n\treturn strings.Join(values, \", \"), true, false\n}\n\n// lastHeaderValue gets the last value for a given header field\n// if more than one is set. If the header field is nil, then\n// the omit is true, meaning some earlier logic in the server\n// wanted to prevent this header from getting written at all.\n// If the header is empty, then ok is false. Callers should\n// still check that the value is not empty (the header field\n// may be set but have an empty value).\nfunc lastHeaderValue(h http.Header, field string) (value string, ok bool, omit bool) {\n\tvalues, ok := h[http.CanonicalHeaderKey(field)]\n\tif ok && values == nil {\n\t\treturn \"\", true, true\n\t}\n\tif len(values) == 0 {\n\t\treturn \"\", false, false\n\t}\n\treturn values[len(values)-1], true, false\n}\n\nfunc upgradeType(h http.Header) string {\n\tif !httpguts.HeaderValuesContainsToken(h[\"Connection\"], \"Upgrade\") {\n\t\treturn \"\"\n\t}\n\treturn strings.ToLower(h.Get(\"Upgrade\"))\n}\n\n// removeConnectionHeaders removes hop-by-hop headers listed in the \"Connection\" header of h.\n// See RFC 7230, section 6.1\nfunc removeConnectionHeaders(h http.Header) {\n\tfor _, f := range h[\"Connection\"] {\n\t\tfor _, sf := range strings.Split(f, \",\") {\n\t\t\tif sf = textproto.TrimString(sf); sf != \"\" {\n\t\t\t\th.Del(sf)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// statusError returns an error value that has a status code.\nfunc statusError(err error) error {\n\t// errors proxying usually mean there is a problem with the upstream(s)\n\tstatusCode := http.StatusBadGateway\n\n\t// timeout errors have a standard status code (see issue #4823)\n\tif err, ok := err.(net.Error); ok && err.Timeout() {\n\t\tstatusCode = http.StatusGatewayTimeout\n\t}\n\n\t// if the client canceled the request (usually this means they closed\n\t// the connection, so they won't see any response), we can report it\n\t// as a client error (4xx) and not a server error (5xx); unfortunately\n\t// the Go standard library, at least at time of writing in late 2020,\n\t// obnoxiously wraps the exported, standard context.Canceled error with\n\t// an unexported garbage value that we have to do a substring check for:\n\t// https://github.com/golang/go/blob/6965b01ea248cabb70c3749fd218b36089a21efb/src/net/net.go#L416-L430\n\tif errors.Is(err, context.Canceled) || strings.Contains(err.Error(), \"operation was canceled\") {\n\t\t// regrettably, there is no standard error code for \"client closed connection\", but\n\t\t// for historical reasons we can use a code that a lot of people are already using;\n\t\t// using 5xx is problematic for users; see #3748\n\t\tstatusCode = 499\n\t}\n\treturn caddyhttp.Error(statusCode, err)\n}\n\n// LoadBalancing has parameters related to load balancing.\ntype LoadBalancing struct {\n\t// A selection policy is how to choose an available backend.\n\t// The default policy is random selection.\n\tSelectionPolicyRaw json.RawMessage `json:\"selection_policy,omitempty\" caddy:\"namespace=http.reverse_proxy.selection_policies inline_key=policy\"`\n\n\t// How many times to retry selecting available backends for each\n\t// request if the next available host is down. If try_duration is\n\t// also configured, then retries may stop early if the duration\n\t// is reached. By default, retries are disabled (zero).\n\tRetries int `json:\"retries,omitempty\"`\n\n\t// How long to try selecting available backends for each request\n\t// if the next available host is down. Clients will wait for up\n\t// to this long while the load balancer tries to find an available\n\t// upstream host. If retries is also configured, tries may stop\n\t// early if the maximum retries is reached. By default, retries\n\t// are disabled (zero duration).\n\tTryDuration caddy.Duration `json:\"try_duration,omitempty\"`\n\n\t// How long to wait between selecting the next host from the pool.\n\t// Default is 250ms if try_duration is enabled, otherwise zero. Only\n\t// relevant when a request to an upstream host fails. Be aware that\n\t// setting this to 0 with a non-zero try_duration can cause the CPU\n\t// to spin if all backends are down and latency is very low.\n\tTryInterval caddy.Duration `json:\"try_interval,omitempty\"`\n\n\t// A list of matcher sets that restricts with which requests retries are\n\t// allowed. A request must match any of the given matcher sets in order\n\t// to be retried if the connection to the upstream succeeded but the\n\t// subsequent round-trip failed. If the connection to the upstream failed,\n\t// a retry is always allowed. If unspecified, only GET requests will be\n\t// allowed to be retried. Note that a retry is done with the next available\n\t// host according to the load balancing policy.\n\tRetryMatchRaw caddyhttp.RawMatcherSets `json:\"retry_match,omitempty\" caddy:\"namespace=http.matchers\"`\n\n\tSelectionPolicy Selector              `json:\"-\"`\n\tRetryMatch      caddyhttp.MatcherSets `json:\"-\"`\n}\n\n// Selector selects an available upstream from the pool.\ntype Selector interface {\n\tSelect(UpstreamPool, *http.Request, http.ResponseWriter) *Upstream\n}\n\n// UpstreamSource gets the list of upstreams that can be used when\n// proxying a request. Returned upstreams will be load balanced and\n// health-checked. This should be a very fast function -- instant\n// if possible -- and the return value must be as stable as possible.\n// In other words, the list of upstreams should ideally not change much\n// across successive calls. If the list of upstreams changes or the\n// ordering is not stable, load balancing will suffer. This function\n// may be called during each retry, multiple times per request, and as\n// such, needs to be instantaneous. The returned slice will not be\n// modified.\ntype UpstreamSource interface {\n\tGetUpstreams(*http.Request) ([]*Upstream, error)\n}\n\n// Hop-by-hop headers. These are removed when sent to the backend.\n// As of RFC 7230, hop-by-hop headers are required to appear in the\n// Connection header field. These are the headers defined by the\n// obsoleted RFC 2616 (section 13.5.1) and are used for backward\n// compatibility.\nvar hopHeaders = []string{\n\t\"Alt-Svc\",\n\t\"Connection\",\n\t\"Proxy-Connection\", // non-standard but still sent by libcurl and rejected by e.g. google\n\t\"Keep-Alive\",\n\t\"Proxy-Authenticate\",\n\t\"Proxy-Authorization\",\n\t\"Te\",      // canonicalized version of \"TE\"\n\t\"Trailer\", // not Trailers per URL above; https://www.rfc-editor.org/errata_search.php?eid=4522\n\t\"Transfer-Encoding\",\n\t\"Upgrade\",\n}\n\n// DialError is an error that specifically occurs\n// in a call to Dial or DialContext.\ntype DialError struct{ error }\n\n// TLSTransport is implemented by transports\n// that are capable of using TLS.\ntype TLSTransport interface {\n\t// TLSEnabled returns true if the transport\n\t// has TLS enabled, false otherwise.\n\tTLSEnabled() bool\n\n\t// EnableTLS enables TLS within the transport\n\t// if it is not already, using the provided\n\t// value as a basis for the TLS config.\n\tEnableTLS(base *TLSConfig) error\n}\n\n// roundtripSucceededError is an error type that is returned if the\n// roundtrip succeeded, but an error occurred after-the-fact.\ntype roundtripSucceededError struct{ error }\n\n// bodyReadCloser is a reader that, upon closing, will return\n// its buffer to the pool and close the underlying body reader.\ntype bodyReadCloser struct {\n\tio.Reader\n\tbuf  *bytes.Buffer\n\tbody io.ReadCloser\n}\n\nfunc (brc bodyReadCloser) Close() error {\n\tbufPool.Put(brc.buf)\n\tif brc.body != nil {\n\t\treturn brc.body.Close()\n\t}\n\treturn nil\n}\n\n// bufPool is used for buffering requests and responses.\nvar bufPool = sync.Pool{\n\tNew: func() any {\n\t\treturn new(bytes.Buffer)\n\t},\n}\n\n// handleResponseContext carries some contextual information about the\n// current proxy handling.\ntype handleResponseContext struct {\n\t// handler is the active proxy handler instance, so that\n\t// routes like copy_response may inherit some config\n\t// options and have access to handler methods.\n\thandler *Handler\n\n\t// response is the actual response received from the proxy\n\t// roundtrip, to potentially be copied if a copy_response\n\t// handler is in the handle_response routes.\n\tresponse *http.Response\n\n\t// start is the time just before the proxy roundtrip was\n\t// performed, used for logging.\n\tstart time.Time\n\n\t// logger is the prepared logger which is used to write logs\n\t// with the request, duration, and selected upstream attached.\n\tlogger *zap.Logger\n\n\t// isFinalized is whether the response has been finalized,\n\t// i.e. copied and closed, to make sure that it doesn't\n\t// happen twice.\n\tisFinalized bool\n}\n\n// proxyHandleResponseContextCtxKey is the context key for the active proxy handler\n// so that handle_response routes can inherit some config options\n// from the proxy handler.\nconst proxyHandleResponseContextCtxKey caddy.CtxKey = \"reverse_proxy_handle_response_context\"\n\n// errNoUpstream occurs when there are no upstream available.\nvar errNoUpstream = fmt.Errorf(\"no upstreams available\")\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*Handler)(nil)\n\t_ caddy.CleanerUpper          = (*Handler)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*Handler)(nil)\n)\n",
    "source_file": "modules/caddyhttp/reverseproxy/reverseproxy.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Most of the code in this file was initially borrowed from the Go\n// standard library and modified; It had this copyright notice:\n// Copyright 2011 The Go Authors\n\npackage reverseproxy\n\nimport (\n\t\"bufio\"\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\tweakrand \"math/rand\"\n\t\"mime\"\n\t\"net/http\"\n\t\"sync\"\n\t\"time\"\n\t\"unsafe\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\t\"golang.org/x/net/http/httpguts\"\n\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\ntype h2ReadWriteCloser struct {\n\tio.ReadCloser\n\thttp.ResponseWriter\n}\n\nfunc (rwc h2ReadWriteCloser) Write(p []byte) (n int, err error) {\n\tn, err = rwc.ResponseWriter.Write(p)\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\n\t//nolint:bodyclose\n\terr = http.NewResponseController(rwc.ResponseWriter).Flush()\n\tif err != nil {\n\t\treturn 0, err\n\t}\n\treturn n, nil\n}\n\nfunc (h *Handler) handleUpgradeResponse(logger *zap.Logger, wg *sync.WaitGroup, rw http.ResponseWriter, req *http.Request, res *http.Response) {\n\treqUpType := upgradeType(req.Header)\n\tresUpType := upgradeType(res.Header)\n\n\t// Taken from https://github.com/golang/go/commit/5c489514bc5e61ad9b5b07bd7d8ec65d66a0512a\n\t// We know reqUpType is ASCII, it's checked by the caller.\n\tif !asciiIsPrint(resUpType) {\n\t\tif c := logger.Check(zapcore.DebugLevel, \"backend tried to switch to invalid protocol\"); c != nil {\n\t\t\tc.Write(zap.String(\"backend_upgrade\", resUpType))\n\t\t}\n\t\treturn\n\t}\n\tif !asciiEqualFold(reqUpType, resUpType) {\n\t\tif c := logger.Check(zapcore.DebugLevel, \"backend tried to switch to unexpected protocol via Upgrade header\"); c != nil {\n\t\t\tc.Write(\n\t\t\t\tzap.String(\"backend_upgrade\", resUpType),\n\t\t\t\tzap.String(\"requested_upgrade\", reqUpType),\n\t\t\t)\n\t\t}\n\t\treturn\n\t}\n\n\tbackConn, ok := res.Body.(io.ReadWriteCloser)\n\tif !ok {\n\t\tlogger.Error(\"internal error: 101 switching protocols response with non-writable body\")\n\t\treturn\n\t}\n\n\t// write header first, response headers should not be counted in size\n\t// like the rest of handler chain.\n\tcopyHeader(rw.Header(), res.Header)\n\tnormalizeWebsocketHeaders(rw.Header())\n\n\tvar (\n\t\tconn io.ReadWriteCloser\n\t\tbrw  *bufio.ReadWriter\n\t)\n\t// websocket over http2, assuming backend doesn't support this, the request will be modified to http1.1 upgrade\n\t// TODO: once we can reliably detect backend support this, it can be removed for those backends\n\tif body, ok := caddyhttp.GetVar(req.Context(), \"h2_websocket_body\").(io.ReadCloser); ok {\n\t\treq.Body = body\n\t\trw.Header().Del(\"Upgrade\")\n\t\trw.Header().Del(\"Connection\")\n\t\tdelete(rw.Header(), \"Sec-WebSocket-Accept\")\n\t\trw.WriteHeader(http.StatusOK)\n\n\t\tif c := logger.Check(zap.DebugLevel, \"upgrading connection\"); c != nil {\n\t\t\tc.Write(zap.Int(\"http_version\", 2))\n\t\t}\n\n\t\t//nolint:bodyclose\n\t\tflushErr := http.NewResponseController(rw).Flush()\n\t\tif flushErr != nil {\n\t\t\tif c := h.logger.Check(zap.ErrorLevel, \"failed to flush http2 websocket response\"); c != nil {\n\t\t\t\tc.Write(zap.Error(flushErr))\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t\tconn = h2ReadWriteCloser{req.Body, rw}\n\t\t// bufio is not needed, use minimal buffer\n\t\tbrw = bufio.NewReadWriter(bufio.NewReaderSize(conn, 1), bufio.NewWriterSize(conn, 1))\n\t} else {\n\t\trw.WriteHeader(res.StatusCode)\n\n\t\tif c := logger.Check(zap.DebugLevel, \"upgrading connection\"); c != nil {\n\t\t\tc.Write(zap.Int(\"http_version\", req.ProtoMajor))\n\t\t}\n\n\t\tvar hijackErr error\n\t\t//nolint:bodyclose\n\t\tconn, brw, hijackErr = http.NewResponseController(rw).Hijack()\n\t\tif errors.Is(hijackErr, http.ErrNotSupported) {\n\t\t\tif c := h.logger.Check(zap.ErrorLevel, \"can't switch protocols using non-Hijacker ResponseWriter\"); c != nil {\n\t\t\t\tc.Write(zap.String(\"type\", fmt.Sprintf(\"%T\", rw)))\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\tif hijackErr != nil {\n\t\t\tif c := h.logger.Check(zap.ErrorLevel, \"hijack failed on protocol switch\"); c != nil {\n\t\t\t\tc.Write(zap.Error(hijackErr))\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t}\n\n\t// adopted from https://github.com/golang/go/commit/8bcf2834afdf6a1f7937390903a41518715ef6f5\n\tbackConnCloseCh := make(chan struct{})\n\tgo func() {\n\t\t// Ensure that the cancelation of a request closes the backend.\n\t\t// See issue https://golang.org/issue/35559.\n\t\tselect {\n\t\tcase <-req.Context().Done():\n\t\tcase <-backConnCloseCh:\n\t\t}\n\t\tbackConn.Close()\n\t}()\n\tdefer close(backConnCloseCh)\n\n\tstart := time.Now()\n\tdefer func() {\n\t\tconn.Close()\n\t\tif c := logger.Check(zapcore.DebugLevel, \"connection closed\"); c != nil {\n\t\t\tc.Write(zap.Duration(\"duration\", time.Since(start)))\n\t\t}\n\t}()\n\n\tif err := brw.Flush(); err != nil {\n\t\tif c := logger.Check(zapcore.DebugLevel, \"response flush\"); c != nil {\n\t\t\tc.Write(zap.Error(err))\n\t\t}\n\t\treturn\n\t}\n\n\t// There may be buffered data in the *bufio.Reader\n\t// see: https://github.com/caddyserver/caddy/issues/6273\n\tif buffered := brw.Reader.Buffered(); buffered > 0 {\n\t\tdata, _ := brw.Peek(buffered)\n\t\t_, err := backConn.Write(data)\n\t\tif err != nil {\n\t\t\tif c := logger.Check(zapcore.DebugLevel, \"backConn write failed\"); c != nil {\n\t\t\t\tc.Write(zap.Error(err))\n\t\t\t}\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Ensure the hijacked client connection, and the new connection established\n\t// with the backend, are both closed in the event of a server shutdown. This\n\t// is done by registering them. We also try to gracefully close connections\n\t// we recognize as websockets.\n\t// We need to make sure the client connection messages (i.e. to upstream)\n\t// are masked, so we need to know whether the connection is considered the\n\t// server or the client side of the proxy.\n\tgracefulClose := func(conn io.ReadWriteCloser, isClient bool) func() error {\n\t\tif isWebsocket(req) {\n\t\t\treturn func() error {\n\t\t\t\treturn writeCloseControl(conn, isClient)\n\t\t\t}\n\t\t}\n\t\treturn nil\n\t}\n\tdeleteFrontConn := h.registerConnection(conn, gracefulClose(conn, false))\n\tdeleteBackConn := h.registerConnection(backConn, gracefulClose(backConn, true))\n\tdefer deleteFrontConn()\n\tdefer deleteBackConn()\n\n\tspc := switchProtocolCopier{user: conn, backend: backConn, wg: wg}\n\n\t// setup the timeout if requested\n\tvar timeoutc <-chan time.Time\n\tif h.StreamTimeout > 0 {\n\t\ttimer := time.NewTimer(time.Duration(h.StreamTimeout))\n\t\tdefer timer.Stop()\n\t\ttimeoutc = timer.C\n\t}\n\n\terrc := make(chan error, 1)\n\twg.Add(2)\n\tgo spc.copyToBackend(errc)\n\tgo spc.copyFromBackend(errc)\n\tselect {\n\tcase err := <-errc:\n\t\tif c := logger.Check(zapcore.DebugLevel, \"streaming error\"); c != nil {\n\t\t\tc.Write(zap.Error(err))\n\t\t}\n\tcase time := <-timeoutc:\n\t\tif c := logger.Check(zapcore.DebugLevel, \"stream timed out\"); c != nil {\n\t\t\tc.Write(zap.Time(\"timeout\", time))\n\t\t}\n\t}\n}\n\n// flushInterval returns the p.FlushInterval value, conditionally\n// overriding its value for a specific request/response.\nfunc (h Handler) flushInterval(req *http.Request, res *http.Response) time.Duration {\n\tresCTHeader := res.Header.Get(\"Content-Type\")\n\tresCT, _, err := mime.ParseMediaType(resCTHeader)\n\n\t// For Server-Sent Events responses, flush immediately.\n\t// The MIME type is defined in https://www.w3.org/TR/eventsource/#text-event-stream\n\tif err == nil && resCT == \"text/event-stream\" {\n\t\treturn -1 // negative means immediately\n\t}\n\n\t// We might have the case of streaming for which Content-Length might be unset.\n\tif res.ContentLength == -1 {\n\t\treturn -1\n\t}\n\n\t// for h2 and h2c upstream streaming data to client (issues #3556 and #3606)\n\tif h.isBidirectionalStream(req, res) {\n\t\treturn -1\n\t}\n\n\treturn time.Duration(h.FlushInterval)\n}\n\n// isBidirectionalStream returns whether we should work in bi-directional stream mode.\n//\n// See https://github.com/caddyserver/caddy/pull/3620 for discussion of nuances.\nfunc (h Handler) isBidirectionalStream(req *http.Request, res *http.Response) bool {\n\t// We have to check the encoding here; only flush headers with identity encoding.\n\t// Non-identity encoding might combine with \"encode\" directive, and in that case,\n\t// if body size larger than enc.MinLength, upper level encode handle might have\n\t// Content-Encoding header to write.\n\t// (see https://github.com/caddyserver/caddy/issues/3606 for use case)\n\tae := req.Header.Get(\"Accept-Encoding\")\n\n\treturn req.ProtoMajor == 2 &&\n\t\tres.ProtoMajor == 2 &&\n\t\tres.ContentLength == -1 &&\n\t\t(ae == \"identity\" || ae == \"\")\n}\n\nfunc (h Handler) copyResponse(dst http.ResponseWriter, src io.Reader, flushInterval time.Duration, logger *zap.Logger) error {\n\tvar w io.Writer = dst\n\n\tif flushInterval != 0 {\n\t\tvar mlwLogger *zap.Logger\n\t\tif h.VerboseLogs {\n\t\t\tmlwLogger = logger.Named(\"max_latency_writer\")\n\t\t} else {\n\t\t\tmlwLogger = zap.NewNop()\n\t\t}\n\t\tmlw := &maxLatencyWriter{\n\t\t\tdst: dst,\n\t\t\t//nolint:bodyclose\n\t\t\tflush:   http.NewResponseController(dst).Flush,\n\t\t\tlatency: flushInterval,\n\t\t\tlogger:  mlwLogger,\n\t\t}\n\t\tdefer mlw.stop()\n\n\t\t// set up initial timer so headers get flushed even if body writes are delayed\n\t\tmlw.flushPending = true\n\t\tmlw.t = time.AfterFunc(flushInterval, mlw.delayedFlush)\n\n\t\tw = mlw\n\t}\n\n\tbuf := streamingBufPool.Get().(*[]byte)\n\tdefer streamingBufPool.Put(buf)\n\n\tvar copyLogger *zap.Logger\n\tif h.VerboseLogs {\n\t\tcopyLogger = logger\n\t} else {\n\t\tcopyLogger = zap.NewNop()\n\t}\n\n\t_, err := h.copyBuffer(w, src, *buf, copyLogger)\n\treturn err\n}\n\n// copyBuffer returns any write errors or non-EOF read errors, and the amount\n// of bytes written.\nfunc (h Handler) copyBuffer(dst io.Writer, src io.Reader, buf []byte, logger *zap.Logger) (int64, error) {\n\tif len(buf) == 0 {\n\t\tbuf = make([]byte, defaultBufferSize)\n\t}\n\tvar written int64\n\tfor {\n\t\tlogger.Debug(\"waiting to read from upstream\")\n\t\tnr, rerr := src.Read(buf)\n\t\tlogger := logger.With(zap.Int(\"read\", nr))\n\t\tif c := logger.Check(zapcore.DebugLevel, \"read from upstream\"); c != nil {\n\t\t\tc.Write(zap.Error(rerr))\n\t\t}\n\t\tif rerr != nil && rerr != io.EOF && rerr != context.Canceled {\n\t\t\t// TODO: this could be useful to know (indeed, it revealed an error in our\n\t\t\t// fastcgi PoC earlier; but it's this single error report here that necessitates\n\t\t\t// a function separate from io.CopyBuffer, since io.CopyBuffer does not distinguish\n\t\t\t// between read or write errors; in a reverse proxy situation, write errors are not\n\t\t\t// something we need to report to the client, but read errors are a problem on our\n\t\t\t// end for sure. so we need to decide what we want.)\n\t\t\t// p.logf(\"copyBuffer: ReverseProxy read error during body copy: %v\", rerr)\n\t\t\tif c := logger.Check(zapcore.ErrorLevel, \"reading from backend\"); c != nil {\n\t\t\t\tc.Write(zap.Error(rerr))\n\t\t\t}\n\t\t}\n\t\tif nr > 0 {\n\t\t\tlogger.Debug(\"writing to downstream\")\n\t\t\tnw, werr := dst.Write(buf[:nr])\n\t\t\tif nw > 0 {\n\t\t\t\twritten += int64(nw)\n\t\t\t}\n\t\t\tif c := logger.Check(zapcore.DebugLevel, \"wrote to downstream\"); c != nil {\n\t\t\t\tc.Write(\n\t\t\t\t\tzap.Int(\"written\", nw),\n\t\t\t\t\tzap.Int64(\"written_total\", written),\n\t\t\t\t\tzap.Error(werr),\n\t\t\t\t)\n\t\t\t}\n\t\t\tif werr != nil {\n\t\t\t\treturn written, fmt.Errorf(\"writing: %w\", werr)\n\t\t\t}\n\t\t\tif nr != nw {\n\t\t\t\treturn written, io.ErrShortWrite\n\t\t\t}\n\t\t}\n\t\tif rerr != nil {\n\t\t\tif rerr == io.EOF {\n\t\t\t\treturn written, nil\n\t\t\t}\n\t\t\treturn written, fmt.Errorf(\"reading: %w\", rerr)\n\t\t}\n\t}\n}\n\n// registerConnection holds onto conn so it can be closed in the event\n// of a server shutdown. This is useful because hijacked connections or\n// connections dialed to backends don't close when server is shut down.\n// The caller should call the returned delete() function when the\n// connection is done to remove it from memory.\nfunc (h *Handler) registerConnection(conn io.ReadWriteCloser, gracefulClose func() error) (del func()) {\n\th.connectionsMu.Lock()\n\th.connections[conn] = openConnection{conn, gracefulClose}\n\th.connectionsMu.Unlock()\n\treturn func() {\n\t\th.connectionsMu.Lock()\n\t\tdelete(h.connections, conn)\n\t\t// if there is no connection left before the connections close timer fires\n\t\tif len(h.connections) == 0 && h.connectionsCloseTimer != nil {\n\t\t\t// we release the timer that holds the reference to Handler\n\t\t\tif (*h.connectionsCloseTimer).Stop() {\n\t\t\t\th.logger.Debug(\"stopped streaming connections close timer - all connections are already closed\")\n\t\t\t}\n\t\t\th.connectionsCloseTimer = nil\n\t\t}\n\t\th.connectionsMu.Unlock()\n\t}\n}\n\n// closeConnections immediately closes all hijacked connections (both to client and backend).\nfunc (h *Handler) closeConnections() error {\n\tvar err error\n\th.connectionsMu.Lock()\n\tdefer h.connectionsMu.Unlock()\n\n\tfor _, oc := range h.connections {\n\t\tif oc.gracefulClose != nil {\n\t\t\t// this is potentially blocking while we have the lock on the connections\n\t\t\t// map, but that should be OK since the server has in theory shut down\n\t\t\t// and we are no longer using the connections map\n\t\t\tgracefulErr := oc.gracefulClose()\n\t\t\tif gracefulErr != nil && err == nil {\n\t\t\t\terr = gracefulErr\n\t\t\t}\n\t\t}\n\t\tcloseErr := oc.conn.Close()\n\t\tif closeErr != nil && err == nil {\n\t\t\terr = closeErr\n\t\t}\n\t}\n\treturn err\n}\n\n// cleanupConnections closes hijacked connections.\n// Depending on the value of StreamCloseDelay it does that either immediately\n// or sets up a timer that will do that later.\nfunc (h *Handler) cleanupConnections() error {\n\tif h.StreamCloseDelay == 0 {\n\t\treturn h.closeConnections()\n\t}\n\n\th.connectionsMu.Lock()\n\tdefer h.connectionsMu.Unlock()\n\t// the handler is shut down, no new connection can appear,\n\t// so we can skip setting up the timer when there are no connections\n\tif len(h.connections) > 0 {\n\t\tdelay := time.Duration(h.StreamCloseDelay)\n\t\th.connectionsCloseTimer = time.AfterFunc(delay, func() {\n\t\t\tif c := h.logger.Check(zapcore.DebugLevel, \"closing streaming connections after delay\"); c != nil {\n\t\t\t\tc.Write(zap.Duration(\"delay\", delay))\n\t\t\t}\n\t\t\terr := h.closeConnections()\n\t\t\tif err != nil {\n\t\t\t\tif c := h.logger.Check(zapcore.ErrorLevel, \"failed to closed connections after delay\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.Error(err),\n\t\t\t\t\t\tzap.Duration(\"delay\", delay),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t}\n\treturn nil\n}\n\n// writeCloseControl sends a best-effort Close control message to the given\n// WebSocket connection. Thanks to @pascaldekloe who provided inspiration\n// from his simple implementation of this I was able to learn from at:\n// github.com/pascaldekloe/websocket. Further work for handling masking\n// taken from github.com/gorilla/websocket.\nfunc writeCloseControl(conn io.Writer, isClient bool) error {\n\t// Sources:\n\t// https://github.com/pascaldekloe/websocket/blob/32050af67a5d/websocket.go#L119\n\t// https://github.com/gorilla/websocket/blob/v1.5.0/conn.go#L413\n\n\t// For now, we're not using a reason. We might later, though.\n\t// The code handling the reason is left in\n\tvar reason string // max 123 bytes (control frame payload limit is 125; status code takes 2)\n\n\tconst closeMessage = 8\n\tconst finalBit = 1 << 7 // Frame header byte 0 bits from Section 5.2 of RFC 6455\n\tconst maskBit = 1 << 7  // Frame header byte 1 bits from Section 5.2 of RFC 6455\n\tconst goingAwayUpper uint8 = 1001 >> 8\n\tconst goingAwayLower uint8 = 1001 & 0xff\n\n\tb0 := byte(closeMessage) | finalBit\n\tb1 := byte(len(reason) + 2)\n\tif isClient {\n\t\tb1 |= maskBit\n\t}\n\n\tbuf := make([]byte, 0, 127)\n\tbuf = append(buf, b0, b1)\n\tmsgLength := 4 + len(reason)\n\n\t// Both branches below append the \"going away\" code and reason\n\tappendMessage := func(buf []byte) []byte {\n\t\tbuf = append(buf, goingAwayUpper, goingAwayLower)\n\t\tbuf = append(buf, []byte(reason)...)\n\t\treturn buf\n\t}\n\n\t// When we're the client, we need to mask the message as per\n\t// https://www.rfc-editor.org/rfc/rfc6455#section-5.3\n\tif isClient {\n\t\tkey := newMaskKey()\n\t\tbuf = append(buf, key[:]...)\n\t\tmsgLength += len(key)\n\t\tbuf = appendMessage(buf)\n\t\tmaskBytes(key, 0, buf[2+len(key):])\n\t} else {\n\t\tbuf = appendMessage(buf)\n\t}\n\n\t// simply best-effort, but return error for logging purposes\n\t// TODO: we might need to ensure we are the exclusive writer by this point (io.Copy is stopped)?\n\t_, err := conn.Write(buf[:msgLength])\n\treturn err\n}\n\n// Copied from https://github.com/gorilla/websocket/blob/v1.5.0/mask.go\nfunc maskBytes(key [4]byte, pos int, b []byte) int {\n\t// Mask one byte at a time for small buffers.\n\tif len(b) < 2*wordSize {\n\t\tfor i := range b {\n\t\t\tb[i] ^= key[pos&3]\n\t\t\tpos++\n\t\t}\n\t\treturn pos & 3\n\t}\n\n\t// Mask one byte at a time to word boundary.\n\tif n := int(uintptr(unsafe.Pointer(&b[0]))) % wordSize; n != 0 {\n\t\tn = wordSize - n\n\t\tfor i := range b[:n] {\n\t\t\tb[i] ^= key[pos&3]\n\t\t\tpos++\n\t\t}\n\t\tb = b[n:]\n\t}\n\n\t// Create aligned word size key.\n\tvar k [wordSize]byte\n\tfor i := range k {\n\t\tk[i] = key[(pos+i)&3]\n\t}\n\tkw := *(*uintptr)(unsafe.Pointer(&k))\n\n\t// Mask one word at a time.\n\tn := (len(b) / wordSize) * wordSize\n\tfor i := 0; i < n; i += wordSize {\n\t\t*(*uintptr)(unsafe.Pointer(uintptr(unsafe.Pointer(&b[0])) + uintptr(i))) ^= kw\n\t}\n\n\t// Mask one byte at a time for remaining bytes.\n\tb = b[n:]\n\tfor i := range b {\n\t\tb[i] ^= key[pos&3]\n\t\tpos++\n\t}\n\n\treturn pos & 3\n}\n\n// Copied from https://github.com/gorilla/websocket/blob/v1.5.0/conn.go#L184\nfunc newMaskKey() [4]byte {\n\tn := weakrand.Uint32()\n\treturn [4]byte{byte(n), byte(n >> 8), byte(n >> 16), byte(n >> 24)}\n}\n\n// isWebsocket returns true if r looks to be an upgrade request for WebSockets.\n// It is a fairly naive check.\nfunc isWebsocket(r *http.Request) bool {\n\treturn httpguts.HeaderValuesContainsToken(r.Header[\"Connection\"], \"upgrade\") &&\n\t\thttpguts.HeaderValuesContainsToken(r.Header[\"Upgrade\"], \"websocket\")\n}\n\n// openConnection maps an open connection to\n// an optional function for graceful close.\ntype openConnection struct {\n\tconn          io.ReadWriteCloser\n\tgracefulClose func() error\n}\n\ntype maxLatencyWriter struct {\n\tdst     io.Writer\n\tflush   func() error\n\tlatency time.Duration // non-zero; negative means to flush immediately\n\n\tmu           sync.Mutex // protects t, flushPending, and dst.Flush\n\tt            *time.Timer\n\tflushPending bool\n\tlogger       *zap.Logger\n}\n\nfunc (m *maxLatencyWriter) Write(p []byte) (n int, err error) {\n\tm.mu.Lock()\n\tdefer m.mu.Unlock()\n\tn, err = m.dst.Write(p)\n\tif c := m.logger.Check(zapcore.DebugLevel, \"wrote bytes\"); c != nil {\n\t\tc.Write(zap.Int(\"n\", n), zap.Error(err))\n\t}\n\tif m.latency < 0 {\n\t\tm.logger.Debug(\"flushing immediately\")\n\t\t//nolint:errcheck\n\t\tm.flush()\n\t\treturn\n\t}\n\tif m.flushPending {\n\t\tm.logger.Debug(\"delayed flush already pending\")\n\t\treturn\n\t}\n\tif m.t == nil {\n\t\tm.t = time.AfterFunc(m.latency, m.delayedFlush)\n\t} else {\n\t\tm.t.Reset(m.latency)\n\t}\n\tif c := m.logger.Check(zapcore.DebugLevel, \"timer set for delayed flush\"); c != nil {\n\t\tc.Write(zap.Duration(\"duration\", m.latency))\n\t}\n\tm.flushPending = true\n\treturn\n}\n\nfunc (m *maxLatencyWriter) delayedFlush() {\n\tm.mu.Lock()\n\tdefer m.mu.Unlock()\n\tif !m.flushPending { // if stop was called but AfterFunc already started this goroutine\n\t\tm.logger.Debug(\"delayed flush is not pending\")\n\t\treturn\n\t}\n\tm.logger.Debug(\"delayed flush\")\n\t//nolint:errcheck\n\tm.flush()\n\tm.flushPending = false\n}\n\nfunc (m *maxLatencyWriter) stop() {\n\tm.mu.Lock()\n\tdefer m.mu.Unlock()\n\tm.flushPending = false\n\tif m.t != nil {\n\t\tm.t.Stop()\n\t}\n}\n\n// switchProtocolCopier exists so goroutines proxying data back and\n// forth have nice names in stacks.\ntype switchProtocolCopier struct {\n\tuser, backend io.ReadWriteCloser\n\twg            *sync.WaitGroup\n}\n\nfunc (c switchProtocolCopier) copyFromBackend(errc chan<- error) {\n\t_, err := io.Copy(c.user, c.backend)\n\terrc <- err\n\tc.wg.Done()\n}\n\nfunc (c switchProtocolCopier) copyToBackend(errc chan<- error) {\n\t_, err := io.Copy(c.backend, c.user)\n\terrc <- err\n\tc.wg.Done()\n}\n\nvar streamingBufPool = sync.Pool{\n\tNew: func() any {\n\t\t// The Pool's New function should generally only return pointer\n\t\t// types, since a pointer can be put into the return interface\n\t\t// value without an allocation\n\t\t// - (from the package docs)\n\t\tb := make([]byte, defaultBufferSize)\n\t\treturn &b\n\t},\n}\n\nconst (\n\tdefaultBufferSize = 32 * 1024\n\twordSize          = int(unsafe.Sizeof(uintptr(0)))\n)\n",
    "source_file": "modules/caddyhttp/reverseproxy/streaming.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"net/http\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/dustin/go-humanize\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/internal\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/headers\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/rewrite\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n\t\"github.com/caddyserver/caddy/v2/modules/internal/network\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterHandlerDirective(\"reverse_proxy\", parseCaddyfile)\n\thttpcaddyfile.RegisterHandlerDirective(\"copy_response\", parseCopyResponseCaddyfile)\n\thttpcaddyfile.RegisterHandlerDirective(\"copy_response_headers\", parseCopyResponseHeadersCaddyfile)\n}\n\nfunc parseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\trp := new(Handler)\n\terr := rp.UnmarshalCaddyfile(h.Dispenser)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = rp.FinalizeUnmarshalCaddyfile(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn rp, nil\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens. Syntax:\n//\n//\treverse_proxy [<matcher>] [<upstreams...>] {\n//\t    # backends\n//\t    to      <upstreams...>\n//\t    dynamic <name> [...]\n//\n//\t    # load balancing\n//\t    lb_policy <name> [<options...>]\n//\t    lb_retries <retries>\n//\t    lb_try_duration <duration>\n//\t    lb_try_interval <interval>\n//\t    lb_retry_match <request-matcher>\n//\n//\t    # active health checking\n//\t    health_uri          <uri>\n//\t    health_port         <port>\n//\t    health_interval     <interval>\n//\t    health_passes       <num>\n//\t    health_fails        <num>\n//\t    health_timeout      <duration>\n//\t    health_status       <status>\n//\t    health_body         <regexp>\n//\t    health_method       <value>\n//\t    health_request_body <value>\n//\t    health_follow_redirects\n//\t    health_headers {\n//\t        <field> [<values...>]\n//\t    }\n//\n//\t    # passive health checking\n//\t    fail_duration     <duration>\n//\t    max_fails         <num>\n//\t    unhealthy_status  <status>\n//\t    unhealthy_latency <duration>\n//\t    unhealthy_request_count <num>\n//\n//\t    # streaming\n//\t    flush_interval     <duration>\n//\t    request_buffers    <size>\n//\t    response_buffers   <size>\n//\t    stream_timeout     <duration>\n//\t    stream_close_delay <duration>\n//\t    verbose_logs\n//\n//\t    # request manipulation\n//\t    trusted_proxies [private_ranges] <ranges...>\n//\t    header_up   [+|-]<field> [<value|regexp> [<replacement>]]\n//\t    header_down [+|-]<field> [<value|regexp> [<replacement>]]\n//\t    method <method>\n//\t    rewrite <to>\n//\n//\t    # round trip\n//\t    transport <name> {\n//\t        ...\n//\t    }\n//\n//\t    # optionally intercept responses from upstream\n//\t    @name {\n//\t        status <code...>\n//\t        header <field> [<value>]\n//\t    }\n//\t    replace_status [<matcher>] <status_code>\n//\t    handle_response [<matcher>] {\n//\t        <directives...>\n//\n//\t        # special directives only available in handle_response\n//\t        copy_response [<matcher>] [<status>] {\n//\t            status <status>\n//\t        }\n//\t        copy_response_headers [<matcher>] {\n//\t            include <fields...>\n//\t            exclude <fields...>\n//\t        }\n//\t    }\n//\t}\n//\n// Proxy upstream addresses should be network dial addresses such\n// as `host:port`, or a URL such as `scheme://host:port`. Scheme\n// and port may be inferred from other parts of the address/URL; if\n// either are missing, defaults to HTTP.\n//\n// The FinalizeUnmarshalCaddyfile method should be called after this\n// to finalize parsing of \"handle_response\" blocks, if possible.\nfunc (h *Handler) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// currently, all backends must use the same scheme/protocol (the\n\t// underlying JSON does not yet support per-backend transports)\n\tvar commonScheme string\n\n\t// we'll wait until the very end of parsing before\n\t// validating and encoding the transport\n\tvar transport http.RoundTripper\n\tvar transportModuleName string\n\n\t// collect the response matchers defined as subdirectives\n\t// prefixed with \"@\" for use with \"handle_response\" blocks\n\th.responseMatchers = make(map[string]caddyhttp.ResponseMatcher)\n\n\t// appendUpstream creates an upstream for address and adds\n\t// it to the list.\n\tappendUpstream := func(address string) error {\n\t\tpa, err := parseUpstreamDialAddress(address)\n\t\tif err != nil {\n\t\t\treturn d.WrapErr(err)\n\t\t}\n\n\t\t// the underlying JSON does not yet support different\n\t\t// transports (protocols or schemes) to each backend,\n\t\t// so we remember the last one we see and compare them\n\n\t\tswitch pa.scheme {\n\t\tcase \"wss\":\n\t\t\treturn d.Errf(\"the scheme wss:// is only supported in browsers; use https:// instead\")\n\t\tcase \"ws\":\n\t\t\treturn d.Errf(\"the scheme ws:// is only supported in browsers; use http:// instead\")\n\t\tcase \"https\", \"http\", \"h2c\", \"\":\n\t\t\t// Do nothing or handle the valid schemes\n\t\tdefault:\n\t\t\treturn d.Errf(\"unsupported URL scheme %s://\", pa.scheme)\n\t\t}\n\n\t\tif commonScheme != \"\" && pa.scheme != commonScheme {\n\t\t\treturn d.Errf(\"for now, all proxy upstreams must use the same scheme (transport protocol); expecting '%s://' but got '%s://'\",\n\t\t\t\tcommonScheme, pa.scheme)\n\t\t}\n\t\tcommonScheme = pa.scheme\n\n\t\t// if the port of upstream address contains a placeholder, only wrap it with the `Upstream` struct,\n\t\t// delaying actual resolution of the address until request time.\n\t\tif pa.replaceablePort() {\n\t\t\th.Upstreams = append(h.Upstreams, &Upstream{Dial: pa.dialAddr()})\n\t\t\treturn nil\n\t\t}\n\t\tparsedAddr, err := caddy.ParseNetworkAddress(pa.dialAddr())\n\t\tif err != nil {\n\t\t\treturn d.WrapErr(err)\n\t\t}\n\n\t\tif pa.isUnix() || !pa.rangedPort() {\n\t\t\t// unix networks don't have ports\n\t\t\th.Upstreams = append(h.Upstreams, &Upstream{\n\t\t\t\tDial: pa.dialAddr(),\n\t\t\t})\n\t\t} else {\n\t\t\t// expand a port range into multiple upstreams\n\t\t\tfor i := parsedAddr.StartPort; i <= parsedAddr.EndPort; i++ {\n\t\t\t\th.Upstreams = append(h.Upstreams, &Upstream{\n\t\t\t\t\tDial: caddy.JoinNetworkAddress(\"\", parsedAddr.Host, fmt.Sprint(i)),\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\n\t\treturn nil\n\t}\n\n\td.Next() // consume the directive name\n\tfor _, up := range d.RemainingArgs() {\n\t\terr := appendUpstream(up)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"parsing upstream '%s': %w\", up, err)\n\t\t}\n\t}\n\n\tfor d.NextBlock(0) {\n\t\t// if the subdirective has an \"@\" prefix then we\n\t\t// parse it as a response matcher for use with \"handle_response\"\n\t\tif strings.HasPrefix(d.Val(), matcherPrefix) {\n\t\t\terr := caddyhttp.ParseNamedResponseMatcher(d.NewFromNextSegment(), h.responseMatchers)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tswitch d.Val() {\n\t\tcase \"to\":\n\t\t\targs := d.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tfor _, up := range args {\n\t\t\t\terr := appendUpstream(up)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn fmt.Errorf(\"parsing upstream '%s': %w\", up, err)\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase \"dynamic\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.DynamicUpstreams != nil {\n\t\t\t\treturn d.Err(\"dynamic upstreams already specified\")\n\t\t\t}\n\t\t\tdynModule := d.Val()\n\t\t\tmodID := \"http.reverse_proxy.upstreams.\" + dynModule\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tsource, ok := unm.(UpstreamSource)\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"module %s (%T) is not an UpstreamSource\", modID, unm)\n\t\t\t}\n\t\t\th.DynamicUpstreamsRaw = caddyconfig.JSONModuleObject(source, \"source\", dynModule, nil)\n\n\t\tcase \"lb_policy\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.LoadBalancing != nil && h.LoadBalancing.SelectionPolicyRaw != nil {\n\t\t\t\treturn d.Err(\"load balancing selection policy already specified\")\n\t\t\t}\n\t\t\tname := d.Val()\n\t\t\tmodID := \"http.reverse_proxy.selection_policies.\" + name\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tsel, ok := unm.(Selector)\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"module %s (%T) is not a reverseproxy.Selector\", modID, unm)\n\t\t\t}\n\t\t\tif h.LoadBalancing == nil {\n\t\t\t\th.LoadBalancing = new(LoadBalancing)\n\t\t\t}\n\t\t\th.LoadBalancing.SelectionPolicyRaw = caddyconfig.JSONModuleObject(sel, \"policy\", name, nil)\n\n\t\tcase \"lb_retries\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\ttries, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad lb_retries number '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tif h.LoadBalancing == nil {\n\t\t\t\th.LoadBalancing = new(LoadBalancing)\n\t\t\t}\n\t\t\th.LoadBalancing.Retries = tries\n\n\t\tcase \"lb_try_duration\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.LoadBalancing == nil {\n\t\t\t\th.LoadBalancing = new(LoadBalancing)\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad duration value %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.LoadBalancing.TryDuration = caddy.Duration(dur)\n\n\t\tcase \"lb_try_interval\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.LoadBalancing == nil {\n\t\t\t\th.LoadBalancing = new(LoadBalancing)\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad interval value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.LoadBalancing.TryInterval = caddy.Duration(dur)\n\n\t\tcase \"lb_retry_match\":\n\t\t\tmatcherSet, err := caddyhttp.ParseCaddyfileNestedMatcherSet(d)\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"failed to parse lb_retry_match: %v\", err)\n\t\t\t}\n\t\t\tif h.LoadBalancing == nil {\n\t\t\t\th.LoadBalancing = new(LoadBalancing)\n\t\t\t}\n\t\t\th.LoadBalancing.RetryMatchRaw = append(h.LoadBalancing.RetryMatchRaw, matcherSet)\n\n\t\tcase \"health_uri\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\th.HealthChecks.Active.URI = d.Val()\n\n\t\tcase \"health_path\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Path = d.Val()\n\t\t\tcaddy.Log().Named(\"config.adapter.caddyfile\").Warn(\"the 'health_path' subdirective is deprecated, please use 'health_uri' instead!\")\n\n\t\tcase \"health_upstream\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\t_, port, err := net.SplitHostPort(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"health_upstream is malformed '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\t_, err = strconv.Atoi(port)\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad port number '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Upstream = d.Val()\n\n\t\tcase \"health_port\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active.Upstream != \"\" {\n\t\t\t\treturn d.Errf(\"the 'health_port' subdirective is ignored if 'health_upstream' is used!\")\n\t\t\t}\n\t\t\tportNum, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad port number '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Port = portNum\n\n\t\tcase \"health_headers\":\n\t\t\thealthHeaders := make(http.Header)\n\t\t\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\t\t\tkey := d.Val()\n\t\t\t\tvalues := d.RemainingArgs()\n\t\t\t\tif len(values) == 0 {\n\t\t\t\t\tvalues = append(values, \"\")\n\t\t\t\t}\n\t\t\t\thealthHeaders[key] = append(healthHeaders[key], values...)\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Headers = healthHeaders\n\n\t\tcase \"health_method\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Method = d.Val()\n\n\t\tcase \"health_request_body\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Body = d.Val()\n\n\t\tcase \"health_interval\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad interval value %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Interval = caddy.Duration(dur)\n\n\t\tcase \"health_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Timeout = caddy.Duration(dur)\n\n\t\tcase \"health_status\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\tval := d.Val()\n\t\t\tif len(val) == 3 && strings.HasSuffix(val, \"xx\") {\n\t\t\t\tval = val[:1]\n\t\t\t}\n\t\t\tstatusNum, err := strconv.Atoi(val)\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad status value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Active.ExpectStatus = statusNum\n\n\t\tcase \"health_body\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\th.HealthChecks.Active.ExpectBody = d.Val()\n\n\t\tcase \"health_follow_redirects\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\th.HealthChecks.Active.FollowRedirects = true\n\n\t\tcase \"health_passes\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\tpasses, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid passes count '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Passes = passes\n\n\t\tcase \"health_fails\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Active == nil {\n\t\t\t\th.HealthChecks.Active = new(ActiveHealthChecks)\n\t\t\t}\n\t\t\tfails, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid fails count '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Active.Fails = fails\n\n\t\tcase \"max_fails\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Passive == nil {\n\t\t\t\th.HealthChecks.Passive = new(PassiveHealthChecks)\n\t\t\t}\n\t\t\tmaxFails, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid maximum fail count '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Passive.MaxFails = maxFails\n\n\t\tcase \"fail_duration\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Passive == nil {\n\t\t\t\th.HealthChecks.Passive = new(PassiveHealthChecks)\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad duration value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Passive.FailDuration = caddy.Duration(dur)\n\n\t\tcase \"unhealthy_request_count\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Passive == nil {\n\t\t\t\th.HealthChecks.Passive = new(PassiveHealthChecks)\n\t\t\t}\n\t\t\tmaxConns, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid maximum connection count '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Passive.UnhealthyRequestCount = maxConns\n\n\t\tcase \"unhealthy_status\":\n\t\t\targs := d.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Passive == nil {\n\t\t\t\th.HealthChecks.Passive = new(PassiveHealthChecks)\n\t\t\t}\n\t\t\tfor _, arg := range args {\n\t\t\t\tif len(arg) == 3 && strings.HasSuffix(arg, \"xx\") {\n\t\t\t\t\targ = arg[:1]\n\t\t\t\t}\n\t\t\t\tstatusNum, err := strconv.Atoi(arg)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn d.Errf(\"bad status value '%s': %v\", d.Val(), err)\n\t\t\t\t}\n\t\t\t\th.HealthChecks.Passive.UnhealthyStatus = append(h.HealthChecks.Passive.UnhealthyStatus, statusNum)\n\t\t\t}\n\n\t\tcase \"unhealthy_latency\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.HealthChecks == nil {\n\t\t\t\th.HealthChecks = new(HealthChecks)\n\t\t\t}\n\t\t\tif h.HealthChecks.Passive == nil {\n\t\t\t\th.HealthChecks.Passive = new(PassiveHealthChecks)\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad duration value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.HealthChecks.Passive.UnhealthyLatency = caddy.Duration(dur)\n\n\t\tcase \"flush_interval\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif fi, err := strconv.Atoi(d.Val()); err == nil {\n\t\t\t\th.FlushInterval = caddy.Duration(fi)\n\t\t\t} else {\n\t\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn d.Errf(\"bad duration value '%s': %v\", d.Val(), err)\n\t\t\t\t}\n\t\t\t\th.FlushInterval = caddy.Duration(dur)\n\t\t\t}\n\n\t\tcase \"request_buffers\", \"response_buffers\":\n\t\t\tsubdir := d.Val()\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tval := d.Val()\n\t\t\tvar size int64\n\t\t\tif val == \"unlimited\" {\n\t\t\t\tsize = -1\n\t\t\t} else {\n\t\t\t\tusize, err := humanize.ParseBytes(val)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn d.Errf(\"invalid byte size '%s': %v\", val, err)\n\t\t\t\t}\n\t\t\t\tsize = int64(usize)\n\t\t\t}\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tswitch subdir {\n\t\t\tcase \"request_buffers\":\n\t\t\t\th.RequestBuffers = size\n\t\t\tcase \"response_buffers\":\n\t\t\t\th.ResponseBuffers = size\n\t\t\t}\n\n\t\tcase \"stream_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif fi, err := strconv.Atoi(d.Val()); err == nil {\n\t\t\t\th.StreamTimeout = caddy.Duration(fi)\n\t\t\t} else {\n\t\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn d.Errf(\"bad duration value '%s': %v\", d.Val(), err)\n\t\t\t\t}\n\t\t\t\th.StreamTimeout = caddy.Duration(dur)\n\t\t\t}\n\n\t\tcase \"stream_close_delay\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif fi, err := strconv.Atoi(d.Val()); err == nil {\n\t\t\t\th.StreamCloseDelay = caddy.Duration(fi)\n\t\t\t} else {\n\t\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn d.Errf(\"bad duration value '%s': %v\", d.Val(), err)\n\t\t\t\t}\n\t\t\t\th.StreamCloseDelay = caddy.Duration(dur)\n\t\t\t}\n\n\t\tcase \"trusted_proxies\":\n\t\t\tfor d.NextArg() {\n\t\t\t\tif d.Val() == \"private_ranges\" {\n\t\t\t\t\th.TrustedProxies = append(h.TrustedProxies, internal.PrivateRangesCIDR()...)\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\th.TrustedProxies = append(h.TrustedProxies, d.Val())\n\t\t\t}\n\n\t\tcase \"header_up\":\n\t\t\tvar err error\n\n\t\t\tif h.Headers == nil {\n\t\t\t\th.Headers = new(headers.Handler)\n\t\t\t}\n\t\t\tif h.Headers.Request == nil {\n\t\t\t\th.Headers.Request = new(headers.HeaderOps)\n\t\t\t}\n\t\t\targs := d.RemainingArgs()\n\n\t\t\tswitch len(args) {\n\t\t\tcase 1:\n\t\t\t\terr = headers.CaddyfileHeaderOp(h.Headers.Request, args[0], \"\", nil)\n\t\t\tcase 2:\n\t\t\t\t// some lint checks, I guess\n\t\t\t\tif strings.EqualFold(args[0], \"host\") && (args[1] == \"{hostport}\" || args[1] == \"{http.request.hostport}\") {\n\t\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\"Unnecessary header_up Host: the reverse proxy's default behavior is to pass headers to the upstream\")\n\t\t\t\t}\n\t\t\t\tif strings.EqualFold(args[0], \"x-forwarded-for\") && (args[1] == \"{remote}\" || args[1] == \"{http.request.remote}\" || args[1] == \"{remote_host}\" || args[1] == \"{http.request.remote.host}\") {\n\t\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\"Unnecessary header_up X-Forwarded-For: the reverse proxy's default behavior is to pass headers to the upstream\")\n\t\t\t\t}\n\t\t\t\tif strings.EqualFold(args[0], \"x-forwarded-proto\") && (args[1] == \"{scheme}\" || args[1] == \"{http.request.scheme}\") {\n\t\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\"Unnecessary header_up X-Forwarded-Proto: the reverse proxy's default behavior is to pass headers to the upstream\")\n\t\t\t\t}\n\t\t\t\tif strings.EqualFold(args[0], \"x-forwarded-host\") && (args[1] == \"{host}\" || args[1] == \"{http.request.host}\" || args[1] == \"{hostport}\" || args[1] == \"{http.request.hostport}\") {\n\t\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\"Unnecessary header_up X-Forwarded-Host: the reverse proxy's default behavior is to pass headers to the upstream\")\n\t\t\t\t}\n\t\t\t\terr = headers.CaddyfileHeaderOp(h.Headers.Request, args[0], args[1], nil)\n\t\t\tcase 3:\n\t\t\t\terr = headers.CaddyfileHeaderOp(h.Headers.Request, args[0], args[1], &args[2])\n\t\t\tdefault:\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\treturn d.Err(err.Error())\n\t\t\t}\n\n\t\tcase \"header_down\":\n\t\t\tvar err error\n\n\t\t\tif h.Headers == nil {\n\t\t\t\th.Headers = new(headers.Handler)\n\t\t\t}\n\t\t\tif h.Headers.Response == nil {\n\t\t\t\th.Headers.Response = &headers.RespHeaderOps{\n\t\t\t\t\tHeaderOps: new(headers.HeaderOps),\n\t\t\t\t}\n\t\t\t}\n\t\t\targs := d.RemainingArgs()\n\n\t\t\tswitch len(args) {\n\t\t\tcase 1:\n\t\t\t\terr = headers.CaddyfileHeaderOp(h.Headers.Response.HeaderOps, args[0], \"\", nil)\n\t\t\tcase 2:\n\t\t\t\terr = headers.CaddyfileHeaderOp(h.Headers.Response.HeaderOps, args[0], args[1], nil)\n\t\t\tcase 3:\n\t\t\t\terr = headers.CaddyfileHeaderOp(h.Headers.Response.HeaderOps, args[0], args[1], &args[2])\n\t\t\tdefault:\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\treturn d.Err(err.Error())\n\t\t\t}\n\n\t\tcase \"method\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.Rewrite == nil {\n\t\t\t\th.Rewrite = &rewrite.Rewrite{}\n\t\t\t}\n\t\t\th.Rewrite.Method = d.Val()\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"rewrite\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.Rewrite == nil {\n\t\t\t\th.Rewrite = &rewrite.Rewrite{}\n\t\t\t}\n\t\t\th.Rewrite.URI = d.Val()\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"transport\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.TransportRaw != nil {\n\t\t\t\treturn d.Err(\"transport already specified\")\n\t\t\t}\n\t\t\ttransportModuleName = d.Val()\n\t\t\tmodID := \"http.reverse_proxy.transport.\" + transportModuleName\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\trt, ok := unm.(http.RoundTripper)\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"module %s (%T) is not a RoundTripper\", modID, unm)\n\t\t\t}\n\t\t\ttransport = rt\n\n\t\tcase \"handle_response\":\n\t\t\t// delegate the parsing of handle_response to the caller,\n\t\t\t// since we need the httpcaddyfile.Helper to parse subroutes.\n\t\t\t// See h.FinalizeUnmarshalCaddyfile\n\t\t\th.handleResponseSegments = append(h.handleResponseSegments, d.NewFromNextSegment())\n\n\t\tcase \"replace_status\":\n\t\t\targs := d.RemainingArgs()\n\t\t\tif len(args) != 1 && len(args) != 2 {\n\t\t\t\treturn d.Errf(\"must have one or two arguments: an optional response matcher, and a status code\")\n\t\t\t}\n\n\t\t\tresponseHandler := caddyhttp.ResponseHandler{}\n\n\t\t\tif len(args) == 2 {\n\t\t\t\tif !strings.HasPrefix(args[0], matcherPrefix) {\n\t\t\t\t\treturn d.Errf(\"must use a named response matcher, starting with '@'\")\n\t\t\t\t}\n\t\t\t\tfoundMatcher, ok := h.responseMatchers[args[0]]\n\t\t\t\tif !ok {\n\t\t\t\t\treturn d.Errf(\"no named response matcher defined with name '%s'\", args[0][1:])\n\t\t\t\t}\n\t\t\t\tresponseHandler.Match = &foundMatcher\n\t\t\t\tresponseHandler.StatusCode = caddyhttp.WeakString(args[1])\n\t\t\t} else if len(args) == 1 {\n\t\t\t\tresponseHandler.StatusCode = caddyhttp.WeakString(args[0])\n\t\t\t}\n\n\t\t\t// make sure there's no block, cause it doesn't make sense\n\t\t\tif nesting := d.Nesting(); d.NextBlock(nesting) {\n\t\t\t\treturn d.Errf(\"cannot define routes for 'replace_status', use 'handle_response' instead.\")\n\t\t\t}\n\n\t\t\th.HandleResponse = append(\n\t\t\t\th.HandleResponse,\n\t\t\t\tresponseHandler,\n\t\t\t)\n\n\t\tcase \"verbose_logs\":\n\t\t\tif h.VerboseLogs {\n\t\t\t\treturn d.Err(\"verbose_logs already specified\")\n\t\t\t}\n\t\t\th.VerboseLogs = true\n\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective %s\", d.Val())\n\t\t}\n\t}\n\n\t// if the scheme inferred from the backends' addresses is\n\t// HTTPS, we will need a non-nil transport to enable TLS,\n\t// or if H2C, to set the transport versions.\n\tif (commonScheme == \"https\" || commonScheme == \"h2c\") && transport == nil {\n\t\ttransport = new(HTTPTransport)\n\t\ttransportModuleName = \"http\"\n\t}\n\n\t// verify transport configuration, and finally encode it\n\tif transport != nil {\n\t\tif te, ok := transport.(TLSTransport); ok {\n\t\t\tif commonScheme == \"https\" && !te.TLSEnabled() {\n\t\t\t\terr := te.EnableTLS(new(TLSConfig))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t\tif commonScheme == \"http\" && te.TLSEnabled() {\n\t\t\t\treturn d.Errf(\"upstream address scheme is HTTP but transport is configured for HTTP+TLS (HTTPS)\")\n\t\t\t}\n\t\t\tif te, ok := transport.(*HTTPTransport); ok && commonScheme == \"h2c\" {\n\t\t\t\tte.Versions = []string{\"h2c\", \"2\"}\n\t\t\t}\n\t\t} else if commonScheme == \"https\" {\n\t\t\treturn d.Errf(\"upstreams are configured for HTTPS but transport module does not support TLS: %T\", transport)\n\t\t}\n\n\t\t// no need to encode empty default transport\n\t\tif !reflect.DeepEqual(transport, new(HTTPTransport)) {\n\t\t\th.TransportRaw = caddyconfig.JSONModuleObject(transport, \"protocol\", transportModuleName, nil)\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// FinalizeUnmarshalCaddyfile finalizes the Caddyfile parsing which\n// requires having an httpcaddyfile.Helper to function, to parse subroutes.\nfunc (h *Handler) FinalizeUnmarshalCaddyfile(helper httpcaddyfile.Helper) error {\n\tfor _, d := range h.handleResponseSegments {\n\t\t// consume the \"handle_response\" token\n\t\td.Next()\n\t\targs := d.RemainingArgs()\n\n\t\t// TODO: Remove this check at some point in the future\n\t\tif len(args) == 2 {\n\t\t\treturn d.Errf(\"configuring 'handle_response' for status code replacement is no longer supported. Use 'replace_status' instead.\")\n\t\t}\n\n\t\tif len(args) > 1 {\n\t\t\treturn d.Errf(\"too many arguments for 'handle_response': %s\", args)\n\t\t}\n\n\t\tvar matcher *caddyhttp.ResponseMatcher\n\t\tif len(args) == 1 {\n\t\t\t// the first arg should always be a matcher.\n\t\t\tif !strings.HasPrefix(args[0], matcherPrefix) {\n\t\t\t\treturn d.Errf(\"must use a named response matcher, starting with '@'\")\n\t\t\t}\n\n\t\t\tfoundMatcher, ok := h.responseMatchers[args[0]]\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"no named response matcher defined with name '%s'\", args[0][1:])\n\t\t\t}\n\t\t\tmatcher = &foundMatcher\n\t\t}\n\n\t\t// parse the block as routes\n\t\thandler, err := httpcaddyfile.ParseSegmentAsSubroute(helper.WithDispenser(d.NewFromNextSegment()))\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsubroute, ok := handler.(*caddyhttp.Subroute)\n\t\tif !ok {\n\t\t\treturn helper.Errf(\"segment was not parsed as a subroute\")\n\t\t}\n\t\th.HandleResponse = append(\n\t\t\th.HandleResponse,\n\t\t\tcaddyhttp.ResponseHandler{\n\t\t\t\tMatch:  matcher,\n\t\t\t\tRoutes: subroute.Routes,\n\t\t\t},\n\t\t)\n\t}\n\n\t// move the handle_response entries without a matcher to the end.\n\t// we can't use sort.SliceStable because it will reorder the rest of the\n\t// entries which may be undesirable because we don't have a good\n\t// heuristic to use for sorting.\n\twithoutMatchers := []caddyhttp.ResponseHandler{}\n\twithMatchers := []caddyhttp.ResponseHandler{}\n\tfor _, hr := range h.HandleResponse {\n\t\tif hr.Match == nil {\n\t\t\twithoutMatchers = append(withoutMatchers, hr)\n\t\t} else {\n\t\t\twithMatchers = append(withMatchers, hr)\n\t\t}\n\t}\n\th.HandleResponse = append(withMatchers, withoutMatchers...)\n\n\t// clean up the bits we only needed for adapting\n\th.handleResponseSegments = nil\n\th.responseMatchers = nil\n\n\treturn nil\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into h.\n//\n//\ttransport http {\n//\t    read_buffer             <size>\n//\t    write_buffer            <size>\n//\t    max_response_header     <size>\n//\t    network_proxy           <module> {\n//\t        ...\n//\t    }\n//\t    dial_timeout            <duration>\n//\t    dial_fallback_delay     <duration>\n//\t    response_header_timeout <duration>\n//\t    expect_continue_timeout <duration>\n//\t    resolvers               <resolvers...>\n//\t    tls\n//\t    tls_client_auth <automate_name> | <cert_file> <key_file>\n//\t    tls_insecure_skip_verify\n//\t    tls_timeout <duration>\n//\t    tls_trusted_ca_certs <cert_files...>\n//\t    tls_trust_pool <module> {\n//\t        ...\n//\t    }\n//\t    tls_server_name <sni>\n//\t    tls_renegotiation <level>\n//\t    tls_except_ports <ports...>\n//\t    keepalive [off|<duration>]\n//\t    keepalive_interval <interval>\n//\t    keepalive_idle_conns <max_count>\n//\t    keepalive_idle_conns_per_host <count>\n//\t    versions <versions...>\n//\t    compression off\n//\t    max_conns_per_host <count>\n//\t    max_idle_conns_per_host <count>\n//\t}\nfunc (h *HTTPTransport) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume transport name\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"read_buffer\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tsize, err := humanize.ParseBytes(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid read buffer size '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.ReadBufferSize = int(size)\n\n\t\tcase \"write_buffer\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tsize, err := humanize.ParseBytes(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid write buffer size '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.WriteBufferSize = int(size)\n\n\t\tcase \"read_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\ttimeout, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid read timeout duration '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.ReadTimeout = caddy.Duration(timeout)\n\n\t\tcase \"write_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\ttimeout, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid write timeout duration '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.WriteTimeout = caddy.Duration(timeout)\n\n\t\tcase \"max_response_header\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tsize, err := humanize.ParseBytes(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"invalid max response header size '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.MaxResponseHeaderSize = int64(size)\n\n\t\tcase \"proxy_protocol\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tswitch proxyProtocol := d.Val(); proxyProtocol {\n\t\t\tcase \"v1\", \"v2\":\n\t\t\t\th.ProxyProtocol = proxyProtocol\n\t\t\tdefault:\n\t\t\t\treturn d.Errf(\"invalid proxy protocol version '%s'\", proxyProtocol)\n\t\t\t}\n\n\t\tcase \"forward_proxy_url\":\n\t\t\tcaddy.Log().Warn(\"The 'forward_proxy_url' field is deprecated. Use 'network_proxy <url>' instead.\")\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tu := network.ProxyFromURL{URL: d.Val()}\n\t\t\th.NetworkProxyRaw = caddyconfig.JSONModuleObject(u, \"from\", \"url\", nil)\n\n\t\tcase \"network_proxy\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tmodStem := d.Val()\n\t\t\tmodID := \"caddy.network_proxy.\" + modStem\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\th.NetworkProxyRaw = caddyconfig.JSONModuleObject(unm, \"from\", modStem, nil)\n\n\t\tcase \"dial_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.DialTimeout = caddy.Duration(dur)\n\n\t\tcase \"dial_fallback_delay\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad fallback delay value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.FallbackDelay = caddy.Duration(dur)\n\n\t\tcase \"response_header_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.ResponseHeaderTimeout = caddy.Duration(dur)\n\n\t\tcase \"expect_continue_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.ExpectContinueTimeout = caddy.Duration(dur)\n\n\t\tcase \"resolvers\":\n\t\t\tif h.Resolver == nil {\n\t\t\t\th.Resolver = new(UpstreamResolver)\n\t\t\t}\n\t\t\th.Resolver.Addresses = d.RemainingArgs()\n\t\t\tif len(h.Resolver.Addresses) == 0 {\n\t\t\t\treturn d.Errf(\"must specify at least one resolver address\")\n\t\t\t}\n\n\t\tcase \"tls\":\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\n\t\tcase \"tls_client_auth\":\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\t\t\targs := d.RemainingArgs()\n\t\t\tswitch len(args) {\n\t\t\tcase 1:\n\t\t\t\th.TLS.ClientCertificateAutomate = args[0]\n\t\t\tcase 2:\n\t\t\t\th.TLS.ClientCertificateFile = args[0]\n\t\t\t\th.TLS.ClientCertificateKeyFile = args[1]\n\t\t\tdefault:\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"tls_insecure_skip_verify\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\t\t\th.TLS.InsecureSkipVerify = true\n\n\t\tcase \"tls_curves\":\n\t\t\targs := d.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\t\t\th.TLS.Curves = args\n\n\t\tcase \"tls_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\t\t\th.TLS.HandshakeTimeout = caddy.Duration(dur)\n\n\t\tcase \"tls_trusted_ca_certs\":\n\t\t\tcaddy.Log().Warn(\"The 'tls_trusted_ca_certs' field is deprecated. Use the 'tls_trust_pool' field instead.\")\n\t\t\targs := d.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\t\t\tif len(h.TLS.CARaw) != 0 {\n\t\t\t\treturn d.Err(\"cannot specify both 'tls_trust_pool' and 'tls_trusted_ca_certs\")\n\t\t\t}\n\t\t\th.TLS.RootCAPEMFiles = args\n\n\t\tcase \"tls_server_name\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\t\t\th.TLS.ServerName = d.Val()\n\n\t\tcase \"tls_renegotiation\":\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tswitch renegotiation := d.Val(); renegotiation {\n\t\t\tcase \"never\", \"once\", \"freely\":\n\t\t\t\th.TLS.Renegotiation = renegotiation\n\t\t\tdefault:\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"tls_except_ports\":\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\t\t\th.TLS.ExceptPorts = d.RemainingArgs()\n\t\t\tif len(h.TLS.ExceptPorts) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"keepalive\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif h.KeepAlive == nil {\n\t\t\t\th.KeepAlive = new(KeepAlive)\n\t\t\t}\n\t\t\tif d.Val() == \"off\" {\n\t\t\t\tvar disable bool\n\t\t\t\th.KeepAlive.Enabled = &disable\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad duration value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.KeepAlive.IdleConnTimeout = caddy.Duration(dur)\n\n\t\tcase \"keepalive_interval\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad interval value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tif h.KeepAlive == nil {\n\t\t\t\th.KeepAlive = new(KeepAlive)\n\t\t\t}\n\t\t\th.KeepAlive.ProbeInterval = caddy.Duration(dur)\n\n\t\tcase \"keepalive_idle_conns\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tnum, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad integer value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tif h.KeepAlive == nil {\n\t\t\t\th.KeepAlive = new(KeepAlive)\n\t\t\t}\n\t\t\th.KeepAlive.MaxIdleConns = num\n\n\t\tcase \"keepalive_idle_conns_per_host\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tnum, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad integer value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tif h.KeepAlive == nil {\n\t\t\t\th.KeepAlive = new(KeepAlive)\n\t\t\t}\n\t\t\th.KeepAlive.MaxIdleConnsPerHost = num\n\n\t\tcase \"versions\":\n\t\t\th.Versions = d.RemainingArgs()\n\t\t\tif len(h.Versions) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"compression\":\n\t\t\tif d.NextArg() {\n\t\t\t\tif d.Val() == \"off\" {\n\t\t\t\t\tvar disable bool\n\t\t\t\t\th.Compression = &disable\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase \"max_conns_per_host\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tnum, err := strconv.Atoi(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad integer value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\th.MaxConnsPerHost = num\n\n\t\tcase \"tls_trust_pool\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tmodStem := d.Val()\n\t\t\tmodID := \"tls.ca_pool.source.\" + modStem\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tca, ok := unm.(caddytls.CA)\n\t\t\tif !ok {\n\t\t\t\treturn d.Errf(\"module %s is not a caddytls.CA\", modID)\n\t\t\t}\n\t\t\tif h.TLS == nil {\n\t\t\t\th.TLS = new(TLSConfig)\n\t\t\t}\n\t\t\tif len(h.TLS.RootCAPEMFiles) != 0 {\n\t\t\t\treturn d.Err(\"cannot specify both 'tls_trust_pool' and 'tls_trusted_ca_certs'\")\n\t\t\t}\n\t\t\tif h.TLS.CARaw != nil {\n\t\t\t\treturn d.Err(\"cannot specify \\\"tls_trust_pool\\\" twice in caddyfile\")\n\t\t\t}\n\t\t\th.TLS.CARaw = caddyconfig.JSONModuleObject(ca, \"provider\", modStem, nil)\n\t\tcase \"local_address\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\th.LocalAddress = d.Val()\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective %s\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc parseCopyResponseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\tcrh := new(CopyResponseHandler)\n\terr := crh.UnmarshalCaddyfile(h.Dispenser)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn crh, nil\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens. Syntax:\n//\n//\tcopy_response [<matcher>] [<status>] {\n//\t    status <status>\n//\t}\nfunc (h *CopyResponseHandler) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume directive name\n\n\targs := d.RemainingArgs()\n\tif len(args) == 1 {\n\t\tif num, err := strconv.Atoi(args[0]); err == nil && num > 0 {\n\t\t\th.StatusCode = caddyhttp.WeakString(args[0])\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"status\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\th.StatusCode = caddyhttp.WeakString(d.Val())\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc parseCopyResponseHeadersCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\tcrh := new(CopyResponseHeadersHandler)\n\terr := crh.UnmarshalCaddyfile(h.Dispenser)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn crh, nil\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens. Syntax:\n//\n//\tcopy_response_headers [<matcher>] {\n//\t    include <fields...>\n//\t    exclude <fields...>\n//\t}\nfunc (h *CopyResponseHeadersHandler) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume directive name\n\n\targs := d.RemainingArgs()\n\tif len(args) > 0 {\n\t\treturn d.ArgErr()\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"include\":\n\t\t\th.Include = append(h.Include, d.RemainingArgs()...)\n\n\t\tcase \"exclude\":\n\t\t\th.Exclude = append(h.Exclude, d.RemainingArgs()...)\n\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into h.\n//\n//\tdynamic srv [<name>] {\n//\t    service             <service>\n//\t    proto               <proto>\n//\t    name                <name>\n//\t    refresh             <interval>\n//\t    resolvers           <resolvers...>\n//\t    dial_timeout        <timeout>\n//\t    dial_fallback_delay <timeout>\n//\t    grace_period        <duration>\n//\t}\nfunc (u *SRVUpstreams) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume upstream source name\n\n\targs := d.RemainingArgs()\n\tif len(args) > 1 {\n\t\treturn d.ArgErr()\n\t}\n\tif len(args) > 0 {\n\t\tu.Name = args[0]\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"service\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif u.Service != \"\" {\n\t\t\t\treturn d.Errf(\"srv service has already been specified\")\n\t\t\t}\n\t\t\tu.Service = d.Val()\n\n\t\tcase \"proto\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif u.Proto != \"\" {\n\t\t\t\treturn d.Errf(\"srv proto has already been specified\")\n\t\t\t}\n\t\t\tu.Proto = d.Val()\n\n\t\tcase \"name\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif u.Name != \"\" {\n\t\t\t\treturn d.Errf(\"srv name has already been specified\")\n\t\t\t}\n\t\t\tu.Name = d.Val()\n\n\t\tcase \"refresh\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"parsing refresh interval duration: %v\", err)\n\t\t\t}\n\t\t\tu.Refresh = caddy.Duration(dur)\n\n\t\tcase \"resolvers\":\n\t\t\tif u.Resolver == nil {\n\t\t\t\tu.Resolver = new(UpstreamResolver)\n\t\t\t}\n\t\t\tu.Resolver.Addresses = d.RemainingArgs()\n\t\t\tif len(u.Resolver.Addresses) == 0 {\n\t\t\t\treturn d.Errf(\"must specify at least one resolver address\")\n\t\t\t}\n\n\t\tcase \"dial_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tu.DialTimeout = caddy.Duration(dur)\n\n\t\tcase \"dial_fallback_delay\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad delay value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tu.FallbackDelay = caddy.Duration(dur)\n\t\tcase \"grace_period\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad grace period value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tu.GracePeriod = caddy.Duration(dur)\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized srv option '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into h.\n//\n//\tdynamic a [<name> <port] {\n//\t    name                <name>\n//\t    port                <port>\n//\t    refresh             <interval>\n//\t    resolvers           <resolvers...>\n//\t    dial_timeout        <timeout>\n//\t    dial_fallback_delay <timeout>\n//\t    versions            ipv4|ipv6\n//\t}\nfunc (u *AUpstreams) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume upstream source name\n\n\targs := d.RemainingArgs()\n\tif len(args) > 2 {\n\t\treturn d.ArgErr()\n\t}\n\tif len(args) > 0 {\n\t\tu.Name = args[0]\n\t\tif len(args) == 2 {\n\t\t\tu.Port = args[1]\n\t\t}\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"name\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif u.Name != \"\" {\n\t\t\t\treturn d.Errf(\"a name has already been specified\")\n\t\t\t}\n\t\t\tu.Name = d.Val()\n\n\t\tcase \"port\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif u.Port != \"\" {\n\t\t\t\treturn d.Errf(\"a port has already been specified\")\n\t\t\t}\n\t\t\tu.Port = d.Val()\n\n\t\tcase \"refresh\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"parsing refresh interval duration: %v\", err)\n\t\t\t}\n\t\t\tu.Refresh = caddy.Duration(dur)\n\n\t\tcase \"resolvers\":\n\t\t\tif u.Resolver == nil {\n\t\t\t\tu.Resolver = new(UpstreamResolver)\n\t\t\t}\n\t\t\tu.Resolver.Addresses = d.RemainingArgs()\n\t\t\tif len(u.Resolver.Addresses) == 0 {\n\t\t\t\treturn d.Errf(\"must specify at least one resolver address\")\n\t\t\t}\n\n\t\tcase \"dial_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tu.DialTimeout = caddy.Duration(dur)\n\n\t\tcase \"dial_fallback_delay\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad delay value '%s': %v\", d.Val(), err)\n\t\t\t}\n\t\t\tu.FallbackDelay = caddy.Duration(dur)\n\n\t\tcase \"versions\":\n\t\t\targs := d.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn d.Errf(\"must specify at least one version\")\n\t\t\t}\n\n\t\t\tif u.Versions == nil {\n\t\t\t\tu.Versions = &IPVersions{}\n\t\t\t}\n\n\t\t\ttrueBool := true\n\t\t\tfor _, arg := range args {\n\t\t\t\tswitch arg {\n\t\t\t\tcase \"ipv4\":\n\t\t\t\t\tu.Versions.IPv4 = &trueBool\n\t\t\t\tcase \"ipv6\":\n\t\t\t\t\tu.Versions.IPv6 = &trueBool\n\t\t\t\tdefault:\n\t\t\t\t\treturn d.Errf(\"unsupported version: '%s'\", arg)\n\t\t\t\t}\n\t\t\t}\n\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized a option '%s'\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into h.\n//\n//\tdynamic multi {\n//\t    <source> [...]\n//\t}\nfunc (u *MultiUpstreams) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume upstream source name\n\n\tif d.NextArg() {\n\t\treturn d.ArgErr()\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tdynModule := d.Val()\n\t\tmodID := \"http.reverse_proxy.upstreams.\" + dynModule\n\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\tsource, ok := unm.(UpstreamSource)\n\t\tif !ok {\n\t\t\treturn d.Errf(\"module %s (%T) is not an UpstreamSource\", modID, unm)\n\t\t}\n\t\tu.SourcesRaw = append(u.SourcesRaw, caddyconfig.JSONModuleObject(source, \"source\", dynModule, nil))\n\t}\n\treturn nil\n}\n\nconst matcherPrefix = \"@\"\n\n// Interface guards\nvar (\n\t_ caddyfile.Unmarshaler = (*Handler)(nil)\n\t_ caddyfile.Unmarshaler = (*HTTPTransport)(nil)\n\t_ caddyfile.Unmarshaler = (*SRVUpstreams)(nil)\n\t_ caddyfile.Unmarshaler = (*AUpstreams)(nil)\n\t_ caddyfile.Unmarshaler = (*MultiUpstreams)(nil)\n)\n",
    "source_file": "modules/caddyhttp/reverseproxy/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage reverseproxy\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"net/url\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\ntype parsedAddr struct {\n\tnetwork, scheme, host, port string\n\tvalid                       bool\n}\n\nfunc (p parsedAddr) dialAddr() string {\n\tif !p.valid {\n\t\treturn \"\"\n\t}\n\t// for simplest possible config, we only need to include\n\t// the network portion if the user specified one\n\tif p.network != \"\" {\n\t\treturn caddy.JoinNetworkAddress(p.network, p.host, p.port)\n\t}\n\n\t// if the host is a placeholder, then we don't want to join with an empty port,\n\t// because that would just append an extra ':' at the end of the address.\n\tif p.port == \"\" && strings.Contains(p.host, \"{\") {\n\t\treturn p.host\n\t}\n\treturn net.JoinHostPort(p.host, p.port)\n}\n\nfunc (p parsedAddr) rangedPort() bool {\n\treturn strings.Contains(p.port, \"-\")\n}\n\nfunc (p parsedAddr) replaceablePort() bool {\n\treturn strings.Contains(p.port, \"{\") && strings.Contains(p.port, \"}\")\n}\n\nfunc (p parsedAddr) isUnix() bool {\n\treturn caddy.IsUnixNetwork(p.network)\n}\n\n// parseUpstreamDialAddress parses configuration inputs for\n// the dial address, including support for a scheme in front\n// as a shortcut for the port number, and a network type,\n// for example 'unix' to dial a unix socket.\nfunc parseUpstreamDialAddress(upstreamAddr string) (parsedAddr, error) {\n\tvar network, scheme, host, port string\n\n\tif strings.Contains(upstreamAddr, \"://\") {\n\t\t// we get a parsing error if a placeholder is specified\n\t\t// so we return a more user-friendly error message instead\n\t\t// to explain what to do instead\n\t\tif strings.Contains(upstreamAddr, \"{\") {\n\t\t\treturn parsedAddr{}, fmt.Errorf(\"due to parsing difficulties, placeholders are not allowed when an upstream address contains a scheme\")\n\t\t}\n\n\t\ttoURL, err := url.Parse(upstreamAddr)\n\t\tif err != nil {\n\t\t\t// if the error seems to be due to a port range,\n\t\t\t// try to replace the port range with a dummy\n\t\t\t// single port so that url.Parse() will succeed\n\t\t\tif strings.Contains(err.Error(), \"invalid port\") && strings.Contains(err.Error(), \"-\") {\n\t\t\t\tindex := strings.LastIndex(upstreamAddr, \":\")\n\t\t\t\tif index == -1 {\n\t\t\t\t\treturn parsedAddr{}, fmt.Errorf(\"parsing upstream URL: %v\", err)\n\t\t\t\t}\n\t\t\t\tportRange := upstreamAddr[index+1:]\n\t\t\t\tif strings.Count(portRange, \"-\") != 1 {\n\t\t\t\t\treturn parsedAddr{}, fmt.Errorf(\"parsing upstream URL: parse \\\"%v\\\": port range invalid: %v\", upstreamAddr, portRange)\n\t\t\t\t}\n\t\t\t\ttoURL, err = url.Parse(strings.ReplaceAll(upstreamAddr, portRange, \"0\"))\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn parsedAddr{}, fmt.Errorf(\"parsing upstream URL: %v\", err)\n\t\t\t\t}\n\t\t\t\tport = portRange\n\t\t\t} else {\n\t\t\t\treturn parsedAddr{}, fmt.Errorf(\"parsing upstream URL: %v\", err)\n\t\t\t}\n\t\t}\n\t\tif port == \"\" {\n\t\t\tport = toURL.Port()\n\t\t}\n\n\t\t// there is currently no way to perform a URL rewrite between choosing\n\t\t// a backend and proxying to it, so we cannot allow extra components\n\t\t// in backend URLs\n\t\tif toURL.Path != \"\" || toURL.RawQuery != \"\" || toURL.Fragment != \"\" {\n\t\t\treturn parsedAddr{}, fmt.Errorf(\"for now, URLs for proxy upstreams only support scheme, host, and port components\")\n\t\t}\n\n\t\t// ensure the port and scheme aren't in conflict\n\t\tif toURL.Scheme == \"http\" && port == \"443\" {\n\t\t\treturn parsedAddr{}, fmt.Errorf(\"upstream address has conflicting scheme (http://) and port (:443, the HTTPS port)\")\n\t\t}\n\t\tif toURL.Scheme == \"https\" && port == \"80\" {\n\t\t\treturn parsedAddr{}, fmt.Errorf(\"upstream address has conflicting scheme (https://) and port (:80, the HTTP port)\")\n\t\t}\n\t\tif toURL.Scheme == \"h2c\" && port == \"443\" {\n\t\t\treturn parsedAddr{}, fmt.Errorf(\"upstream address has conflicting scheme (h2c://) and port (:443, the HTTPS port)\")\n\t\t}\n\n\t\t// if port is missing, attempt to infer from scheme\n\t\tif port == \"\" {\n\t\t\tswitch toURL.Scheme {\n\t\t\tcase \"\", \"http\", \"h2c\":\n\t\t\t\tport = \"80\"\n\t\t\tcase \"https\":\n\t\t\t\tport = \"443\"\n\t\t\t}\n\t\t}\n\n\t\tscheme, host = toURL.Scheme, toURL.Hostname()\n\t} else {\n\t\tvar err error\n\t\tnetwork, host, port, err = caddy.SplitNetworkAddress(upstreamAddr)\n\t\tif err != nil {\n\t\t\thost = upstreamAddr\n\t\t}\n\t\t// we can assume a port if only a hostname is specified, but use of a\n\t\t// placeholder without a port likely means a port will be filled in\n\t\tif port == \"\" && !strings.Contains(host, \"{\") && !caddy.IsUnixNetwork(network) && !caddy.IsFdNetwork(network) {\n\t\t\tport = \"80\"\n\t\t}\n\t}\n\n\t// special case network to support both unix and h2c at the same time\n\tif network == \"unix+h2c\" {\n\t\tnetwork = \"unix\"\n\t\tscheme = \"h2c\"\n\t}\n\treturn parsedAddr{network, scheme, host, port, true}, nil\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/addresses.go",
    "chunk_type": "code"
  },
  {
    "content": "package standard\n\nimport (\n\t// standard Caddy HTTP app modules\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/caddyauth\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode/brotli\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode/gzip\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode/zstd\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/fileserver\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/headers\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/intercept\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/logging\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/map\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/proxyprotocol\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/push\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/requestbody\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/reverseproxy\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/reverseproxy/fastcgi\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/reverseproxy/forwardauth\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/rewrite\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/templates\"\n\t_ \"github.com/caddyserver/caddy/v2/modules/caddyhttp/tracing\"\n)\n",
    "source_file": "modules/caddyhttp/standard/imports.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage push\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/headers\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Handler{})\n}\n\n// Handler is a middleware for HTTP/2 server push. Note that\n// HTTP/2 server push has been deprecated by some clients and\n// its use is discouraged unless you can accurately predict\n// which resources actually need to be pushed to the client;\n// it can be difficult to know what the client already has\n// cached. Pushing unnecessary resources results in worse\n// performance. Consider using HTTP 103 Early Hints instead.\n//\n// This handler supports pushing from Link headers; in other\n// words, if the eventual response has Link headers, this\n// handler will push the resources indicated by those headers,\n// even without specifying any resources in its config.\ntype Handler struct {\n\t// The resources to push.\n\tResources []Resource `json:\"resources,omitempty\"`\n\n\t// Headers to modify for the push requests.\n\tHeaders *HeaderConfig `json:\"headers,omitempty\"`\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Handler) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.push\",\n\t\tNew: func() caddy.Module { return new(Handler) },\n\t}\n}\n\n// Provision sets up h.\nfunc (h *Handler) Provision(ctx caddy.Context) error {\n\th.logger = ctx.Logger()\n\tif h.Headers != nil {\n\t\terr := h.Headers.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"provisioning header operations: %v\", err)\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (h Handler) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\tpusher, ok := w.(http.Pusher)\n\tif !ok {\n\t\treturn next.ServeHTTP(w, r)\n\t}\n\n\t// short-circuit recursive pushes\n\tif _, ok := r.Header[pushHeader]; ok {\n\t\treturn next.ServeHTTP(w, r)\n\t}\n\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tserver := r.Context().Value(caddyhttp.ServerCtxKey).(*caddyhttp.Server)\n\tshouldLogCredentials := server.Logs != nil && server.Logs.ShouldLogCredentials\n\n\t// create header for push requests\n\thdr := h.initializePushHeaders(r, repl)\n\n\t// push first!\n\tfor _, resource := range h.Resources {\n\t\tif c := h.logger.Check(zapcore.DebugLevel, \"pushing resource\"); c != nil {\n\t\t\tc.Write(\n\t\t\t\tzap.String(\"uri\", r.RequestURI),\n\t\t\t\tzap.String(\"push_method\", resource.Method),\n\t\t\t\tzap.String(\"push_target\", resource.Target),\n\t\t\t\tzap.Object(\"push_headers\", caddyhttp.LoggableHTTPHeader{\n\t\t\t\t\tHeader:               hdr,\n\t\t\t\t\tShouldLogCredentials: shouldLogCredentials,\n\t\t\t\t}),\n\t\t\t)\n\t\t}\n\t\terr := pusher.Push(repl.ReplaceAll(resource.Target, \".\"), &http.PushOptions{\n\t\t\tMethod: resource.Method,\n\t\t\tHeader: hdr,\n\t\t})\n\t\tif err != nil {\n\t\t\t// usually this means either that push is not\n\t\t\t// supported or concurrent streams are full\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// wrap the response writer so that we can initiate push of any resources\n\t// described in Link header fields before the response is written\n\tlp := linkPusher{\n\t\tResponseWriterWrapper: &caddyhttp.ResponseWriterWrapper{ResponseWriter: w},\n\t\thandler:               h,\n\t\tpusher:                pusher,\n\t\theader:                hdr,\n\t\trequest:               r,\n\t}\n\n\t// serve only after pushing!\n\tif err := next.ServeHTTP(lp, r); err != nil {\n\t\treturn err\n\t}\n\n\treturn nil\n}\n\nfunc (h Handler) initializePushHeaders(r *http.Request, repl *caddy.Replacer) http.Header {\n\thdr := make(http.Header)\n\n\t// prevent recursive pushes\n\thdr.Set(pushHeader, \"1\")\n\n\t// set initial header fields; since exactly how headers should\n\t// be implemented for server push is not well-understood, we\n\t// are being conservative for now like httpd is:\n\t// https://httpd.apache.org/docs/2.4/en/howto/http2.html#push\n\t// we only copy some well-known, safe headers that are likely\n\t// crucial when requesting certain kinds of content\n\tfor _, fieldName := range safeHeaders {\n\t\tif vals, ok := r.Header[fieldName]; ok {\n\t\t\thdr[fieldName] = vals\n\t\t}\n\t}\n\n\t// user can customize the push request headers\n\tif h.Headers != nil {\n\t\th.Headers.ApplyTo(hdr, repl)\n\t}\n\n\treturn hdr\n}\n\n// servePreloadLinks parses Link headers from upstream and pushes\n// resources described by them. If a resource has the \"nopush\"\n// attribute or describes an external entity (meaning, the resource\n// URI includes a scheme), it will not be pushed.\nfunc (h Handler) servePreloadLinks(pusher http.Pusher, hdr http.Header, resources []string) {\n\tfor _, resource := range resources {\n\t\tfor _, resource := range parseLinkHeader(resource) {\n\t\t\tif _, ok := resource.params[\"nopush\"]; ok {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif isRemoteResource(resource.uri) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\terr := pusher.Push(resource.uri, &http.PushOptions{\n\t\t\t\tHeader: hdr,\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n}\n\n// Resource represents a request for a resource to push.\ntype Resource struct {\n\t// Method is the request method, which must be GET or HEAD.\n\t// Default is GET.\n\tMethod string `json:\"method,omitempty\"`\n\n\t// Target is the path to the resource being pushed.\n\tTarget string `json:\"target,omitempty\"`\n}\n\n// HeaderConfig configures headers for synthetic push requests.\ntype HeaderConfig struct {\n\theaders.HeaderOps\n}\n\n// linkPusher is a http.ResponseWriter that intercepts\n// the WriteHeader() call to ensure that any resources\n// described by Link response headers get pushed before\n// the response is allowed to be written.\ntype linkPusher struct {\n\t*caddyhttp.ResponseWriterWrapper\n\thandler Handler\n\tpusher  http.Pusher\n\theader  http.Header\n\trequest *http.Request\n}\n\nfunc (lp linkPusher) WriteHeader(statusCode int) {\n\tif links, ok := lp.ResponseWriter.Header()[\"Link\"]; ok {\n\t\t// only initiate these pushes if it hasn't been done yet\n\t\tif val := caddyhttp.GetVar(lp.request.Context(), pushedLink); val == nil {\n\t\t\tif c := lp.handler.logger.Check(zapcore.DebugLevel, \"pushing Link resources\"); c != nil {\n\t\t\t\tc.Write(zap.Strings(\"linked\", links))\n\t\t\t}\n\t\t\tcaddyhttp.SetVar(lp.request.Context(), pushedLink, true)\n\t\t\tlp.handler.servePreloadLinks(lp.pusher, lp.header, links)\n\t\t}\n\t}\n\tlp.ResponseWriter.WriteHeader(statusCode)\n}\n\n// isRemoteResource returns true if resource starts with\n// a scheme or is a protocol-relative URI.\nfunc isRemoteResource(resource string) bool {\n\treturn strings.HasPrefix(resource, \"//\") ||\n\t\tstrings.HasPrefix(resource, \"http://\") ||\n\t\tstrings.HasPrefix(resource, \"https://\")\n}\n\n// safeHeaders is a list of header fields that are\n// safe to copy to push requests implicitly. It is\n// assumed that requests for certain kinds of content\n// would fail without these fields present.\nvar safeHeaders = []string{\n\t\"Accept-Encoding\",\n\t\"Accept-Language\",\n\t\"Accept\",\n\t\"Cache-Control\",\n\t\"User-Agent\",\n}\n\n// pushHeader is a header field that gets added to push requests\n// in order to avoid recursive/infinite pushes.\nconst pushHeader = \"Caddy-Push\"\n\n// pushedLink is the key for the variable on the request\n// context that we use to remember whether we have already\n// pushed resources from Link headers yet; otherwise, if\n// multiple push handlers are invoked, it would repeat the\n// pushing of Link headers.\nconst pushedLink = \"http.handlers.push.pushed_link\"\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*Handler)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*Handler)(nil)\n\t_ http.ResponseWriter         = (*linkPusher)(nil)\n\t_ http.Pusher                 = (*linkPusher)(nil)\n)\n",
    "source_file": "modules/caddyhttp/push/handler.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage push\n\nimport (\n\t\"strings\"\n)\n\n// linkResource contains the results of a parsed Link header.\ntype linkResource struct {\n\turi    string\n\tparams map[string]string\n}\n\n// parseLinkHeader is responsible for parsing Link header\n// and returning list of found resources.\n//\n// Accepted formats are:\n//\n//\tLink: <resource>; as=script\n//\tLink: <resource>; as=script,<resource>; as=style\n//\tLink: <resource>;<resource2>\n//\n// where <resource> begins with a forward slash (/).\nfunc parseLinkHeader(header string) []linkResource {\n\tresources := []linkResource{}\n\n\tif header == \"\" {\n\t\treturn resources\n\t}\n\n\tfor _, link := range strings.Split(header, comma) {\n\t\tl := linkResource{params: make(map[string]string)}\n\n\t\tli, ri := strings.Index(link, \"<\"), strings.Index(link, \">\")\n\t\tif li == -1 || ri == -1 {\n\t\t\tcontinue\n\t\t}\n\n\t\tl.uri = strings.TrimSpace(link[li+1 : ri])\n\n\t\tfor _, param := range strings.Split(strings.TrimSpace(link[ri+1:]), semicolon) {\n\t\t\tbefore, after, isCut := strings.Cut(strings.TrimSpace(param), equal)\n\t\t\tkey := strings.TrimSpace(before)\n\t\t\tif key == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif isCut {\n\t\t\t\tl.params[key] = strings.TrimSpace(after)\n\t\t\t} else {\n\t\t\t\tl.params[key] = key\n\t\t\t}\n\t\t}\n\n\t\tresources = append(resources, l)\n\t}\n\n\treturn resources\n}\n\nconst (\n\tcomma     = \",\"\n\tsemicolon = \";\"\n\tequal     = \"=\"\n)\n",
    "source_file": "modules/caddyhttp/push/link.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage push\n\nimport (\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/headers\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterHandlerDirective(\"push\", parseCaddyfile)\n}\n\n// parseCaddyfile sets up the push handler. Syntax:\n//\n//\tpush [<matcher>] [<resource>] {\n//\t    [GET|HEAD] <resource>\n//\t    headers {\n//\t        [+]<field> [<value|regexp> [<replacement>]]\n//\t        -<field>\n//\t    }\n//\t}\n//\n// A single resource can be specified inline without opening a\n// block for the most common/simple case. Or, a block can be\n// opened and multiple resources can be specified, one per\n// line, optionally preceded by the method. The headers\n// subdirective can be used to customize the headers that\n// are set on each (synthetic) push request, using the same\n// syntax as the 'header' directive for request headers.\n// Placeholders are accepted in resource and header field\n// name and value and replacement tokens.\nfunc parseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\n\thandler := new(Handler)\n\n\t// inline resources\n\tif h.NextArg() {\n\t\thandler.Resources = append(handler.Resources, Resource{Target: h.Val()})\n\t}\n\n\t// optional block\n\tfor h.NextBlock(0) {\n\t\tswitch h.Val() {\n\t\tcase \"headers\":\n\t\t\tif h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tfor nesting := h.Nesting(); h.NextBlock(nesting); {\n\t\t\t\tvar err error\n\n\t\t\t\t// include current token, which we treat as an argument here\n\t\t\t\targs := []string{h.Val()}\n\t\t\t\targs = append(args, h.RemainingArgs()...)\n\n\t\t\t\tif handler.Headers == nil {\n\t\t\t\t\thandler.Headers = new(HeaderConfig)\n\t\t\t\t}\n\n\t\t\t\tswitch len(args) {\n\t\t\t\tcase 1:\n\t\t\t\t\terr = headers.CaddyfileHeaderOp(&handler.Headers.HeaderOps, args[0], \"\", nil)\n\t\t\t\tcase 2:\n\t\t\t\t\terr = headers.CaddyfileHeaderOp(&handler.Headers.HeaderOps, args[0], args[1], nil)\n\t\t\t\tcase 3:\n\t\t\t\t\terr = headers.CaddyfileHeaderOp(&handler.Headers.HeaderOps, args[0], args[1], &args[2])\n\t\t\t\tdefault:\n\t\t\t\t\treturn nil, h.ArgErr()\n\t\t\t\t}\n\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, h.Err(err.Error())\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase \"GET\", \"HEAD\":\n\t\t\tmethod := h.Val()\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\ttarget := h.Val()\n\t\t\thandler.Resources = append(handler.Resources, Resource{\n\t\t\t\tMethod: method,\n\t\t\t\tTarget: target,\n\t\t\t})\n\n\t\tdefault:\n\t\t\thandler.Resources = append(handler.Resources, Resource{Target: h.Val()})\n\t\t}\n\t}\n\treturn handler, nil\n}\n",
    "source_file": "modules/caddyhttp/push/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage requestbody\n\nimport (\n\t\"errors\"\n\t\"io\"\n\t\"net/http\"\n\t\"strings\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(RequestBody{})\n}\n\n// RequestBody is a middleware for manipulating the request body.\ntype RequestBody struct {\n\t// The maximum number of bytes to allow reading from the body by a later handler.\n\t// If more bytes are read, an error with HTTP status 413 is returned.\n\tMaxSize int64 `json:\"max_size,omitempty\"`\n\n\t// EXPERIMENTAL. Subject to change/removal.\n\tReadTimeout time.Duration `json:\"read_timeout,omitempty\"`\n\n\t// EXPERIMENTAL. Subject to change/removal.\n\tWriteTimeout time.Duration `json:\"write_timeout,omitempty\"`\n\n\t// This field permit to replace body on the fly\n\t// EXPERIMENTAL. Subject to change/removal.\n\tSet string `json:\"set,omitempty\"`\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (RequestBody) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.request_body\",\n\t\tNew: func() caddy.Module { return new(RequestBody) },\n\t}\n}\n\nfunc (rb *RequestBody) Provision(ctx caddy.Context) error {\n\trb.logger = ctx.Logger()\n\treturn nil\n}\n\nfunc (rb RequestBody) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\tif rb.Set != \"\" {\n\t\tif r.Body != nil {\n\t\t\terr := r.Body.Close()\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\t\treplacedBody := repl.ReplaceAll(rb.Set, \"\")\n\t\tr.Body = io.NopCloser(strings.NewReader(replacedBody))\n\t\tr.ContentLength = int64(len(replacedBody))\n\t}\n\tif r.Body == nil {\n\t\treturn next.ServeHTTP(w, r)\n\t}\n\tif rb.MaxSize > 0 {\n\t\tr.Body = errorWrapper{http.MaxBytesReader(w, r.Body, rb.MaxSize)}\n\t}\n\tif rb.ReadTimeout > 0 || rb.WriteTimeout > 0 {\n\t\t//nolint:bodyclose\n\t\trc := http.NewResponseController(w)\n\t\tif rb.ReadTimeout > 0 {\n\t\t\tif err := rc.SetReadDeadline(time.Now().Add(rb.ReadTimeout)); err != nil {\n\t\t\t\tif c := rb.logger.Check(zapcore.ErrorLevel, \"could not set read deadline\"); c != nil {\n\t\t\t\t\tc.Write(zap.Error(err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif rb.WriteTimeout > 0 {\n\t\t\tif err := rc.SetWriteDeadline(time.Now().Add(rb.WriteTimeout)); err != nil {\n\t\t\t\tif c := rb.logger.Check(zapcore.ErrorLevel, \"could not set write deadline\"); c != nil {\n\t\t\t\t\tc.Write(zap.Error(err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn next.ServeHTTP(w, r)\n}\n\n// errorWrapper wraps errors that are returned from Read()\n// so that they can be associated with a proper status code.\ntype errorWrapper struct {\n\tio.ReadCloser\n}\n\nfunc (ew errorWrapper) Read(p []byte) (n int, err error) {\n\tn, err = ew.ReadCloser.Read(p)\n\tvar mbe *http.MaxBytesError\n\tif errors.As(err, &mbe) {\n\t\terr = caddyhttp.Error(http.StatusRequestEntityTooLarge, err)\n\t}\n\treturn\n}\n\n// Interface guard\nvar _ caddyhttp.MiddlewareHandler = (*RequestBody)(nil)\n",
    "source_file": "modules/caddyhttp/requestbody/requestbody.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage requestbody\n\nimport (\n\t\"time\"\n\n\t\"github.com/dustin/go-humanize\"\n\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterHandlerDirective(\"request_body\", parseCaddyfile)\n}\n\nfunc parseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\n\trb := new(RequestBody)\n\n\t// configuration should be in a block\n\tfor h.NextBlock(0) {\n\t\tswitch h.Val() {\n\t\tcase \"max_size\":\n\t\t\tvar sizeStr string\n\t\t\tif !h.AllArgs(&sizeStr) {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tsize, err := humanize.ParseBytes(sizeStr)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, h.Errf(\"parsing max_size: %v\", err)\n\t\t\t}\n\t\t\trb.MaxSize = int64(size)\n\n\t\tcase \"read_timeout\":\n\t\t\tvar timeoutStr string\n\t\t\tif !h.AllArgs(&timeoutStr) {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\ttimeout, err := time.ParseDuration(timeoutStr)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, h.Errf(\"parsing read_timeout: %v\", err)\n\t\t\t}\n\t\t\trb.ReadTimeout = timeout\n\n\t\tcase \"write_timeout\":\n\t\t\tvar timeoutStr string\n\t\t\tif !h.AllArgs(&timeoutStr) {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\ttimeout, err := time.ParseDuration(timeoutStr)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, h.Errf(\"parsing write_timeout: %v\", err)\n\t\t\t}\n\t\t\trb.WriteTimeout = timeout\n\n\t\tcase \"set\":\n\t\t\tvar setStr string\n\t\t\tif !h.AllArgs(&setStr) {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\trb.Set = setStr\n\t\tdefault:\n\t\t\treturn nil, h.Errf(\"unrecognized request_body subdirective '%s'\", h.Val())\n\t\t}\n\t}\n\n\treturn rb, nil\n}\n",
    "source_file": "modules/caddyhttp/requestbody/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fileserver\n\nimport (\n\t\"fmt\"\n\t\"io/fs\"\n\t\"net/http\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/google/cel-go/cel\"\n\t\"github.com/google/cel-go/common\"\n\t\"github.com/google/cel-go/common/ast\"\n\t\"github.com/google/cel-go/common/operators\"\n\t\"github.com/google/cel-go/common/types\"\n\t\"github.com/google/cel-go/common/types/ref\"\n\t\"github.com/google/cel-go/parser\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(MatchFile{})\n}\n\n// MatchFile is an HTTP request matcher that can match\n// requests based upon file existence.\n//\n// Upon matching, three new placeholders will be made\n// available:\n//\n// - `{http.matchers.file.relative}` The root-relative\n// path of the file. This is often useful when rewriting\n// requests.\n// - `{http.matchers.file.absolute}` The absolute path\n// of the matched file.\n// - `{http.matchers.file.type}` Set to \"directory\" if\n// the matched file is a directory, \"file\" otherwise.\n// - `{http.matchers.file.remainder}` Set to the remainder\n// of the path if the path was split by `split_path`.\n//\n// Even though file matching may depend on the OS path\n// separator, the placeholder values always use /.\ntype MatchFile struct {\n\t// The file system implementation to use. By default, the\n\t// local disk file system will be used.\n\tFileSystem string `json:\"fs,omitempty\"`\n\n\t// The root directory, used for creating absolute\n\t// file paths, and required when working with\n\t// relative paths; if not specified, `{http.vars.root}`\n\t// will be used, if set; otherwise, the current\n\t// directory is assumed. Accepts placeholders.\n\tRoot string `json:\"root,omitempty\"`\n\n\t// The list of files to try. Each path here is\n\t// considered related to Root. If nil, the request\n\t// URL's path will be assumed. Files and\n\t// directories are treated distinctly, so to match\n\t// a directory, the filepath MUST end in a forward\n\t// slash `/`. To match a regular file, there must\n\t// be no trailing slash. Accepts placeholders. If\n\t// the policy is \"first_exist\", then an error may\n\t// be triggered as a fallback by configuring \"=\"\n\t// followed by a status code number,\n\t// for example \"=404\".\n\tTryFiles []string `json:\"try_files,omitempty\"`\n\n\t// How to choose a file in TryFiles. Can be:\n\t//\n\t// - first_exist\n\t// - first_exist_fallback\n\t// - smallest_size\n\t// - largest_size\n\t// - most_recently_modified\n\t//\n\t// Default is first_exist.\n\tTryPolicy string `json:\"try_policy,omitempty\"`\n\n\t// A list of delimiters to use to split the path in two\n\t// when trying files. If empty, no splitting will\n\t// occur, and the path will be tried as-is. For each\n\t// split value, the left-hand side of the split,\n\t// including the split value, will be the path tried.\n\t// For example, the path `/remote.php/dav/` using the\n\t// split value `.php` would try the file `/remote.php`.\n\t// Each delimiter must appear at the end of a URI path\n\t// component in order to be used as a split delimiter.\n\tSplitPath []string `json:\"split_path,omitempty\"`\n\n\tfsmap caddy.FileSystems\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (MatchFile) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.matchers.file\",\n\t\tNew: func() caddy.Module { return new(MatchFile) },\n\t}\n}\n\n// UnmarshalCaddyfile sets up the matcher from Caddyfile tokens. Syntax:\n//\n//\tfile <files...> {\n//\t    root      <path>\n//\t    try_files <files...>\n//\t    try_policy first_exist|smallest_size|largest_size|most_recently_modified\n//\t}\nfunc (m *MatchFile) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\t// iterate to merge multiple matchers into one\n\tfor d.Next() {\n\t\tm.TryFiles = append(m.TryFiles, d.RemainingArgs()...)\n\t\tfor d.NextBlock(0) {\n\t\t\tswitch d.Val() {\n\t\t\tcase \"root\":\n\t\t\t\tif !d.NextArg() {\n\t\t\t\t\treturn d.ArgErr()\n\t\t\t\t}\n\t\t\t\tm.Root = d.Val()\n\t\t\tcase \"try_files\":\n\t\t\t\tm.TryFiles = append(m.TryFiles, d.RemainingArgs()...)\n\t\t\t\tif len(m.TryFiles) == 0 {\n\t\t\t\t\treturn d.ArgErr()\n\t\t\t\t}\n\t\t\tcase \"try_policy\":\n\t\t\t\tif !d.NextArg() {\n\t\t\t\t\treturn d.ArgErr()\n\t\t\t\t}\n\t\t\t\tm.TryPolicy = d.Val()\n\t\t\tcase \"split_path\":\n\t\t\t\tm.SplitPath = d.RemainingArgs()\n\t\t\t\tif len(m.SplitPath) == 0 {\n\t\t\t\t\treturn d.ArgErr()\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn d.Errf(\"unrecognized subdirective: %s\", d.Val())\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// CELLibrary produces options that expose this matcher for use in CEL\n// expression matchers.\n//\n// Example:\n//\n//\texpression file()\n//\texpression file({http.request.uri.path}, '/index.php')\n//\texpression file({'root': '/srv', 'try_files': [{http.request.uri.path}, '/index.php'], 'try_policy': 'first_exist', 'split_path': ['.php']})\nfunc (MatchFile) CELLibrary(ctx caddy.Context) (cel.Library, error) {\n\trequestType := cel.ObjectType(\"http.Request\")\n\n\tmatcherFactory := func(data ref.Val) (caddyhttp.RequestMatcherWithError, error) {\n\t\tvalues, err := caddyhttp.CELValueToMapStrList(data)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tvar root string\n\t\tif len(values[\"root\"]) > 0 {\n\t\t\troot = values[\"root\"][0]\n\t\t}\n\n\t\tvar fsName string\n\t\tif len(values[\"fs\"]) > 0 {\n\t\t\tfsName = values[\"fs\"][0]\n\t\t}\n\n\t\tvar try_policy string\n\t\tif len(values[\"try_policy\"]) > 0 {\n\t\t\ttry_policy = values[\"try_policy\"][0]\n\t\t}\n\n\t\tm := MatchFile{\n\t\t\tRoot:       root,\n\t\t\tTryFiles:   values[\"try_files\"],\n\t\t\tTryPolicy:  try_policy,\n\t\t\tSplitPath:  values[\"split_path\"],\n\t\t\tFileSystem: fsName,\n\t\t}\n\n\t\terr = m.Provision(ctx)\n\t\treturn m, err\n\t}\n\n\tenvOptions := []cel.EnvOption{\n\t\tcel.Macros(parser.NewGlobalVarArgMacro(\"file\", celFileMatcherMacroExpander())),\n\t\tcel.Function(\"file\", cel.Overload(\"file_request_map\", []*cel.Type{requestType, caddyhttp.CELTypeJSON}, cel.BoolType)),\n\t\tcel.Function(\"file_request_map\",\n\t\t\tcel.Overload(\"file_request_map\", []*cel.Type{requestType, caddyhttp.CELTypeJSON}, cel.BoolType),\n\t\t\tcel.SingletonBinaryBinding(caddyhttp.CELMatcherRuntimeFunction(\"file_request_map\", matcherFactory))),\n\t}\n\n\tprogramOptions := []cel.ProgramOption{\n\t\tcel.CustomDecorator(caddyhttp.CELMatcherDecorator(\"file_request_map\", matcherFactory)),\n\t}\n\n\treturn caddyhttp.NewMatcherCELLibrary(envOptions, programOptions), nil\n}\n\nfunc celFileMatcherMacroExpander() parser.MacroExpander {\n\treturn func(eh parser.ExprHelper, target ast.Expr, args []ast.Expr) (ast.Expr, *common.Error) {\n\t\tif len(args) == 0 {\n\t\t\treturn eh.NewCall(\"file\",\n\t\t\t\teh.NewIdent(caddyhttp.CELRequestVarName),\n\t\t\t\teh.NewMap(),\n\t\t\t), nil\n\t\t}\n\t\tif len(args) == 1 {\n\t\t\targ := args[0]\n\t\t\tif isCELStringLiteral(arg) || isCELCaddyPlaceholderCall(arg) {\n\t\t\t\treturn eh.NewCall(\"file\",\n\t\t\t\t\teh.NewIdent(caddyhttp.CELRequestVarName),\n\t\t\t\t\teh.NewMap(eh.NewMapEntry(\n\t\t\t\t\t\teh.NewLiteral(types.String(\"try_files\")),\n\t\t\t\t\t\teh.NewList(arg),\n\t\t\t\t\t\tfalse,\n\t\t\t\t\t)),\n\t\t\t\t), nil\n\t\t\t}\n\t\t\tif isCELTryFilesLiteral(arg) {\n\t\t\t\treturn eh.NewCall(\"file\", eh.NewIdent(caddyhttp.CELRequestVarName), arg), nil\n\t\t\t}\n\t\t\treturn nil, &common.Error{\n\t\t\t\tLocation: eh.OffsetLocation(arg.ID()),\n\t\t\t\tMessage:  \"matcher requires either a map or string literal argument\",\n\t\t\t}\n\t\t}\n\n\t\tfor _, arg := range args {\n\t\t\tif !isCELStringLiteral(arg) && !isCELCaddyPlaceholderCall(arg) {\n\t\t\t\treturn nil, &common.Error{\n\t\t\t\t\tLocation: eh.OffsetLocation(arg.ID()),\n\t\t\t\t\tMessage:  \"matcher only supports repeated string literal arguments\",\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn eh.NewCall(\"file\",\n\t\t\teh.NewIdent(caddyhttp.CELRequestVarName),\n\t\t\teh.NewMap(eh.NewMapEntry(\n\t\t\t\teh.NewLiteral(types.String(\"try_files\")),\n\t\t\t\teh.NewList(args...),\n\t\t\t\tfalse,\n\t\t\t)),\n\t\t), nil\n\t}\n}\n\n// Provision sets up m's defaults.\nfunc (m *MatchFile) Provision(ctx caddy.Context) error {\n\tm.logger = ctx.Logger()\n\n\tm.fsmap = ctx.FileSystems()\n\n\tif m.Root == \"\" {\n\t\tm.Root = \"{http.vars.root}\"\n\t}\n\n\tif m.FileSystem == \"\" {\n\t\tm.FileSystem = \"{http.vars.fs}\"\n\t}\n\n\t// if list of files to try was omitted entirely, assume URL path\n\t// (use placeholder instead of r.URL.Path; see issue #4146)\n\tif m.TryFiles == nil {\n\t\tm.TryFiles = []string{\"{http.request.uri.path}\"}\n\t}\n\treturn nil\n}\n\n// Validate ensures m has a valid configuration.\nfunc (m MatchFile) Validate() error {\n\tswitch m.TryPolicy {\n\tcase \"\",\n\t\ttryPolicyFirstExist,\n\t\ttryPolicyFirstExistFallback,\n\t\ttryPolicyLargestSize,\n\t\ttryPolicySmallestSize,\n\t\ttryPolicyMostRecentlyMod:\n\tdefault:\n\t\treturn fmt.Errorf(\"unknown try policy %s\", m.TryPolicy)\n\t}\n\treturn nil\n}\n\n// Match returns true if r matches m. Returns true\n// if a file was matched. If so, four placeholders\n// will be available:\n//   - http.matchers.file.relative: Path to file relative to site root\n//   - http.matchers.file.absolute: Path to file including site root\n//   - http.matchers.file.type: file or directory\n//   - http.matchers.file.remainder: Portion remaining after splitting file path (if configured)\nfunc (m MatchFile) Match(r *http.Request) bool {\n\tmatch, err := m.selectFile(r)\n\tif err != nil {\n\t\t// nolint:staticcheck\n\t\tcaddyhttp.SetVar(r.Context(), caddyhttp.MatcherErrorVarKey, err)\n\t}\n\treturn match\n}\n\n// MatchWithError returns true if r matches m.\nfunc (m MatchFile) MatchWithError(r *http.Request) (bool, error) {\n\treturn m.selectFile(r)\n}\n\n// selectFile chooses a file according to m.TryPolicy by appending\n// the paths in m.TryFiles to m.Root, with placeholder replacements.\nfunc (m MatchFile) selectFile(r *http.Request) (bool, error) {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\troot := filepath.Clean(repl.ReplaceAll(m.Root, \".\"))\n\n\tfsName := repl.ReplaceAll(m.FileSystem, \"\")\n\n\tfileSystem, ok := m.fsmap.Get(fsName)\n\tif !ok {\n\t\tif c := m.logger.Check(zapcore.ErrorLevel, \"use of unregistered filesystem\"); c != nil {\n\t\t\tc.Write(zap.String(\"fs\", fsName))\n\t\t}\n\t\treturn false, nil\n\t}\n\ttype matchCandidate struct {\n\t\tfullpath, relative, splitRemainder string\n\t}\n\n\t// makeCandidates evaluates placeholders in file and expands any glob expressions\n\t// to build a list of file candidates. Special glob characters are escaped in\n\t// placeholder replacements so globs cannot be expanded from placeholders, and\n\t// globs are not evaluated on Windows because of its path separator character:\n\t// escaping is not supported so we can't safely glob on Windows, or we can't\n\t// support placeholders on Windows (pick one). (Actually, evaluating untrusted\n\t// globs is not the end of the world since the file server will still hide any\n\t// hidden files, it just might lead to unexpected behavior.)\n\tmakeCandidates := func(file string) []matchCandidate {\n\t\t// first, evaluate placeholders in the file pattern\n\t\texpandedFile, err := repl.ReplaceFunc(file, func(variable string, val any) (any, error) {\n\t\t\tif runtime.GOOS == \"windows\" {\n\t\t\t\treturn val, nil\n\t\t\t}\n\t\t\tswitch v := val.(type) {\n\t\t\tcase string:\n\t\t\t\treturn globSafeRepl.Replace(v), nil\n\t\t\tcase fmt.Stringer:\n\t\t\t\treturn globSafeRepl.Replace(v.String()), nil\n\t\t\t}\n\t\t\treturn val, nil\n\t\t})\n\t\tif err != nil {\n\t\t\tif c := m.logger.Check(zapcore.ErrorLevel, \"evaluating placeholders\"); c != nil {\n\t\t\t\tc.Write(zap.Error(err))\n\t\t\t}\n\n\t\t\texpandedFile = file // \"oh well,\" I guess?\n\t\t}\n\n\t\t// clean the path and split, if configured -- we must split before\n\t\t// globbing so that the file system doesn't include the remainder\n\t\t// (\"afterSplit\") in the filename; be sure to restore trailing slash\n\t\tbeforeSplit, afterSplit := m.firstSplit(path.Clean(expandedFile))\n\t\tif strings.HasSuffix(file, \"/\") {\n\t\t\tbeforeSplit += \"/\"\n\t\t}\n\n\t\t// create the full path to the file by prepending the site root\n\t\tfullPattern := caddyhttp.SanitizedPathJoin(root, beforeSplit)\n\n\t\t// expand glob expressions, but not on Windows because Glob() doesn't\n\t\t// support escaping on Windows due to path separator)\n\t\tvar globResults []string\n\t\tif runtime.GOOS == \"windows\" {\n\t\t\tglobResults = []string{fullPattern} // precious Windows\n\t\t} else {\n\t\t\tglobResults, err = fs.Glob(fileSystem, fullPattern)\n\t\t\tif err != nil {\n\t\t\t\tif c := m.logger.Check(zapcore.ErrorLevel, \"expanding glob\"); c != nil {\n\t\t\t\t\tc.Write(zap.Error(err))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// for each glob result, combine all the forms of the path\n\t\tvar candidates []matchCandidate\n\t\tfor _, result := range globResults {\n\t\t\tcandidates = append(candidates, matchCandidate{\n\t\t\t\tfullpath:       result,\n\t\t\t\trelative:       strings.TrimPrefix(result, root),\n\t\t\t\tsplitRemainder: afterSplit,\n\t\t\t})\n\t\t}\n\n\t\treturn candidates\n\t}\n\n\t// setPlaceholders creates the placeholders for the matched file\n\tsetPlaceholders := func(candidate matchCandidate, isDir bool) {\n\t\trepl.Set(\"http.matchers.file.relative\", filepath.ToSlash(candidate.relative))\n\t\trepl.Set(\"http.matchers.file.absolute\", filepath.ToSlash(candidate.fullpath))\n\t\trepl.Set(\"http.matchers.file.remainder\", filepath.ToSlash(candidate.splitRemainder))\n\n\t\tfileType := \"file\"\n\t\tif isDir {\n\t\t\tfileType = \"directory\"\n\t\t}\n\t\trepl.Set(\"http.matchers.file.type\", fileType)\n\t}\n\n\t// match file according to the configured policy\n\tswitch m.TryPolicy {\n\tcase \"\", tryPolicyFirstExist, tryPolicyFirstExistFallback:\n\t\tmaxI := -1\n\t\tif m.TryPolicy == tryPolicyFirstExistFallback {\n\t\t\tmaxI = len(m.TryFiles) - 1\n\t\t}\n\n\t\tfor i, pattern := range m.TryFiles {\n\t\t\t// If the pattern is a status code, emit an error,\n\t\t\t// which short-circuits the middleware pipeline and\n\t\t\t// writes an HTTP error response.\n\t\t\tif err := parseErrorCode(pattern); err != nil {\n\t\t\t\treturn false, err\n\t\t\t}\n\n\t\t\tcandidates := makeCandidates(pattern)\n\t\t\tfor _, c := range candidates {\n\t\t\t\t// Skip the IO if using fallback policy and it's the latest item\n\t\t\t\tif i == maxI {\n\t\t\t\t\tsetPlaceholders(c, false)\n\n\t\t\t\t\treturn true, nil\n\t\t\t\t}\n\n\t\t\t\tif info, exists := m.strictFileExists(fileSystem, c.fullpath); exists {\n\t\t\t\t\tsetPlaceholders(c, info.IsDir())\n\t\t\t\t\treturn true, nil\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\tcase tryPolicyLargestSize:\n\t\tvar largestSize int64\n\t\tvar largest matchCandidate\n\t\tvar largestInfo os.FileInfo\n\t\tfor _, pattern := range m.TryFiles {\n\t\t\tcandidates := makeCandidates(pattern)\n\t\t\tfor _, c := range candidates {\n\t\t\t\tinfo, err := fs.Stat(fileSystem, c.fullpath)\n\t\t\t\tif err == nil && info.Size() > largestSize {\n\t\t\t\t\tlargestSize = info.Size()\n\t\t\t\t\tlargest = c\n\t\t\t\t\tlargestInfo = info\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif largestInfo == nil {\n\t\t\treturn false, nil\n\t\t}\n\t\tsetPlaceholders(largest, largestInfo.IsDir())\n\t\treturn true, nil\n\n\tcase tryPolicySmallestSize:\n\t\tvar smallestSize int64\n\t\tvar smallest matchCandidate\n\t\tvar smallestInfo os.FileInfo\n\t\tfor _, pattern := range m.TryFiles {\n\t\t\tcandidates := makeCandidates(pattern)\n\t\t\tfor _, c := range candidates {\n\t\t\t\tinfo, err := fs.Stat(fileSystem, c.fullpath)\n\t\t\t\tif err == nil && (smallestSize == 0 || info.Size() < smallestSize) {\n\t\t\t\t\tsmallestSize = info.Size()\n\t\t\t\t\tsmallest = c\n\t\t\t\t\tsmallestInfo = info\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif smallestInfo == nil {\n\t\t\treturn false, nil\n\t\t}\n\t\tsetPlaceholders(smallest, smallestInfo.IsDir())\n\t\treturn true, nil\n\n\tcase tryPolicyMostRecentlyMod:\n\t\tvar recent matchCandidate\n\t\tvar recentInfo os.FileInfo\n\t\tfor _, pattern := range m.TryFiles {\n\t\t\tcandidates := makeCandidates(pattern)\n\t\t\tfor _, c := range candidates {\n\t\t\t\tinfo, err := fs.Stat(fileSystem, c.fullpath)\n\t\t\t\tif err == nil &&\n\t\t\t\t\t(recentInfo == nil || info.ModTime().After(recentInfo.ModTime())) {\n\t\t\t\t\trecent = c\n\t\t\t\t\trecentInfo = info\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif recentInfo == nil {\n\t\t\treturn false, nil\n\t\t}\n\t\tsetPlaceholders(recent, recentInfo.IsDir())\n\t\treturn true, nil\n\t}\n\n\treturn false, nil\n}\n\n// parseErrorCode checks if the input is a status\n// code number, prefixed by \"=\", and returns an\n// error if so.\nfunc parseErrorCode(input string) error {\n\tif len(input) > 1 && input[0] == '=' {\n\t\tcode, err := strconv.Atoi(input[1:])\n\t\tif err != nil || code < 100 || code > 999 {\n\t\t\treturn nil\n\t\t}\n\t\treturn caddyhttp.Error(code, fmt.Errorf(\"%s\", input[1:]))\n\t}\n\treturn nil\n}\n\n// strictFileExists returns true if file exists\n// and matches the convention of the given file\n// path. If the path ends in a forward slash,\n// the file must also be a directory; if it does\n// NOT end in a forward slash, the file must NOT\n// be a directory.\nfunc (m MatchFile) strictFileExists(fileSystem fs.FS, file string) (os.FileInfo, bool) {\n\tinfo, err := fs.Stat(fileSystem, file)\n\tif err != nil {\n\t\t// in reality, this can be any error\n\t\t// such as permission or even obscure\n\t\t// ones like \"is not a directory\" (when\n\t\t// trying to stat a file within a file);\n\t\t// in those cases we can't be sure if\n\t\t// the file exists, so we just treat any\n\t\t// error as if it does not exist; see\n\t\t// https://stackoverflow.com/a/12518877/1048862\n\t\treturn nil, false\n\t}\n\tif strings.HasSuffix(file, separator) {\n\t\t// by convention, file paths ending\n\t\t// in a path separator must be a directory\n\t\treturn info, info.IsDir()\n\t}\n\t// by convention, file paths NOT ending\n\t// in a path separator must NOT be a directory\n\treturn info, !info.IsDir()\n}\n\n// firstSplit returns the first result where the path\n// can be split in two by a value in m.SplitPath. The\n// return values are the first piece of the path that\n// ends with the split substring and the remainder.\n// If the path cannot be split, the path is returned\n// as-is (with no remainder).\nfunc (m MatchFile) firstSplit(path string) (splitPart, remainder string) {\n\tfor _, split := range m.SplitPath {\n\t\tif idx := indexFold(path, split); idx > -1 {\n\t\t\tpos := idx + len(split)\n\t\t\t// skip the split if it's not the final part of the filename\n\t\t\tif pos != len(path) && !strings.HasPrefix(path[pos:], \"/\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn path[:pos], path[pos:]\n\t\t}\n\t}\n\treturn path, \"\"\n}\n\n// There is no strings.IndexFold() function like there is strings.EqualFold(),\n// but we can use strings.EqualFold() to build our own case-insensitive\n// substring search (as of Go 1.14).\nfunc indexFold(haystack, needle string) int {\n\tnlen := len(needle)\n\tfor i := 0; i+nlen < len(haystack); i++ {\n\t\tif strings.EqualFold(haystack[i:i+nlen], needle) {\n\t\t\treturn i\n\t\t}\n\t}\n\treturn -1\n}\n\n// isCELTryFilesLiteral returns whether the expression resolves to a map literal containing\n// only string keys with or a placeholder call.\nfunc isCELTryFilesLiteral(e ast.Expr) bool {\n\tswitch e.Kind() {\n\tcase ast.MapKind:\n\t\tmapExpr := e.AsMap()\n\t\tfor _, entry := range mapExpr.Entries() {\n\t\t\tmapKey := entry.AsMapEntry().Key()\n\t\t\tmapVal := entry.AsMapEntry().Value()\n\t\t\tif !isCELStringLiteral(mapKey) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tmapKeyStr := mapKey.AsLiteral().ConvertToType(types.StringType).Value()\n\t\t\tswitch mapKeyStr {\n\t\t\tcase \"try_files\", \"split_path\":\n\t\t\t\tif !isCELStringListLiteral(mapVal) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\tcase \"try_policy\", \"root\":\n\t\t\t\tif !(isCELStringExpr(mapVal)) {\n\t\t\t\t\treturn false\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\n\tcase ast.UnspecifiedExprKind, ast.CallKind, ast.ComprehensionKind, ast.IdentKind, ast.ListKind, ast.LiteralKind, ast.SelectKind, ast.StructKind:\n\t\t// appeasing the linter :)\n\t}\n\treturn false\n}\n\n// isCELStringExpr indicates whether the expression is a supported string expression\nfunc isCELStringExpr(e ast.Expr) bool {\n\treturn isCELStringLiteral(e) || isCELCaddyPlaceholderCall(e) || isCELConcatCall(e)\n}\n\n// isCELStringLiteral returns whether the expression is a CEL string literal.\nfunc isCELStringLiteral(e ast.Expr) bool {\n\tswitch e.Kind() {\n\tcase ast.LiteralKind:\n\t\tconstant := e.AsLiteral()\n\t\tswitch constant.Type() {\n\t\tcase types.StringType:\n\t\t\treturn true\n\t\t}\n\tcase ast.UnspecifiedExprKind, ast.CallKind, ast.ComprehensionKind, ast.IdentKind, ast.ListKind, ast.MapKind, ast.SelectKind, ast.StructKind:\n\t\t// appeasing the linter :)\n\t}\n\treturn false\n}\n\n// isCELCaddyPlaceholderCall returns whether the expression is a caddy placeholder call.\nfunc isCELCaddyPlaceholderCall(e ast.Expr) bool {\n\tswitch e.Kind() {\n\tcase ast.CallKind:\n\t\tcall := e.AsCall()\n\t\tif call.FunctionName() == caddyhttp.CELPlaceholderFuncName {\n\t\t\treturn true\n\t\t}\n\tcase ast.UnspecifiedExprKind, ast.ComprehensionKind, ast.IdentKind, ast.ListKind, ast.LiteralKind, ast.MapKind, ast.SelectKind, ast.StructKind:\n\t\t// appeasing the linter :)\n\t}\n\treturn false\n}\n\n// isCELConcatCall tests whether the expression is a concat function (+) with string, placeholder, or\n// other concat call arguments.\nfunc isCELConcatCall(e ast.Expr) bool {\n\tswitch e.Kind() {\n\tcase ast.CallKind:\n\t\tcall := e.AsCall()\n\t\tif call.Target().Kind() != ast.UnspecifiedExprKind {\n\t\t\treturn false\n\t\t}\n\t\tif call.FunctionName() != operators.Add {\n\t\t\treturn false\n\t\t}\n\t\tfor _, arg := range call.Args() {\n\t\t\tif !isCELStringExpr(arg) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase ast.UnspecifiedExprKind, ast.ComprehensionKind, ast.IdentKind, ast.ListKind, ast.LiteralKind, ast.MapKind, ast.SelectKind, ast.StructKind:\n\t\t// appeasing the linter :)\n\t}\n\treturn false\n}\n\n// isCELStringListLiteral returns whether the expression resolves to a list literal\n// containing only string constants or a placeholder call.\nfunc isCELStringListLiteral(e ast.Expr) bool {\n\tswitch e.Kind() {\n\tcase ast.ListKind:\n\t\tlist := e.AsList()\n\t\tfor _, elem := range list.Elements() {\n\t\t\tif !isCELStringExpr(elem) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t\treturn true\n\tcase ast.UnspecifiedExprKind, ast.CallKind, ast.ComprehensionKind, ast.IdentKind, ast.LiteralKind, ast.MapKind, ast.SelectKind, ast.StructKind:\n\t\t// appeasing the linter :)\n\t}\n\treturn false\n}\n\n// globSafeRepl replaces special glob characters with escaped\n// equivalents. Note that the filepath godoc states that\n// escaping is not done on Windows because of the separator.\nvar globSafeRepl = strings.NewReplacer(\n\t\"*\", \"\\\\*\",\n\t\"[\", \"\\\\[\",\n\t\"?\", \"\\\\?\",\n)\n\nconst (\n\ttryPolicyFirstExist         = \"first_exist\"\n\ttryPolicyFirstExistFallback = \"first_exist_fallback\"\n\ttryPolicyLargestSize        = \"largest_size\"\n\ttryPolicySmallestSize       = \"smallest_size\"\n\ttryPolicyMostRecentlyMod    = \"most_recently_modified\"\n)\n\n// Interface guards\nvar (\n\t_ caddy.Validator                   = (*MatchFile)(nil)\n\t_ caddyhttp.RequestMatcherWithError = (*MatchFile)(nil)\n\t_ caddyhttp.CELLibraryProducer      = (*MatchFile)(nil)\n)\n",
    "source_file": "modules/caddyhttp/fileserver/matcher.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fileserver\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"os\"\n\t\"strconv\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/spf13/cobra\"\n\t\"go.uber.org/zap\"\n\n\tcaddycmd \"github.com/caddyserver/caddy/v2/cmd\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode\"\n\tcaddytpl \"github.com/caddyserver/caddy/v2/modules/caddyhttp/templates\"\n)\n\nfunc init() {\n\tcaddycmd.RegisterCommand(caddycmd.Command{\n\t\tName:  \"file-server\",\n\t\tUsage: \"[--domain <example.com>] [--root <path>] [--listen <addr>] [--browse] [--reveal-symlinks] [--access-log] [--precompressed]\",\n\t\tShort: \"Spins up a production-ready file server\",\n\t\tLong: `\nA simple but production-ready file server. Useful for quick deployments,\ndemos, and development.\n\nThe listener's socket address can be customized with the --listen flag.\n\nIf a domain name is specified with --domain, the default listener address\nwill be changed to the HTTPS port and the server will use HTTPS. If using\na public domain, ensure A/AAAA records are properly configured before\nusing this option.\n\nBy default, Zstandard and Gzip compression are enabled. Use --no-compress\nto disable compression.\n\nIf --browse is enabled, requests for folders without an index file will\nrespond with a file listing.`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"domain\", \"d\", \"\", \"Domain name at which to serve the files\")\n\t\t\tcmd.Flags().StringP(\"root\", \"r\", \"\", \"The path to the root of the site\")\n\t\t\tcmd.Flags().StringP(\"listen\", \"l\", \"\", \"The address to which to bind the listener\")\n\t\t\tcmd.Flags().BoolP(\"browse\", \"b\", false, \"Enable directory browsing\")\n\t\t\tcmd.Flags().BoolP(\"reveal-symlinks\", \"\", false, \"Show symlink paths when browse is enabled.\")\n\t\t\tcmd.Flags().BoolP(\"templates\", \"t\", false, \"Enable template rendering\")\n\t\t\tcmd.Flags().BoolP(\"access-log\", \"a\", false, \"Enable the access log\")\n\t\t\tcmd.Flags().BoolP(\"debug\", \"v\", false, \"Enable verbose debug logs\")\n\t\t\tcmd.Flags().IntP(\"file-limit\", \"f\", defaultDirEntryLimit, \"Max directories to read\")\n\t\t\tcmd.Flags().BoolP(\"no-compress\", \"\", false, \"Disable Zstandard and Gzip compression\")\n\t\t\tcmd.Flags().StringSliceP(\"precompressed\", \"p\", []string{}, \"Specify precompression file extensions. Compression preference implied from flag order.\")\n\t\t\tcmd.RunE = caddycmd.WrapCommandFuncForCobra(cmdFileServer)\n\t\t\tcmd.AddCommand(&cobra.Command{\n\t\t\t\tUse:     \"export-template\",\n\t\t\t\tShort:   \"Exports the default file browser template\",\n\t\t\t\tExample: \"caddy file-server export-template > browse.html\",\n\t\t\t\tRunE: func(cmd *cobra.Command, args []string) error {\n\t\t\t\t\t_, err := io.WriteString(os.Stdout, BrowseTemplate)\n\t\t\t\t\treturn err\n\t\t\t\t},\n\t\t\t})\n\t\t},\n\t})\n}\n\nfunc cmdFileServer(fs caddycmd.Flags) (int, error) {\n\tcaddy.TrapSignals()\n\n\tdomain := fs.String(\"domain\")\n\troot := fs.String(\"root\")\n\tlisten := fs.String(\"listen\")\n\tbrowse := fs.Bool(\"browse\")\n\ttemplates := fs.Bool(\"templates\")\n\taccessLog := fs.Bool(\"access-log\")\n\tfileLimit := fs.Int(\"file-limit\")\n\tdebug := fs.Bool(\"debug\")\n\trevealSymlinks := fs.Bool(\"reveal-symlinks\")\n\tcompress := !fs.Bool(\"no-compress\")\n\tprecompressed, err := fs.GetStringSlice(\"precompressed\")\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"invalid precompressed flag: %v\", err)\n\t}\n\tvar handlers []json.RawMessage\n\n\tif compress {\n\t\tzstd, err := caddy.GetModule(\"http.encoders.zstd\")\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\n\t\tgzip, err := caddy.GetModule(\"http.encoders.gzip\")\n\t\tif err != nil {\n\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t}\n\n\t\thandlers = append(handlers, caddyconfig.JSONModuleObject(encode.Encode{\n\t\t\tEncodingsRaw: caddy.ModuleMap{\n\t\t\t\t\"zstd\": caddyconfig.JSON(zstd.New(), nil),\n\t\t\t\t\"gzip\": caddyconfig.JSON(gzip.New(), nil),\n\t\t\t},\n\t\t\tPrefer: []string{\"zstd\", \"gzip\"},\n\t\t}, \"handler\", \"encode\", nil))\n\t}\n\n\tif templates {\n\t\thandler := caddytpl.Templates{FileRoot: root}\n\t\thandlers = append(handlers, caddyconfig.JSONModuleObject(handler, \"handler\", \"templates\", nil))\n\t}\n\n\thandler := FileServer{Root: root}\n\n\tif len(precompressed) != 0 {\n\t\t// logic mirrors modules/caddyhttp/fileserver/caddyfile.go case \"precompressed\"\n\t\tvar order []string\n\t\tfor _, compression := range precompressed {\n\t\t\tmodID := \"http.precompressed.\" + compression\n\t\t\tmod, err := caddy.GetModule(modID)\n\t\t\tif err != nil {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"getting module named '%s': %v\", modID, err)\n\t\t\t}\n\t\t\tinst := mod.New()\n\t\t\tprecompress, ok := inst.(encode.Precompressed)\n\t\t\tif !ok {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"module %s is not a precompressor; is %T\", modID, inst)\n\t\t\t}\n\t\t\tif handler.PrecompressedRaw == nil {\n\t\t\t\thandler.PrecompressedRaw = make(caddy.ModuleMap)\n\t\t\t}\n\t\t\thandler.PrecompressedRaw[compression] = caddyconfig.JSON(precompress, nil)\n\t\t\torder = append(order, compression)\n\t\t}\n\t\thandler.PrecompressedOrder = order\n\t}\n\n\tif browse {\n\t\thandler.Browse = &Browse{RevealSymlinks: revealSymlinks, FileLimit: fileLimit}\n\t}\n\n\thandlers = append(handlers, caddyconfig.JSONModuleObject(handler, \"handler\", \"file_server\", nil))\n\n\troute := caddyhttp.Route{HandlersRaw: handlers}\n\n\tif domain != \"\" {\n\t\troute.MatcherSetsRaw = []caddy.ModuleMap{\n\t\t\t{\n\t\t\t\t\"host\": caddyconfig.JSON(caddyhttp.MatchHost{domain}, nil),\n\t\t\t},\n\t\t}\n\t}\n\n\tserver := &caddyhttp.Server{\n\t\tReadHeaderTimeout: caddy.Duration(10 * time.Second),\n\t\tIdleTimeout:       caddy.Duration(30 * time.Second),\n\t\tMaxHeaderBytes:    1024 * 10,\n\t\tRoutes:            caddyhttp.RouteList{route},\n\t}\n\tif listen == \"\" {\n\t\tif domain == \"\" {\n\t\t\tlisten = \":80\"\n\t\t} else {\n\t\t\tlisten = \":\" + strconv.Itoa(certmagic.HTTPSPort)\n\t\t}\n\t}\n\tserver.Listen = []string{listen}\n\tif accessLog {\n\t\tserver.Logs = &caddyhttp.ServerLogConfig{}\n\t}\n\n\thttpApp := caddyhttp.App{\n\t\tServers: map[string]*caddyhttp.Server{\"static\": server},\n\t}\n\n\tvar false bool\n\tcfg := &caddy.Config{\n\t\tAdmin: &caddy.AdminConfig{\n\t\t\tDisabled: true,\n\t\t\tConfig: &caddy.ConfigSettings{\n\t\t\t\tPersist: &false,\n\t\t\t},\n\t\t},\n\t\tAppsRaw: caddy.ModuleMap{\n\t\t\t\"http\": caddyconfig.JSON(httpApp, nil),\n\t\t},\n\t}\n\n\tif debug {\n\t\tcfg.Logging = &caddy.Logging{\n\t\t\tLogs: map[string]*caddy.CustomLog{\n\t\t\t\t\"default\": {\n\t\t\t\t\tBaseLog: caddy.BaseLog{Level: zap.DebugLevel.CapitalString()},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t}\n\n\terr = caddy.Run(cfg)\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tlog.Printf(\"Caddy serving static files on %s\", listen)\n\n\tselect {}\n}\n",
    "source_file": "modules/caddyhttp/fileserver/command.go",
    "chunk_type": "code"
  },
  {
    "content": "{{ $nonce := uuidv4 -}}\n{{ $nonceAttribute := print \"nonce=\" (quote $nonce) -}}\n{{ $csp := printf \"default-src 'none'; img-src 'self'; object-src 'none'; base-uri 'none'; script-src 'nonce-%s'; style-src 'nonce-%s'; frame-ancestors 'self'; form-action 'self';\" $nonce $nonce -}}\n{{/* To disable the Content-Security-Policy, set this to false */}}{{ $enableCsp := true -}}\n{{ if $enableCsp -}}\n  {{- .RespHeader.Set \"Content-Security-Policy\" $csp -}}\n{{ end -}}\n{{- define \"icon\"}}\n\t{{- if .IsDir}}\n\t\t{{- if .IsSymlink}}\n\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-folder-filled\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t<path d=\"M9 3a1 1 0 0 1 .608 .206l.1 .087l2.706 2.707h6.586a3 3 0 0 1 2.995 2.824l.005 .176v8a3 3 0 0 1 -2.824 2.995l-.176 .005h-14a3 3 0 0 1 -2.995 -2.824l-.005 -.176v-11a3 3 0 0 1 2.824 -2.995l.176 -.005h4z\" stroke-width=\"0\" fill=\"currentColor\"/>\n\t\t\t<path fill=\"#000\" d=\"M2.795 17.306c0-2.374 1.792-4.314 4.078-4.538v-1.104a.38.38 0 0 1 .651-.272l2.45 2.492a.132.132 0 0 1 0 .188l-2.45 2.492a.381.381 0 0 1-.651-.272V15.24c-1.889.297-3.436 1.39-3.817 3.26a2.809 2.809 0 0 1-.261-1.193Z\" stroke-width=\".127478\"/>\n\t\t</svg>\n\t\t{{- else}}\n\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-folder-filled\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t<path d=\"M9 3a1 1 0 0 1 .608 .206l.1 .087l2.706 2.707h6.586a3 3 0 0 1 2.995 2.824l.005 .176v8a3 3 0 0 1 -2.824 2.995l-.176 .005h-14a3 3 0 0 1 -2.995 -2.824l-.005 -.176v-11a3 3 0 0 1 2.824 -2.995l.176 -.005h4z\" stroke-width=\"0\" fill=\"currentColor\"/>\n\t\t</svg>\n\t\t{{- end}}\n\t{{- else if or (eq .Name \"LICENSE\") (eq .Name \"README\")}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-license\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M15 21h-9a3 3 0 0 1 -3 -3v-1h10v2a2 2 0 0 0 4 0v-14a2 2 0 1 1 2 2h-2m2 -4h-11a3 3 0 0 0 -3 3v11\"/>\n\t\t<path d=\"M9 7l4 0\"/>\n\t\t<path d=\"M9 11l4 0\"/>\n\t</svg>\n\t{{- else if .HasExt \".jpg\" \".jpeg\" \".png\" \".gif\" \".webp\" \".tiff\" \".bmp\" \".heif\" \".heic\" \".svg\" \".avif\"}}\n\t\t{{- if eq .Tpl.Layout \"grid\"}}\n\t\t<img loading=\"lazy\" src=\"{{.Name | pathEscape}}\">\n\t\t{{- else}}\n\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-photo\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t<path d=\"M15 8h.01\"/>\n\t\t\t<path d=\"M3 6a3 3 0 0 1 3 -3h12a3 3 0 0 1 3 3v12a3 3 0 0 1 -3 3h-12a3 3 0 0 1 -3 -3v-12z\"/>\n\t\t\t<path d=\"M3 16l5 -5c.928 -.893 2.072 -.893 3 0l5 5\"/>\n\t\t\t<path d=\"M14 14l1 -1c.928 -.893 2.072 -.893 3 0l3 3\"/>\n\t\t</svg>\n\t\t{{- end}}\n\t{{- else if .HasExt \".mp4\" \".mov\" \".m4v\" \".mpeg\" \".mpg\" \".avi\" \".ogg\" \".webm\" \".mkv\" \".vob\" \".gifv\" \".3gp\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-movie\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M4 4m0 2a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v12a2 2 0 0 1 -2 2h-12a2 2 0 0 1 -2 -2z\"/>\n\t\t<path d=\"M8 4l0 16\"/>\n\t\t<path d=\"M16 4l0 16\"/>\n\t\t<path d=\"M4 8l4 0\"/>\n\t\t<path d=\"M4 16l4 0\"/>\n\t\t<path d=\"M4 12l16 0\"/>\n\t\t<path d=\"M16 8l4 0\"/>\n\t\t<path d=\"M16 16l4 0\"/>\n\t</svg>\n\t{{- else if .HasExt \".mp3\" \".m4a\" \".aac\" \".ogg\" \".flac\" \".wav\" \".wma\" \".midi\" \".cda\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-music\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M6 17m-3 0a3 3 0 1 0 6 0a3 3 0 1 0 -6 0\"/>\n\t\t<path d=\"M16 17m-3 0a3 3 0 1 0 6 0a3 3 0 1 0 -6 0\"/>\n\t\t<path d=\"M9 17l0 -13l10 0l0 13\"/>\n\t\t<path d=\"M9 8l10 0\"/>\n\t</svg>\n\t{{- else if .HasExt \".pdf\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-type-pdf\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M5 12v-7a2 2 0 0 1 2 -2h7l5 5v4\"/>\n\t\t<path d=\"M5 18h1.5a1.5 1.5 0 0 0 0 -3h-1.5v6\"/>\n\t\t<path d=\"M17 18h2\"/>\n\t\t<path d=\"M20 15h-3v6\"/>\n\t\t<path d=\"M11 15v6h1a2 2 0 0 0 2 -2v-2a2 2 0 0 0 -2 -2h-1z\"/>\n\t</svg>\n\t{{- else if .HasExt \".csv\" \".tsv\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-type-csv\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M5 12v-7a2 2 0 0 1 2 -2h7l5 5v4\"/>\n\t\t<path d=\"M7 16.5a1.5 1.5 0 0 0 -3 0v3a1.5 1.5 0 0 0 3 0\"/>\n\t\t<path d=\"M10 20.25c0 .414 .336 .75 .75 .75h1.25a1 1 0 0 0 1 -1v-1a1 1 0 0 0 -1 -1h-1a1 1 0 0 1 -1 -1v-1a1 1 0 0 1 1 -1h1.25a.75 .75 0 0 1 .75 .75\"/>\n\t\t<path d=\"M16 15l2 6l2 -6\"/>\n\t</svg>\n\t{{- else if .HasExt \".txt\" \".doc\" \".docx\" \".odt\" \".fodt\" \".rtf\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-text\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M17 21h-10a2 2 0 0 1 -2 -2v-14a2 2 0 0 1 2 -2h7l5 5v11a2 2 0 0 1 -2 2z\"/>\n\t\t<path d=\"M9 9l1 0\"/>\n\t\t<path d=\"M9 13l6 0\"/>\n\t\t<path d=\"M9 17l6 0\"/>\n\t</svg>\n\t{{- else if .HasExt \".xls\" \".xlsx\" \".ods\" \".fods\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-spreadsheet\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M17 21h-10a2 2 0 0 1 -2 -2v-14a2 2 0 0 1 2 -2h7l5 5v11a2 2 0 0 1 -2 2z\"/>\n\t\t<path d=\"M8 11h8v7h-8z\"/>\n\t\t<path d=\"M8 15h8\"/>\n\t\t<path d=\"M11 11v7\"/>\n\t</svg>\n\t{{- else if .HasExt \".ppt\" \".pptx\" \".odp\" \".fodp\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-presentation-analytics\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M9 12v-4\"/>\n\t\t<path d=\"M15 12v-2\"/>\n\t\t<path d=\"M12 12v-1\"/>\n\t\t<path d=\"M3 4h18\"/>\n\t\t<path d=\"M4 4v10a2 2 0 0 0 2 2h12a2 2 0 0 0 2 -2v-10\"/>\n\t\t<path d=\"M12 16v4\"/>\n\t\t<path d=\"M9 20h6\"/>\n\t</svg>\n\t{{- else if .HasExt \".zip\" \".gz\" \".xz\" \".tar\" \".7z\" \".rar\" \".xz\" \".zst\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-zip\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M6 20.735a2 2 0 0 1 -1 -1.735v-14a2 2 0 0 1 2 -2h7l5 5v11a2 2 0 0 1 -2 2h-1\"/>\n\t\t<path d=\"M11 17a2 2 0 0 1 2 2v2a1 1 0 0 1 -1 1h-2a1 1 0 0 1 -1 -1v-2a2 2 0 0 1 2 -2z\"/>\n\t\t<path d=\"M11 5l-1 0\"/>\n\t\t<path d=\"M13 7l-1 0\"/>\n\t\t<path d=\"M11 9l-1 0\"/>\n\t\t<path d=\"M13 11l-1 0\"/>\n\t\t<path d=\"M11 13l-1 0\"/>\n\t\t<path d=\"M13 15l-1 0\"/>\n\t</svg>\n\t{{- else if .HasExt \".deb\" \".dpkg\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-brand-debian\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M12 17c-2.397 -.943 -4 -3.153 -4 -5.635c0 -2.19 1.039 -3.14 1.604 -3.595c2.646 -2.133 6.396 -.27 6.396 3.23c0 2.5 -2.905 2.121 -3.5 1.5c-.595 -.621 -1 -1.5 -.5 -2.5\"/>\n\t\t<path d=\"M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0\"/>\n\t</svg>\n\t{{- else if .HasExt \".rpm\" \".exe\" \".flatpak\" \".appimage\" \".jar\" \".msi\" \".apk\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-package\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M12 3l8 4.5l0 9l-8 4.5l-8 -4.5l0 -9l8 -4.5\"/>\n\t\t<path d=\"M12 12l8 -4.5\"/>\n\t\t<path d=\"M12 12l0 9\"/>\n\t\t<path d=\"M12 12l-8 -4.5\"/>\n\t\t<path d=\"M16 5.25l-8 4.5\"/>\n\t</svg>\n\t{{- else if .HasExt \".ps1\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-brand-powershell\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M4.887 20h11.868c.893 0 1.664 -.665 1.847 -1.592l2.358 -12c.212 -1.081 -.442 -2.14 -1.462 -2.366a1.784 1.784 0 0 0 -.385 -.042h-11.868c-.893 0 -1.664 .665 -1.847 1.592l-2.358 12c-.212 1.081 .442 2.14 1.462 2.366c.127 .028 .256 .042 .385 .042z\"/>\n\t\t<path d=\"M9 8l4 4l-6 4\"/>\n\t\t<path d=\"M12 16h3\"/>\n\t</svg>\n\t{{- else if .HasExt \".py\" \".pyc\" \".pyo\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-brand-python\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M12 9h-7a2 2 0 0 0 -2 2v4a2 2 0 0 0 2 2h3\"/>\n\t\t<path d=\"M12 15h7a2 2 0 0 0 2 -2v-4a2 2 0 0 0 -2 -2h-3\"/>\n\t\t<path d=\"M8 9v-4a2 2 0 0 1 2 -2h4a2 2 0 0 1 2 2v5a2 2 0 0 1 -2 2h-4a2 2 0 0 0 -2 2v5a2 2 0 0 0 2 2h4a2 2 0 0 0 2 -2v-4\"/>\n\t\t<path d=\"M11 6l0 .01\"/>\n\t\t<path d=\"M13 18l0 .01\"/>\n\t</svg>\n\t{{- else if .HasExt \".bash\" \".sh\" \".com\" \".bat\" \".dll\" \".so\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-script\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M17 20h-11a3 3 0 0 1 0 -6h11a3 3 0 0 0 0 6h1a3 3 0 0 0 3 -3v-11a2 2 0 0 0 -2 -2h-10a2 2 0 0 0 -2 2v8\"/>\n\t</svg>\n\t{{- else if .HasExt \".dmg\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-brand-finder\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M3 4m0 1a1 1 0 0 1 1 -1h16a1 1 0 0 1 1 1v14a1 1 0 0 1 -1 1h-16a1 1 0 0 1 -1 -1z\"/>\n\t\t<path d=\"M7 8v1\"/>\n\t\t<path d=\"M17 8v1\"/>\n\t\t<path d=\"M12.5 4c-.654 1.486 -1.26 3.443 -1.5 9h2.5c-.19 2.867 .094 5.024 .5 7\"/>\n\t\t<path d=\"M7 15.5c3.667 2 6.333 2 10 0\"/>\n\t</svg>\n\t{{- else if .HasExt \".iso\" \".img\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-disc\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M12 12m-9 0a9 9 0 1 0 18 0a9 9 0 1 0 -18 0\"/>\n\t\t<path d=\"M12 12m-1 0a1 1 0 1 0 2 0a1 1 0 1 0 -2 0\"/>\n\t\t<path d=\"M7 12a5 5 0 0 1 5 -5\"/>\n\t\t<path d=\"M12 17a5 5 0 0 0 5 -5\"/>\n\t</svg>\n\t{{- else if .HasExt \".md\" \".mdown\" \".markdown\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-markdown\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M3 5m0 2a2 2 0 0 1 2 -2h14a2 2 0 0 1 2 2v10a2 2 0 0 1 -2 2h-14a2 2 0 0 1 -2 -2z\"/>\n\t\t<path d=\"M7 15v-6l2 2l2 -2v6\"/>\n\t\t<path d=\"M14 13l2 2l2 -2m-2 2v-6\"/>\n\t</svg>\n\t{{- else if .HasExt \".ttf\" \".otf\" \".woff\" \".woff2\" \".eof\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-typography\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M17 21h-10a2 2 0 0 1 -2 -2v-14a2 2 0 0 1 2 -2h7l5 5v11a2 2 0 0 1 -2 2z\"/>\n\t\t<path d=\"M11 18h2\"/>\n\t\t<path d=\"M12 18v-7\"/>\n\t\t<path d=\"M9 12v-1h6v1\"/>\n\t</svg>\n\t{{- else if .HasExt \".go\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-brand-golang\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M15.695 14.305c1.061 1.06 2.953 .888 4.226 -.384c1.272 -1.273 1.444 -3.165 .384 -4.226c-1.061 -1.06 -2.953 -.888 -4.226 .384c-1.272 1.273 -1.444 3.165 -.384 4.226z\"/>\n\t\t<path d=\"M12.68 9.233c-1.084 -.497 -2.545 -.191 -3.591 .846c-1.284 1.273 -1.457 3.165 -.388 4.226c1.07 1.06 2.978 .888 4.261 -.384a3.669 3.669 0 0 0 1.038 -1.921h-2.427\"/>\n\t\t<path d=\"M5.5 15h-1.5\"/>\n\t\t<path d=\"M6 9h-2\"/>\n\t\t<path d=\"M5 12h-3\"/>\n\t</svg>\n\t{{- else if .HasExt \".html\" \".htm\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-type-html\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M5 12v-7a2 2 0 0 1 2 -2h7l5 5v4\"/>\n\t\t<path d=\"M2 21v-6\"/>\n\t\t<path d=\"M5 15v6\"/>\n\t\t<path d=\"M2 18h3\"/>\n\t\t<path d=\"M20 15v6h2\"/>\n\t\t<path d=\"M13 21v-6l2 3l2 -3v6\"/>\n\t\t<path d=\"M7.5 15h3\"/>\n\t\t<path d=\"M9 15v6\"/>\n\t</svg>\n\t{{- else if .HasExt \".js\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-type-js\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M3 15h3v4.5a1.5 1.5 0 0 1 -3 0\"/>\n\t\t<path d=\"M9 20.25c0 .414 .336 .75 .75 .75h1.25a1 1 0 0 0 1 -1v-1a1 1 0 0 0 -1 -1h-1a1 1 0 0 1 -1 -1v-1a1 1 0 0 1 1 -1h1.25a.75 .75 0 0 1 .75 .75\"/>\n\t\t<path d=\"M5 12v-7a2 2 0 0 1 2 -2h7l5 5v11a2 2 0 0 1 -2 2h-1\"/>\n\t</svg>\n\t{{- else if .HasExt \".css\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-type-css\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M5 12v-7a2 2 0 0 1 2 -2h7l5 5v4\"/>\n\t\t<path d=\"M8 16.5a1.5 1.5 0 0 0 -3 0v3a1.5 1.5 0 0 0 3 0\"/>\n\t\t<path d=\"M11 20.25c0 .414 .336 .75 .75 .75h1.25a1 1 0 0 0 1 -1v-1a1 1 0 0 0 -1 -1h-1a1 1 0 0 1 -1 -1v-1a1 1 0 0 1 1 -1h1.25a.75 .75 0 0 1 .75 .75\"/>\n\t\t<path d=\"M17 20.25c0 .414 .336 .75 .75 .75h1.25a1 1 0 0 0 1 -1v-1a1 1 0 0 0 -1 -1h-1a1 1 0 0 1 -1 -1v-1a1 1 0 0 1 1 -1h1.25a.75 .75 0 0 1 .75 .75\"/>\n\t</svg>\n\t{{- else if .HasExt \".json\" \".json5\" \".jsonc\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-json\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M20 16v-8l3 8v-8\"/>\n\t\t<path d=\"M15 8a2 2 0 0 1 2 2v4a2 2 0 1 1 -4 0v-4a2 2 0 0 1 2 -2z\"/>\n\t\t<path d=\"M1 8h3v6.5a1.5 1.5 0 0 1 -3 0v-.5\"/>\n\t\t<path d=\"M7 15a1 1 0 0 0 1 1h1a1 1 0 0 0 1 -1v-2a1 1 0 0 0 -1 -1h-1a1 1 0 0 1 -1 -1v-2a1 1 0 0 1 1 -1h1a1 1 0 0 1 1 1\"/>\n\t</svg>\n\t{{- else if .HasExt \".ts\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-type-ts\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M5 12v-7a2 2 0 0 1 2 -2h7l5 5v11a2 2 0 0 1 -2 2h-1\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M9 20.25c0 .414 .336 .75 .75 .75h1.25a1 1 0 0 0 1 -1v-1a1 1 0 0 0 -1 -1h-1a1 1 0 0 1 -1 -1v-1a1 1 0 0 1 1 -1h1.25a.75 .75 0 0 1 .75 .75\"/>\n\t\t<path d=\"M3.5 15h3\"/>\n\t\t<path d=\"M5 15v6\"/>\n\t</svg>\n\t{{- else if .HasExt \".sql\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-type-sql\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t<path d=\"M5 20.25c0 .414 .336 .75 .75 .75h1.25a1 1 0 0 0 1 -1v-1a1 1 0 0 0 -1 -1h-1a1 1 0 0 1 -1 -1v-1a1 1 0 0 1 1 -1h1.25a.75 .75 0 0 1 .75 .75\"/>\n\t\t<path d=\"M5 12v-7a2 2 0 0 1 2 -2h7l5 5v4\"/>\n\t\t<path d=\"M18 15v6h2\"/>\n\t\t<path d=\"M13 15a2 2 0 0 1 2 2v2a2 2 0 1 1 -4 0v-2a2 2 0 0 1 2 -2z\"/>\n\t\t<path d=\"M14 20l1.5 1.5\"/>\n\t</svg>\n\t{{- else if .HasExt \".db\" \".sqlite\" \".bak\" \".mdb\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-database\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M12 6m-8 0a8 3 0 1 0 16 0a8 3 0 1 0 -16 0\"/>\n\t\t<path d=\"M4 6v6a8 3 0 0 0 16 0v-6\"/>\n\t\t<path d=\"M4 12v6a8 3 0 0 0 16 0v-6\"/>\n\t</svg>\n\t{{- else if .HasExt \".eml\" \".email\" \".mailbox\" \".mbox\" \".msg\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-mail\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M3 7a2 2 0 0 1 2 -2h14a2 2 0 0 1 2 2v10a2 2 0 0 1 -2 2h-14a2 2 0 0 1 -2 -2v-10z\"/>\n\t\t<path d=\"M3 7l9 6l9 -6\"/>\n\t</svg>\n\t{{- else if .HasExt \".crt\" \".pem\" \".x509\" \".cer\" \".ca-bundle\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-certificate\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M15 15m-3 0a3 3 0 1 0 6 0a3 3 0 1 0 -6 0\"/>\n\t\t<path d=\"M13 17.5v4.5l2 -1.5l2 1.5v-4.5\"/>\n\t\t<path d=\"M10 19h-5a2 2 0 0 1 -2 -2v-10c0 -1.1 .9 -2 2 -2h14a2 2 0 0 1 2 2v10a2 2 0 0 1 -1 1.73\"/>\n\t\t<path d=\"M6 9l12 0\"/>\n\t\t<path d=\"M6 12l3 0\"/>\n\t\t<path d=\"M6 15l2 0\"/>\n\t</svg>\n\t{{- else if .HasExt \".key\" \".keystore\" \".jks\" \".p12\" \".pfx\" \".pub\"}}\n\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-key\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t<path d=\"M16.555 3.843l3.602 3.602a2.877 2.877 0 0 1 0 4.069l-2.643 2.643a2.877 2.877 0 0 1 -4.069 0l-.301 -.301l-6.558 6.558a2 2 0 0 1 -1.239 .578l-.175 .008h-1.172a1 1 0 0 1 -.993 -.883l-.007 -.117v-1.172a2 2 0 0 1 .467 -1.284l.119 -.13l.414 -.414h2v-2h2v-2l2.144 -2.144l-.301 -.301a2.877 2.877 0 0 1 0 -4.069l2.643 -2.643a2.877 2.877 0 0 1 4.069 0z\"/>\n\t\t<path d=\"M15 9h.01\"/>\n\t</svg>\n\t{{- else}}\n\t\t{{- if .IsSymlink}}\n\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file-symlink\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t<path d=\"M4 21v-4a3 3 0 0 1 3 -3h5\"/>\n\t\t\t<path d=\"M9 17l3 -3l-3 -3\"/>\n\t\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t\t<path d=\"M5 11v-6a2 2 0 0 1 2 -2h7l5 5v11a2 2 0 0 1 -2 2h-9.5\"/>\n\t\t</svg>\n\t\t{{- else}}\n\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-file\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t<path d=\"M14 3v4a1 1 0 0 0 1 1h4\"/>\n\t\t\t<path d=\"M17 21h-10a2 2 0 0 1 -2 -2v-14a2 2 0 0 1 2 -2h7l5 5v11a2 2 0 0 1 -2 2z\"/>\n\t\t</svg>\n\t\t{{- end}}\n\t{{- end}}\n{{- end}}\n<!DOCTYPE html>\n<html>\n\t<head>\n\t\t<title>{{html .Name}}</title>\n\t\t<link rel=\"canonical\" href=\"{{.Path}}/\"  />\n\t\t<meta charset=\"utf-8\">\n\t\t<meta name=\"color-scheme\" content=\"light dark\">\n\t\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n<style {{ $nonceAttribute }}>\n* { padding: 0; margin: 0; box-sizing: border-box; }\n\nbody {\n\tfont-family: Inter, system-ui, sans-serif;\n\tfont-size: 16px;\n\ttext-rendering: optimizespeed;\n\tbackground-color: #f3f6f7;\n\tmin-height: 100vh;\n}\n\nimg,\nsvg {\n\tvertical-align: middle;\n\tz-index: 1;\n}\n\nimg {\n\tmax-width: 100%;\n\tmax-height: 100%;\n\tborder-radius: 5px;\n}\n\ntd img {\n\tmax-width: 1.5em;\n\tmax-height: 2em;\n\tobject-fit: cover;\n}\n\nbody,\na,\nsvg,\n.layout.current,\n.layout.current svg,\n.go-up {\n\tcolor: #333;\n\ttext-decoration: none;\n}\n\n#layout-list, #layout-grid {\n\tcursor: pointer;\n}\n\n.wrapper {\n\tmax-width: 1200px;\n\tmargin-left: auto;\n\tmargin-right: auto;\n}\n\nheader,\n.meta {\n\tpadding-left: 5%;\n\tpadding-right: 5%;\n}\n\ntd a {\n\tcolor: #006ed3;\n\ttext-decoration: none;\n}\n\ntd a:hover {\n\tcolor: #0095e4;\n}\n\ntd a:visited {\n\tcolor: #800080;\n}\n\ntd a:visited:hover {\n\tcolor: #b900b9;\n}\n\nth:first-child,\ntd:first-child {\n\twidth: 5%;\n}\n\nth:last-child,\ntd:last-child {\n\twidth: 5%;\n}\n\n.size,\n.timestamp {\n\tfont-size: 14px;\n}\n\n.grid .size {\n\tfont-size: 12px;\n\tmargin-top: .5em;\n\tcolor: #496a84;\n}\n\nheader {\n\tpadding-top: 15px;\n\tpadding-bottom: 15px;\n\tbox-shadow: 0px 0px 20px 0px rgb(0 0 0 / 10%);\n}\n\n.breadcrumbs {\n\ttext-transform: uppercase;\n\tfont-size: 10px;\n\tletter-spacing: 1px;\n\tcolor: #939393;\n\tmargin-bottom: 5px;\n\tpadding-left: 3px;\n}\n\nh1 {\n\tfont-size: 20px;\n\tfont-family: Poppins, system-ui, sans-serif;\n\tfont-weight: normal;\n\twhite-space: nowrap;\n\toverflow-x: hidden;\n\ttext-overflow: ellipsis;\n\tcolor: #c5c5c5;\n}\n\nh1 a,\nth a {\n\tcolor: #000;\n}\n\nh1 a {\n\tpadding: 0 3px;\n\tmargin: 0 1px;\n}\n\nh1 a:hover {\n\tbackground: #ffffc4;\n}\n\nh1 a:first-child {\n\tmargin: 0;\n}\n\nheader,\nmain {\n\tbackground-color: white;\n}\n\nmain {\n\tmargin: 3em auto 0;\n\tborder-radius: 5px;\n\tbox-shadow: 0 2px 5px 1px rgb(0 0 0 / 5%);\n}\n\n.meta {\n\tdisplay: flex;\n\tgap: 1em;\n\tfont-size: 14px;\n\tborder-bottom: 1px solid #e5e9ea;\n\tpadding-top: 1em;\n\tpadding-bottom: 1em;\n}\n\n#summary {\n\tdisplay: flex;\n\tgap: 1em;\n\talign-items: center;\n\tmargin-right: auto;\n}\n\n.filter-container {\n\tposition: relative;\n\tdisplay: inline-block;\n\tmargin-left: 1em;\n}\n\n#search-icon {\n\tcolor: #777;\n\tposition: absolute;\n\theight: 1em;\n\ttop: .6em;\n\tleft: .5em;\n}\n\n#filter {\n\tpadding: .5em 1em .5em 2.5em;\n\tborder: none;\n\tborder: 1px solid #CCC;\n\tborder-radius: 5px;\n\tfont-family: inherit;\n\tposition: relative;\n\tz-index: 2;\n\tbackground: none;\n}\n\n.layout,\n.layout svg {\n\tcolor: #9a9a9a;\n}\n\ntable {\n\twidth: 100%;\n\tborder-collapse: collapse;\n}\n\ntbody tr,\ntbody tr a,\n.entry a {\n\ttransition: all .15s;\n}\n\ntbody tr:hover,\n.grid .entry a:hover {\n\tbackground-color: #f4f9fd;\n}\n\nth,\ntd {\n\ttext-align: left;\n}\n\nth {\n\tposition: sticky;\n\ttop: 0;\n\tbackground: white;\n\twhite-space: nowrap;\n\tz-index: 2;\n\ttext-transform: uppercase;\n\tfont-size: 14px;\n\tletter-spacing: 1px;\n\tpadding: .75em 0;\n}\n\ntd {\n\twhite-space: nowrap;\n}\n\ntd:nth-child(2) {\n\twidth: 75%;\n}\n\ntd:nth-child(2) a {\n\tpadding: 1em 0;\n\tdisplay: block;\n}\n\ntd:nth-child(3),\nth:nth-child(3) {\n\tpadding: 0 20px 0 20px;\n\tmin-width: 150px;\n}\n\ntd .go-up {\n\ttext-transform: uppercase;\n\tfont-size: 12px;\n\tfont-weight: bold;\n}\n\n.name,\n.go-up {\n\tword-break: break-all;\n\toverflow-wrap: break-word;\n\twhite-space: pre-wrap;\n}\n\n.listing .icon-tabler {\n\tcolor: #454545;\n}\n\n.listing .icon-tabler-folder-filled {\n\tcolor: #ffb900 !important;\n}\n\n.sizebar {\n\tposition: relative;\n\tpadding: 0.25rem 0.5rem;\n\tdisplay: flex;\n}\n\n.sizebar-bar {\n\tbackground-color: #dbeeff;\n\tposition: absolute;\n\ttop: 0;\n\tright: 0;\n\tbottom: 0;\n\tleft: 0;\n\tz-index: 0;\n\theight: 100%;\n\tpointer-events: none;\n}\n\n.sizebar-text {\n\tposition: relative;\n\tz-index: 1;\n\toverflow: hidden;\n\ttext-overflow: ellipsis;\n\twhite-space: nowrap;\n}\n\n.grid {\n\tdisplay: grid;\n\tgrid-template-columns: repeat(auto-fill, minmax(16em, 1fr));\n\tgap: 2px;\n}\n\n.grid .entry {\n\tposition: relative;\n\twidth: 100%;\n}\n\n.grid .entry a {\n\tdisplay: flex;\n\tflex-direction: column;\n\talign-items: center;\n\tjustify-content: center;\n\tpadding: 1.5em;\n\theight: 100%;\n}\n\n.grid .entry svg {\n\twidth: 75px;\n\theight: 75px;\n}\n\n.grid .entry img {\n\tmax-height: 200px;\n\tobject-fit: cover;\n}\n\n.grid .entry .name {\n\tmargin-top: 1em;\n}\n\nfooter {\n\tpadding: 40px 20px;\n\tfont-size: 12px;\n\ttext-align: center;\n}\n\n.caddy-logo {\n\tdisplay: inline-block;\n\theight: 2.5em;\n\tmargin: 0 auto;\n}\n\n@media (max-width: 600px) {\n\t.hideable {\n\t\tdisplay: none;\n\t}\n\n\ttd:nth-child(2) {\n\t\twidth: auto;\n\t}\n\n\tth:nth-child(3),\n\ttd:nth-child(3) {\n\t\tpadding-right: 5%;\n\t\ttext-align: right;\n\t}\n\n\th1 {\n\t\tcolor: #000;\n\t}\n\n\th1 a {\n\t\tmargin: 0;\n\t}\n\n\t#filter {\n\t\tmax-width: 100px;\n\t}\n\n\t.grid .entry {\n\t\tmax-width: initial;\n\t}\n}\n\n\n@media (prefers-color-scheme: dark) {\n\thtml {\n\t\tbackground: black; /* overscroll */\n\t}\n\n\tbody {\n\t\tbackground: linear-gradient(180deg, rgb(34 50 66) 0%, rgb(26 31 38) 100%);\n\t\tbackground-attachment: fixed;\n\t}\n\n\tbody,\n\ta,\n\tsvg,\n\t.layout.current,\n\t.layout.current svg,\n\t.go-up {\n\t\tcolor: #ccc;\n\t}\n\n\th1 a,\n\tth a {\n\t\tcolor: white;\n\t}\n\n\th1 {\n\t\tcolor: white;\n\t}\n\n\th1 a:hover {\n\t\tbackground: hsl(213deg 100% 73% / 20%);\n\t}\n\n\theader,\n\tmain,\n\t.grid .entry {\n\t\tbackground-color: #101720;\n\t}\n\n\ttbody tr:hover,\n\t.grid .entry a:hover {\n\t\tbackground-color: #162030;\n\t\tcolor: #fff;\n\t}\n\n\tth {\n\t\tbackground-color: #18212c;\n\t}\n\n\ttd a,\n\t.listing .icon-tabler {\n\t\tcolor: #abc8e3;\n\t}\n\n\ttd a:hover,\n\ttd a:hover .icon-tabler {\n\t\tcolor: white;\n\t}\n\n\ttd a:visited {\n\t\tcolor: #cd53cd;\n\t}\n\n\ttd a:visited:hover {\n\t\tcolor: #f676f6;\n\t}\n\n\t#search-icon {\n\t\tcolor: #7798c4;\n\t}\n\n\t#filter {\n\t\tcolor: #ffffff;\n\t\tborder: 1px solid #29435c;\n\t}\n\n\t.meta {\n\t\tborder-bottom: 1px solid #222e3b;\n\t}\n\n\t.sizebar-bar {\n\t\tbackground-color: #1f3549;\n\t}\n\n\t.grid .entry a {\n\t\tbackground-color: #080b0f;\n\t}\n\n\t#Wordmark path,\n\t#R path {\n\t\tfill: #ccc !important;\n\t}\n\t#R circle {\n\t\tstroke: #ccc !important;\n\t}\n}\n\n</style>\n{{- if eq .Layout \"grid\"}}\n<style {{ $nonceAttribute }}>.wrapper { max-width: none; } main { margin-top: 1px; }</style>\n{{- end}}\n</head>\n<body>\n\t<header>\n\t\t<div class=\"wrapper\">\n\t\t\t<div class=\"breadcrumbs\">Folder Path</div>\n\t\t\t\t<h1>\n\t\t\t\t\t{{range $i, $crumb := .Breadcrumbs}}<a href=\"{{html $crumb.Link}}\">{{html $crumb.Text}}</a>{{if ne $i 0}}/{{end}}{{end}}\n\t\t\t\t</h1>\n\t\t\t</div>\n\t\t</header>\n\t\t<div class=\"wrapper\">\n\t\t\t<main>\n\t\t\t\t<div class=\"meta\">\n\t\t\t\t\t<div id=\"summary\">\n\t\t\t\t\t\t<span class=\"meta-item\">\n\t\t\t\t\t\t\t<b>{{.NumDirs}}</b> director{{if eq 1 .NumDirs}}y{{else}}ies{{end}}\n\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<span class=\"meta-item\">\n\t\t\t\t\t\t\t<b>{{.NumFiles}}</b> file{{if ne 1 .NumFiles}}s{{end}}\n\t\t\t\t\t\t</span>\n\t\t\t\t\t\t<span class=\"meta-item\">\n\t\t\t\t\t\t\t<b>{{.HumanTotalFileSize}}</b> total\n\t\t\t\t\t\t</span>\n\t\t\t\t\t\t{{- if ne 0 .Limit}}\n\t\t\t\t\t\t<span class=\"meta-item\">\n\t\t\t\t\t\t\t(of which only <b>{{.Limit}}</b> are displayed)\n\t\t\t\t\t\t</span>\n\t\t\t\t\t\t{{- end}}\n\t\t\t\t\t</div>\n\t\t\t\t\t<a id=\"layout-list\" class='layout{{if eq $.Layout \"list\" \"\"}}current{{end}}'>\n\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-layout-list\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t<path d=\"M4 4m0 2a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v2a2 2 0 0 1 -2 2h-12a2 2 0 0 1 -2 -2z\"/>\n\t\t\t\t\t\t\t<path d=\"M4 14m0 2a2 2 0 0 1 2 -2h12a2 2 0 0 1 2 2v2a2 2 0 0 1 -2 2h-12a2 2 0 0 1 -2 -2z\"/>\n\t\t\t\t\t\t</svg>\n\t\t\t\t\t\tList\n\t\t\t\t\t</a>\n\t\t\t\t\t<a id=\"layout-grid\" class='layout{{if eq $.Layout \"grid\"}}current{{end}}'>\n\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-layout-grid\" width=\"16\" height=\"16\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t<path d=\"M4 4m0 1a1 1 0 0 1 1 -1h4a1 1 0 0 1 1 1v4a1 1 0 0 1 -1 1h-4a1 1 0 0 1 -1 -1z\"/>\n\t\t\t\t\t\t\t<path d=\"M14 4m0 1a1 1 0 0 1 1 -1h4a1 1 0 0 1 1 1v4a1 1 0 0 1 -1 1h-4a1 1 0 0 1 -1 -1z\"/>\n\t\t\t\t\t\t\t<path d=\"M4 14m0 1a1 1 0 0 1 1 -1h4a1 1 0 0 1 1 1v4a1 1 0 0 1 -1 1h-4a1 1 0 0 1 -1 -1z\"/>\n\t\t\t\t\t\t\t<path d=\"M14 14m0 1a1 1 0 0 1 1 -1h4a1 1 0 0 1 1 1v4a1 1 0 0 1 -1 1h-4a1 1 0 0 1 -1 -1z\"/>\n\t\t\t\t\t\t</svg>\n\t\t\t\t\t\tGrid\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class='listing{{if eq .Layout \"grid\"}} grid{{end}}'>\n\t\t\t\t{{- if eq .Layout \"grid\"}}\n\t\t\t\t{{- range .Items}}\n\t\t\t\t<div class=\"entry\">\n\t\t\t\t\t<a href=\"{{html .URL}}\" title='{{html (.HumanModTime \"January 2, 2006 at 15:04:05\")}}'>\n\t\t\t\t\t\t{{template \"icon\" .}}\n\t\t\t\t\t\t<div class=\"name\">{{html .Name}}</div>\n\t\t\t\t\t\t<div class=\"size\">{{.HumanSize}}</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t{{- end}}\n\t\t\t\t{{- else}}\n\t\t\t\t<table aria-describedby=\"summary\">\n\t\t\t\t\t<thead>\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<th></th>\n\t\t\t\t\t\t<th>\n\t\t\t\t\t\t\t{{- if and (eq .Sort \"namedirfirst\") (ne .Order \"desc\")}}\n\t\t\t\t\t\t\t<a href=\"?sort=namedirfirst&order=desc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\" class=\"icon\">\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-caret-up\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M18 14l-6 -6l-6 6h12\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- else if and (eq .Sort \"namedirfirst\") (ne .Order \"asc\")}}\n\t\t\t\t\t\t\t<a href=\"?sort=namedirfirst&order=asc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\" class=\"icon\">\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-caret-down\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M6 10l6 6l6 -6h-12\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- else}}\n\t\t\t\t\t\t\t<a href=\"?sort=namedirfirst&order=asc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\" class=\"icon sort\">\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-caret-up\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M18 14l-6 -6l-6 6h12\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- end}}\n\n\t\t\t\t\t\t\t{{- if and (eq .Sort \"name\") (ne .Order \"desc\")}}\n\t\t\t\t\t\t\t<a href=\"?sort=name&order=desc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\">\n\t\t\t\t\t\t\t\tName\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-caret-up\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M18 14l-6 -6l-6 6h12\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- else if and (eq .Sort \"name\") (ne .Order \"asc\")}}\n\t\t\t\t\t\t\t<a href=\"?sort=name&order=asc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\">\n\t\t\t\t\t\t\t\tName\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-caret-down\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M6 10l6 6l6 -6h-12\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- else}}\n\t\t\t\t\t\t\t<a href=\"?sort=name&order=asc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\">\n\t\t\t\t\t\t\t\tName\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- end}}\n\n\t\t\t\t\t\t\t<div class=\"filter-container\">\n\t\t\t\t\t\t\t\t<svg id=\"search-icon\" xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-search\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M10 10m-7 0a7 7 0 1 0 14 0a7 7 0 1 0 -14 0\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M21 21l-6 -6\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t\t<input type=\"search\" placeholder=\"Search\" id=\"filter\">\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</th>\n\t\t\t\t\t\t<th>\n\t\t\t\t\t\t\t{{- if and (eq .Sort \"size\") (ne .Order \"desc\")}}\n\t\t\t\t\t\t\t<a href=\"?sort=size&order=desc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\">\n\t\t\t\t\t\t\t\tSize\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-caret-up\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M18 14l-6 -6l-6 6h12\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- else if and (eq .Sort \"size\") (ne .Order \"asc\")}}\n\t\t\t\t\t\t\t<a href=\"?sort=size&order=asc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\">\n\t\t\t\t\t\t\t\tSize\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-caret-down\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M6 10l6 6l6 -6h-12\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- else}}\n\t\t\t\t\t\t\t<a href=\"?sort=size&order=asc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\">\n\t\t\t\t\t\t\t\tSize\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- end}}\n\t\t\t\t\t\t</th>\n\t\t\t\t\t\t<th class=\"hideable\">\n\t\t\t\t\t\t\t{{- if and (eq .Sort \"time\") (ne .Order \"desc\")}}\n\t\t\t\t\t\t\t<a href=\"?sort=time&order=desc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\">\n\t\t\t\t\t\t\t\tModified\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-caret-up\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M18 14l-6 -6l-6 6h12\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- else if and (eq .Sort \"time\") (ne .Order \"asc\")}}\n\t\t\t\t\t\t\t<a href=\"?sort=time&order=asc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\">\n\t\t\t\t\t\t\t\tModified\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-caret-down\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M6 10l6 6l6 -6h-12\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- else}}\n\t\t\t\t\t\t\t<a href=\"?sort=time&order=asc{{if ne 0 .Limit}}&limit={{.Limit}}{{end}}{{if ne 0 .Offset}}&offset={{.Offset}}{{end}}\">\n\t\t\t\t\t\t\t\tModified\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t{{- end}}\n\t\t\t\t\t\t</th>\n\t\t\t\t\t\t<th class=\"hideable\"></th>\n\t\t\t\t\t</tr>\n\t\t\t\t\t</thead>\n\t\t\t\t\t<tbody>\n\t\t\t\t\t{{- if .CanGoUp}}\n\t\t\t\t\t<tr>\n\t\t\t\t\t\t<td></td>\n\t\t\t\t\t\t<td>\n\t\t\t\t\t\t\t<a href=\"..\">\n\t\t\t\t\t\t\t\t<svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-corner-left-up\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n\t\t\t\t\t\t\t\t\t<path d=\"M18 18h-6a3 3 0 0 1 -3 -3v-10l-4 4m8 0l-4 -4\"/>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t\t<span class=\"go-up\">Up</span>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t</td>\n\t\t\t\t\t\t<td></td>\n\t\t\t\t\t\t<td class=\"hideable\"></td>\n\t\t\t\t\t\t<td class=\"hideable\"></td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t{{- end}}\n\t\t\t\t\t{{- range .Items}}\n\t\t\t\t\t<tr class=\"file\">\n\t\t\t\t\t\t<td></td>\n\t\t\t\t\t\t<td>\n\t\t\t\t\t\t\t<a href=\"{{html .URL}}\">\n\t\t\t\t\t\t\t\t{{template \"icon\" .}}\n\t\t\t\t\t\t\t\t{{- if not .SymlinkPath}}\n\t\t\t\t\t\t\t\t<span class=\"name\">{{html .Name}}</span>\n\t\t\t\t\t\t\t\t{{- else}}\n\t\t\t\t\t\t\t\t<span class=\"name\">{{html .Name}} <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-arrow-narrow-right\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t\t\t\t\t<path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/><path d=\"M5 12l14 0\" />\n\t\t\t\t\t\t\t\t\t<path d=\"M15 16l4 -4\" />\n\t\t\t\t\t\t\t\t\t<path d=\"M15 8l4 4\" />\n\t\t\t\t\t\t\t\t</svg> {{html .SymlinkPath}}</span>\n\t\t\t\t\t\t\t\t{{- end}}\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t</td>\n\t\t\t\t\t\t{{- if .IsDir}}\n\t\t\t\t\t\t<td>&mdash;</td>\n\t\t\t\t\t\t{{- else}}\n\t\t\t\t\t\t<td class=\"size\" data-size=\"{{.Size}}\">\n\t\t\t\t\t\t\t<div class=\"sizebar\">\n\t\t\t\t\t\t\t\t<div class=\"sizebar-bar\"></div>\n\t\t\t\t\t\t\t\t<div class=\"sizebar-text\">\n\t\t\t\t\t\t\t\t\t{{if .IsSymlink}}\u21b1&nbsp;{{end}}{{.HumanSize}}\n\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</td>\n\t\t\t\t\t\t{{- end}}\n\t\t\t\t\t\t<td class=\"timestamp hideable\">\n\t\t\t\t\t\t\t<time datetime=\"{{.HumanModTime \"2006-01-02T15:04:05Z\"}}\">{{.HumanModTime \"01/02/2006 03:04:05 PM -07:00\"}}</time>\n\t\t\t\t\t\t</td>\n\t\t\t\t\t\t<td class=\"hideable\"></td>\n\t\t\t\t\t</tr>\n\t\t\t\t\t{{- end}}\n\t\t\t\t\t</tbody>\n\t\t\t\t</table>\n\t\t\t\t{{- end}}\n\t\t\t</div>\n\t\t\t</main>\n\t\t</div>\n\t\t<footer>\n\t\t\tServed with\n\t\t\t<a rel=\"noopener noreferrer\" href=\"https://caddyserver.com\">\n\t\t\t\t<svg class=\"caddy-logo\" viewBox=\"0 0 379 114\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:space=\"preserve\" xmlns:serif=\"http://www.serif.com/\" fill-rule=\"evenodd\" clip-rule=\"evenodd\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n\t\t\t\t\t<g transform=\"matrix(1,0,0,1,-1982.99,-530.985)\">\n\t\t\t\t\t\t<g transform=\"matrix(1.16548,0,0,1.10195,1823.12,393.466)\">\n\t\t\t\t\t\t\t<g transform=\"matrix(1,0,0,1,0.233052,1.17986)\">\n\t\t\t\t\t\t\t\t<g id=\"Icon\" transform=\"matrix(0.858013,0,0,0.907485,-3224.99,-1435.83)\">\n\t\t\t\t\t\t\t\t\t<g>\n\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(-0.191794,-0.715786,0.715786,-0.191794,4329.14,4673.64)\">\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M3901.56,610.734C3893.53,610.261 3886.06,608.1 3879.2,604.877C3872.24,601.608 3866.04,597.093 3860.8,591.633C3858.71,589.457 3856.76,587.149 3854.97,584.709C3853.2,582.281 3851.57,579.733 3850.13,577.066C3845.89,569.224 3843.21,560.381 3842.89,550.868C3842.57,543.321 3843.64,536.055 3845.94,529.307C3848.37,522.203 3852.08,515.696 3856.83,510.049L3855.79,509.095C3850.39,514.54 3846.02,520.981 3842.9,528.125C3839.84,535.125 3838.03,542.781 3837.68,550.868C3837.34,561.391 3839.51,571.425 3843.79,580.306C3845.27,583.38 3847.03,586.304 3849.01,589.049C3851.01,591.806 3853.24,594.39 3855.69,596.742C3861.75,602.568 3869,607.19 3877.03,610.1C3884.66,612.867 3892.96,614.059 3901.56,613.552L3901.56,610.734Z\" fill=\"rgb(0,144,221)\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(-0.191794,-0.715786,0.715786,-0.191794,4329.14,4673.64)\">\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M3875.69,496.573C3879.62,494.538 3883.8,492.897 3888.2,491.786C3892.49,490.704 3896.96,490.124 3901.56,490.032C3903.82,490.13 3906.03,490.332 3908.21,490.688C3917.13,492.147 3925.19,495.814 3932.31,500.683C3936.13,503.294 3939.59,506.335 3942.81,509.619C3947.09,513.98 3950.89,518.816 3953.85,524.232C3958.2,532.197 3960.96,541.186 3961.32,550.868C3961.61,558.748 3960.46,566.345 3957.88,573.322C3956.09,578.169 3953.7,582.753 3950.66,586.838C3947.22,591.461 3942.96,595.427 3938.27,598.769C3933.66,602.055 3928.53,604.619 3923.09,606.478C3922.37,606.721 3921.6,606.805 3920.93,607.167C3920.42,607.448 3920.14,607.854 3919.69,608.224L3920.37,610.389C3920.98,610.432 3921.47,610.573 3922.07,610.474C3922.86,610.344 3923.55,609.883 3924.28,609.566C3931.99,606.216 3938.82,601.355 3944.57,595.428C3947.02,592.903 3949.25,590.174 3951.31,587.319C3953.59,584.168 3955.66,580.853 3957.43,577.348C3961.47,569.34 3964.01,560.422 3964.36,550.868C3964.74,540.511 3962.66,530.628 3958.48,521.868C3955.57,515.775 3951.72,510.163 3946.95,505.478C3943.37,501.962 3939.26,498.99 3934.84,496.562C3926.88,492.192 3917.87,489.76 3908.37,489.229C3906.12,489.104 3903.86,489.054 3901.56,489.154C3896.87,489.06 3892.3,489.519 3887.89,490.397C3883.3,491.309 3878.89,492.683 3874.71,494.525L3875.69,496.573Z\" fill=\"rgb(0,144,221)\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t<g>\n\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(-3.37109,-0.514565,0.514565,-3.37109,4078.07,1806.88)\">\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M22,12C22,10.903 21.097,10 20,10C19.421,10 18.897,10.251 18.53,10.649C18.202,11.006 18,11.481 18,12C18,13.097 18.903,14 20,14C21.097,14 22,13.097 22,12Z\" fill=\"none\" fill-rule=\"nonzero\" stroke=\"rgb(0,144,221)\" stroke-width=\"1.05px\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(-5.33921,-5.26159,-3.12106,-6.96393,4073.87,1861.55)\">\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M10.315,5.333C10.315,5.333 9.748,5.921 9.03,6.673C7.768,7.995 6.054,9.805 6.054,9.805L6.237,9.86C6.237,9.86 8.045,8.077 9.36,6.771C10.107,6.028 10.689,5.444 10.689,5.444L10.315,5.333Z\" fill=\"rgb(0,144,221)\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t<g id=\"Padlock\" transform=\"matrix(3.11426,0,0,3.11426,3938.31,1737.25)\">\n\t\t\t\t\t\t\t\t\t\t<g>\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M9.876,21L18.162,21C18.625,21 19,20.625 19,20.162L19,11.838C19,11.375 18.625,11 18.162,11L5.838,11C5.375,11 5,11.375 5,11.838L5,16.758\" fill=\"none\" stroke=\"rgb(34,182,56)\" stroke-width=\"1.89px\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/>\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M8,11L8,7C8,4.806 9.806,3 12,3C14.194,3 16,4.806 16,7L16,11\" fill=\"none\" fill-rule=\"nonzero\" stroke=\"rgb(34,182,56)\" stroke-width=\"1.89px\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t<g>\n\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(5.30977,0.697415,-0.697415,5.30977,3852.72,1727.97)\">\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M22,12C22,11.659 21.913,11.337 21.76,11.055C21.421,10.429 20.756,10 20,10C18.903,10 18,10.903 18,12C18,13.097 18.903,14 20,14C21.097,14 22,13.097 22,12Z\" fill=\"none\" fill-rule=\"nonzero\" stroke=\"rgb(0,144,221)\" stroke-width=\"0.98px\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(4.93114,2.49604,1.11018,5.44847,3921.41,1726.72)\">\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M8.902,6.77C8.902,6.77 7.235,8.253 6.027,9.366C5.343,9.996 4.819,10.502 4.819,10.502L5.52,11.164C5.52,11.164 6.021,10.637 6.646,9.951C7.749,8.739 9.219,7.068 9.219,7.068L8.902,6.77Z\" fill=\"rgb(0,144,221)\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t<g id=\"Text\">\n\t\t\t\t\t\t\t\t\t<g id=\"Wordmark\" transform=\"matrix(1.32271,0,0,2.60848,-899.259,-791.691)\">\n\t\t\t\t\t\t\t\t\t\t<g id=\"y\" transform=\"matrix(0.50291,0,0,0.281607,905.533,304.987)\">\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M192.152,286.875L202.629,268.64C187.804,270.106 183.397,265.779 180.143,263.391C176.888,261.004 174.362,257.99 172.563,254.347C170.765,250.705 169.866,246.691 169.866,242.305L169.866,208.107L183.21,208.107L183.21,242.213C183.21,245.188 183.896,247.822 185.268,250.116C186.64,252.41 188.465,254.197 190.743,255.475C193.022,256.754 195.501,257.393 198.182,257.393C200.894,257.393 203.393,256.75 205.68,255.463C207.966,254.177 209.799,252.391 211.178,250.105C212.558,247.818 213.248,245.188 213.248,242.213L213.248,208.107L226.545,208.107L226.545,242.305C226.545,246.707 225.378,258.46 218.079,268.64C215.735,271.909 207.835,286.875 207.835,286.875L192.152,286.875Z\" fill=\"rgb(47,47,47)\" fill-rule=\"nonzero\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t<g id=\"add\" transform=\"matrix(0.525075,0,0,0.281607,801.871,304.987)\">\n\t\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(116.242,0,0,116.242,161.846,267.39)\">\n\t\t\t\t\t\t\t\t\t\t\t\t<path d=\"M0.276,0.012C0.227,0.012 0.186,0 0.15,-0.024C0.115,-0.048 0.088,-0.08 0.069,-0.12C0.05,-0.161 0.04,-0.205 0.04,-0.254C0.04,-0.305 0.051,-0.35 0.072,-0.39C0.094,-0.431 0.125,-0.463 0.165,-0.487C0.205,-0.51 0.254,-0.522 0.31,-0.522C0.366,-0.522 0.413,-0.51 0.452,-0.486C0.491,-0.463 0.521,-0.431 0.542,-0.39C0.562,-0.35 0.573,-0.305 0.573,-0.256L0.573,-0L0.458,-0L0.458,-0.095L0.456,-0.095C0.446,-0.076 0.433,-0.058 0.417,-0.042C0.401,-0.026 0.381,-0.013 0.358,-0.003C0.335,0.007 0.307,0.012 0.276,0.012ZM0.307,-0.086C0.337,-0.086 0.363,-0.093 0.386,-0.108C0.408,-0.123 0.426,-0.144 0.438,-0.17C0.45,-0.195 0.456,-0.224 0.456,-0.256C0.456,-0.288 0.45,-0.317 0.438,-0.342C0.426,-0.367 0.409,-0.387 0.387,-0.402C0.365,-0.417 0.338,-0.424 0.308,-0.424C0.276,-0.424 0.249,-0.417 0.226,-0.402C0.204,-0.387 0.186,-0.366 0.174,-0.341C0.162,-0.315 0.156,-0.287 0.156,-0.255C0.156,-0.224 0.162,-0.195 0.174,-0.169C0.186,-0.144 0.203,-0.123 0.226,-0.108C0.248,-0.093 0.275,-0.086 0.307,-0.086Z\" fill=\"rgb(47,47,47)\" fill-rule=\"nonzero\"/>\n\t\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(116.242,0,0,116.242,226.592,267.39)\">\n\t\t\t\t\t\t\t\t\t\t\t\t<path d=\"M0.306,0.012C0.265,0.012 0.229,0.006 0.196,-0.008C0.163,-0.021 0.135,-0.039 0.112,-0.064C0.089,-0.088 0.071,-0.117 0.059,-0.151C0.046,-0.185 0.04,-0.222 0.04,-0.263C0.04,-0.315 0.051,-0.36 0.072,-0.399C0.093,-0.437 0.122,-0.468 0.159,-0.489C0.196,-0.511 0.239,-0.522 0.287,-0.522C0.311,-0.522 0.333,-0.518 0.355,-0.511C0.377,-0.504 0.396,-0.493 0.413,-0.48C0.431,-0.466 0.445,-0.451 0.455,-0.433L0.456,-0.433L0.456,-0.73L0.571,-0.73L0.571,-0.261C0.571,-0.205 0.56,-0.156 0.537,-0.115C0.515,-0.074 0.484,-0.043 0.444,-0.021C0.405,0.001 0.358,0.012 0.306,0.012ZM0.306,-0.086C0.335,-0.086 0.361,-0.093 0.384,-0.107C0.406,-0.122 0.423,-0.141 0.436,-0.167C0.448,-0.192 0.455,-0.221 0.455,-0.255C0.455,-0.288 0.448,-0.317 0.436,-0.343C0.423,-0.368 0.406,-0.388 0.383,-0.402C0.361,-0.417 0.335,-0.424 0.305,-0.424C0.276,-0.424 0.251,-0.417 0.228,-0.402C0.206,-0.387 0.188,-0.368 0.175,-0.342C0.163,-0.317 0.156,-0.288 0.156,-0.255C0.156,-0.222 0.163,-0.193 0.175,-0.167C0.188,-0.142 0.206,-0.122 0.229,-0.108C0.251,-0.093 0.277,-0.086 0.306,-0.086Z\" fill=\"rgb(47,47,47)\" fill-rule=\"nonzero\"/>\n\t\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(116.242,0,0,116.242,290.293,267.39)\">\n\t\t\t\t\t\t\t\t\t\t\t\t<path d=\"M0.306,0.012C0.265,0.012 0.229,0.006 0.196,-0.008C0.163,-0.021 0.135,-0.039 0.112,-0.064C0.089,-0.088 0.071,-0.117 0.059,-0.151C0.046,-0.185 0.04,-0.222 0.04,-0.263C0.04,-0.315 0.051,-0.36 0.072,-0.399C0.093,-0.437 0.122,-0.468 0.159,-0.489C0.196,-0.511 0.239,-0.522 0.287,-0.522C0.311,-0.522 0.333,-0.518 0.355,-0.511C0.377,-0.504 0.396,-0.493 0.413,-0.48C0.431,-0.466 0.445,-0.451 0.455,-0.433L0.456,-0.433L0.456,-0.73L0.571,-0.73L0.571,-0.261C0.571,-0.205 0.56,-0.156 0.537,-0.115C0.515,-0.074 0.484,-0.043 0.444,-0.021C0.405,0.001 0.358,0.012 0.306,0.012ZM0.306,-0.086C0.335,-0.086 0.361,-0.093 0.384,-0.107C0.406,-0.122 0.423,-0.141 0.436,-0.167C0.448,-0.192 0.455,-0.221 0.455,-0.255C0.455,-0.288 0.448,-0.317 0.436,-0.343C0.423,-0.368 0.406,-0.388 0.383,-0.402C0.361,-0.417 0.335,-0.424 0.305,-0.424C0.276,-0.424 0.251,-0.417 0.228,-0.402C0.206,-0.387 0.188,-0.368 0.175,-0.342C0.163,-0.317 0.156,-0.288 0.156,-0.255C0.156,-0.222 0.163,-0.193 0.175,-0.167C0.188,-0.142 0.206,-0.122 0.229,-0.108C0.251,-0.093 0.277,-0.086 0.306,-0.086Z\" fill=\"rgb(47,47,47)\" fill-rule=\"nonzero\"/>\n\t\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t<g id=\"c\" transform=\"matrix(-0.0716462,0.31304,-0.583685,-0.0384251,1489.76,-444.051)\">\n\t\t\t\t\t\t\t\t\t\t\t<path d=\"M2668.11,700.4C2666.79,703.699 2666.12,707.216 2666.12,710.766C2666.12,726.268 2678.71,738.854 2694.21,738.854C2709.71,738.854 2722.3,726.268 2722.3,710.766C2722.3,704.111 2719.93,697.672 2715.63,692.597L2707.63,699.378C2710.33,702.559 2711.57,706.602 2711.81,710.766C2712.2,717.38 2706.61,724.52 2697.27,726.637C2683.9,728.581 2676.61,720.482 2676.61,710.766C2676.61,708.541 2677.03,706.336 2677.85,704.269L2668.11,700.4Z\" fill=\"rgb(46,46,46)\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t<g id=\"R\" transform=\"matrix(0.426446,0,0,0.451034,-1192.44,-722.167)\">\n\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(1,0,0,1,-0.10786,0.450801)\">\n\t\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(12.1247,0,0,12.1247,3862.61,1929.9)\">\n\t\t\t\t\t\t\t\t\t\t\t\t<path d=\"M0.073,-0L0.073,-0.7L0.383,-0.7C0.428,-0.7 0.469,-0.69 0.506,-0.67C0.543,-0.651 0.572,-0.623 0.594,-0.588C0.616,-0.553 0.627,-0.512 0.627,-0.465C0.627,-0.418 0.615,-0.377 0.592,-0.342C0.569,-0.306 0.539,-0.279 0.501,-0.259L0.57,-0.128C0.574,-0.12 0.579,-0.115 0.584,-0.111C0.59,-0.107 0.596,-0.106 0.605,-0.106L0.664,-0.106L0.664,-0L0.587,-0C0.56,-0 0.535,-0.007 0.514,-0.02C0.493,-0.034 0.476,-0.052 0.463,-0.075L0.381,-0.232C0.375,-0.231 0.368,-0.231 0.361,-0.231C0.354,-0.231 0.347,-0.231 0.34,-0.231L0.192,-0.231L0.192,-0L0.073,-0ZM0.192,-0.336L0.368,-0.336C0.394,-0.336 0.417,-0.341 0.438,-0.351C0.459,-0.361 0.476,-0.376 0.489,-0.396C0.501,-0.415 0.507,-0.438 0.507,-0.465C0.507,-0.492 0.501,-0.516 0.488,-0.535C0.475,-0.554 0.459,-0.569 0.438,-0.579C0.417,-0.59 0.394,-0.595 0.369,-0.595L0.192,-0.595L0.192,-0.336Z\" fill=\"rgb(46,46,46)\" fill-rule=\"nonzero\"/>\n\t\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t\t<g transform=\"matrix(1,0,0,1,0.278569,0.101881)\">\n\t\t\t\t\t\t\t\t\t\t\t<circle cx=\"3866.43\" cy=\"1926.14\" r=\"8.923\" fill=\"none\" stroke=\"rgb(46,46,46)\" stroke-width=\"2px\" stroke-linecap=\"butt\" stroke-linejoin=\"miter\"/>\n\t\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t</g>\n\t\t\t\t\t</g>\n\t\t\t\t</svg>\n\t\t\t</a>\n\t\t</footer>\n\n\t\t<script {{ $nonceAttribute }}>\n\t\t\tconst filterEl = document.getElementById('filter');\n\t\t\tfilterEl?.focus({ preventScroll: true });\n\n\t\t\tfunction initPage() {\n\t\t\t\t// populate and evaluate filter\n\t\t\t\tif (!filterEl?.value) {\n\t\t\t\t\tconst filterParam = new URL(window.location.href).searchParams.get('filter');\n\t\t\t\t\tif (filterParam) {\n\t\t\t\t\t\tfilterEl.value = filterParam;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tfilter();\n\n\t\t\t\t// fill in size bars\n\t\t\t\tlet largest = 0;\n\t\t\t\tdocument.querySelectorAll('.size').forEach(el => {\n\t\t\t\t\tlargest = Math.max(largest, Number(el.dataset.size));\n\t\t\t\t});\n\t\t\t\tdocument.querySelectorAll('.size').forEach(el => {\n\t\t\t\t\tconst size = Number(el.dataset.size);\n\t\t\t\t\tconst sizebar = el.querySelector('.sizebar-bar');\n\t\t\t\t\tif (sizebar) {\n\t\t\t\t\t\tsizebar.style.width = `${size/largest * 100}%`;\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tfunction filter() {\n\t\t\t\tif (!filterEl) return;\n\t\t\t\tconst q = filterEl.value.trim().toLowerCase();\n\t\t\t\tdocument.querySelectorAll('tr.file').forEach(function(el) {\n\t\t\t\t\tif (!q) {\n\t\t\t\t\t\tel.style.display = '';\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t\tconst nameEl = el.querySelector('.name');\n\t\t\t\t\tconst nameVal = nameEl.textContent.trim().toLowerCase();\n\t\t\t\t\tif (nameVal.indexOf(q) !== -1) {\n\t\t\t\t\t\tel.style.display = '';\n\t\t\t\t\t} else {\n\t\t\t\t\t\tel.style.display = 'none';\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\n\t\t\tconst filterElem = document.getElementById(\"filter\");\n\t\t\tif (filterElem) {\n\t\t\t\tfilterElem.addEventListener(\"keyup\", filter);\n\t\t\t}\n\n\t\t\tdocument.getElementById(\"layout-list\").addEventListener(\"click\", function() {\n\t\t\t\tqueryParam('layout', '');\n\t\t\t});\n\t\t\tdocument.getElementById(\"layout-grid\").addEventListener(\"click\", function() {\n\t\t\t\tqueryParam('layout', 'grid');\n\t\t\t});\n\n\t\t\twindow.addEventListener(\"load\", initPage);\n\n\t\t\tfunction queryParam(k, v) {\n\t\t\t\tconst qs = new URLSearchParams(window.location.search);\n\t\t\t\tif (!v) {\n\t\t\t\t\tqs.delete(k);\n\t\t\t\t} else {\n\t\t\t\t\tqs.set(k, v);\n\t\t\t\t}\n\t\t\t\tconst qsStr = qs.toString();\n\t\t\t\tif (qsStr) {\n\t\t\t\t\twindow.location.search = qsStr;\n\t\t\t\t} else {\n\t\t\t\t\twindow.location = window.location.pathname;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfunction localizeDatetime(e, index, ar) {\n\t\t\t\tif (e.textContent === undefined) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tvar d = new Date(e.getAttribute('datetime'));\n\t\t\t\tif (isNaN(d)) {\n\t\t\t\t\td = new Date(e.textContent);\n\t\t\t\t\tif (isNaN(d)) {\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\te.textContent = d.toLocaleString();\n\t\t\t}\n\t\t\tvar timeList = Array.prototype.slice.call(document.getElementsByTagName(\"time\"));\n\t\t\ttimeList.forEach(localizeDatetime);\n\t\t</script>\n\t</body>\n</html>\n",
    "source_file": "modules/caddyhttp/fileserver/browse.html",
    "chunk_type": "unknown"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fileserver\n\nimport (\n\t\"bytes\"\n\t\"context\"\n\t_ \"embed\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\t\"net/http\"\n\t\"os\"\n\t\"path\"\n\t\"strings\"\n\t\"sync\"\n\t\"text/tabwriter\"\n\t\"text/template\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/templates\"\n)\n\n// BrowseTemplate is the default template document to use for\n// file listings. By default, its default value is an embedded\n// document. You can override this value at program start, or\n// if you are running Caddy via config, you can specify a\n// custom template_file in the browse configuration.\n//\n//go:embed browse.html\nvar BrowseTemplate string\n\n// Browse configures directory browsing.\ntype Browse struct {\n\t// Filename of the template to use instead of the embedded browse template.\n\tTemplateFile string `json:\"template_file,omitempty\"`\n\n\t// Determines whether or not targets of symlinks should be revealed.\n\tRevealSymlinks bool `json:\"reveal_symlinks,omitempty\"`\n\n\t// Override the default sort.\n\t// It includes the following options:\n\t//   - sort_by: name(default), namedirfirst, size, time\n\t//   - order: asc(default), desc\n\t// eg.:\n\t//   - `sort time desc` will sort by time in descending order\n\t//   - `sort size` will sort by size in ascending order\n\t// The first option must be `sort_by` and the second option must be `order` (if exists).\n\tSortOptions []string `json:\"sort,omitempty\"`\n\n\t// FileLimit limits the number of up to n DirEntry values in directory order.\n\tFileLimit int `json:\"file_limit,omitempty\"`\n}\n\nconst (\n\tdefaultDirEntryLimit = 10000\n)\n\nfunc (fsrv *FileServer) serveBrowse(fileSystem fs.FS, root, dirPath string, w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"browse enabled; listing directory contents\"); c != nil {\n\t\tc.Write(zap.String(\"path\", dirPath), zap.String(\"root\", root))\n\t}\n\n\t// Navigation on the client-side gets messed up if the\n\t// URL doesn't end in a trailing slash because hrefs to\n\t// \"b/c\" at path \"/a\" end up going to \"/b/c\" instead\n\t// of \"/a/b/c\" - so we have to redirect in this case\n\t// so that the path is \"/a/\" and the client constructs\n\t// relative hrefs \"b/c\" to be \"/a/b/c\".\n\t//\n\t// Only redirect if the last element of the path (the filename) was not\n\t// rewritten; if the admin wanted to rewrite to the canonical path, they\n\t// would have, and we have to be very careful not to introduce unwanted\n\t// redirects and especially redirect loops! (Redirecting using the\n\t// original URI is necessary because that's the URI the browser knows,\n\t// we don't want to redirect from internally-rewritten URIs.)\n\t// See https://github.com/caddyserver/caddy/issues/4205.\n\t// We also redirect if the path is empty, because this implies the path\n\t// prefix was fully stripped away by a `handle_path` handler for example.\n\t// See https://github.com/caddyserver/caddy/issues/4466.\n\torigReq := r.Context().Value(caddyhttp.OriginalRequestCtxKey).(http.Request)\n\tif r.URL.Path == \"\" || path.Base(origReq.URL.Path) == path.Base(r.URL.Path) {\n\t\tif !strings.HasSuffix(origReq.URL.Path, \"/\") {\n\t\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"redirecting to trailing slash to preserve hrefs\"); c != nil {\n\t\t\t\tc.Write(zap.String(\"request_path\", r.URL.Path))\n\t\t\t}\n\t\t\treturn redirect(w, r, origReq.URL.Path+\"/\")\n\t\t}\n\t}\n\n\tdir, err := fsrv.openFile(fileSystem, dirPath, w)\n\tif err != nil {\n\t\treturn err\n\t}\n\tdefer dir.Close()\n\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\t// TODO: not entirely sure if path.Clean() is necessary here but seems like a safe plan (i.e. /%2e%2e%2f) - someone could verify this\n\tlisting, err := fsrv.loadDirectoryContents(r.Context(), fileSystem, dir.(fs.ReadDirFile), root, path.Clean(r.URL.EscapedPath()), repl)\n\tswitch {\n\tcase errors.Is(err, fs.ErrPermission):\n\t\treturn caddyhttp.Error(http.StatusForbidden, err)\n\tcase errors.Is(err, fs.ErrNotExist):\n\t\treturn fsrv.notFound(w, r, next)\n\tcase err != nil:\n\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t}\n\n\tw.Header().Add(\"Vary\", \"Accept, Accept-Encoding\")\n\n\t// speed up browser/client experience and caching by supporting If-Modified-Since\n\tif ifModSinceStr := r.Header.Get(\"If-Modified-Since\"); ifModSinceStr != \"\" {\n\t\t// basically a copy of stdlib file server's handling of If-Modified-Since\n\t\tifModSince, err := http.ParseTime(ifModSinceStr)\n\t\tif err == nil && listing.lastModified.Truncate(time.Second).Compare(ifModSince) <= 0 {\n\t\t\tw.WriteHeader(http.StatusNotModified)\n\t\t\treturn nil\n\t\t}\n\t}\n\n\tfsrv.browseApplyQueryParams(w, r, listing)\n\n\tbuf := bufPool.Get().(*bytes.Buffer)\n\tbuf.Reset()\n\tdefer bufPool.Put(buf)\n\n\tacceptHeader := strings.ToLower(strings.Join(r.Header[\"Accept\"], \",\"))\n\tw.Header().Set(\"Last-Modified\", listing.lastModified.Format(http.TimeFormat))\n\n\tswitch {\n\tcase strings.Contains(acceptHeader, \"application/json\"):\n\t\tif err := json.NewEncoder(buf).Encode(listing.Items); err != nil {\n\t\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t\t}\n\t\tw.Header().Set(\"Content-Type\", \"application/json; charset=utf-8\")\n\n\tcase strings.Contains(acceptHeader, \"text/plain\"):\n\t\twriter := tabwriter.NewWriter(buf, 0, 8, 1, '\\t', tabwriter.AlignRight)\n\n\t\t// Header on top\n\t\tif _, err := fmt.Fprintln(writer, \"Name\\tSize\\tModified\"); err != nil {\n\t\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t\t}\n\n\t\t// Lines to separate the header\n\t\tif _, err := fmt.Fprintln(writer, \"----\\t----\\t--------\"); err != nil {\n\t\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t\t}\n\n\t\t// Actual files\n\t\tfor _, item := range listing.Items {\n\t\t\tif _, err := fmt.Fprintf(writer, \"%s\\t%s\\t%s\\n\",\n\t\t\t\titem.Name, item.HumanSize(), item.HumanModTime(\"January 2, 2006 at 15:04:05\"),\n\t\t\t); err != nil {\n\t\t\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t\t\t}\n\t\t}\n\n\t\tif err := writer.Flush(); err != nil {\n\t\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t\t}\n\n\t\tw.Header().Set(\"Content-Type\", \"text/plain; charset=utf-8\")\n\n\tdefault:\n\t\tvar fs http.FileSystem\n\t\tif fsrv.Root != \"\" {\n\t\t\tfs = http.Dir(repl.ReplaceAll(fsrv.Root, \".\"))\n\t\t}\n\n\t\ttplCtx := &templateContext{\n\t\t\tTemplateContext: templates.TemplateContext{\n\t\t\t\tRoot:       fs,\n\t\t\t\tReq:        r,\n\t\t\t\tRespHeader: templates.WrappedHeader{Header: w.Header()},\n\t\t\t},\n\t\t\tbrowseTemplateContext: listing,\n\t\t}\n\n\t\ttpl, err := fsrv.makeBrowseTemplate(tplCtx)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"parsing browse template: %v\", err)\n\t\t}\n\t\tif err := tpl.Execute(buf, tplCtx); err != nil {\n\t\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t\t}\n\t\tw.Header().Set(\"Content-Type\", \"text/html; charset=utf-8\")\n\t}\n\n\t_, _ = buf.WriteTo(w)\n\n\treturn nil\n}\n\nfunc (fsrv *FileServer) loadDirectoryContents(ctx context.Context, fileSystem fs.FS, dir fs.ReadDirFile, root, urlPath string, repl *caddy.Replacer) (*browseTemplateContext, error) {\n\t// modTime for the directory itself\n\tstat, err := dir.Stat()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tdirLimit := defaultDirEntryLimit\n\tif fsrv.Browse.FileLimit != 0 {\n\t\tdirLimit = fsrv.Browse.FileLimit\n\t}\n\tfiles, err := dir.ReadDir(dirLimit)\n\tif err != nil && err != io.EOF {\n\t\treturn nil, err\n\t}\n\n\t// user can presumably browse \"up\" to parent folder if path is longer than \"/\"\n\tcanGoUp := len(urlPath) > 1\n\n\treturn fsrv.directoryListing(ctx, fileSystem, stat.ModTime(), files, canGoUp, root, urlPath, repl), nil\n}\n\n// browseApplyQueryParams applies query parameters to the listing.\n// It mutates the listing and may set cookies.\nfunc (fsrv *FileServer) browseApplyQueryParams(w http.ResponseWriter, r *http.Request, listing *browseTemplateContext) {\n\tvar orderParam, sortParam string\n\n\t// The configs in Caddyfile have lower priority than Query params,\n\t// so put it at first.\n\tfor idx, item := range fsrv.Browse.SortOptions {\n\t\t// Only `sort` & `order`, 2 params are allowed\n\t\tif idx >= 2 {\n\t\t\tbreak\n\t\t}\n\t\tswitch item {\n\t\tcase sortByName, sortByNameDirFirst, sortBySize, sortByTime:\n\t\t\tsortParam = item\n\t\tcase sortOrderAsc, sortOrderDesc:\n\t\t\torderParam = item\n\t\t}\n\t}\n\n\tlayoutParam := r.URL.Query().Get(\"layout\")\n\tlimitParam := r.URL.Query().Get(\"limit\")\n\toffsetParam := r.URL.Query().Get(\"offset\")\n\tsortParamTmp := r.URL.Query().Get(\"sort\")\n\tif sortParamTmp != \"\" {\n\t\tsortParam = sortParamTmp\n\t}\n\torderParamTmp := r.URL.Query().Get(\"order\")\n\tif orderParamTmp != \"\" {\n\t\torderParam = orderParamTmp\n\t}\n\n\tswitch layoutParam {\n\tcase \"list\", \"grid\", \"\":\n\t\tlisting.Layout = layoutParam\n\tdefault:\n\t\tlisting.Layout = \"list\"\n\t}\n\n\t// figure out what to sort by\n\tswitch sortParam {\n\tcase \"\":\n\t\tsortParam = sortByNameDirFirst\n\t\tif sortCookie, sortErr := r.Cookie(\"sort\"); sortErr == nil {\n\t\t\tsortParam = sortCookie.Value\n\t\t}\n\tcase sortByName, sortByNameDirFirst, sortBySize, sortByTime:\n\t\thttp.SetCookie(w, &http.Cookie{Name: \"sort\", Value: sortParam, Secure: r.TLS != nil})\n\t}\n\n\t// then figure out the order\n\tswitch orderParam {\n\tcase \"\":\n\t\torderParam = sortOrderAsc\n\t\tif orderCookie, orderErr := r.Cookie(\"order\"); orderErr == nil {\n\t\t\torderParam = orderCookie.Value\n\t\t}\n\tcase sortOrderAsc, sortOrderDesc:\n\t\thttp.SetCookie(w, &http.Cookie{Name: \"order\", Value: orderParam, Secure: r.TLS != nil})\n\t}\n\n\t// finally, apply the sorting and limiting\n\tlisting.applySortAndLimit(sortParam, orderParam, limitParam, offsetParam)\n}\n\n// makeBrowseTemplate creates the template to be used for directory listings.\nfunc (fsrv *FileServer) makeBrowseTemplate(tplCtx *templateContext) (*template.Template, error) {\n\tvar tpl *template.Template\n\tvar err error\n\n\tif fsrv.Browse.TemplateFile != \"\" {\n\t\ttpl = tplCtx.NewTemplate(path.Base(fsrv.Browse.TemplateFile))\n\t\ttpl, err = tpl.ParseFiles(fsrv.Browse.TemplateFile)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"parsing browse template file: %v\", err)\n\t\t}\n\t} else {\n\t\ttpl = tplCtx.NewTemplate(\"default_listing\")\n\t\ttpl, err = tpl.Parse(BrowseTemplate)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"parsing default browse template: %v\", err)\n\t\t}\n\t}\n\n\treturn tpl, nil\n}\n\n// isSymlinkTargetDir returns true if f's symbolic link target\n// is a directory.\nfunc (fsrv *FileServer) isSymlinkTargetDir(fileSystem fs.FS, f fs.FileInfo, root, urlPath string) bool {\n\tif !isSymlink(f) {\n\t\treturn false\n\t}\n\ttarget := caddyhttp.SanitizedPathJoin(root, path.Join(urlPath, f.Name()))\n\ttargetInfo, err := fs.Stat(fileSystem, target)\n\tif err != nil {\n\t\treturn false\n\t}\n\treturn targetInfo.IsDir()\n}\n\n// isSymlink return true if f is a symbolic link.\nfunc isSymlink(f fs.FileInfo) bool {\n\treturn f.Mode()&os.ModeSymlink != 0\n}\n\n// templateContext powers the context used when evaluating the browse template.\n// It combines browse-specific features with the standard templates handler\n// features.\ntype templateContext struct {\n\ttemplates.TemplateContext\n\t*browseTemplateContext\n}\n\n// bufPool is used to increase the efficiency of file listings.\nvar bufPool = sync.Pool{\n\tNew: func() any {\n\t\treturn new(bytes.Buffer)\n\t},\n}\n",
    "source_file": "modules/caddyhttp/fileserver/browse.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fileserver\n\nimport (\n\t\"context\"\n\t\"io/fs\"\n\t\"net/url\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"slices\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/dustin/go-humanize\"\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc (fsrv *FileServer) directoryListing(ctx context.Context, fileSystem fs.FS, parentModTime time.Time, entries []fs.DirEntry, canGoUp bool, root, urlPath string, repl *caddy.Replacer) *browseTemplateContext {\n\tfilesToHide := fsrv.transformHidePaths(repl)\n\n\tname, _ := url.PathUnescape(urlPath)\n\n\ttplCtx := &browseTemplateContext{\n\t\tName:         path.Base(name),\n\t\tPath:         urlPath,\n\t\tCanGoUp:      canGoUp,\n\t\tlastModified: parentModTime,\n\t}\n\n\tfor _, entry := range entries {\n\t\tif err := ctx.Err(); err != nil {\n\t\t\tbreak\n\t\t}\n\n\t\tname := entry.Name()\n\n\t\tif fileHidden(name, filesToHide) {\n\t\t\tcontinue\n\t\t}\n\n\t\tinfo, err := entry.Info()\n\t\tif err != nil {\n\t\t\tif c := fsrv.logger.Check(zapcore.ErrorLevel, \"could not get info about directory entry\"); c != nil {\n\t\t\t\tc.Write(zap.String(\"name\", entry.Name()), zap.String(\"root\", root))\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// keep track of the most recently modified item in the listing\n\t\tmodTime := info.ModTime()\n\t\tif tplCtx.lastModified.IsZero() || modTime.After(tplCtx.lastModified) {\n\t\t\ttplCtx.lastModified = modTime\n\t\t}\n\n\t\tisDir := entry.IsDir() || fsrv.isSymlinkTargetDir(fileSystem, info, root, urlPath)\n\n\t\t// add the slash after the escape of path to avoid escaping the slash as well\n\t\tif isDir {\n\t\t\tname += \"/\"\n\t\t\ttplCtx.NumDirs++\n\t\t} else {\n\t\t\ttplCtx.NumFiles++\n\t\t}\n\n\t\tsize := info.Size()\n\n\t\tif !isDir {\n\t\t\t// increase the total by the symlink's size, not the target's size,\n\t\t\t// by incrementing before we follow the symlink\n\t\t\ttplCtx.TotalFileSize += size\n\t\t}\n\n\t\tfileIsSymlink := isSymlink(info)\n\t\tsymlinkPath := \"\"\n\t\tif fileIsSymlink {\n\t\t\tpath := caddyhttp.SanitizedPathJoin(root, path.Join(urlPath, info.Name()))\n\t\t\tfileInfo, err := fs.Stat(fileSystem, path)\n\t\t\tif err == nil {\n\t\t\t\tsize = fileInfo.Size()\n\t\t\t}\n\n\t\t\tif fsrv.Browse.RevealSymlinks {\n\t\t\t\tsymLinkTarget, err := filepath.EvalSymlinks(path)\n\t\t\t\tif err == nil {\n\t\t\t\t\tsymlinkPath = symLinkTarget\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// An error most likely means the symlink target doesn't exist,\n\t\t\t// which isn't entirely unusual and shouldn't fail the listing.\n\t\t\t// In this case, just use the size of the symlink itself, which\n\t\t\t// was already set above.\n\t\t}\n\n\t\tif !isDir {\n\t\t\t// increase the total including the symlink target's size\n\t\t\ttplCtx.TotalFileSizeFollowingSymlinks += size\n\t\t}\n\n\t\tu := url.URL{Path: \"./\" + name} // prepend with \"./\" to fix paths with ':' in the name\n\n\t\ttplCtx.Items = append(tplCtx.Items, fileInfo{\n\t\t\tIsDir:       isDir,\n\t\t\tIsSymlink:   fileIsSymlink,\n\t\t\tName:        name,\n\t\t\tSize:        size,\n\t\t\tURL:         u.String(),\n\t\t\tModTime:     modTime.UTC(),\n\t\t\tMode:        info.Mode(),\n\t\t\tTpl:         tplCtx, // a reference up to the template context is useful\n\t\t\tSymlinkPath: symlinkPath,\n\t\t})\n\t}\n\n\t// this time is used for the Last-Modified header and comparing If-Modified-Since from client\n\t// both are expected to be in UTC, so we convert to UTC here\n\t// see: https://github.com/caddyserver/caddy/issues/6828\n\ttplCtx.lastModified = tplCtx.lastModified.UTC()\n\treturn tplCtx\n}\n\n// browseTemplateContext provides the template context for directory listings.\ntype browseTemplateContext struct {\n\t// The name of the directory (the last element of the path).\n\tName string `json:\"name\"`\n\n\t// The full path of the request.\n\tPath string `json:\"path\"`\n\n\t// Whether the parent directory is browsable.\n\tCanGoUp bool `json:\"can_go_up\"`\n\n\t// The items (files and folders) in the path.\n\tItems []fileInfo `json:\"items,omitempty\"`\n\n\t// If \u22600 then Items starting from that many elements.\n\tOffset int `json:\"offset,omitempty\"`\n\n\t// If \u22600 then Items have been limited to that many elements.\n\tLimit int `json:\"limit,omitempty\"`\n\n\t// The number of directories in the listing.\n\tNumDirs int `json:\"num_dirs\"`\n\n\t// The number of files (items that aren't directories) in the listing.\n\tNumFiles int `json:\"num_files\"`\n\n\t// The total size of all files in the listing. Only includes the\n\t// size of the files themselves, not the size of symlink targets\n\t// (i.e. the calculation of this value does not follow symlinks).\n\tTotalFileSize int64 `json:\"total_file_size\"`\n\n\t// The total size of all files in the listing, including the\n\t// size of the files targeted by symlinks.\n\tTotalFileSizeFollowingSymlinks int64 `json:\"total_file_size_following_symlinks\"`\n\n\t// Sort column used\n\tSort string `json:\"sort,omitempty\"`\n\n\t// Sorting order\n\tOrder string `json:\"order,omitempty\"`\n\n\t// Display format (list or grid)\n\tLayout string `json:\"layout,omitempty\"`\n\n\t// The most recent file modification date in the listing.\n\t// Used for HTTP header purposes.\n\tlastModified time.Time\n}\n\n// Breadcrumbs returns l.Path where every element maps\n// the link to the text to display.\nfunc (l browseTemplateContext) Breadcrumbs() []crumb {\n\tif len(l.Path) == 0 {\n\t\treturn []crumb{}\n\t}\n\n\t// skip trailing slash\n\tlpath := l.Path\n\tif lpath[len(lpath)-1] == '/' {\n\t\tlpath = lpath[:len(lpath)-1]\n\t}\n\tparts := strings.Split(lpath, \"/\")\n\tresult := make([]crumb, len(parts))\n\tfor i, p := range parts {\n\t\tif i == 0 && p == \"\" {\n\t\t\tp = \"/\"\n\t\t}\n\t\t// the directory name could include an encoded slash in its path,\n\t\t// so the item name should be unescaped in the loop rather than unescaping the\n\t\t// entire path outside the loop.\n\t\tp, _ = url.PathUnescape(p)\n\t\tlnk := strings.Repeat(\"../\", len(parts)-i-1)\n\t\tresult[i] = crumb{Link: lnk, Text: p}\n\t}\n\n\treturn result\n}\n\nfunc (l *browseTemplateContext) applySortAndLimit(sortParam, orderParam, limitParam string, offsetParam string) {\n\tl.Sort = sortParam\n\tl.Order = orderParam\n\n\tif l.Order == \"desc\" {\n\t\tswitch l.Sort {\n\t\tcase sortByName:\n\t\t\tsort.Sort(sort.Reverse(byName(*l)))\n\t\tcase sortByNameDirFirst:\n\t\t\tsort.Sort(sort.Reverse(byNameDirFirst(*l)))\n\t\tcase sortBySize:\n\t\t\tsort.Sort(sort.Reverse(bySize(*l)))\n\t\tcase sortByTime:\n\t\t\tsort.Sort(sort.Reverse(byTime(*l)))\n\t\t}\n\t} else {\n\t\tswitch l.Sort {\n\t\tcase sortByName:\n\t\t\tsort.Sort(byName(*l))\n\t\tcase sortByNameDirFirst:\n\t\t\tsort.Sort(byNameDirFirst(*l))\n\t\tcase sortBySize:\n\t\t\tsort.Sort(bySize(*l))\n\t\tcase sortByTime:\n\t\t\tsort.Sort(byTime(*l))\n\t\t}\n\t}\n\n\tif offsetParam != \"\" {\n\t\toffset, _ := strconv.Atoi(offsetParam)\n\t\tif offset > 0 && offset <= len(l.Items) {\n\t\t\tl.Items = l.Items[offset:]\n\t\t\tl.Offset = offset\n\t\t}\n\t}\n\n\tif limitParam != \"\" {\n\t\tlimit, _ := strconv.Atoi(limitParam)\n\n\t\tif limit > 0 && limit <= len(l.Items) {\n\t\t\tl.Items = l.Items[:limit]\n\t\t\tl.Limit = limit\n\t\t}\n\t}\n}\n\n// crumb represents part of a breadcrumb menu,\n// pairing a link with the text to display.\ntype crumb struct {\n\tLink, Text string\n}\n\n// fileInfo contains serializable information\n// about a file or directory.\ntype fileInfo struct {\n\tName        string      `json:\"name\"`\n\tSize        int64       `json:\"size\"`\n\tURL         string      `json:\"url\"`\n\tModTime     time.Time   `json:\"mod_time\"`\n\tMode        os.FileMode `json:\"mode\"`\n\tIsDir       bool        `json:\"is_dir\"`\n\tIsSymlink   bool        `json:\"is_symlink\"`\n\tSymlinkPath string      `json:\"symlink_path,omitempty\"`\n\n\t// a pointer to the template context is useful inside nested templates\n\tTpl *browseTemplateContext `json:\"-\"`\n}\n\n// HasExt returns true if the filename has any of the given suffixes, case-insensitive.\nfunc (fi fileInfo) HasExt(exts ...string) bool {\n\treturn slices.ContainsFunc(exts, func(ext string) bool {\n\t\treturn strings.HasSuffix(strings.ToLower(fi.Name), strings.ToLower(ext))\n\t})\n}\n\n// HumanSize returns the size of the file as a\n// human-readable string in IEC format (i.e.\n// power of 2 or base 1024).\nfunc (fi fileInfo) HumanSize() string {\n\treturn humanize.IBytes(uint64(fi.Size))\n}\n\n// HumanTotalFileSize returns the total size of all files\n// in the listing as a human-readable string in IEC format\n// (i.e. power of 2 or base 1024).\nfunc (btc browseTemplateContext) HumanTotalFileSize() string {\n\treturn humanize.IBytes(uint64(btc.TotalFileSize))\n}\n\n// HumanTotalFileSizeFollowingSymlinks is the same as HumanTotalFileSize\n// except the returned value reflects the size of symlink targets.\nfunc (btc browseTemplateContext) HumanTotalFileSizeFollowingSymlinks() string {\n\treturn humanize.IBytes(uint64(btc.TotalFileSizeFollowingSymlinks))\n}\n\n// HumanModTime returns the modified time of the file\n// as a human-readable string given by format.\nfunc (fi fileInfo) HumanModTime(format string) string {\n\treturn fi.ModTime.Format(format)\n}\n\ntype (\n\tbyName         browseTemplateContext\n\tbyNameDirFirst browseTemplateContext\n\tbySize         browseTemplateContext\n\tbyTime         browseTemplateContext\n)\n\nfunc (l byName) Len() int      { return len(l.Items) }\nfunc (l byName) Swap(i, j int) { l.Items[i], l.Items[j] = l.Items[j], l.Items[i] }\n\nfunc (l byName) Less(i, j int) bool {\n\treturn strings.ToLower(l.Items[i].Name) < strings.ToLower(l.Items[j].Name)\n}\n\nfunc (l byNameDirFirst) Len() int      { return len(l.Items) }\nfunc (l byNameDirFirst) Swap(i, j int) { l.Items[i], l.Items[j] = l.Items[j], l.Items[i] }\n\nfunc (l byNameDirFirst) Less(i, j int) bool {\n\t// sort by name if both are dir or file\n\tif l.Items[i].IsDir == l.Items[j].IsDir {\n\t\treturn strings.ToLower(l.Items[i].Name) < strings.ToLower(l.Items[j].Name)\n\t}\n\t// sort dir ahead of file\n\treturn l.Items[i].IsDir\n}\n\nfunc (l bySize) Len() int      { return len(l.Items) }\nfunc (l bySize) Swap(i, j int) { l.Items[i], l.Items[j] = l.Items[j], l.Items[i] }\n\nfunc (l bySize) Less(i, j int) bool {\n\tconst directoryOffset = -1 << 31 // = -math.MinInt32\n\n\tiSize, jSize := l.Items[i].Size, l.Items[j].Size\n\n\t// directory sizes depend on the file system; to\n\t// provide a consistent experience, put them up front\n\t// and sort them by name\n\tif l.Items[i].IsDir {\n\t\tiSize = directoryOffset\n\t}\n\tif l.Items[j].IsDir {\n\t\tjSize = directoryOffset\n\t}\n\tif l.Items[i].IsDir && l.Items[j].IsDir {\n\t\treturn strings.ToLower(l.Items[i].Name) < strings.ToLower(l.Items[j].Name)\n\t}\n\n\treturn iSize < jSize\n}\n\nfunc (l byTime) Len() int           { return len(l.Items) }\nfunc (l byTime) Swap(i, j int)      { l.Items[i], l.Items[j] = l.Items[j], l.Items[i] }\nfunc (l byTime) Less(i, j int) bool { return l.Items[i].ModTime.Before(l.Items[j].ModTime) }\n\nconst (\n\tsortByName         = \"name\"\n\tsortByNameDirFirst = \"namedirfirst\"\n\tsortBySize         = \"size\"\n\tsortByTime         = \"time\"\n\n\tsortOrderAsc  = \"asc\"\n\tsortOrderDesc = \"desc\"\n)\n",
    "source_file": "modules/caddyhttp/fileserver/browsetplcontext.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fileserver\n\nimport (\n\t\"bytes\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"io/fs\"\n\tweakrand \"math/rand\"\n\t\"mime\"\n\t\"net/http\"\n\t\"os\"\n\t\"path\"\n\t\"path/filepath\"\n\t\"runtime\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(FileServer{})\n}\n\n// FileServer implements a handler that serves static files.\n//\n// The path of the file to serve is constructed by joining the site root\n// and the sanitized request path. Any and all files within the root and\n// links with targets outside the site root may therefore be accessed.\n// For example, with a site root of `/www`, requests to `/foo/bar.txt`\n// will serve the file at `/www/foo/bar.txt`.\n//\n// The request path is sanitized using the Go standard library's\n// path.Clean() function (https://pkg.go.dev/path#Clean) before being\n// joined to the root. Request paths must be valid and well-formed.\n//\n// For requests that access directories instead of regular files,\n// Caddy will attempt to serve an index file if present. For example,\n// a request to `/dir/` will attempt to serve `/dir/index.html` if\n// it exists. The index file names to try are configurable. If a\n// requested directory does not have an index file, Caddy writes a\n// 404 response. Alternatively, file browsing can be enabled with\n// the \"browse\" parameter which shows a list of files when directories\n// are requested if no index file is present. If \"browse\" is enabled,\n// Caddy may serve a JSON array of the directory listing when the `Accept`\n// header mentions `application/json` with the following structure:\n//\n//\t[{\n//\t\t\"name\": \"\",\n//\t\t\"size\": 0,\n//\t\t\"url\": \"\",\n//\t\t\"mod_time\": \"\",\n//\t\t\"mode\": 0,\n//\t\t\"is_dir\": false,\n//\t\t\"is_symlink\": false\n//\t}]\n//\n// with the `url` being relative to the request path and `mod_time` in the RFC 3339 format\n// with sub-second precision. For any other value for the `Accept` header, the\n// respective browse template is executed with `Content-Type: text/html`.\n//\n// By default, this handler will canonicalize URIs so that requests to\n// directories end with a slash, but requests to regular files do not.\n// This is enforced with HTTP redirects automatically and can be disabled.\n// Canonicalization redirects are not issued, however, if a URI rewrite\n// modified the last component of the path (the filename).\n//\n// This handler sets the Etag and Last-Modified headers for static files.\n// It does not perform MIME sniffing to determine Content-Type based on\n// contents, but does use the extension (if known); see the Go docs for\n// details: https://pkg.go.dev/mime#TypeByExtension\n//\n// The file server properly handles requests with If-Match,\n// If-Unmodified-Since, If-Modified-Since, If-None-Match, Range, and\n// If-Range headers. It includes the file's modification time in the\n// Last-Modified header of the response.\ntype FileServer struct {\n\t// The file system implementation to use. By default, Caddy uses the local\n\t// disk file system.\n\t//\n\t// if a non default filesystem is used, it must be first be registered in the globals section.\n\tFileSystem string `json:\"fs,omitempty\"`\n\n\t// The path to the root of the site. Default is `{http.vars.root}` if set,\n\t// or current working directory otherwise. This should be a trusted value.\n\t//\n\t// Note that a site root is not a sandbox. Although the file server does\n\t// sanitize the request URI to prevent directory traversal, files (including\n\t// links) within the site root may be directly accessed based on the request\n\t// path. Files and folders within the root should be secure and trustworthy.\n\tRoot string `json:\"root,omitempty\"`\n\n\t// A list of files or folders to hide; the file server will pretend as if\n\t// they don't exist. Accepts globular patterns like `*.ext` or `/foo/*/bar`\n\t// as well as placeholders. Because site roots can be dynamic, this list\n\t// uses file system paths, not request paths. To clarify, the base of\n\t// relative paths is the current working directory, NOT the site root.\n\t//\n\t// Entries without a path separator (`/` or `\\` depending on OS) will match\n\t// any file or directory of that name regardless of its path. To hide only a\n\t// specific file with a name that may not be unique, always use a path\n\t// separator. For example, to hide all files or folder trees named \"hidden\",\n\t// put \"hidden\" in the list. To hide only ./hidden, put \"./hidden\" in the list.\n\t//\n\t// When possible, all paths are resolved to their absolute form before\n\t// comparisons are made. For maximum clarity and explictness, use complete,\n\t// absolute paths; or, for greater portability, use relative paths instead.\n\tHide []string `json:\"hide,omitempty\"`\n\n\t// The names of files to try as index files if a folder is requested.\n\t// Default: index.html, index.txt.\n\tIndexNames []string `json:\"index_names,omitempty\"`\n\n\t// Enables file listings if a directory was requested and no index\n\t// file is present.\n\tBrowse *Browse `json:\"browse,omitempty\"`\n\n\t// Use redirects to enforce trailing slashes for directories, or to\n\t// remove trailing slash from URIs for files. Default is true.\n\t//\n\t// Canonicalization will not happen if the last element of the request's\n\t// path (the filename) is changed in an internal rewrite, to avoid\n\t// clobbering the explicit rewrite with implicit behavior.\n\tCanonicalURIs *bool `json:\"canonical_uris,omitempty\"`\n\n\t// Override the status code written when successfully serving a file.\n\t// Particularly useful when explicitly serving a file as display for\n\t// an error, like a 404 page. A placeholder may be used. By default,\n\t// the status code will typically be 200, or 206 for partial content.\n\tStatusCode caddyhttp.WeakString `json:\"status_code,omitempty\"`\n\n\t// If pass-thru mode is enabled and a requested file is not found,\n\t// it will invoke the next handler in the chain instead of returning\n\t// a 404 error. By default, this is false (disabled).\n\tPassThru bool `json:\"pass_thru,omitempty\"`\n\n\t// Selection of encoders to use to check for precompressed files.\n\tPrecompressedRaw caddy.ModuleMap `json:\"precompressed,omitempty\" caddy:\"namespace=http.precompressed\"`\n\n\t// If the client has no strong preference (q-factor), choose these encodings in order.\n\t// If no order specified here, the first encoding from the Accept-Encoding header\n\t// that both client and server support is used\n\tPrecompressedOrder []string `json:\"precompressed_order,omitempty\"`\n\tprecompressors     map[string]encode.Precompressed\n\n\t// List of file extensions to try to read Etags from.\n\t// If set, file Etags will be read from sidecar files\n\t// with any of these suffixes, instead of generating\n\t// our own Etag.\n\tEtagFileExtensions []string `json:\"etag_file_extensions,omitempty\"`\n\n\tfsmap caddy.FileSystems\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (FileServer) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.file_server\",\n\t\tNew: func() caddy.Module { return new(FileServer) },\n\t}\n}\n\n// Provision sets up the static files responder.\nfunc (fsrv *FileServer) Provision(ctx caddy.Context) error {\n\tfsrv.logger = ctx.Logger()\n\n\tfsrv.fsmap = ctx.FileSystems()\n\n\tif fsrv.FileSystem == \"\" {\n\t\tfsrv.FileSystem = \"{http.vars.fs}\"\n\t}\n\n\tif fsrv.Root == \"\" {\n\t\tfsrv.Root = \"{http.vars.root}\"\n\t}\n\n\tif fsrv.IndexNames == nil {\n\t\tfsrv.IndexNames = defaultIndexNames\n\t}\n\n\t// for hide paths that are static (i.e. no placeholders), we can transform them into\n\t// absolute paths before the server starts for very slight performance improvement\n\tfor i, h := range fsrv.Hide {\n\t\tif !strings.Contains(h, \"{\") && strings.Contains(h, separator) {\n\t\t\tif abs, err := caddy.FastAbs(h); err == nil {\n\t\t\t\tfsrv.Hide[i] = abs\n\t\t\t}\n\t\t}\n\t}\n\n\t// support precompressed sidecar files\n\tmods, err := ctx.LoadModule(fsrv, \"PrecompressedRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading encoder modules: %v\", err)\n\t}\n\tfor modName, modIface := range mods.(map[string]any) {\n\t\tp, ok := modIface.(encode.Precompressed)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"module %s is not precompressor\", modName)\n\t\t}\n\t\tae := p.AcceptEncoding()\n\t\tif ae == \"\" {\n\t\t\treturn fmt.Errorf(\"precompressor does not specify an Accept-Encoding value\")\n\t\t}\n\t\tsuffix := p.Suffix()\n\t\tif suffix == \"\" {\n\t\t\treturn fmt.Errorf(\"precompressor does not specify a Suffix value\")\n\t\t}\n\t\tif _, ok := fsrv.precompressors[ae]; ok {\n\t\t\treturn fmt.Errorf(\"precompressor already added: %s\", ae)\n\t\t}\n\t\tif fsrv.precompressors == nil {\n\t\t\tfsrv.precompressors = make(map[string]encode.Precompressed)\n\t\t}\n\t\tfsrv.precompressors[ae] = p\n\t}\n\n\tif fsrv.Browse != nil {\n\t\t// check sort options\n\t\tfor idx, sortOption := range fsrv.Browse.SortOptions {\n\t\t\tswitch idx {\n\t\t\tcase 0:\n\t\t\t\tif sortOption != sortByName && sortOption != sortByNameDirFirst && sortOption != sortBySize && sortOption != sortByTime {\n\t\t\t\t\treturn fmt.Errorf(\"the first option must be one of the following: %s, %s, %s, %s, but got %s\", sortByName, sortByNameDirFirst, sortBySize, sortByTime, sortOption)\n\t\t\t\t}\n\t\t\tcase 1:\n\t\t\t\tif sortOption != sortOrderAsc && sortOption != sortOrderDesc {\n\t\t\t\t\treturn fmt.Errorf(\"the second option must be one of the following: %s, %s, but got %s\", sortOrderAsc, sortOrderDesc, sortOption)\n\t\t\t\t}\n\t\t\tdefault:\n\t\t\t\treturn fmt.Errorf(\"only max 2 sort options are allowed, but got %d\", idx+1)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (fsrv *FileServer) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\tif runtime.GOOS == \"windows\" {\n\t\t// reject paths with Alternate Data Streams (ADS)\n\t\tif strings.Contains(r.URL.Path, \":\") {\n\t\t\treturn caddyhttp.Error(http.StatusBadRequest, fmt.Errorf(\"illegal ADS path\"))\n\t\t}\n\t\t// reject paths with \"8.3\" short names\n\t\ttrimmedPath := strings.TrimRight(r.URL.Path, \". \") // Windows ignores trailing dots and spaces, sigh\n\t\tif len(path.Base(trimmedPath)) <= 12 && strings.Contains(trimmedPath, \"~\") {\n\t\t\treturn caddyhttp.Error(http.StatusBadRequest, fmt.Errorf(\"illegal short name\"))\n\t\t}\n\t\t// both of those could bypass file hiding or possibly leak information even if the file is not hidden\n\t}\n\n\tfilesToHide := fsrv.transformHidePaths(repl)\n\n\troot := repl.ReplaceAll(fsrv.Root, \".\")\n\tfsName := repl.ReplaceAll(fsrv.FileSystem, \"\")\n\n\tfileSystem, ok := fsrv.fsmap.Get(fsName)\n\tif !ok {\n\t\treturn caddyhttp.Error(http.StatusNotFound, fmt.Errorf(\"filesystem not found\"))\n\t}\n\n\t// remove any trailing `/` as it breaks fs.ValidPath() in the stdlib\n\tfilename := strings.TrimSuffix(caddyhttp.SanitizedPathJoin(root, r.URL.Path), \"/\")\n\n\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"sanitized path join\"); c != nil {\n\t\tc.Write(\n\t\t\tzap.String(\"site_root\", root),\n\t\t\tzap.String(\"fs\", fsName),\n\t\t\tzap.String(\"request_path\", r.URL.Path),\n\t\t\tzap.String(\"result\", filename),\n\t\t)\n\t}\n\n\t// get information about the file\n\tinfo, err := fs.Stat(fileSystem, filename)\n\tif err != nil {\n\t\terr = fsrv.mapDirOpenError(fileSystem, err, filename)\n\t\tif errors.Is(err, fs.ErrNotExist) {\n\t\t\treturn fsrv.notFound(w, r, next)\n\t\t} else if errors.Is(err, fs.ErrInvalid) {\n\t\t\treturn caddyhttp.Error(http.StatusBadRequest, err)\n\t\t} else if errors.Is(err, fs.ErrPermission) {\n\t\t\treturn caddyhttp.Error(http.StatusForbidden, err)\n\t\t}\n\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t}\n\n\t// if the request mapped to a directory, see if\n\t// there is an index file we can serve\n\tvar implicitIndexFile bool\n\tif info.IsDir() && len(fsrv.IndexNames) > 0 {\n\t\tfor _, indexPage := range fsrv.IndexNames {\n\t\t\tindexPage := repl.ReplaceAll(indexPage, \"\")\n\t\t\tindexPath := caddyhttp.SanitizedPathJoin(filename, indexPage)\n\t\t\tif fileHidden(indexPath, filesToHide) {\n\t\t\t\t// pretend this file doesn't exist\n\t\t\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"hiding index file\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.String(\"filename\", indexPath),\n\t\t\t\t\t\tzap.Strings(\"files_to_hide\", filesToHide),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tindexInfo, err := fs.Stat(fileSystem, indexPath)\n\t\t\tif err != nil {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// don't rewrite the request path to append\n\t\t\t// the index file, because we might need to\n\t\t\t// do a canonical-URL redirect below based\n\t\t\t// on the URL as-is\n\n\t\t\t// we've chosen to use this index file,\n\t\t\t// so replace the last file info and path\n\t\t\t// with that of the index file\n\t\t\tinfo = indexInfo\n\t\t\tfilename = indexPath\n\t\t\timplicitIndexFile = true\n\t\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"located index file\"); c != nil {\n\t\t\t\tc.Write(zap.String(\"filename\", filename))\n\t\t\t}\n\t\t\tbreak\n\t\t}\n\t}\n\n\t// if still referencing a directory, delegate\n\t// to browse or return an error\n\tif info.IsDir() {\n\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"no index file in directory\"); c != nil {\n\t\t\tc.Write(\n\t\t\t\tzap.String(\"path\", filename),\n\t\t\t\tzap.Strings(\"index_filenames\", fsrv.IndexNames),\n\t\t\t)\n\t\t}\n\t\tif fsrv.Browse != nil && !fileHidden(filename, filesToHide) {\n\t\t\treturn fsrv.serveBrowse(fileSystem, root, filename, w, r, next)\n\t\t}\n\t\treturn fsrv.notFound(w, r, next)\n\t}\n\n\t// one last check to ensure the file isn't hidden (we might\n\t// have changed the filename from when we last checked)\n\tif fileHidden(filename, filesToHide) {\n\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"hiding file\"); c != nil {\n\t\t\tc.Write(\n\t\t\t\tzap.String(\"filename\", filename),\n\t\t\t\tzap.Strings(\"files_to_hide\", filesToHide),\n\t\t\t)\n\t\t}\n\t\treturn fsrv.notFound(w, r, next)\n\t}\n\n\t// if URL canonicalization is enabled, we need to enforce trailing\n\t// slash convention: if a directory, trailing slash; if a file, no\n\t// trailing slash - not enforcing this can break relative hrefs\n\t// in HTML (see https://github.com/caddyserver/caddy/issues/2741)\n\tif fsrv.CanonicalURIs == nil || *fsrv.CanonicalURIs {\n\t\t// Only redirect if the last element of the path (the filename) was not\n\t\t// rewritten; if the admin wanted to rewrite to the canonical path, they\n\t\t// would have, and we have to be very careful not to introduce unwanted\n\t\t// redirects and especially redirect loops!\n\t\t// See https://github.com/caddyserver/caddy/issues/4205.\n\t\torigReq := r.Context().Value(caddyhttp.OriginalRequestCtxKey).(http.Request)\n\t\tif path.Base(origReq.URL.Path) == path.Base(r.URL.Path) {\n\t\t\tif implicitIndexFile && !strings.HasSuffix(origReq.URL.Path, \"/\") {\n\t\t\t\tto := origReq.URL.Path + \"/\"\n\t\t\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"redirecting to canonical URI (adding trailing slash for directory\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.String(\"from_path\", origReq.URL.Path),\n\t\t\t\t\t\tzap.String(\"to_path\", to),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\treturn redirect(w, r, to)\n\t\t\t} else if !implicitIndexFile && strings.HasSuffix(origReq.URL.Path, \"/\") {\n\t\t\t\tto := origReq.URL.Path[:len(origReq.URL.Path)-1]\n\t\t\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"redirecting to canonical URI (removing trailing slash for file\"); c != nil {\n\t\t\t\t\tc.Write(\n\t\t\t\t\t\tzap.String(\"from_path\", origReq.URL.Path),\n\t\t\t\t\t\tzap.String(\"to_path\", to),\n\t\t\t\t\t)\n\t\t\t\t}\n\t\t\t\treturn redirect(w, r, to)\n\t\t\t}\n\t\t}\n\t}\n\n\tvar file fs.File\n\trespHeader := w.Header()\n\n\t// etag is usually unset, but if the user knows what they're doing, let them override it\n\tetag := respHeader.Get(\"Etag\")\n\n\t// static file responses are often compressed, either on-the-fly\n\t// or with precompressed sidecar files; in any case, the headers\n\t// should contain \"Vary: Accept-Encoding\" even when not compressed\n\t// so caches can craft a reliable key (according to REDbot results)\n\t// see #5849\n\trespHeader.Add(\"Vary\", \"Accept-Encoding\")\n\n\t// check for precompressed files\n\tfor _, ae := range encode.AcceptedEncodings(r, fsrv.PrecompressedOrder) {\n\t\tprecompress, ok := fsrv.precompressors[ae]\n\t\tif !ok {\n\t\t\tcontinue\n\t\t}\n\t\tcompressedFilename := filename + precompress.Suffix()\n\t\tcompressedInfo, err := fs.Stat(fileSystem, compressedFilename)\n\t\tif err != nil || compressedInfo.IsDir() {\n\t\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"precompressed file not accessible\"); c != nil {\n\t\t\t\tc.Write(zap.String(\"filename\", compressedFilename), zap.Error(err))\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"opening compressed sidecar file\"); c != nil {\n\t\t\tc.Write(zap.String(\"filename\", compressedFilename), zap.Error(err))\n\t\t}\n\t\tfile, err = fsrv.openFile(fileSystem, compressedFilename, w)\n\t\tif err != nil {\n\t\t\tif c := fsrv.logger.Check(zapcore.WarnLevel, \"opening precompressed file failed\"); c != nil {\n\t\t\t\tc.Write(zap.String(\"filename\", compressedFilename), zap.Error(err))\n\t\t\t}\n\t\t\tif caddyErr, ok := err.(caddyhttp.HandlerError); ok && caddyErr.StatusCode == http.StatusServiceUnavailable {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tfile = nil\n\t\t\tcontinue\n\t\t}\n\t\tdefer file.Close()\n\t\trespHeader.Set(\"Content-Encoding\", ae)\n\t\trespHeader.Del(\"Accept-Ranges\")\n\n\t\t// try to get the etag from pre computed files if an etag suffix list was provided\n\t\tif etag == \"\" && fsrv.EtagFileExtensions != nil {\n\t\t\tetag, err = fsrv.getEtagFromFile(fileSystem, compressedFilename)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\n\t\t// don't assign info = compressedInfo because sidecars are kind\n\t\t// of transparent; however we do need to set the Etag:\n\t\t// https://caddy.community/t/gzipped-sidecar-file-wrong-same-etag/16793\n\t\tif etag == \"\" {\n\t\t\tetag = calculateEtag(compressedInfo)\n\t\t}\n\n\t\tbreak\n\t}\n\n\t// no precompressed file found, use the actual file\n\tif file == nil {\n\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"opening file\"); c != nil {\n\t\t\tc.Write(zap.String(\"filename\", filename))\n\t\t}\n\n\t\t// open the file\n\t\tfile, err = fsrv.openFile(fileSystem, filename, w)\n\t\tif err != nil {\n\t\t\tif herr, ok := err.(caddyhttp.HandlerError); ok &&\n\t\t\t\therr.StatusCode == http.StatusNotFound {\n\t\t\t\treturn fsrv.notFound(w, r, next)\n\t\t\t}\n\t\t\treturn err // error is already structured\n\t\t}\n\t\tdefer file.Close()\n\t\t// try to get the etag from pre computed files if an etag suffix list was provided\n\t\tif etag == \"\" && fsrv.EtagFileExtensions != nil {\n\t\t\tetag, err = fsrv.getEtagFromFile(fileSystem, filename)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\tif etag == \"\" {\n\t\t\tetag = calculateEtag(info)\n\t\t}\n\t}\n\n\t// at this point, we're serving a file; Go std lib supports only\n\t// GET and HEAD, which is sensible for a static file server - reject\n\t// any other methods (see issue #5166)\n\tif r.Method != http.MethodGet && r.Method != http.MethodHead {\n\t\t// if we're in an error context, then it doesn't make sense\n\t\t// to repeat the error; just continue because we're probably\n\t\t// trying to write an error page response (see issue #5703)\n\t\tif _, ok := r.Context().Value(caddyhttp.ErrorCtxKey).(error); !ok {\n\t\t\trespHeader.Add(\"Allow\", \"GET, HEAD\")\n\t\t\treturn caddyhttp.Error(http.StatusMethodNotAllowed, nil)\n\t\t}\n\t}\n\n\t// set the Etag - note that a conditional If-None-Match request is handled\n\t// by http.ServeContent below, which checks against this Etag value\n\tif etag != \"\" {\n\t\trespHeader.Set(\"Etag\", etag)\n\t}\n\n\tif respHeader.Get(\"Content-Type\") == \"\" {\n\t\tmtyp := mime.TypeByExtension(filepath.Ext(filename))\n\t\tif mtyp == \"\" {\n\t\t\t// do not allow Go to sniff the content-type; see https://www.youtube.com/watch?v=8t8JYpt0egE\n\t\t\trespHeader[\"Content-Type\"] = nil\n\t\t} else {\n\t\t\trespHeader.Set(\"Content-Type\", mtyp)\n\t\t}\n\t}\n\n\tvar statusCodeOverride int\n\n\t// if this handler exists in an error context (i.e. is part of a\n\t// handler chain that is supposed to handle a previous error),\n\t// we should set status code to the one from the error instead\n\t// of letting http.ServeContent set the default (usually 200)\n\tif reqErr, ok := r.Context().Value(caddyhttp.ErrorCtxKey).(error); ok {\n\t\tstatusCodeOverride = http.StatusInternalServerError\n\t\tif handlerErr, ok := reqErr.(caddyhttp.HandlerError); ok {\n\t\t\tif handlerErr.StatusCode > 0 {\n\t\t\t\tstatusCodeOverride = handlerErr.StatusCode\n\t\t\t}\n\t\t}\n\t}\n\n\t// if a status code override is configured, run the replacer on it\n\tif codeStr := fsrv.StatusCode.String(); codeStr != \"\" {\n\t\tstatusCodeOverride, err = strconv.Atoi(repl.ReplaceAll(codeStr, \"\"))\n\t\tif err != nil {\n\t\t\treturn caddyhttp.Error(http.StatusInternalServerError, err)\n\t\t}\n\t}\n\n\t// if we do have an override from the previous two parts, then\n\t// we wrap the response writer to intercept the WriteHeader call\n\tif statusCodeOverride > 0 {\n\t\tw = statusOverrideResponseWriter{ResponseWriter: w, code: statusCodeOverride}\n\t}\n\n\t// let the standard library do what it does best; note, however,\n\t// that errors generated by ServeContent are written immediately\n\t// to the response, so we cannot handle them (but errors there\n\t// are rare)\n\thttp.ServeContent(w, r, info.Name(), info.ModTime(), file.(io.ReadSeeker))\n\n\treturn nil\n}\n\n// openFile opens the file at the given filename. If there was an error,\n// the response is configured to inform the client how to best handle it\n// and a well-described handler error is returned (do not wrap the\n// returned error value).\nfunc (fsrv *FileServer) openFile(fileSystem fs.FS, filename string, w http.ResponseWriter) (fs.File, error) {\n\tfile, err := fileSystem.Open(filename)\n\tif err != nil {\n\t\terr = fsrv.mapDirOpenError(fileSystem, err, filename)\n\t\tif errors.Is(err, fs.ErrNotExist) {\n\t\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"file not found\"); c != nil {\n\t\t\t\tc.Write(zap.String(\"filename\", filename), zap.Error(err))\n\t\t\t}\n\t\t\treturn nil, caddyhttp.Error(http.StatusNotFound, err)\n\t\t} else if errors.Is(err, fs.ErrPermission) {\n\t\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"permission denied\"); c != nil {\n\t\t\t\tc.Write(zap.String(\"filename\", filename), zap.Error(err))\n\t\t\t}\n\t\t\treturn nil, caddyhttp.Error(http.StatusForbidden, err)\n\t\t}\n\t\t// maybe the server is under load and ran out of file descriptors?\n\t\t// have client wait arbitrary seconds to help prevent a stampede\n\t\t//nolint:gosec\n\t\tbackoff := weakrand.Intn(maxBackoff-minBackoff) + minBackoff\n\t\tw.Header().Set(\"Retry-After\", strconv.Itoa(backoff))\n\t\tif c := fsrv.logger.Check(zapcore.DebugLevel, \"retry after backoff\"); c != nil {\n\t\t\tc.Write(zap.String(\"filename\", filename), zap.Int(\"backoff\", backoff), zap.Error(err))\n\t\t}\n\t\treturn nil, caddyhttp.Error(http.StatusServiceUnavailable, err)\n\t}\n\treturn file, nil\n}\n\n// mapDirOpenError maps the provided non-nil error from opening name\n// to a possibly better non-nil error. In particular, it turns OS-specific errors\n// about opening files in non-directories into os.ErrNotExist. See golang/go#18984.\n// Adapted from the Go standard library; originally written by Nathaniel Caza.\n// https://go-review.googlesource.com/c/go/+/36635/\n// https://go-review.googlesource.com/c/go/+/36804/\nfunc (fsrv *FileServer) mapDirOpenError(fileSystem fs.FS, originalErr error, name string) error {\n\tif errors.Is(originalErr, fs.ErrNotExist) || errors.Is(originalErr, fs.ErrPermission) {\n\t\treturn originalErr\n\t}\n\n\tvar pathErr *fs.PathError\n\tif errors.As(originalErr, &pathErr) {\n\t\treturn fs.ErrInvalid\n\t}\n\n\tparts := strings.Split(name, separator)\n\tfor i := range parts {\n\t\tif parts[i] == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tfi, err := fs.Stat(fileSystem, strings.Join(parts[:i+1], separator))\n\t\tif err != nil {\n\t\t\treturn originalErr\n\t\t}\n\t\tif !fi.IsDir() {\n\t\t\treturn fs.ErrNotExist\n\t\t}\n\t}\n\n\treturn originalErr\n}\n\n// transformHidePaths performs replacements for all the elements of fsrv.Hide and\n// makes them absolute paths (if they contain a path separator), then returns a\n// new list of the transformed values.\nfunc (fsrv *FileServer) transformHidePaths(repl *caddy.Replacer) []string {\n\thide := make([]string, len(fsrv.Hide))\n\tfor i := range fsrv.Hide {\n\t\thide[i] = repl.ReplaceAll(fsrv.Hide[i], \"\")\n\t\tif strings.Contains(hide[i], separator) {\n\t\t\tabs, err := caddy.FastAbs(hide[i])\n\t\t\tif err == nil {\n\t\t\t\thide[i] = abs\n\t\t\t}\n\t\t}\n\t}\n\treturn hide\n}\n\n// fileHidden returns true if filename is hidden according to the hide list.\n// filename must be a relative or absolute file system path, not a request\n// URI path. It is expected that all the paths in the hide list are absolute\n// paths or are singular filenames (without a path separator).\nfunc fileHidden(filename string, hide []string) bool {\n\tif len(hide) == 0 {\n\t\treturn false\n\t}\n\n\t// all path comparisons use the complete absolute path if possible\n\tfilenameAbs, err := caddy.FastAbs(filename)\n\tif err == nil {\n\t\tfilename = filenameAbs\n\t}\n\n\tvar components []string\n\n\tfor _, h := range hide {\n\t\tif !strings.Contains(h, separator) {\n\t\t\t// if there is no separator in h, then we assume the user\n\t\t\t// wants to hide any files or folders that match that\n\t\t\t// name; thus we have to compare against each component\n\t\t\t// of the filename, e.g. hiding \"bar\" would hide \"/bar\"\n\t\t\t// as well as \"/foo/bar/baz\" but not \"/barstool\".\n\t\t\tif len(components) == 0 {\n\t\t\t\tcomponents = strings.Split(filename, separator)\n\t\t\t}\n\t\t\tfor _, c := range components {\n\t\t\t\tif hidden, _ := filepath.Match(h, c); hidden {\n\t\t\t\t\treturn true\n\t\t\t\t}\n\t\t\t}\n\t\t} else if strings.HasPrefix(filename, h) {\n\t\t\t// if there is a separator in h, and filename is exactly\n\t\t\t// prefixed with h, then we can do a prefix match so that\n\t\t\t// \"/foo\" matches \"/foo/bar\" but not \"/foobar\".\n\t\t\twithoutPrefix := strings.TrimPrefix(filename, h)\n\t\t\tif strings.HasPrefix(withoutPrefix, separator) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\n\t\t// in the general case, a glob match will suffice\n\t\tif hidden, _ := filepath.Match(h, filename); hidden {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n\n// notFound returns a 404 error or, if pass-thru is enabled,\n// it calls the next handler in the chain.\nfunc (fsrv *FileServer) notFound(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\tif fsrv.PassThru {\n\t\treturn next.ServeHTTP(w, r)\n\t}\n\treturn caddyhttp.Error(http.StatusNotFound, nil)\n}\n\n// calculateEtag computes an entity tag using a strong validator\n// without consuming the contents of the file. It requires the\n// file info contain the correct size and modification time.\n// It strives to implement the semantics regarding ETags as defined\n// by RFC 9110 section 8.8.3 and 8.8.1. See\n// https://www.rfc-editor.org/rfc/rfc9110.html#section-8.8.3.\n//\n// As our implementation uses file modification timestamp and size,\n// note the following from RFC 9110 section 8.8.1: \"A representation's\n// modification time, if defined with only one-second resolution,\n// might be a weak validator if it is possible for the representation to\n// be modified twice during a single second and retrieved between those\n// modifications.\" The ext4 file system, which underpins the vast majority\n// of Caddy deployments, stores mod times with millisecond precision,\n// which we consider precise enough to qualify as a strong validator.\nfunc calculateEtag(d os.FileInfo) string {\n\tmtime := d.ModTime()\n\tif mtimeUnix := mtime.Unix(); mtimeUnix == 0 || mtimeUnix == 1 {\n\t\treturn \"\" // not useful anyway; see issue #5548\n\t}\n\tvar sb strings.Builder\n\tsb.WriteRune('\"')\n\tsb.WriteString(strconv.FormatInt(mtime.UnixNano(), 36))\n\tsb.WriteString(strconv.FormatInt(d.Size(), 36))\n\tsb.WriteRune('\"')\n\treturn sb.String()\n}\n\n// Finds the first corresponding etag file for a given file in the file system and return its content\nfunc (fsrv *FileServer) getEtagFromFile(fileSystem fs.FS, filename string) (string, error) {\n\tfor _, suffix := range fsrv.EtagFileExtensions {\n\t\tetagFilename := filename + suffix\n\t\tetag, err := fs.ReadFile(fileSystem, etagFilename)\n\t\tif errors.Is(err, fs.ErrNotExist) {\n\t\t\tcontinue\n\t\t}\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"cannot read etag from file %s: %v\", etagFilename, err)\n\t\t}\n\n\t\t// Etags should not contain newline characters\n\t\tetag = bytes.ReplaceAll(etag, []byte(\"\\n\"), []byte{})\n\n\t\treturn string(etag), nil\n\t}\n\treturn \"\", nil\n}\n\n// redirect performs a redirect to a given path. The 'toPath' parameter\n// MUST be solely a path, and MUST NOT include a query.\nfunc redirect(w http.ResponseWriter, r *http.Request, toPath string) error {\n\tfor strings.HasPrefix(toPath, \"//\") {\n\t\t// prevent path-based open redirects\n\t\ttoPath = strings.TrimPrefix(toPath, \"/\")\n\t}\n\t// preserve the query string if present\n\tif r.URL.RawQuery != \"\" {\n\t\ttoPath += \"?\" + r.URL.RawQuery\n\t}\n\thttp.Redirect(w, r, toPath, http.StatusPermanentRedirect)\n\treturn nil\n}\n\n// statusOverrideResponseWriter intercepts WriteHeader calls\n// to instead write the HTTP status code we want instead\n// of the one http.ServeContent will use by default (usually 200)\ntype statusOverrideResponseWriter struct {\n\thttp.ResponseWriter\n\tcode int\n}\n\n// WriteHeader intercepts calls by the stdlib to WriteHeader\n// to instead write the HTTP status code we want.\nfunc (wr statusOverrideResponseWriter) WriteHeader(int) {\n\twr.ResponseWriter.WriteHeader(wr.code)\n}\n\n// Unwrap returns the underlying ResponseWriter, necessary for\n// http.ResponseController to work correctly.\nfunc (wr statusOverrideResponseWriter) Unwrap() http.ResponseWriter {\n\treturn wr.ResponseWriter\n}\n\nvar defaultIndexNames = []string{\"index.html\", \"index.txt\"}\n\nconst (\n\tminBackoff, maxBackoff = 2, 5\n\tseparator              = string(filepath.Separator)\n)\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*FileServer)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*FileServer)(nil)\n)\n",
    "source_file": "modules/caddyhttp/fileserver/staticfiles.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fileserver\n\nimport (\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/rewrite\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterHandlerDirective(\"file_server\", parseCaddyfile)\n\thttpcaddyfile.RegisterDirective(\"try_files\", parseTryFiles)\n}\n\n// parseCaddyfile parses the file_server directive.\n// See UnmarshalCaddyfile for the syntax.\nfunc parseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\tfsrv := new(FileServer)\n\terr := fsrv.UnmarshalCaddyfile(h.Dispenser)\n\tif err != nil {\n\t\treturn fsrv, err\n\t}\n\terr = fsrv.FinalizeUnmarshalCaddyfile(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn fsrv, err\n}\n\n// UnmarshalCaddyfile parses the file_server directive. It enables\n// the static file server and configures it with this syntax:\n//\n//\tfile_server [<matcher>] [browse] {\n//\t    fs            <filesystem>\n//\t    root          <path>\n//\t    hide          <files...>\n//\t    index         <files...>\n//\t    browse        [<template_file>]\n//\t    precompressed <formats...>\n//\t    status        <status>\n//\t    disable_canonical_uris\n//\t}\n//\n// The FinalizeUnmarshalCaddyfile method should be called after this\n// to finalize setup of hidden Caddyfiles.\nfunc (fsrv *FileServer) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume directive name\n\n\targs := d.RemainingArgs()\n\tswitch len(args) {\n\tcase 0:\n\tcase 1:\n\t\tif args[0] != \"browse\" {\n\t\t\treturn d.ArgErr()\n\t\t}\n\t\tfsrv.Browse = new(Browse)\n\tdefault:\n\t\treturn d.ArgErr()\n\t}\n\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"fs\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif fsrv.FileSystem != \"\" {\n\t\t\t\treturn d.Err(\"file system already specified\")\n\t\t\t}\n\t\t\tfsrv.FileSystem = d.Val()\n\n\t\tcase \"hide\":\n\t\t\tfsrv.Hide = d.RemainingArgs()\n\t\t\tif len(fsrv.Hide) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"index\":\n\t\t\tfsrv.IndexNames = d.RemainingArgs()\n\t\t\tif len(fsrv.IndexNames) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"root\":\n\t\t\tif !d.Args(&fsrv.Root) {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"browse\":\n\t\t\tif fsrv.Browse != nil {\n\t\t\t\treturn d.Err(\"browsing is already configured\")\n\t\t\t}\n\t\t\tfsrv.Browse = new(Browse)\n\t\t\td.Args(&fsrv.Browse.TemplateFile)\n\t\t\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\t\t\tswitch d.Val() {\n\t\t\t\tcase \"reveal_symlinks\":\n\t\t\t\t\tif fsrv.Browse.RevealSymlinks {\n\t\t\t\t\t\treturn d.Err(\"Symlinks path reveal is already enabled\")\n\t\t\t\t\t}\n\t\t\t\t\tfsrv.Browse.RevealSymlinks = true\n\t\t\t\tcase \"sort\":\n\t\t\t\t\tfor d.NextArg() {\n\t\t\t\t\t\tdVal := d.Val()\n\t\t\t\t\t\tswitch dVal {\n\t\t\t\t\t\tcase sortByName, sortByNameDirFirst, sortBySize, sortByTime, sortOrderAsc, sortOrderDesc:\n\t\t\t\t\t\t\tfsrv.Browse.SortOptions = append(fsrv.Browse.SortOptions, dVal)\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\treturn d.Errf(\"unknown sort option '%s'\", dVal)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\tcase \"file_limit\":\n\t\t\t\t\tfileLimit := d.RemainingArgs()\n\t\t\t\t\tif len(fileLimit) != 1 {\n\t\t\t\t\t\treturn d.Err(\"file_limit should have an integer value\")\n\t\t\t\t\t}\n\t\t\t\t\tval, _ := strconv.Atoi(fileLimit[0])\n\t\t\t\t\tif fsrv.Browse.FileLimit != 0 {\n\t\t\t\t\t\treturn d.Err(\"file_limit is already enabled\")\n\t\t\t\t\t}\n\t\t\t\t\tfsrv.Browse.FileLimit = val\n\t\t\t\tdefault:\n\t\t\t\t\treturn d.Errf(\"unknown subdirective '%s'\", d.Val())\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase \"precompressed\":\n\t\t\tfsrv.PrecompressedOrder = d.RemainingArgs()\n\t\t\tif len(fsrv.PrecompressedOrder) == 0 {\n\t\t\t\tfsrv.PrecompressedOrder = []string{\"br\", \"zstd\", \"gzip\"}\n\t\t\t}\n\n\t\t\tfor _, format := range fsrv.PrecompressedOrder {\n\t\t\t\tmodID := \"http.precompressed.\" + format\n\t\t\t\tmod, err := caddy.GetModule(modID)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn d.Errf(\"getting module named '%s': %v\", modID, err)\n\t\t\t\t}\n\t\t\t\tinst := mod.New()\n\t\t\t\tprecompress, ok := inst.(encode.Precompressed)\n\t\t\t\tif !ok {\n\t\t\t\t\treturn d.Errf(\"module %s is not a precompressor; is %T\", modID, inst)\n\t\t\t\t}\n\t\t\t\tif fsrv.PrecompressedRaw == nil {\n\t\t\t\t\tfsrv.PrecompressedRaw = make(caddy.ModuleMap)\n\t\t\t\t}\n\t\t\t\tfsrv.PrecompressedRaw[format] = caddyconfig.JSON(precompress, nil)\n\t\t\t}\n\n\t\tcase \"status\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tfsrv.StatusCode = caddyhttp.WeakString(d.Val())\n\n\t\tcase \"disable_canonical_uris\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tfalseBool := false\n\t\t\tfsrv.CanonicalURIs = &falseBool\n\n\t\tcase \"pass_thru\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tfsrv.PassThru = true\n\n\t\tcase \"etag_file_extensions\":\n\t\t\tetagFileExtensions := d.RemainingArgs()\n\t\t\tif len(etagFileExtensions) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tfsrv.EtagFileExtensions = etagFileExtensions\n\n\t\tdefault:\n\t\t\treturn d.Errf(\"unknown subdirective '%s'\", d.Val())\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// FinalizeUnmarshalCaddyfile finalizes the Caddyfile parsing which\n// requires having an httpcaddyfile.Helper to function, to setup hidden Caddyfiles.\nfunc (fsrv *FileServer) FinalizeUnmarshalCaddyfile(h httpcaddyfile.Helper) error {\n\t// Hide the Caddyfile (and any imported Caddyfiles).\n\t// This needs to be done in here instead of UnmarshalCaddyfile\n\t// because UnmarshalCaddyfile only has access to the dispenser\n\t// and not the helper, and only the helper has access to the\n\t// Caddyfiles function.\n\tif configFiles := h.Caddyfiles(); len(configFiles) > 0 {\n\t\tfor _, file := range configFiles {\n\t\t\tfile = filepath.Clean(file)\n\t\t\tif !fileHidden(file, fsrv.Hide) {\n\t\t\t\t// if there's no path separator, the file server module will hide all\n\t\t\t\t// files by that name, rather than a specific one; but we want to hide\n\t\t\t\t// only this specific file, so ensure there's always a path separator\n\t\t\t\tif !strings.Contains(file, separator) {\n\t\t\t\t\tfile = \".\" + separator + file\n\t\t\t\t}\n\t\t\t\tfsrv.Hide = append(fsrv.Hide, file)\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// parseTryFiles parses the try_files directive. It combines a file matcher\n// with a rewrite directive, so this is not a standard handler directive.\n// A try_files directive has this syntax (notice no matcher tokens accepted):\n//\n//\ttry_files <files...> {\n//\t\tpolicy first_exist|smallest_size|largest_size|most_recently_modified\n//\t}\n//\n// and is basically shorthand for:\n//\n//\t@try_files file {\n//\t\ttry_files <files...>\n//\t\tpolicy first_exist|smallest_size|largest_size|most_recently_modified\n//\t}\n//\trewrite @try_files {http.matchers.file.relative}\n//\n// This directive rewrites request paths only, preserving any other part\n// of the URI, unless the part is explicitly given in the file list. For\n// example, if any of the files in the list have a query string:\n//\n//\ttry_files {path} index.php?{query}&p={path}\n//\n// then the query string will not be treated as part of the file name; and\n// if that file matches, the given query string will replace any query string\n// that already exists on the request URI.\nfunc parseTryFiles(h httpcaddyfile.Helper) ([]httpcaddyfile.ConfigValue, error) {\n\tif !h.Next() {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\ttryFiles := h.RemainingArgs()\n\tif len(tryFiles) == 0 {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\t// parse out the optional try policy\n\tvar tryPolicy string\n\tfor h.NextBlock(0) {\n\t\tswitch h.Val() {\n\t\tcase \"policy\":\n\t\t\tif tryPolicy != \"\" {\n\t\t\t\treturn nil, h.Err(\"try policy already configured\")\n\t\t\t}\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\ttryPolicy = h.Val()\n\n\t\t\tswitch tryPolicy {\n\t\t\tcase tryPolicyFirstExist, tryPolicyFirstExistFallback, tryPolicyLargestSize, tryPolicySmallestSize, tryPolicyMostRecentlyMod:\n\t\t\tdefault:\n\t\t\t\treturn nil, h.Errf(\"unrecognized try policy: %s\", tryPolicy)\n\t\t\t}\n\t\t}\n\t}\n\n\t// makeRoute returns a route that tries the files listed in try\n\t// and then rewrites to the matched file; userQueryString is\n\t// appended to the rewrite rule.\n\tmakeRoute := func(try []string, userQueryString string) []httpcaddyfile.ConfigValue {\n\t\thandler := rewrite.Rewrite{\n\t\t\tURI: \"{http.matchers.file.relative}\" + userQueryString,\n\t\t}\n\t\tmatcherSet := caddy.ModuleMap{\n\t\t\t\"file\": h.JSON(MatchFile{TryFiles: try, TryPolicy: tryPolicy}),\n\t\t}\n\t\treturn h.NewRoute(matcherSet, handler)\n\t}\n\n\tvar result []httpcaddyfile.ConfigValue\n\n\t// if there are query strings in the list, we have to split into\n\t// a separate route for each item with a query string, because\n\t// the rewrite is different for that item\n\ttry := make([]string, 0, len(tryFiles))\n\tfor _, item := range tryFiles {\n\t\tif idx := strings.Index(item, \"?\"); idx >= 0 {\n\t\t\tif len(try) > 0 {\n\t\t\t\tresult = append(result, makeRoute(try, \"\")...)\n\t\t\t\ttry = []string{}\n\t\t\t}\n\t\t\tresult = append(result, makeRoute([]string{item[:idx]}, item[idx:])...)\n\t\t\tcontinue\n\t\t}\n\t\t// accumulate consecutive non-query-string parameters\n\t\ttry = append(try, item)\n\t}\n\tif len(try) > 0 {\n\t\tresult = append(result, makeRoute(try, \"\")...)\n\t}\n\n\t// ensure that multiple routes (possible if rewrite targets\n\t// have query strings, for example) are grouped together\n\t// so only the first matching rewrite is performed (#2891)\n\th.GroupRoutes(result)\n\n\treturn result, nil\n}\n\nvar _ caddyfile.Unmarshaler = (*FileServer)(nil)\n",
    "source_file": "modules/caddyhttp/fileserver/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage maphandler\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"regexp\"\n\t\"slices\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Handler{})\n}\n\n// Handler implements a middleware that maps inputs to outputs. Specifically, it\n// compares a source value against the map inputs, and for one that matches, it\n// applies the output values to each destination. Destinations become placeholder\n// names.\n//\n// Mapped placeholders are not evaluated until they are used, so even for very\n// large mappings, this handler is quite efficient.\ntype Handler struct {\n\t// Source is the placeholder from which to get the input value.\n\tSource string `json:\"source,omitempty\"`\n\n\t// Destinations are the names of placeholders in which to store the outputs.\n\t// Destination values should be wrapped in braces, for example, {my_placeholder}.\n\tDestinations []string `json:\"destinations,omitempty\"`\n\n\t// Mappings from source values (inputs) to destination values (outputs).\n\t// The first matching, non-nil mapping will be applied.\n\tMappings []Mapping `json:\"mappings,omitempty\"`\n\n\t// If no mappings match or if the mapped output is null/nil, the associated\n\t// default output will be applied (optional).\n\tDefaults []string `json:\"defaults,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Handler) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.map\",\n\t\tNew: func() caddy.Module { return new(Handler) },\n\t}\n}\n\n// Provision sets up h.\nfunc (h *Handler) Provision(_ caddy.Context) error {\n\tfor j, dest := range h.Destinations {\n\t\tif strings.Count(dest, \"{\") != 1 || !strings.HasPrefix(dest, \"{\") {\n\t\t\treturn fmt.Errorf(\"destination must be a placeholder and only a placeholder\")\n\t\t}\n\t\th.Destinations[j] = strings.Trim(dest, \"{}\")\n\t}\n\n\tfor i, m := range h.Mappings {\n\t\tif m.InputRegexp == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tvar err error\n\t\th.Mappings[i].re, err = regexp.Compile(m.InputRegexp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"compiling regexp for mapping %d: %v\", i, err)\n\t\t}\n\t}\n\n\t// TODO: improve efficiency even further by using an actual map type\n\t// for the non-regexp mappings, OR sort them and do a binary search\n\n\treturn nil\n}\n\n// Validate ensures that h is configured properly.\nfunc (h *Handler) Validate() error {\n\tnDest, nDef := len(h.Destinations), len(h.Defaults)\n\tif nDef > 0 && nDef != nDest {\n\t\treturn fmt.Errorf(\"%d destinations != %d defaults\", nDest, nDef)\n\t}\n\n\tseen := make(map[string]int)\n\tfor i, m := range h.Mappings {\n\t\t// prevent confusing/ambiguous mappings\n\t\tif m.Input != \"\" && m.InputRegexp != \"\" {\n\t\t\treturn fmt.Errorf(\"mapping %d has both input and input_regexp fields specified, which is confusing\", i)\n\t\t}\n\n\t\t// prevent duplicate mappings\n\t\tinput := m.Input\n\t\tif m.InputRegexp != \"\" {\n\t\t\tinput = m.InputRegexp\n\t\t}\n\t\tif prev, ok := seen[input]; ok {\n\t\t\treturn fmt.Errorf(\"mapping %d has a duplicate input '%s' previously used with mapping %d\", i, input, prev)\n\t\t}\n\t\tseen[input] = i\n\n\t\t// ensure mappings have 1:1 output-to-destination correspondence\n\t\tnOut := len(m.Outputs)\n\t\tif nOut != nDest {\n\t\t\treturn fmt.Errorf(\"mapping %d has %d outputs but there are %d destinations defined\", i, nOut, nDest)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (h Handler) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\t// defer work until a variable is actually evaluated by using replacer's Map callback\n\trepl.Map(func(key string) (any, bool) {\n\t\t// return early if the variable is not even a configured destination\n\t\tdestIdx := slices.Index(h.Destinations, key)\n\t\tif destIdx < 0 {\n\t\t\treturn nil, false\n\t\t}\n\n\t\tinput := repl.ReplaceAll(h.Source, \"\")\n\n\t\t// find the first mapping matching the input and return\n\t\t// the requested destination/output value\n\t\tfor _, m := range h.Mappings {\n\t\t\toutput := m.Outputs[destIdx]\n\t\t\tif output == nil {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\toutputStr := caddy.ToString(output)\n\n\t\t\t// evaluate regular expression if configured\n\t\t\tif m.re != nil {\n\t\t\t\tvar result []byte\n\t\t\t\tmatches := m.re.FindStringSubmatchIndex(input)\n\t\t\t\tif matches == nil {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tresult = m.re.ExpandString(result, outputStr, input, matches)\n\t\t\t\treturn string(result), true\n\t\t\t}\n\n\t\t\t// otherwise simple string comparison\n\t\t\tif input == m.Input {\n\t\t\t\treturn repl.ReplaceAll(outputStr, \"\"), true\n\t\t\t}\n\t\t}\n\n\t\t// fall back to default if no match or if matched nil value\n\t\tif len(h.Defaults) > destIdx {\n\t\t\treturn repl.ReplaceAll(h.Defaults[destIdx], \"\"), true\n\t\t}\n\n\t\treturn nil, true\n\t})\n\n\treturn next.ServeHTTP(w, r)\n}\n\n// Mapping describes a mapping from input to outputs.\ntype Mapping struct {\n\t// The input value to match. Must be distinct from other mappings.\n\t// Mutually exclusive to input_regexp.\n\tInput string `json:\"input,omitempty\"`\n\n\t// The input regular expression to match. Mutually exclusive to input.\n\tInputRegexp string `json:\"input_regexp,omitempty\"`\n\n\t// Upon a match with the input, each output is positionally correlated\n\t// with each destination of the parent handler. An output that is null\n\t// (nil) will be treated as if it was not mapped at all.\n\tOutputs []any `json:\"outputs,omitempty\"`\n\n\tre *regexp.Regexp\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*Handler)(nil)\n\t_ caddy.Validator             = (*Handler)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*Handler)(nil)\n)\n",
    "source_file": "modules/caddyhttp/map/map.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage maphandler\n\nimport (\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterHandlerDirective(\"map\", parseCaddyfile)\n}\n\n// parseCaddyfile sets up the map handler from Caddyfile tokens. Syntax:\n//\n//\tmap [<matcher>] <source> <destinations...> {\n//\t    [~]<input> <outputs...>\n//\t    default    <defaults...>\n//\t}\n//\n// If the input value is prefixed with a tilde (~), then the input will be parsed as a\n// regular expression.\n//\n// The Caddyfile adapter treats outputs that are a literal hyphen (-) as a null/nil\n// value. This is useful if you want to fall back to default for that particular output.\n//\n// The number of outputs for each mapping must not be more than the number of destinations.\n// However, for convenience, there may be fewer outputs than destinations and any missing\n// outputs will be filled in implicitly.\nfunc parseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\n\tvar handler Handler\n\n\t// source\n\tif !h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\thandler.Source = h.Val()\n\n\t// destinations\n\thandler.Destinations = h.RemainingArgs()\n\tif len(handler.Destinations) == 0 {\n\t\treturn nil, h.Err(\"missing destination argument(s)\")\n\t}\n\tfor _, dest := range handler.Destinations {\n\t\tif shorthand := httpcaddyfile.WasReplacedPlaceholderShorthand(dest); shorthand != \"\" {\n\t\t\treturn nil, h.Errf(\"destination %s conflicts with a Caddyfile placeholder shorthand\", shorthand)\n\t\t}\n\t}\n\n\t// mappings\n\tfor h.NextBlock(0) {\n\t\t// defaults are a special case\n\t\tif h.Val() == \"default\" {\n\t\t\tif len(handler.Defaults) > 0 {\n\t\t\t\treturn nil, h.Err(\"defaults already defined\")\n\t\t\t}\n\t\t\thandler.Defaults = h.RemainingArgs()\n\t\t\tfor len(handler.Defaults) < len(handler.Destinations) {\n\t\t\t\thandler.Defaults = append(handler.Defaults, \"\")\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// every line maps an input value to one or more outputs\n\t\tin := h.Val()\n\t\tvar outs []any\n\t\tfor h.NextArg() {\n\t\t\tval := h.ScalarVal()\n\t\t\tif val == \"-\" {\n\t\t\t\touts = append(outs, nil)\n\t\t\t} else {\n\t\t\t\touts = append(outs, val)\n\t\t\t}\n\t\t}\n\n\t\t// cannot have more outputs than destinations\n\t\tif len(outs) > len(handler.Destinations) {\n\t\t\treturn nil, h.Err(\"too many outputs\")\n\t\t}\n\n\t\t// for convenience, can have fewer outputs than destinations, but the\n\t\t// underlying handler won't accept that, so we fill in nil values\n\t\tfor len(outs) < len(handler.Destinations) {\n\t\t\touts = append(outs, nil)\n\t\t}\n\n\t\t// create the mapping\n\t\tmapping := Mapping{Outputs: outs}\n\t\tif strings.HasPrefix(in, \"~\") {\n\t\t\tmapping.InputRegexp = in[1:]\n\t\t} else {\n\t\t\tmapping.Input = in\n\t\t}\n\n\t\thandler.Mappings = append(handler.Mappings, mapping)\n\t}\n\treturn handler, nil\n}\n",
    "source_file": "modules/caddyhttp/map/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage headers\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"regexp\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Handler{})\n}\n\n// Handler is a middleware which modifies request and response headers.\n//\n// Changes to headers are applied immediately, except for the response\n// headers when Deferred is true or when Required is set. In those cases,\n// the changes are applied when the headers are written to the response.\n// Note that deferred changes do not take effect if an error occurs later\n// in the middleware chain.\n//\n// Properties in this module accept placeholders.\n//\n// Response header operations can be conditioned upon response status code\n// and/or other header values.\ntype Handler struct {\n\tRequest  *HeaderOps     `json:\"request,omitempty\"`\n\tResponse *RespHeaderOps `json:\"response,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Handler) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.headers\",\n\t\tNew: func() caddy.Module { return new(Handler) },\n\t}\n}\n\n// Provision sets up h's configuration.\nfunc (h *Handler) Provision(ctx caddy.Context) error {\n\tif h.Request != nil {\n\t\terr := h.Request.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif h.Response != nil {\n\t\terr := h.Response.Provision(ctx)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\n// Validate ensures h's configuration is valid.\nfunc (h Handler) Validate() error {\n\tif h.Request != nil {\n\t\terr := h.Request.validate()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\tif h.Response != nil && h.Response.HeaderOps != nil {\n\t\terr := h.Response.validate()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (h Handler) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\tif h.Request != nil {\n\t\th.Request.ApplyToRequest(r)\n\t}\n\n\tif h.Response != nil {\n\t\tif h.Response.Deferred || h.Response.Require != nil {\n\t\t\tw = &responseWriterWrapper{\n\t\t\t\tResponseWriterWrapper: &caddyhttp.ResponseWriterWrapper{ResponseWriter: w},\n\t\t\t\treplacer:              repl,\n\t\t\t\trequire:               h.Response.Require,\n\t\t\t\theaderOps:             h.Response.HeaderOps,\n\t\t\t}\n\t\t} else {\n\t\t\th.Response.ApplyTo(w.Header(), repl)\n\t\t}\n\t}\n\n\treturn next.ServeHTTP(w, r)\n}\n\n// HeaderOps defines manipulations for HTTP headers.\ntype HeaderOps struct {\n\t// Adds HTTP headers; does not replace any existing header fields.\n\tAdd http.Header `json:\"add,omitempty\"`\n\n\t// Sets HTTP headers; replaces existing header fields.\n\tSet http.Header `json:\"set,omitempty\"`\n\n\t// Names of HTTP header fields to delete. Basic wildcards are supported:\n\t//\n\t// - Start with `*` for all field names with the given suffix;\n\t// - End with `*` for all field names with the given prefix;\n\t// - Start and end with `*` for all field names containing a substring.\n\tDelete []string `json:\"delete,omitempty\"`\n\n\t// Performs in-situ substring replacements of HTTP headers.\n\t// Keys are the field names on which to perform the associated replacements.\n\t// If the field name is `*`, the replacements are performed on all header fields.\n\tReplace map[string][]Replacement `json:\"replace,omitempty\"`\n}\n\n// Provision sets up the header operations.\nfunc (ops *HeaderOps) Provision(_ caddy.Context) error {\n\tif ops == nil {\n\t\treturn nil // it's possible no ops are configured; fix #6893\n\t}\n\tfor fieldName, replacements := range ops.Replace {\n\t\tfor i, r := range replacements {\n\t\t\tif r.SearchRegexp == \"\" {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tre, err := regexp.Compile(r.SearchRegexp)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"replacement %d for header field '%s': %v\", i, fieldName, err)\n\t\t\t}\n\t\t\treplacements[i].re = re\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (ops HeaderOps) validate() error {\n\tfor fieldName, replacements := range ops.Replace {\n\t\tfor _, r := range replacements {\n\t\t\tif r.Search != \"\" && r.SearchRegexp != \"\" {\n\t\t\t\treturn fmt.Errorf(\"cannot specify both a substring search and a regular expression search for field '%s'\", fieldName)\n\t\t\t}\n\t\t}\n\t}\n\treturn nil\n}\n\n// Replacement describes a string replacement,\n// either a simple and fast substring search\n// or a slower but more powerful regex search.\ntype Replacement struct {\n\t// The substring to search for.\n\tSearch string `json:\"search,omitempty\"`\n\n\t// The regular expression to search with.\n\tSearchRegexp string `json:\"search_regexp,omitempty\"`\n\n\t// The string with which to replace matches.\n\tReplace string `json:\"replace,omitempty\"`\n\n\tre *regexp.Regexp\n}\n\n// RespHeaderOps defines manipulations for response headers.\ntype RespHeaderOps struct {\n\t*HeaderOps\n\n\t// If set, header operations will be deferred until\n\t// they are written out and only performed if the\n\t// response matches these criteria.\n\tRequire *caddyhttp.ResponseMatcher `json:\"require,omitempty\"`\n\n\t// If true, header operations will be deferred until\n\t// they are written out. Superseded if Require is set.\n\t// Usually you will need to set this to true if any\n\t// fields are being deleted.\n\tDeferred bool `json:\"deferred,omitempty\"`\n}\n\n// ApplyTo applies ops to hdr using repl.\nfunc (ops HeaderOps) ApplyTo(hdr http.Header, repl *caddy.Replacer) {\n\t// before manipulating headers in other ways, check if there\n\t// is configuration to delete all headers, and do that first\n\t// because if a header is to be added, we don't want to delete\n\t// it also\n\tfor _, fieldName := range ops.Delete {\n\t\tfieldName = repl.ReplaceKnown(fieldName, \"\")\n\t\tif fieldName == \"*\" {\n\t\t\tclear(hdr)\n\t\t}\n\t}\n\n\t// add\n\tfor fieldName, vals := range ops.Add {\n\t\tfieldName = repl.ReplaceKnown(fieldName, \"\")\n\t\tfor _, v := range vals {\n\t\t\thdr.Add(fieldName, repl.ReplaceKnown(v, \"\"))\n\t\t}\n\t}\n\n\t// set\n\tfor fieldName, vals := range ops.Set {\n\t\tfieldName = repl.ReplaceKnown(fieldName, \"\")\n\t\tvar newVals []string\n\t\tfor i := range vals {\n\t\t\t// append to new slice so we don't overwrite\n\t\t\t// the original values in ops.Set\n\t\t\tnewVals = append(newVals, repl.ReplaceKnown(vals[i], \"\"))\n\t\t}\n\t\thdr.Set(fieldName, strings.Join(newVals, \",\"))\n\t}\n\n\t// delete\n\tfor _, fieldName := range ops.Delete {\n\t\tfieldName = strings.ToLower(repl.ReplaceKnown(fieldName, \"\"))\n\t\tif fieldName == \"*\" {\n\t\t\tcontinue // handled above\n\t\t}\n\t\tswitch {\n\t\tcase strings.HasPrefix(fieldName, \"*\") && strings.HasSuffix(fieldName, \"*\"):\n\t\t\tfor existingField := range hdr {\n\t\t\t\tif strings.Contains(strings.ToLower(existingField), fieldName[1:len(fieldName)-1]) {\n\t\t\t\t\tdelete(hdr, existingField)\n\t\t\t\t}\n\t\t\t}\n\t\tcase strings.HasPrefix(fieldName, \"*\"):\n\t\t\tfor existingField := range hdr {\n\t\t\t\tif strings.HasSuffix(strings.ToLower(existingField), fieldName[1:]) {\n\t\t\t\t\tdelete(hdr, existingField)\n\t\t\t\t}\n\t\t\t}\n\t\tcase strings.HasSuffix(fieldName, \"*\"):\n\t\t\tfor existingField := range hdr {\n\t\t\t\tif strings.HasPrefix(strings.ToLower(existingField), fieldName[:len(fieldName)-1]) {\n\t\t\t\t\tdelete(hdr, existingField)\n\t\t\t\t}\n\t\t\t}\n\t\tdefault:\n\t\t\thdr.Del(fieldName)\n\t\t}\n\t}\n\n\t// replace\n\tfor fieldName, replacements := range ops.Replace {\n\t\tfieldName = http.CanonicalHeaderKey(repl.ReplaceKnown(fieldName, \"\"))\n\n\t\t// all fields...\n\t\tif fieldName == \"*\" {\n\t\t\tfor _, r := range replacements {\n\t\t\t\tsearch := repl.ReplaceKnown(r.Search, \"\")\n\t\t\t\treplace := repl.ReplaceKnown(r.Replace, \"\")\n\t\t\t\tfor fieldName, vals := range hdr {\n\t\t\t\t\tfor i := range vals {\n\t\t\t\t\t\tif r.re != nil {\n\t\t\t\t\t\t\thdr[fieldName][i] = r.re.ReplaceAllString(hdr[fieldName][i], replace)\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\thdr[fieldName][i] = strings.ReplaceAll(hdr[fieldName][i], search, replace)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// ...or only with the named field\n\t\tfor _, r := range replacements {\n\t\t\tsearch := repl.ReplaceKnown(r.Search, \"\")\n\t\t\treplace := repl.ReplaceKnown(r.Replace, \"\")\n\t\t\tfor hdrFieldName, vals := range hdr {\n\t\t\t\t// see issue #4330 for why we don't simply use hdr[fieldName]\n\t\t\t\tif http.CanonicalHeaderKey(hdrFieldName) != fieldName {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\tfor i := range vals {\n\t\t\t\t\tif r.re != nil {\n\t\t\t\t\t\thdr[hdrFieldName][i] = r.re.ReplaceAllString(hdr[hdrFieldName][i], replace)\n\t\t\t\t\t} else {\n\t\t\t\t\t\thdr[hdrFieldName][i] = strings.ReplaceAll(hdr[hdrFieldName][i], search, replace)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n\n// ApplyToRequest applies ops to r, specially handling the Host\n// header which the standard library does not include with the\n// header map with all the others. This method mutates r.Host.\nfunc (ops HeaderOps) ApplyToRequest(r *http.Request) {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\t// capture the current Host header so we can\n\t// reset to it when we're done\n\torigHost, hadHost := r.Header[\"Host\"]\n\n\t// append r.Host; this way, we know that our value\n\t// was last in the list, and if an Add operation\n\t// appended something else after it, that's probably\n\t// fine because it's weird to have multiple Host\n\t// headers anyway and presumably the one they added\n\t// is the one they wanted\n\tr.Header[\"Host\"] = append(r.Header[\"Host\"], r.Host)\n\n\t// apply header operations\n\tops.ApplyTo(r.Header, repl)\n\n\t// retrieve the last Host value (likely the one we appended)\n\tif len(r.Header[\"Host\"]) > 0 {\n\t\tr.Host = r.Header[\"Host\"][len(r.Header[\"Host\"])-1]\n\t} else {\n\t\tr.Host = \"\"\n\t}\n\n\t// reset the Host header slice\n\tif hadHost {\n\t\tr.Header[\"Host\"] = origHost\n\t} else {\n\t\tdelete(r.Header, \"Host\")\n\t}\n}\n\n// responseWriterWrapper defers response header\n// operations until WriteHeader is called.\ntype responseWriterWrapper struct {\n\t*caddyhttp.ResponseWriterWrapper\n\treplacer    *caddy.Replacer\n\trequire     *caddyhttp.ResponseMatcher\n\theaderOps   *HeaderOps\n\twroteHeader bool\n}\n\nfunc (rww *responseWriterWrapper) WriteHeader(status int) {\n\tif rww.wroteHeader {\n\t\treturn\n\t}\n\t// 1xx responses aren't final; just informational\n\tif status < 100 || status > 199 {\n\t\trww.wroteHeader = true\n\t}\n\tif rww.require == nil || rww.require.Match(status, rww.ResponseWriterWrapper.Header()) {\n\t\tif rww.headerOps != nil {\n\t\t\trww.headerOps.ApplyTo(rww.ResponseWriterWrapper.Header(), rww.replacer)\n\t\t}\n\t}\n\trww.ResponseWriterWrapper.WriteHeader(status)\n}\n\nfunc (rww *responseWriterWrapper) Write(d []byte) (int, error) {\n\tif !rww.wroteHeader {\n\t\trww.WriteHeader(http.StatusOK)\n\t}\n\treturn rww.ResponseWriterWrapper.Write(d)\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*Handler)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*Handler)(nil)\n\t_ http.ResponseWriter         = (*responseWriterWrapper)(nil)\n)\n",
    "source_file": "modules/caddyhttp/headers/headers.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage headers\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\t\"reflect\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterDirective(\"header\", parseCaddyfile)\n\thttpcaddyfile.RegisterDirective(\"request_header\", parseReqHdrCaddyfile)\n}\n\n// parseCaddyfile sets up the handler for response headers from\n// Caddyfile tokens. Syntax:\n//\n//\theader [<matcher>] [[+|-|?|>]<field> [<value|regexp>] [<replacement>]] {\n//\t\t[+]<field> [<value|regexp> [<replacement>]]\n//\t\t?<field> <default_value>\n//\t\t-<field>\n//\t\t><field>\n//\t\t[defer]\n//\t}\n//\n// Either a block can be opened or a single header field can be configured\n// in the first line, but not both in the same directive. Header operations\n// are deferred to write-time if any headers are being deleted or if the\n// 'defer' subdirective is used. + appends a header value, - deletes a field,\n// ? conditionally sets a value only if the header field is not already set,\n// and > sets a field with defer enabled.\nfunc parseCaddyfile(h httpcaddyfile.Helper) ([]httpcaddyfile.ConfigValue, error) {\n\th.Next() // consume directive name\n\tmatcherSet, err := h.ExtractMatcherSet()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\th.Next() // consume the directive name again (matcher parsing resets)\n\n\tmakeHandler := func() Handler {\n\t\treturn Handler{\n\t\t\tResponse: &RespHeaderOps{\n\t\t\t\tHeaderOps: &HeaderOps{},\n\t\t\t},\n\t\t}\n\t}\n\thandler, handlerWithRequire := makeHandler(), makeHandler()\n\n\t// first see if headers are in the initial line\n\tvar hasArgs bool\n\tif h.NextArg() {\n\t\thasArgs = true\n\t\tfield := h.Val()\n\t\tvar value string\n\t\tvar replacement *string\n\t\tif h.NextArg() {\n\t\t\tvalue = h.Val()\n\t\t}\n\t\tif h.NextArg() {\n\t\t\targ := h.Val()\n\t\t\treplacement = &arg\n\t\t}\n\t\terr := applyHeaderOp(\n\t\t\thandler.Response.HeaderOps,\n\t\t\thandler.Response,\n\t\t\tfield,\n\t\t\tvalue,\n\t\t\treplacement,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, h.Err(err.Error())\n\t\t}\n\t\tif len(handler.Response.HeaderOps.Delete) > 0 {\n\t\t\thandler.Response.Deferred = true\n\t\t}\n\t}\n\n\t// if not, they should be in a block\n\tfor h.NextBlock(0) {\n\t\tfield := h.Val()\n\t\tif field == \"defer\" {\n\t\t\thandler.Response.Deferred = true\n\t\t\tcontinue\n\t\t}\n\t\tif field == \"match\" {\n\t\t\tresponseMatchers := make(map[string]caddyhttp.ResponseMatcher)\n\t\t\terr := caddyhttp.ParseNamedResponseMatcher(h.NewFromNextSegment(), responseMatchers)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tmatcher := responseMatchers[\"match\"]\n\t\t\thandler.Response.Require = &matcher\n\t\t\tcontinue\n\t\t}\n\t\tif hasArgs {\n\t\t\treturn nil, h.Err(\"cannot specify headers in both arguments and block\") // because it would be weird\n\t\t}\n\n\t\t// sometimes it is habitual for users to suffix a field name with a colon,\n\t\t// as if they were writing a curl command or something; see\n\t\t// https://caddy.community/t/v2-reverse-proxy-please-add-cors-example-to-the-docs/7349/19\n\t\tfield = strings.TrimSuffix(field, \":\")\n\n\t\tvar value string\n\t\tvar replacement *string\n\t\tif h.NextArg() {\n\t\t\tvalue = h.Val()\n\t\t}\n\t\tif h.NextArg() {\n\t\t\targ := h.Val()\n\t\t\treplacement = &arg\n\t\t}\n\n\t\thandlerToUse := handler\n\t\tif strings.HasPrefix(field, \"?\") {\n\t\t\thandlerToUse = handlerWithRequire\n\t\t}\n\n\t\terr := applyHeaderOp(\n\t\t\thandlerToUse.Response.HeaderOps,\n\t\t\thandlerToUse.Response,\n\t\t\tfield,\n\t\t\tvalue,\n\t\t\treplacement,\n\t\t)\n\t\tif err != nil {\n\t\t\treturn nil, h.Err(err.Error())\n\t\t}\n\t}\n\n\tvar configValues []httpcaddyfile.ConfigValue\n\tif !reflect.DeepEqual(handler, makeHandler()) {\n\t\tconfigValues = append(configValues, h.NewRoute(matcherSet, handler)...)\n\t}\n\tif !reflect.DeepEqual(handlerWithRequire, makeHandler()) {\n\t\tconfigValues = append(configValues, h.NewRoute(matcherSet, handlerWithRequire)...)\n\t}\n\n\treturn configValues, nil\n}\n\n// parseReqHdrCaddyfile sets up the handler for request headers\n// from Caddyfile tokens. Syntax:\n//\n//\trequest_header [<matcher>] [[+|-]<field> [<value|regexp>] [<replacement>]]\nfunc parseReqHdrCaddyfile(h httpcaddyfile.Helper) ([]httpcaddyfile.ConfigValue, error) {\n\th.Next() // consume directive name\n\tmatcherSet, err := h.ExtractMatcherSet()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\th.Next() // consume the directive name again (matcher parsing resets)\n\n\tconfigValues := []httpcaddyfile.ConfigValue{}\n\n\tif !h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\tfield := h.Val()\n\n\thdr := Handler{\n\t\tRequest: &HeaderOps{},\n\t}\n\n\t// sometimes it is habitual for users to suffix a field name with a colon,\n\t// as if they were writing a curl command or something; see\n\t// https://caddy.community/t/v2-reverse-proxy-please-add-cors-example-to-the-docs/7349/19\n\tfield = strings.TrimSuffix(field, \":\")\n\n\tvar value string\n\tvar replacement *string\n\tif h.NextArg() {\n\t\tvalue = h.Val()\n\t}\n\tif h.NextArg() {\n\t\targ := h.Val()\n\t\treplacement = &arg\n\t\tif h.NextArg() {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\t}\n\n\tif hdr.Request == nil {\n\t\thdr.Request = new(HeaderOps)\n\t}\n\tif err := CaddyfileHeaderOp(hdr.Request, field, value, replacement); err != nil {\n\t\treturn nil, h.Err(err.Error())\n\t}\n\n\tconfigValues = append(configValues, h.NewRoute(matcherSet, hdr)...)\n\n\tif h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\treturn configValues, nil\n}\n\n// CaddyfileHeaderOp applies a new header operation according to\n// field, value, and replacement. The field can be prefixed with\n// \"+\" or \"-\" to specify adding or removing; otherwise, the value\n// will be set (overriding any previous value). If replacement is\n// non-nil, value will be treated as a regular expression which\n// will be used to search and then replacement will be used to\n// complete the substring replacement; in that case, any + or -\n// prefix to field will be ignored.\nfunc CaddyfileHeaderOp(ops *HeaderOps, field, value string, replacement *string) error {\n\treturn applyHeaderOp(ops, nil, field, value, replacement)\n}\n\nfunc applyHeaderOp(ops *HeaderOps, respHeaderOps *RespHeaderOps, field, value string, replacement *string) error {\n\tswitch {\n\tcase strings.HasPrefix(field, \"+\"): // append\n\t\tif ops.Add == nil {\n\t\t\tops.Add = make(http.Header)\n\t\t}\n\t\tops.Add.Add(field[1:], value)\n\n\tcase strings.HasPrefix(field, \"-\"): // delete\n\t\tops.Delete = append(ops.Delete, field[1:])\n\t\tif respHeaderOps != nil {\n\t\t\trespHeaderOps.Deferred = true\n\t\t}\n\n\tcase strings.HasPrefix(field, \"?\"): // default (conditional on not existing) - response headers only\n\t\tif respHeaderOps == nil {\n\t\t\treturn fmt.Errorf(\"%v: the default header modifier ('?') can only be used on response headers; for conditional manipulation of request headers, use matchers\", field)\n\t\t}\n\t\tif respHeaderOps.Require == nil {\n\t\t\trespHeaderOps.Require = &caddyhttp.ResponseMatcher{\n\t\t\t\tHeaders: make(http.Header),\n\t\t\t}\n\t\t}\n\t\tfield = strings.TrimPrefix(field, \"?\")\n\t\trespHeaderOps.Require.Headers[field] = nil\n\t\tif respHeaderOps.Set == nil {\n\t\t\trespHeaderOps.Set = make(http.Header)\n\t\t}\n\t\trespHeaderOps.Set.Set(field, value)\n\n\tcase replacement != nil: // replace\n\t\t// allow defer shortcut for replace syntax\n\t\tif strings.HasPrefix(field, \">\") && respHeaderOps != nil {\n\t\t\trespHeaderOps.Deferred = true\n\t\t}\n\t\tif ops.Replace == nil {\n\t\t\tops.Replace = make(map[string][]Replacement)\n\t\t}\n\t\tfield = strings.TrimLeft(field, \"+-?>\")\n\t\tops.Replace[field] = append(\n\t\t\tops.Replace[field],\n\t\t\tReplacement{\n\t\t\t\tSearchRegexp: value,\n\t\t\t\tReplace:      *replacement,\n\t\t\t},\n\t\t)\n\n\tcase strings.HasPrefix(field, \">\"): // set (overwrite) with defer\n\t\tif ops.Set == nil {\n\t\t\tops.Set = make(http.Header)\n\t\t}\n\t\tops.Set.Set(field[1:], value)\n\t\tif respHeaderOps != nil {\n\t\t\trespHeaderOps.Deferred = true\n\t\t}\n\n\tdefault: // set (overwrite)\n\t\tif ops.Set == nil {\n\t\t\tops.Set = make(http.Header)\n\t\t}\n\t\tops.Set.Set(field, value)\n\t}\n\n\treturn nil\n}\n",
    "source_file": "modules/caddyhttp/headers/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyauth\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"fmt\"\n\t\"os\"\n\t\"os/signal\"\n\n\t\"github.com/spf13/cobra\"\n\t\"golang.org/x/term\"\n\n\tcaddycmd \"github.com/caddyserver/caddy/v2/cmd\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddycmd.RegisterCommand(caddycmd.Command{\n\t\tName:  \"hash-password\",\n\t\tUsage: \"[--plaintext <password>] [--algorithm <name>]\",\n\t\tShort: \"Hashes a password and writes base64\",\n\t\tLong: `\nConvenient way to hash a plaintext password. The resulting\nhash is written to stdout as a base64 string.\n\n--plaintext, when omitted, will be read from stdin. If\nCaddy is attached to a controlling tty, the plaintext will\nnot be echoed.\n\n--algorithm currently only supports 'bcrypt', and is the default.\n`,\n\t\tCobraFunc: func(cmd *cobra.Command) {\n\t\t\tcmd.Flags().StringP(\"plaintext\", \"p\", \"\", \"The plaintext password\")\n\t\t\tcmd.Flags().StringP(\"algorithm\", \"a\", \"bcrypt\", \"Name of the hash algorithm\")\n\t\t\tcmd.RunE = caddycmd.WrapCommandFuncForCobra(cmdHashPassword)\n\t\t},\n\t})\n}\n\nfunc cmdHashPassword(fs caddycmd.Flags) (int, error) {\n\tvar err error\n\n\talgorithm := fs.String(\"algorithm\")\n\tplaintext := []byte(fs.String(\"plaintext\"))\n\n\tif len(plaintext) == 0 {\n\t\tfd := int(os.Stdin.Fd())\n\t\tif term.IsTerminal(fd) {\n\t\t\t// ensure the terminal state is restored on SIGINT\n\t\t\tstate, _ := term.GetState(fd)\n\t\t\tc := make(chan os.Signal, 1)\n\t\t\tsignal.Notify(c, os.Interrupt)\n\t\t\tgo func() {\n\t\t\t\t<-c\n\t\t\t\t_ = term.Restore(fd, state)\n\t\t\t\tos.Exit(caddy.ExitCodeFailedStartup)\n\t\t\t}()\n\t\t\tdefer signal.Stop(c)\n\n\t\t\tfmt.Fprint(os.Stderr, \"Enter password: \")\n\t\t\tplaintext, err = term.ReadPassword(fd)\n\t\t\tfmt.Fprintln(os.Stderr)\n\t\t\tif err != nil {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t\t}\n\n\t\t\tfmt.Fprint(os.Stderr, \"Confirm password: \")\n\t\t\tconfirmation, err := term.ReadPassword(fd)\n\t\t\tfmt.Fprintln(os.Stderr)\n\t\t\tif err != nil {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t\t}\n\n\t\t\tif !bytes.Equal(plaintext, confirmation) {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"password does not match\")\n\t\t\t}\n\t\t} else {\n\t\t\trd := bufio.NewReader(os.Stdin)\n\t\t\tplaintext, err = rd.ReadBytes('\\n')\n\t\t\tif err != nil {\n\t\t\t\treturn caddy.ExitCodeFailedStartup, err\n\t\t\t}\n\n\t\t\tplaintext = plaintext[:len(plaintext)-1] // Trailing newline\n\t\t}\n\n\t\tif len(plaintext) == 0 {\n\t\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"plaintext is required\")\n\t\t}\n\t}\n\n\tvar hash []byte\n\tvar hashString string\n\tswitch algorithm {\n\tcase \"bcrypt\":\n\t\thash, err = BcryptHash{}.Hash(plaintext)\n\t\thashString = string(hash)\n\tdefault:\n\t\treturn caddy.ExitCodeFailedStartup, fmt.Errorf(\"unrecognized hash algorithm: %s\", algorithm)\n\t}\n\tif err != nil {\n\t\treturn caddy.ExitCodeFailedStartup, err\n\t}\n\n\tfmt.Println(hashString)\n\n\treturn 0, nil\n}\n",
    "source_file": "modules/caddyhttp/caddyauth/command.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyauth\n\nimport (\n\t\"fmt\"\n\t\"net/http\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Authentication{})\n}\n\n// Authentication is a middleware which provides user authentication.\n// Rejects requests with HTTP 401 if the request is not authenticated.\n//\n// After a successful authentication, the placeholder\n// `{http.auth.user.id}` will be set to the username, and also\n// `{http.auth.user.*}` placeholders may be set for any authentication\n// modules that provide user metadata.\n//\n// In case of an error, the placeholder `{http.auth.<provider>.error}`\n// will be set to the error message returned by the authentication\n// provider.\n//\n// Its API is still experimental and may be subject to change.\ntype Authentication struct {\n\t// A set of authentication providers. If none are specified,\n\t// all requests will always be unauthenticated.\n\tProvidersRaw caddy.ModuleMap `json:\"providers,omitempty\" caddy:\"namespace=http.authentication.providers\"`\n\n\tProviders map[string]Authenticator `json:\"-\"`\n\n\tlogger *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Authentication) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.handlers.authentication\",\n\t\tNew: func() caddy.Module { return new(Authentication) },\n\t}\n}\n\n// Provision sets up a.\nfunc (a *Authentication) Provision(ctx caddy.Context) error {\n\ta.logger = ctx.Logger()\n\ta.Providers = make(map[string]Authenticator)\n\tmods, err := ctx.LoadModule(a, \"ProvidersRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading authentication providers: %v\", err)\n\t}\n\tfor modName, modIface := range mods.(map[string]any) {\n\t\ta.Providers[modName] = modIface.(Authenticator)\n\t}\n\treturn nil\n}\n\nfunc (a Authentication) ServeHTTP(w http.ResponseWriter, r *http.Request, next caddyhttp.Handler) error {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\tvar user User\n\tvar authed bool\n\tvar err error\n\tfor provName, prov := range a.Providers {\n\t\tuser, authed, err = prov.Authenticate(w, r)\n\t\tif err != nil {\n\t\t\tif c := a.logger.Check(zapcore.ErrorLevel, \"auth provider returned error\"); c != nil {\n\t\t\t\tc.Write(zap.String(\"provider\", provName), zap.Error(err))\n\t\t\t}\n\t\t\t// Set the error from the authentication provider in a placeholder,\n\t\t\t// so it can be used in the handle_errors directive.\n\t\t\trepl.Set(\"http.auth.\"+provName+\".error\", err.Error())\n\t\t\tcontinue\n\t\t}\n\t\tif authed {\n\t\t\tbreak\n\t\t}\n\t}\n\tif !authed {\n\t\treturn caddyhttp.Error(http.StatusUnauthorized, fmt.Errorf(\"not authenticated\"))\n\t}\n\n\trepl.Set(\"http.auth.user.id\", user.ID)\n\tfor k, v := range user.Metadata {\n\t\trepl.Set(\"http.auth.user.\"+k, v)\n\t}\n\n\treturn next.ServeHTTP(w, r)\n}\n\n// Authenticator is a type which can authenticate a request.\n// If a request was not authenticated, it returns false. An\n// error is only returned if authenticating the request fails\n// for a technical reason (not for bad/missing credentials).\ntype Authenticator interface {\n\tAuthenticate(http.ResponseWriter, *http.Request) (User, bool, error)\n}\n\n// User represents an authenticated user.\ntype User struct {\n\t// The ID of the authenticated user.\n\tID string\n\n\t// Any other relevant data about this\n\t// user. Keys should be adhere to Caddy\n\t// conventions (snake_casing), as all\n\t// keys will be made available as\n\t// placeholders.\n\tMetadata map[string]string\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner           = (*Authentication)(nil)\n\t_ caddyhttp.MiddlewareHandler = (*Authentication)(nil)\n)\n",
    "source_file": "modules/caddyhttp/caddyauth/caddyauth.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyauth\n\nimport (\n\t\"encoding/base64\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\tweakrand \"math/rand\"\n\t\"net/http\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"golang.org/x/sync/singleflight\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(HTTPBasicAuth{})\n}\n\n// HTTPBasicAuth facilitates HTTP basic authentication.\ntype HTTPBasicAuth struct {\n\t// The algorithm with which the passwords are hashed. Default: bcrypt\n\tHashRaw json.RawMessage `json:\"hash,omitempty\" caddy:\"namespace=http.authentication.hashes inline_key=algorithm\"`\n\n\t// The list of accounts to authenticate.\n\tAccountList []Account `json:\"accounts,omitempty\"`\n\n\t// The name of the realm. Default: restricted\n\tRealm string `json:\"realm,omitempty\"`\n\n\t// If non-nil, a mapping of plaintext passwords to their\n\t// hashes will be cached in memory (with random eviction).\n\t// This can greatly improve the performance of traffic-heavy\n\t// servers that use secure password hashing algorithms, with\n\t// the downside that plaintext passwords will be stored in\n\t// memory for a longer time (this should not be a problem\n\t// as long as your machine is not compromised, at which point\n\t// all bets are off, since basicauth necessitates plaintext\n\t// passwords being received over the wire anyway). Note that\n\t// a cache hit does not mean it is a valid password.\n\tHashCache *Cache `json:\"hash_cache,omitempty\"`\n\n\tAccounts map[string]Account `json:\"-\"`\n\tHash     Comparer           `json:\"-\"`\n\n\t// fakePassword is used when a given user is not found,\n\t// so that timing side-channels can be mitigated: it gives\n\t// us something to hash and compare even if the user does\n\t// not exist, which should have similar timing as a user\n\t// account that does exist.\n\tfakePassword []byte\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (HTTPBasicAuth) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.authentication.providers.http_basic\",\n\t\tNew: func() caddy.Module { return new(HTTPBasicAuth) },\n\t}\n}\n\n// Provision provisions the HTTP basic auth provider.\nfunc (hba *HTTPBasicAuth) Provision(ctx caddy.Context) error {\n\tif hba.HashRaw == nil {\n\t\thba.HashRaw = json.RawMessage(`{\"algorithm\": \"bcrypt\"}`)\n\t}\n\n\t// load password hasher\n\thasherIface, err := ctx.LoadModule(hba, \"HashRaw\")\n\tif err != nil {\n\t\treturn fmt.Errorf(\"loading password hasher module: %v\", err)\n\t}\n\thba.Hash = hasherIface.(Comparer)\n\n\tif hba.Hash == nil {\n\t\treturn fmt.Errorf(\"hash is required\")\n\t}\n\n\t// if supported, generate a fake password we can compare against if needed\n\tif hasher, ok := hba.Hash.(Hasher); ok {\n\t\thba.fakePassword = hasher.FakeHash()\n\t}\n\n\trepl := caddy.NewReplacer()\n\n\t// load account list\n\thba.Accounts = make(map[string]Account)\n\tfor i, acct := range hba.AccountList {\n\t\tif _, ok := hba.Accounts[acct.Username]; ok {\n\t\t\treturn fmt.Errorf(\"account %d: username is not unique: %s\", i, acct.Username)\n\t\t}\n\n\t\tacct.Username = repl.ReplaceAll(acct.Username, \"\")\n\t\tacct.Password = repl.ReplaceAll(acct.Password, \"\")\n\n\t\tif acct.Username == \"\" || acct.Password == \"\" {\n\t\t\treturn fmt.Errorf(\"account %d: username and password are required\", i)\n\t\t}\n\n\t\t// TODO: Remove support for redundantly-encoded b64-encoded hashes\n\t\t// Passwords starting with '$' are likely in Modular Crypt Format,\n\t\t// so we don't need to base64 decode them. But historically, we\n\t\t// required redundant base64, so we try to decode it otherwise.\n\t\tif strings.HasPrefix(acct.Password, \"$\") {\n\t\t\tacct.password = []byte(acct.Password)\n\t\t} else {\n\t\t\tacct.password, err = base64.StdEncoding.DecodeString(acct.Password)\n\t\t\tif err != nil {\n\t\t\t\treturn fmt.Errorf(\"base64-decoding password: %v\", err)\n\t\t\t}\n\t\t}\n\n\t\thba.Accounts[acct.Username] = acct\n\t}\n\thba.AccountList = nil // allow GC to deallocate\n\n\tif hba.HashCache != nil {\n\t\thba.HashCache.cache = make(map[string]bool)\n\t\thba.HashCache.mu = new(sync.RWMutex)\n\t\thba.HashCache.g = new(singleflight.Group)\n\t}\n\n\treturn nil\n}\n\n// Authenticate validates the user credentials in req and returns the user, if valid.\nfunc (hba HTTPBasicAuth) Authenticate(w http.ResponseWriter, req *http.Request) (User, bool, error) {\n\tusername, plaintextPasswordStr, ok := req.BasicAuth()\n\tif !ok {\n\t\treturn hba.promptForCredentials(w, nil)\n\t}\n\n\taccount, accountExists := hba.Accounts[username]\n\tif !accountExists {\n\t\t// don't return early if account does not exist; we want\n\t\t// to try to avoid side-channels that leak existence, so\n\t\t// we use a fake password to simulate realistic CPU cycles\n\t\taccount.password = hba.fakePassword\n\t}\n\n\tsame, err := hba.correctPassword(account, []byte(plaintextPasswordStr))\n\tif err != nil || !same || !accountExists {\n\t\treturn hba.promptForCredentials(w, err)\n\t}\n\n\treturn User{ID: username}, true, nil\n}\n\nfunc (hba HTTPBasicAuth) correctPassword(account Account, plaintextPassword []byte) (bool, error) {\n\tcompare := func() (bool, error) {\n\t\treturn hba.Hash.Compare(account.password, plaintextPassword)\n\t}\n\n\t// if no caching is enabled, simply return the result of hashing + comparing\n\tif hba.HashCache == nil {\n\t\treturn compare()\n\t}\n\n\t// compute a cache key that is unique for these input parameters\n\tcacheKey := hex.EncodeToString(append(account.password, plaintextPassword...))\n\n\t// fast track: if the result of the input is already cached, use it\n\thba.HashCache.mu.RLock()\n\tsame, ok := hba.HashCache.cache[cacheKey]\n\thba.HashCache.mu.RUnlock()\n\tif ok {\n\t\treturn same, nil\n\t}\n\t// slow track: do the expensive op, then add it to the cache\n\t// but perform it in a singleflight group so that multiple\n\t// parallel requests using the same password don't cause a\n\t// thundering herd problem by all performing the same hashing\n\t// operation before the first one finishes and caches it.\n\tv, err, _ := hba.HashCache.g.Do(cacheKey, func() (any, error) {\n\t\treturn compare()\n\t})\n\tif err != nil {\n\t\treturn false, err\n\t}\n\tsame = v.(bool)\n\thba.HashCache.mu.Lock()\n\tif len(hba.HashCache.cache) >= 1000 {\n\t\thba.HashCache.makeRoom() // keep cache size under control\n\t}\n\thba.HashCache.cache[cacheKey] = same\n\thba.HashCache.mu.Unlock()\n\n\treturn same, nil\n}\n\nfunc (hba HTTPBasicAuth) promptForCredentials(w http.ResponseWriter, err error) (User, bool, error) {\n\t// browsers show a message that says something like:\n\t// \"The website says: <realm>\"\n\t// which is kinda dumb, but whatever.\n\trealm := hba.Realm\n\tif realm == \"\" {\n\t\trealm = \"restricted\"\n\t}\n\tw.Header().Set(\"WWW-Authenticate\", fmt.Sprintf(`Basic realm=\"%s\"`, realm))\n\treturn User{}, false, err\n}\n\n// Cache enables caching of basic auth results. This is especially\n// helpful for secure password hashes which can be expensive to\n// compute on every HTTP request.\ntype Cache struct {\n\tmu *sync.RWMutex\n\tg  *singleflight.Group\n\n\t// map of concatenated hashed password + plaintext password, to result\n\tcache map[string]bool\n}\n\n// makeRoom deletes about 1/10 of the items in the cache\n// in order to keep its size under control. It must not be\n// called without a lock on c.mu.\nfunc (c *Cache) makeRoom() {\n\t// we delete more than just 1 entry so that we don't have\n\t// to do this on every request; assuming the capacity of\n\t// the cache is on a long tail, we can save a lot of CPU\n\t// time by doing a whole bunch of deletions now and then\n\t// we won't have to do them again for a while\n\tnumToDelete := max(len(c.cache)/10, 1)\n\tfor deleted := 0; deleted <= numToDelete; deleted++ {\n\t\t// Go maps are \"nondeterministic\" not actually random,\n\t\t// so although we could just chop off the \"front\" of the\n\t\t// map with less code, this is a heavily skewed eviction\n\t\t// strategy; generating random numbers is cheap and\n\t\t// ensures a much better distribution.\n\t\t//nolint:gosec\n\t\trnd := weakrand.Intn(len(c.cache))\n\t\ti := 0\n\t\tfor key := range c.cache {\n\t\t\tif i == rnd {\n\t\t\t\tdelete(c.cache, key)\n\t\t\t\tbreak\n\t\t\t}\n\t\t\ti++\n\t\t}\n\t}\n}\n\n// Comparer is a type that can securely compare\n// a plaintext password with a hashed password\n// in constant-time. Comparers should hash the\n// plaintext password and then use constant-time\n// comparison.\ntype Comparer interface {\n\t// Compare returns true if the result of hashing\n\t// plaintextPassword is hashedPassword, false\n\t// otherwise. An error is returned only if\n\t// there is a technical/configuration error.\n\tCompare(hashedPassword, plaintextPassword []byte) (bool, error)\n}\n\n// Hasher is a type that can generate a secure hash\n// given a plaintext. Hashing modules which implement\n// this interface can be used with the hash-password\n// subcommand as well as benefitting from anti-timing\n// features. A hasher also returns a fake hash which\n// can be used for timing side-channel mitigation.\ntype Hasher interface {\n\tHash(plaintext []byte) ([]byte, error)\n\tFakeHash() []byte\n}\n\n// Account contains a username and password.\ntype Account struct {\n\t// A user's username.\n\tUsername string `json:\"username\"`\n\n\t// The user's hashed password, in Modular Crypt Format (with `$` prefix)\n\t// or base64-encoded.\n\tPassword string `json:\"password\"`\n\n\tpassword []byte\n}\n\n// Interface guards\nvar (\n\t_ caddy.Provisioner = (*HTTPBasicAuth)(nil)\n\t_ Authenticator     = (*HTTPBasicAuth)(nil)\n)\n",
    "source_file": "modules/caddyhttp/caddyauth/basicauth.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyauth\n\nimport (\n\t\"golang.org/x/crypto/bcrypt\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(BcryptHash{})\n}\n\n// BcryptHash implements the bcrypt hash.\ntype BcryptHash struct{}\n\n// CaddyModule returns the Caddy module information.\nfunc (BcryptHash) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.authentication.hashes.bcrypt\",\n\t\tNew: func() caddy.Module { return new(BcryptHash) },\n\t}\n}\n\n// Compare compares passwords.\nfunc (BcryptHash) Compare(hashed, plaintext []byte) (bool, error) {\n\terr := bcrypt.CompareHashAndPassword(hashed, plaintext)\n\tif err == bcrypt.ErrMismatchedHashAndPassword {\n\t\treturn false, nil\n\t}\n\tif err != nil {\n\t\treturn false, err\n\t}\n\treturn true, nil\n}\n\n// Hash hashes plaintext using a random salt.\nfunc (BcryptHash) Hash(plaintext []byte) ([]byte, error) {\n\treturn bcrypt.GenerateFromPassword(plaintext, 14)\n}\n\n// FakeHash returns a fake hash.\nfunc (BcryptHash) FakeHash() []byte {\n\t// hashed with the following command:\n\t// caddy hash-password --plaintext \"antitiming\" --algorithm \"bcrypt\"\n\treturn []byte(\"$2a$14$X3ulqf/iGxnf1k6oMZ.RZeJUoqI9PX2PM4rS5lkIKJXduLGXGPrt6\")\n}\n\n// Interface guards\nvar (\n\t_ Comparer = (*BcryptHash)(nil)\n\t_ Hasher   = (*BcryptHash)(nil)\n)\n",
    "source_file": "modules/caddyhttp/caddyauth/hashes.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyauth\n\nimport (\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterHandlerDirective(\"basicauth\", parseCaddyfile) // deprecated\n\thttpcaddyfile.RegisterHandlerDirective(\"basic_auth\", parseCaddyfile)\n}\n\n// parseCaddyfile sets up the handler from Caddyfile tokens. Syntax:\n//\n//\tbasic_auth [<matcher>] [<hash_algorithm> [<realm>]] {\n//\t    <username> <hashed_password>\n//\t    ...\n//\t}\n//\n// If no hash algorithm is supplied, bcrypt will be assumed.\nfunc parseCaddyfile(h httpcaddyfile.Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\n\t// \"basicauth\" is deprecated, replaced by \"basic_auth\"\n\tif h.Val() == \"basicauth\" {\n\t\tcaddy.Log().Named(\"config.adapter.caddyfile\").Warn(\"the 'basicauth' directive is deprecated, please use 'basic_auth' instead!\")\n\t}\n\n\tvar ba HTTPBasicAuth\n\tba.HashCache = new(Cache)\n\n\tvar cmp Comparer\n\targs := h.RemainingArgs()\n\n\tvar hashName string\n\tswitch len(args) {\n\tcase 0:\n\t\thashName = \"bcrypt\"\n\tcase 1:\n\t\thashName = args[0]\n\tcase 2:\n\t\thashName = args[0]\n\t\tba.Realm = args[1]\n\tdefault:\n\t\treturn nil, h.ArgErr()\n\t}\n\n\tswitch hashName {\n\tcase \"bcrypt\":\n\t\tcmp = BcryptHash{}\n\tdefault:\n\t\treturn nil, h.Errf(\"unrecognized hash algorithm: %s\", hashName)\n\t}\n\n\tba.HashRaw = caddyconfig.JSONModuleObject(cmp, \"algorithm\", hashName, nil)\n\n\tfor h.NextBlock(0) {\n\t\tusername := h.Val()\n\n\t\tvar b64Pwd string\n\t\th.Args(&b64Pwd)\n\t\tif h.NextArg() {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\n\t\tif username == \"\" || b64Pwd == \"\" {\n\t\t\treturn nil, h.Err(\"username and password cannot be empty or missing\")\n\t\t}\n\n\t\tba.AccountList = append(ba.AccountList, Account{\n\t\t\tUsername: username,\n\t\t\tPassword: b64Pwd,\n\t\t})\n\t}\n\n\treturn Authentication{\n\t\tProvidersRaw: caddy.ModuleMap{\n\t\t\t\"http_basic\": caddyconfig.JSON(ba, nil),\n\t\t},\n\t}, nil\n}\n",
    "source_file": "modules/caddyhttp/caddyauth/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage forwardauth\n\nimport (\n\t\"encoding/json\"\n\t\"net/http\"\n\t\"sort\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/headers\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/reverseproxy\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/rewrite\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterDirective(\"forward_auth\", parseCaddyfile)\n}\n\n// parseCaddyfile parses the forward_auth directive, which has the same syntax\n// as the reverse_proxy directive (in fact, the reverse_proxy's directive\n// Unmarshaler is invoked by this function) but the resulting proxy is specially\n// configured for most\u2122\ufe0f auth gateways that support forward auth. The typical\n// config which looks something like this:\n//\n//\tforward_auth auth-gateway:9091 {\n//\t    uri /authenticate?redirect=https://auth.example.com\n//\t    copy_headers Remote-User Remote-Email\n//\t}\n//\n// is equivalent to a reverse_proxy directive like this:\n//\n//\treverse_proxy auth-gateway:9091 {\n//\t    method GET\n//\t    rewrite /authenticate?redirect=https://auth.example.com\n//\n//\t    header_up X-Forwarded-Method {method}\n//\t    header_up X-Forwarded-Uri {uri}\n//\n//\t    @good status 2xx\n//\t    handle_response @good {\n//\t        request_header {\n//\t            Remote-User {http.reverse_proxy.header.Remote-User}\n//\t            Remote-Email {http.reverse_proxy.header.Remote-Email}\n//\t        }\n//\t    }\n//\t}\nfunc parseCaddyfile(h httpcaddyfile.Helper) ([]httpcaddyfile.ConfigValue, error) {\n\tif !h.Next() {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\t// if the user specified a matcher token, use that\n\t// matcher in a route that wraps both of our routes;\n\t// either way, strip the matcher token and pass\n\t// the remaining tokens to the unmarshaler so that\n\t// we can gain the rest of the reverse_proxy syntax\n\tuserMatcherSet, err := h.ExtractMatcherSet()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// make a new dispenser from the remaining tokens so that we\n\t// can reset the dispenser back to this point for the\n\t// reverse_proxy unmarshaler to read from it as well\n\tdispenser := h.NewFromNextSegment()\n\n\t// create the reverse proxy handler\n\trpHandler := &reverseproxy.Handler{\n\t\t// set up defaults for header_up; reverse_proxy already deals with\n\t\t// adding  the other three X-Forwarded-* headers, but for this flow,\n\t\t// we want to also send along the incoming method and URI since this\n\t\t// request will have a rewritten URI and method.\n\t\tHeaders: &headers.Handler{\n\t\t\tRequest: &headers.HeaderOps{\n\t\t\t\tSet: http.Header{\n\t\t\t\t\t\"X-Forwarded-Method\": []string{\"{http.request.method}\"},\n\t\t\t\t\t\"X-Forwarded-Uri\":    []string{\"{http.request.uri}\"},\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\n\t\t// we always rewrite the method to GET, which implicitly\n\t\t// turns off sending the incoming request's body, which\n\t\t// allows later middleware handlers to consume it\n\t\tRewrite: &rewrite.Rewrite{\n\t\t\tMethod: \"GET\",\n\t\t},\n\n\t\tHandleResponse: []caddyhttp.ResponseHandler{},\n\t}\n\n\t// collect the headers to copy from the auth response\n\t// onto the original request, so they can get passed\n\t// through to a backend app\n\theadersToCopy := make(map[string]string)\n\n\t// read the subdirectives for configuring the forward_auth shortcut\n\t// NOTE: we delete the tokens as we go so that the reverse_proxy\n\t// unmarshal doesn't see these subdirectives which it cannot handle\n\tfor dispenser.Next() {\n\t\tfor dispenser.NextBlock(0) {\n\t\t\t// ignore any sub-subdirectives that might\n\t\t\t// have the same name somewhere within\n\t\t\t// the reverse_proxy passthrough tokens\n\t\t\tif dispenser.Nesting() != 1 {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// parse the forward_auth subdirectives\n\t\t\tswitch dispenser.Val() {\n\t\t\tcase \"uri\":\n\t\t\t\tif !dispenser.NextArg() {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\t\t\t\trpHandler.Rewrite.URI = dispenser.Val()\n\t\t\t\tdispenser.DeleteN(2)\n\n\t\t\tcase \"copy_headers\":\n\t\t\t\targs := dispenser.RemainingArgs()\n\t\t\t\thadBlock := false\n\t\t\t\tfor nesting := dispenser.Nesting(); dispenser.NextBlock(nesting); {\n\t\t\t\t\thadBlock = true\n\t\t\t\t\targs = append(args, dispenser.Val())\n\t\t\t\t}\n\n\t\t\t\t// directive name + args\n\t\t\t\tdispenser.DeleteN(len(args) + 1)\n\t\t\t\tif hadBlock {\n\t\t\t\t\t// opening & closing brace\n\t\t\t\t\tdispenser.DeleteN(2)\n\t\t\t\t}\n\n\t\t\t\tfor _, headerField := range args {\n\t\t\t\t\tif strings.Contains(headerField, \">\") {\n\t\t\t\t\t\tparts := strings.Split(headerField, \">\")\n\t\t\t\t\t\theadersToCopy[parts[0]] = parts[1]\n\t\t\t\t\t} else {\n\t\t\t\t\t\theadersToCopy[headerField] = headerField\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif len(headersToCopy) == 0 {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// reset the dispenser after we're done so that the reverse_proxy\n\t// unmarshaler can read it from the start\n\tdispenser.Reset()\n\n\t// the auth target URI must not be empty\n\tif rpHandler.Rewrite.URI == \"\" {\n\t\treturn nil, dispenser.Errf(\"the 'uri' subdirective is required\")\n\t}\n\n\t// Set up handler for good responses; when a response has 2xx status,\n\t// then we will copy some headers from the response onto the original\n\t// request, and allow handling to continue down the middleware chain,\n\t// by _not_ executing a terminal handler. We must have at least one\n\t// route in the response handler, even if it's no-op, so that the\n\t// response handling logic in reverse_proxy doesn't skip this entry.\n\tgoodResponseHandler := caddyhttp.ResponseHandler{\n\t\tMatch: &caddyhttp.ResponseMatcher{\n\t\t\tStatusCode: []int{2},\n\t\t},\n\t\tRoutes: []caddyhttp.Route{\n\t\t\t{\n\t\t\t\tHandlersRaw: []json.RawMessage{caddyconfig.JSONModuleObject(\n\t\t\t\t\t&caddyhttp.VarsMiddleware{},\n\t\t\t\t\t\"handler\",\n\t\t\t\t\t\"vars\",\n\t\t\t\t\tnil,\n\t\t\t\t)},\n\t\t\t},\n\t\t},\n\t}\n\n\t// Sort the headers so that the order in the JSON output is deterministic.\n\tsortedHeadersToCopy := make([]string, 0, len(headersToCopy))\n\tfor k := range headersToCopy {\n\t\tsortedHeadersToCopy = append(sortedHeadersToCopy, k)\n\t}\n\tsort.Strings(sortedHeadersToCopy)\n\n\t// Set up handlers to copy headers from the auth response onto the\n\t// original request. We use vars matchers to test that the placeholder\n\t// values aren't empty, because the header handler would not replace\n\t// placeholders which have no value.\n\tcopyHeaderRoutes := []caddyhttp.Route{}\n\tfor _, from := range sortedHeadersToCopy {\n\t\tto := http.CanonicalHeaderKey(headersToCopy[from])\n\t\tplaceholderName := \"http.reverse_proxy.header.\" + http.CanonicalHeaderKey(from)\n\t\thandler := &headers.Handler{\n\t\t\tRequest: &headers.HeaderOps{\n\t\t\t\tSet: http.Header{\n\t\t\t\t\tto: []string{\"{\" + placeholderName + \"}\"},\n\t\t\t\t},\n\t\t\t},\n\t\t}\n\t\tcopyHeaderRoutes = append(copyHeaderRoutes, caddyhttp.Route{\n\t\t\tMatcherSetsRaw: []caddy.ModuleMap{{\n\t\t\t\t\"not\": h.JSON(caddyhttp.MatchNot{MatcherSetsRaw: []caddy.ModuleMap{{\n\t\t\t\t\t\"vars\": h.JSON(caddyhttp.VarsMatcher{\"{\" + placeholderName + \"}\": []string{\"\"}}),\n\t\t\t\t}}}),\n\t\t\t}},\n\t\t\tHandlersRaw: []json.RawMessage{caddyconfig.JSONModuleObject(\n\t\t\t\thandler,\n\t\t\t\t\"handler\",\n\t\t\t\t\"headers\",\n\t\t\t\tnil,\n\t\t\t)},\n\t\t})\n\t}\n\n\tgoodResponseHandler.Routes = append(goodResponseHandler.Routes, copyHeaderRoutes...)\n\n\t// note that when a response has any other status than 2xx, then we\n\t// use the reverse proxy's default behaviour of copying the response\n\t// back to the client, so we don't need to explicitly add a response\n\t// handler specifically for that behaviour; we do need the 2xx handler\n\t// though, to make handling fall through to handlers deeper in the chain.\n\trpHandler.HandleResponse = append(rpHandler.HandleResponse, goodResponseHandler)\n\n\t// the rest of the config is specified by the user\n\t// using the reverse_proxy directive syntax\n\tdispenser.Next() // consume the directive name\n\terr = rpHandler.UnmarshalCaddyfile(dispenser)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = rpHandler.FinalizeUnmarshalCaddyfile(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// create the final reverse proxy route\n\trpRoute := caddyhttp.Route{\n\t\tHandlersRaw: []json.RawMessage{caddyconfig.JSONModuleObject(\n\t\t\trpHandler,\n\t\t\t\"handler\",\n\t\t\t\"reverse_proxy\",\n\t\t\tnil,\n\t\t)},\n\t}\n\n\t// apply the user's matcher if any\n\tif userMatcherSet != nil {\n\t\trpRoute.MatcherSetsRaw = []caddy.ModuleMap{userMatcherSet}\n\t}\n\n\treturn []httpcaddyfile.ConfigValue{\n\t\t{\n\t\t\tClass: \"route\",\n\t\t\tValue: rpRoute,\n\t\t},\n\t}, nil\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/forwardauth/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fastcgi\n\ntype header struct {\n\tVersion       uint8\n\tType          uint8\n\tID            uint16\n\tContentLength uint16\n\tPaddingLength uint8\n\tReserved      uint8\n}\n\nfunc (h *header) init(recType uint8, reqID uint16, contentLength int) {\n\th.Version = 1\n\th.Type = recType\n\th.ID = reqID\n\th.ContentLength = uint16(contentLength)\n\th.PaddingLength = uint8(-contentLength & 7)\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/fastcgi/header.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Forked Jan. 2015 from http://bitbucket.org/PinIdea/fcgi_client\n// (which is forked from https://code.google.com/p/go-fastcgi-client/).\n// This fork contains several fixes and improvements by Matt Holt and\n// other contributors to the Caddy project.\n\n// Copyright 2012 Junqing Tan <ivan@mysqlab.net> and The Go Authors\n// Use of this source code is governed by a BSD-style\n// Part of source code is from Go fcgi package\n\npackage fastcgi\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"io\"\n\t\"mime/multipart\"\n\t\"net\"\n\t\"net/http\"\n\t\"net/http/httputil\"\n\t\"net/textproto\"\n\t\"net/url\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\n// FCGIListenSockFileno describes listen socket file number.\nconst FCGIListenSockFileno uint8 = 0\n\n// FCGIHeaderLen describes header length.\nconst FCGIHeaderLen uint8 = 8\n\n// Version1 describes the version.\nconst Version1 uint8 = 1\n\n// FCGINullRequestID describes the null request ID.\nconst FCGINullRequestID uint8 = 0\n\n// FCGIKeepConn describes keep connection mode.\nconst FCGIKeepConn uint8 = 1\n\nconst (\n\t// BeginRequest is the begin request flag.\n\tBeginRequest uint8 = iota + 1\n\t// AbortRequest is the abort request flag.\n\tAbortRequest\n\t// EndRequest is the end request flag.\n\tEndRequest\n\t// Params is the parameters flag.\n\tParams\n\t// Stdin is the standard input flag.\n\tStdin\n\t// Stdout is the standard output flag.\n\tStdout\n\t// Stderr is the standard error flag.\n\tStderr\n\t// Data is the data flag.\n\tData\n\t// GetValues is the get values flag.\n\tGetValues\n\t// GetValuesResult is the get values result flag.\n\tGetValuesResult\n\t// UnknownType is the unknown type flag.\n\tUnknownType\n\t// MaxType is the maximum type flag.\n\tMaxType = UnknownType\n)\n\nconst (\n\t// Responder is the responder flag.\n\tResponder uint8 = iota + 1\n\t// Authorizer is the authorizer flag.\n\tAuthorizer\n\t// Filter is the filter flag.\n\tFilter\n)\n\nconst (\n\t// RequestComplete is the completed request flag.\n\tRequestComplete uint8 = iota\n\t// CantMultiplexConns is the multiplexed connections flag.\n\tCantMultiplexConns\n\t// Overloaded is the overloaded flag.\n\tOverloaded\n\t// UnknownRole is the unknown role flag.\n\tUnknownRole\n)\n\nconst (\n\t// MaxConns is the maximum connections flag.\n\tMaxConns string = \"MAX_CONNS\"\n\t// MaxRequests is the maximum requests flag.\n\tMaxRequests string = \"MAX_REQS\"\n\t// MultiplexConns is the multiplex connections flag.\n\tMultiplexConns string = \"MPXS_CONNS\"\n)\n\nconst (\n\tmaxWrite = 65500 // 65530 may work, but for compatibility\n\tmaxPad   = 255\n)\n\n// for padding so we don't have to allocate all the time\n// not synchronized because we don't care what the contents are\nvar pad [maxPad]byte\n\n// client implements a FastCGI client, which is a standard for\n// interfacing external applications with Web servers.\ntype client struct {\n\trwc net.Conn\n\t// keepAlive bool // TODO: implement\n\treqID  uint16\n\tstderr bool\n\tlogger *zap.Logger\n}\n\n// Do made the request and returns a io.Reader that translates the data read\n// from fcgi responder out of fcgi packet before returning it.\nfunc (c *client) Do(p map[string]string, req io.Reader) (r io.Reader, err error) {\n\t// check for CONTENT_LENGTH, since the lack of it or wrong value will cause the backend to hang\n\tif clStr, ok := p[\"CONTENT_LENGTH\"]; !ok {\n\t\treturn nil, caddyhttp.Error(http.StatusLengthRequired, nil)\n\t} else if _, err := strconv.ParseUint(clStr, 10, 64); err != nil {\n\t\t// stdlib won't return a negative Content-Length, but we check just in case,\n\t\t// the most likely cause is from a missing content length, which is -1\n\t\treturn nil, caddyhttp.Error(http.StatusLengthRequired, err)\n\t}\n\n\twriter := &streamWriter{c: c}\n\twriter.buf = bufPool.Get().(*bytes.Buffer)\n\twriter.buf.Reset()\n\tdefer bufPool.Put(writer.buf)\n\n\terr = writer.writeBeginRequest(uint16(Responder), 0)\n\tif err != nil {\n\t\treturn\n\t}\n\n\twriter.recType = Params\n\terr = writer.writePairs(p)\n\tif err != nil {\n\t\treturn\n\t}\n\n\twriter.recType = Stdin\n\tif req != nil {\n\t\t_, err = io.Copy(writer, req)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\terr = writer.FlushStream()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tr = &streamReader{c: c}\n\treturn\n}\n\n// clientCloser is a io.ReadCloser. It wraps a io.Reader with a Closer\n// that closes the client connection.\ntype clientCloser struct {\n\trwc net.Conn\n\tr   *streamReader\n\tio.Reader\n\n\tstatus int\n\tlogger *zap.Logger\n}\n\nfunc (f clientCloser) Close() error {\n\tstderr := f.r.stderr.Bytes()\n\tif len(stderr) == 0 {\n\t\treturn f.rwc.Close()\n\t}\n\n\tlogLevel := zapcore.WarnLevel\n\tif f.status >= 400 {\n\t\tlogLevel = zapcore.ErrorLevel\n\t}\n\n\tif c := f.logger.Check(logLevel, \"stderr\"); c != nil {\n\t\tc.Write(zap.ByteString(\"body\", stderr))\n\t}\n\n\treturn f.rwc.Close()\n}\n\n// Request returns a HTTP Response with Header and Body\n// from fcgi responder\nfunc (c *client) Request(p map[string]string, req io.Reader) (resp *http.Response, err error) {\n\tr, err := c.Do(p, req)\n\tif err != nil {\n\t\treturn\n\t}\n\n\trb := bufio.NewReader(r)\n\ttp := textproto.NewReader(rb)\n\tresp = new(http.Response)\n\n\t// Parse the response headers.\n\tmimeHeader, err := tp.ReadMIMEHeader()\n\tif err != nil && err != io.EOF {\n\t\treturn\n\t}\n\tresp.Header = http.Header(mimeHeader)\n\n\tif resp.Header.Get(\"Status\") != \"\" {\n\t\tstatusNumber, statusInfo, statusIsCut := strings.Cut(resp.Header.Get(\"Status\"), \" \")\n\t\tresp.StatusCode, err = strconv.Atoi(statusNumber)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t\tif statusIsCut {\n\t\t\tresp.Status = statusInfo\n\t\t}\n\t} else {\n\t\tresp.StatusCode = http.StatusOK\n\t}\n\n\t// TODO: fixTransferEncoding ?\n\tresp.TransferEncoding = resp.Header[\"Transfer-Encoding\"]\n\tresp.ContentLength, _ = strconv.ParseInt(resp.Header.Get(\"Content-Length\"), 10, 64)\n\n\t// wrap the response body in our closer\n\tcloser := clientCloser{\n\t\trwc:    c.rwc,\n\t\tr:      r.(*streamReader),\n\t\tReader: rb,\n\t\tstatus: resp.StatusCode,\n\t\tlogger: noopLogger,\n\t}\n\tif chunked(resp.TransferEncoding) {\n\t\tcloser.Reader = httputil.NewChunkedReader(rb)\n\t}\n\tif c.stderr {\n\t\tcloser.logger = c.logger\n\t}\n\tresp.Body = closer\n\n\treturn\n}\n\n// Get issues a GET request to the fcgi responder.\nfunc (c *client) Get(p map[string]string, body io.Reader, l int64) (resp *http.Response, err error) {\n\tp[\"REQUEST_METHOD\"] = \"GET\"\n\tp[\"CONTENT_LENGTH\"] = strconv.FormatInt(l, 10)\n\n\treturn c.Request(p, body)\n}\n\n// Head issues a HEAD request to the fcgi responder.\nfunc (c *client) Head(p map[string]string) (resp *http.Response, err error) {\n\tp[\"REQUEST_METHOD\"] = \"HEAD\"\n\tp[\"CONTENT_LENGTH\"] = \"0\"\n\n\treturn c.Request(p, nil)\n}\n\n// Options issues an OPTIONS request to the fcgi responder.\nfunc (c *client) Options(p map[string]string) (resp *http.Response, err error) {\n\tp[\"REQUEST_METHOD\"] = \"OPTIONS\"\n\tp[\"CONTENT_LENGTH\"] = \"0\"\n\n\treturn c.Request(p, nil)\n}\n\n// Post issues a POST request to the fcgi responder. with request body\n// in the format that bodyType specified\nfunc (c *client) Post(p map[string]string, method string, bodyType string, body io.Reader, l int64) (resp *http.Response, err error) {\n\tif p == nil {\n\t\tp = make(map[string]string)\n\t}\n\n\tp[\"REQUEST_METHOD\"] = strings.ToUpper(method)\n\n\tif len(p[\"REQUEST_METHOD\"]) == 0 || p[\"REQUEST_METHOD\"] == \"GET\" {\n\t\tp[\"REQUEST_METHOD\"] = \"POST\"\n\t}\n\n\tp[\"CONTENT_LENGTH\"] = strconv.FormatInt(l, 10)\n\tif len(bodyType) > 0 {\n\t\tp[\"CONTENT_TYPE\"] = bodyType\n\t} else {\n\t\tp[\"CONTENT_TYPE\"] = \"application/x-www-form-urlencoded\"\n\t}\n\n\treturn c.Request(p, body)\n}\n\n// PostForm issues a POST to the fcgi responder, with form\n// as a string key to a list values (url.Values)\nfunc (c *client) PostForm(p map[string]string, data url.Values) (resp *http.Response, err error) {\n\tbody := bytes.NewReader([]byte(data.Encode()))\n\treturn c.Post(p, \"POST\", \"application/x-www-form-urlencoded\", body, int64(body.Len()))\n}\n\n// PostFile issues a POST to the fcgi responder in multipart(RFC 2046) standard,\n// with form as a string key to a list values (url.Values),\n// and/or with file as a string key to a list file path.\nfunc (c *client) PostFile(p map[string]string, data url.Values, file map[string]string) (resp *http.Response, err error) {\n\tbuf := &bytes.Buffer{}\n\twriter := multipart.NewWriter(buf)\n\tbodyType := writer.FormDataContentType()\n\n\tfor key, val := range data {\n\t\tfor _, v0 := range val {\n\t\t\terr = writer.WriteField(key, v0)\n\t\t\tif err != nil {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\tfor key, val := range file {\n\t\tfd, e := os.Open(val)\n\t\tif e != nil {\n\t\t\treturn nil, e\n\t\t}\n\t\tdefer fd.Close()\n\n\t\tpart, e := writer.CreateFormFile(key, filepath.Base(val))\n\t\tif e != nil {\n\t\t\treturn nil, e\n\t\t}\n\t\t_, err = io.Copy(part, fd)\n\t\tif err != nil {\n\t\t\treturn\n\t\t}\n\t}\n\n\terr = writer.Close()\n\tif err != nil {\n\t\treturn\n\t}\n\n\treturn c.Post(p, \"POST\", bodyType, buf, int64(buf.Len()))\n}\n\n// SetReadTimeout sets the read timeout for future calls that read from the\n// fcgi responder. A zero value for t means no timeout will be set.\nfunc (c *client) SetReadTimeout(t time.Duration) error {\n\tif t != 0 {\n\t\treturn c.rwc.SetReadDeadline(time.Now().Add(t))\n\t}\n\treturn nil\n}\n\n// SetWriteTimeout sets the write timeout for future calls that send data to\n// the fcgi responder. A zero value for t means no timeout will be set.\nfunc (c *client) SetWriteTimeout(t time.Duration) error {\n\tif t != 0 {\n\t\treturn c.rwc.SetWriteDeadline(time.Now().Add(t))\n\t}\n\treturn nil\n}\n\n// Checks whether chunked is part of the encodings stack\nfunc chunked(te []string) bool { return len(te) > 0 && te[0] == \"chunked\" }\n",
    "source_file": "modules/caddyhttp/reverseproxy/fastcgi/client.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fastcgi\n\nimport (\n\t\"bytes\"\n\t\"encoding/binary\"\n)\n\n// streamWriter abstracts out the separation of a stream into discrete records.\n// It only writes maxWrite bytes at a time.\ntype streamWriter struct {\n\tc       *client\n\th       header\n\tbuf     *bytes.Buffer\n\trecType uint8\n}\n\nfunc (w *streamWriter) writeRecord(recType uint8, content []byte) (err error) {\n\tw.h.init(recType, w.c.reqID, len(content))\n\tw.buf.Write(pad[:8])\n\tw.writeHeader()\n\tw.buf.Write(content)\n\tw.buf.Write(pad[:w.h.PaddingLength])\n\t_, err = w.buf.WriteTo(w.c.rwc)\n\treturn err\n}\n\nfunc (w *streamWriter) writeBeginRequest(role uint16, flags uint8) error {\n\tb := [8]byte{byte(role >> 8), byte(role), flags}\n\treturn w.writeRecord(BeginRequest, b[:])\n}\n\nfunc (w *streamWriter) Write(p []byte) (int, error) {\n\t// init header\n\tif w.buf.Len() < 8 {\n\t\tw.buf.Write(pad[:8])\n\t}\n\n\tnn := 0\n\tfor len(p) > 0 {\n\t\tn := len(p)\n\t\tnl := maxWrite + 8 - w.buf.Len()\n\t\tif n > nl {\n\t\t\tn = nl\n\t\t\tw.buf.Write(p[:n])\n\t\t\tif err := w.Flush(); err != nil {\n\t\t\t\treturn nn, err\n\t\t\t}\n\t\t\t// reset headers\n\t\t\tw.buf.Write(pad[:8])\n\t\t} else {\n\t\t\tw.buf.Write(p[:n])\n\t\t}\n\t\tnn += n\n\t\tp = p[n:]\n\t}\n\treturn nn, nil\n}\n\nfunc (w *streamWriter) endStream() error {\n\t// send empty record to close the stream\n\treturn w.writeRecord(w.recType, nil)\n}\n\nfunc (w *streamWriter) writePairs(pairs map[string]string) error {\n\tb := make([]byte, 8)\n\tnn := 0\n\t// init headers\n\tw.buf.Write(b)\n\tfor k, v := range pairs {\n\t\tm := 8 + len(k) + len(v)\n\t\tif m > maxWrite {\n\t\t\t// param data size exceed 65535 bytes\"\n\t\t\tvl := maxWrite - 8 - len(k)\n\t\t\tv = v[:vl]\n\t\t}\n\t\tn := encodeSize(b, uint32(len(k)))\n\t\tn += encodeSize(b[n:], uint32(len(v)))\n\t\tm = n + len(k) + len(v)\n\t\tif (nn + m) > maxWrite {\n\t\t\tif err := w.Flush(); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\t// reset headers\n\t\t\tw.buf.Write(b)\n\t\t\tnn = 0\n\t\t}\n\t\tnn += m\n\t\tw.buf.Write(b[:n])\n\t\tw.buf.WriteString(k)\n\t\tw.buf.WriteString(v)\n\t}\n\treturn w.FlushStream()\n}\n\nfunc encodeSize(b []byte, size uint32) int {\n\tif size > 127 {\n\t\tsize |= 1 << 31\n\t\tbinary.BigEndian.PutUint32(b, size)\n\t\treturn 4\n\t}\n\tb[0] = byte(size)\n\treturn 1\n}\n\n// writeHeader populate header wire data in buf, it abuses buffer.Bytes() modification\nfunc (w *streamWriter) writeHeader() {\n\th := w.buf.Bytes()[:8]\n\th[0] = w.h.Version\n\th[1] = w.h.Type\n\tbinary.BigEndian.PutUint16(h[2:4], w.h.ID)\n\tbinary.BigEndian.PutUint16(h[4:6], w.h.ContentLength)\n\th[6] = w.h.PaddingLength\n\th[7] = w.h.Reserved\n}\n\n// Flush write buffer data to the underlying connection, it assumes header data is the first 8 bytes of buf\nfunc (w *streamWriter) Flush() error {\n\tw.h.init(w.recType, w.c.reqID, w.buf.Len()-8)\n\tw.writeHeader()\n\tw.buf.Write(pad[:w.h.PaddingLength])\n\t_, err := w.buf.WriteTo(w.c.rwc)\n\treturn err\n}\n\n// FlushStream flush data then end current stream\nfunc (w *streamWriter) FlushStream() error {\n\tif err := w.Flush(); err != nil {\n\t\treturn err\n\t}\n\treturn w.endStream()\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/fastcgi/writer.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fastcgi\n\nimport (\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"io\"\n)\n\ntype record struct {\n\th       header\n\tlr      io.LimitedReader\n\tpadding int64\n}\n\nfunc (rec *record) fill(r io.Reader) (err error) {\n\trec.lr.N = rec.padding\n\trec.lr.R = r\n\tif _, err = io.Copy(io.Discard, rec); err != nil {\n\t\treturn\n\t}\n\n\tif err = binary.Read(r, binary.BigEndian, &rec.h); err != nil {\n\t\treturn\n\t}\n\tif rec.h.Version != 1 {\n\t\terr = errors.New(\"fcgi: invalid header version\")\n\t\treturn\n\t}\n\tif rec.h.Type == EndRequest {\n\t\terr = io.EOF\n\t\treturn\n\t}\n\trec.lr.N = int64(rec.h.ContentLength)\n\trec.padding = int64(rec.h.PaddingLength)\n\treturn\n}\n\nfunc (rec *record) Read(p []byte) (n int, err error) {\n\treturn rec.lr.Read(p)\n}\n\nfunc (rec *record) hasMore() bool {\n\treturn rec.lr.N > 0\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/fastcgi/record.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fastcgi\n\nimport (\n\t\"bytes\"\n\t\"io\"\n)\n\ntype streamReader struct {\n\tc      *client\n\trec    record\n\tstderr bytes.Buffer\n}\n\nfunc (w *streamReader) Read(p []byte) (n int, err error) {\n\tfor !w.rec.hasMore() {\n\t\terr = w.rec.fill(w.c.rwc)\n\t\tif err != nil {\n\t\t\treturn 0, err\n\t\t}\n\n\t\t// standard error output\n\t\tif w.rec.h.Type == Stderr {\n\t\t\tif _, err = io.Copy(&w.stderr, &w.rec); err != nil {\n\t\t\t\treturn 0, err\n\t\t\t}\n\t\t}\n\t}\n\n\treturn w.rec.Read(p)\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/fastcgi/reader.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fastcgi\n\nimport (\n\t\"crypto/tls\"\n\t\"fmt\"\n\t\"net\"\n\t\"net/http\"\n\t\"path/filepath\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"go.uber.org/zap\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/reverseproxy\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\nvar noopLogger = zap.NewNop()\n\nfunc init() {\n\tcaddy.RegisterModule(Transport{})\n}\n\n// Transport facilitates FastCGI communication.\ntype Transport struct {\n\t// Use this directory as the fastcgi root directory. Defaults to the root\n\t// directory of the parent virtual host.\n\tRoot string `json:\"root,omitempty\"`\n\n\t// The path in the URL will be split into two, with the first piece ending\n\t// with the value of SplitPath. The first piece will be assumed as the\n\t// actual resource (CGI script) name, and the second piece will be set to\n\t// PATH_INFO for the CGI script to use.\n\t//\n\t// Future enhancements should be careful to avoid CVE-2019-11043,\n\t// which can be mitigated with use of a try_files-like behavior\n\t// that 404s if the fastcgi path info is not found.\n\tSplitPath []string `json:\"split_path,omitempty\"`\n\n\t// Path declared as root directory will be resolved to its absolute value\n\t// after the evaluation of any symbolic links.\n\t// Due to the nature of PHP opcache, root directory path is cached: when\n\t// using a symlinked directory as root this could generate errors when\n\t// symlink is changed without php-fpm being restarted; enabling this\n\t// directive will set $_SERVER['DOCUMENT_ROOT'] to the real directory path.\n\tResolveRootSymlink bool `json:\"resolve_root_symlink,omitempty\"`\n\n\t// Extra environment variables.\n\tEnvVars map[string]string `json:\"env,omitempty\"`\n\n\t// The duration used to set a deadline when connecting to an upstream. Default: `3s`.\n\tDialTimeout caddy.Duration `json:\"dial_timeout,omitempty\"`\n\n\t// The duration used to set a deadline when reading from the FastCGI server.\n\tReadTimeout caddy.Duration `json:\"read_timeout,omitempty\"`\n\n\t// The duration used to set a deadline when sending to the FastCGI server.\n\tWriteTimeout caddy.Duration `json:\"write_timeout,omitempty\"`\n\n\t// Capture and log any messages sent by the upstream on stderr. Logs at WARN\n\t// level by default. If the response has a 4xx or 5xx status ERROR level will\n\t// be used instead.\n\tCaptureStderr bool `json:\"capture_stderr,omitempty\"`\n\n\tserverSoftware string\n\tlogger         *zap.Logger\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Transport) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.reverse_proxy.transport.fastcgi\",\n\t\tNew: func() caddy.Module { return new(Transport) },\n\t}\n}\n\n// Provision sets up t.\nfunc (t *Transport) Provision(ctx caddy.Context) error {\n\tt.logger = ctx.Logger()\n\n\tif t.Root == \"\" {\n\t\tt.Root = \"{http.vars.root}\"\n\t}\n\n\tversion, _ := caddy.Version()\n\tt.serverSoftware = \"Caddy/\" + version\n\n\t// Set a relatively short default dial timeout.\n\t// This is helpful to make load-balancer retries more speedy.\n\tif t.DialTimeout == 0 {\n\t\tt.DialTimeout = caddy.Duration(3 * time.Second)\n\t}\n\n\treturn nil\n}\n\n// RoundTrip implements http.RoundTripper.\nfunc (t Transport) RoundTrip(r *http.Request) (*http.Response, error) {\n\tserver := r.Context().Value(caddyhttp.ServerCtxKey).(*caddyhttp.Server)\n\n\t// Disallow null bytes in the request path, because\n\t// PHP upstreams may do bad things, like execute a\n\t// non-PHP file as PHP code. See #4574\n\tif strings.Contains(r.URL.Path, \"\\x00\") {\n\t\treturn nil, caddyhttp.Error(http.StatusBadRequest, fmt.Errorf(\"invalid request path\"))\n\t}\n\n\tenv, err := t.buildEnv(r)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"building environment: %v\", err)\n\t}\n\n\tctx := r.Context()\n\n\t// extract dial information from request (should have been embedded by the reverse proxy)\n\tnetwork, address := \"tcp\", r.URL.Host\n\tif dialInfo, ok := reverseproxy.GetDialInfo(ctx); ok {\n\t\tnetwork = dialInfo.Network\n\t\taddress = dialInfo.Address\n\t}\n\n\tlogCreds := server.Logs != nil && server.Logs.ShouldLogCredentials\n\tloggableReq := caddyhttp.LoggableHTTPRequest{\n\t\tRequest:              r,\n\t\tShouldLogCredentials: logCreds,\n\t}\n\tloggableEnv := loggableEnv{vars: env, logCredentials: logCreds}\n\n\tlogger := t.logger.With(\n\t\tzap.Object(\"request\", loggableReq),\n\t\tzap.Object(\"env\", loggableEnv),\n\t)\n\tif c := t.logger.Check(zapcore.DebugLevel, \"roundtrip\"); c != nil {\n\t\tc.Write(\n\t\t\tzap.String(\"dial\", address),\n\t\t\tzap.Object(\"env\", loggableEnv),\n\t\t\tzap.Object(\"request\", loggableReq),\n\t\t)\n\t}\n\n\t// connect to the backend\n\tdialer := net.Dialer{Timeout: time.Duration(t.DialTimeout)}\n\tconn, err := dialer.DialContext(ctx, network, address)\n\tif err != nil {\n\t\treturn nil, fmt.Errorf(\"dialing backend: %v\", err)\n\t}\n\tdefer func() {\n\t\t// conn will be closed with the response body unless there's an error\n\t\tif err != nil {\n\t\t\tconn.Close()\n\t\t}\n\t}()\n\n\t// create the client that will facilitate the protocol\n\tclient := client{\n\t\trwc:    conn,\n\t\treqID:  1,\n\t\tlogger: logger,\n\t\tstderr: t.CaptureStderr,\n\t}\n\n\t// read/write timeouts\n\tif err = client.SetReadTimeout(time.Duration(t.ReadTimeout)); err != nil {\n\t\treturn nil, fmt.Errorf(\"setting read timeout: %v\", err)\n\t}\n\tif err = client.SetWriteTimeout(time.Duration(t.WriteTimeout)); err != nil {\n\t\treturn nil, fmt.Errorf(\"setting write timeout: %v\", err)\n\t}\n\n\tcontentLength := r.ContentLength\n\tif contentLength == 0 {\n\t\tcontentLength, _ = strconv.ParseInt(r.Header.Get(\"Content-Length\"), 10, 64)\n\t}\n\n\tvar resp *http.Response\n\tswitch r.Method {\n\tcase http.MethodHead:\n\t\tresp, err = client.Head(env)\n\tcase http.MethodGet:\n\t\tresp, err = client.Get(env, r.Body, contentLength)\n\tcase http.MethodOptions:\n\t\tresp, err = client.Options(env)\n\tdefault:\n\t\tresp, err = client.Post(env, r.Method, r.Header.Get(\"Content-Type\"), r.Body, contentLength)\n\t}\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn resp, nil\n}\n\n// buildEnv returns a set of CGI environment variables for the request.\nfunc (t Transport) buildEnv(r *http.Request) (envVars, error) {\n\trepl := r.Context().Value(caddy.ReplacerCtxKey).(*caddy.Replacer)\n\n\tvar env envVars\n\n\t// Separate remote IP and port; more lenient than net.SplitHostPort\n\tvar ip, port string\n\tif idx := strings.LastIndex(r.RemoteAddr, \":\"); idx > -1 {\n\t\tip = r.RemoteAddr[:idx]\n\t\tport = r.RemoteAddr[idx+1:]\n\t} else {\n\t\tip = r.RemoteAddr\n\t}\n\n\t// Remove [] from IPv6 addresses\n\tip = strings.Replace(ip, \"[\", \"\", 1)\n\tip = strings.Replace(ip, \"]\", \"\", 1)\n\n\t// make sure file root is absolute\n\troot, err := caddy.FastAbs(repl.ReplaceAll(t.Root, \".\"))\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif t.ResolveRootSymlink {\n\t\troot, err = filepath.EvalSymlinks(root)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t}\n\n\tfpath := r.URL.Path\n\tscriptName := fpath\n\n\tdocURI := fpath\n\t// split \"actual path\" from \"path info\" if configured\n\tvar pathInfo string\n\tif splitPos := t.splitPos(fpath); splitPos > -1 {\n\t\tdocURI = fpath[:splitPos]\n\t\tpathInfo = fpath[splitPos:]\n\n\t\t// Strip PATH_INFO from SCRIPT_NAME\n\t\tscriptName = strings.TrimSuffix(scriptName, pathInfo)\n\t}\n\n\t// Try to grab the path remainder from a file matcher\n\t// if we didn't get a split result here.\n\t// See https://github.com/caddyserver/caddy/issues/3718\n\tif pathInfo == \"\" {\n\t\tpathInfo, _ = repl.GetString(\"http.matchers.file.remainder\")\n\t}\n\n\t// SCRIPT_FILENAME is the absolute path of SCRIPT_NAME\n\tscriptFilename := caddyhttp.SanitizedPathJoin(root, scriptName)\n\n\t// Ensure the SCRIPT_NAME has a leading slash for compliance with RFC3875\n\t// Info: https://tools.ietf.org/html/rfc3875#section-4.1.13\n\tif scriptName != \"\" && !strings.HasPrefix(scriptName, \"/\") {\n\t\tscriptName = \"/\" + scriptName\n\t}\n\n\t// Get the request URL from context. The context stores the original URL in case\n\t// it was changed by a middleware such as rewrite. By default, we pass the\n\t// original URI in as the value of REQUEST_URI (the user can overwrite this\n\t// if desired). Most PHP apps seem to want the original URI. Besides, this is\n\t// how nginx defaults: http://stackoverflow.com/a/12485156/1048862\n\torigReq := r.Context().Value(caddyhttp.OriginalRequestCtxKey).(http.Request)\n\n\trequestScheme := \"http\"\n\tif r.TLS != nil {\n\t\trequestScheme = \"https\"\n\t}\n\n\treqHost, reqPort, err := net.SplitHostPort(r.Host)\n\tif err != nil {\n\t\t// whatever, just assume there was no port\n\t\treqHost = r.Host\n\t}\n\n\tauthUser, _ := repl.GetString(\"http.auth.user.id\")\n\n\t// Some variables are unused but cleared explicitly to prevent\n\t// the parent environment from interfering.\n\tenv = envVars{\n\t\t// Variables defined in CGI 1.1 spec\n\t\t\"AUTH_TYPE\":         \"\", // Not used\n\t\t\"CONTENT_LENGTH\":    r.Header.Get(\"Content-Length\"),\n\t\t\"CONTENT_TYPE\":      r.Header.Get(\"Content-Type\"),\n\t\t\"GATEWAY_INTERFACE\": \"CGI/1.1\",\n\t\t\"PATH_INFO\":         pathInfo,\n\t\t\"QUERY_STRING\":      r.URL.RawQuery,\n\t\t\"REMOTE_ADDR\":       ip,\n\t\t\"REMOTE_HOST\":       ip, // For speed, remote host lookups disabled\n\t\t\"REMOTE_PORT\":       port,\n\t\t\"REMOTE_IDENT\":      \"\", // Not used\n\t\t\"REMOTE_USER\":       authUser,\n\t\t\"REQUEST_METHOD\":    r.Method,\n\t\t\"REQUEST_SCHEME\":    requestScheme,\n\t\t\"SERVER_NAME\":       reqHost,\n\t\t\"SERVER_PROTOCOL\":   r.Proto,\n\t\t\"SERVER_SOFTWARE\":   t.serverSoftware,\n\n\t\t// Other variables\n\t\t\"DOCUMENT_ROOT\":   root,\n\t\t\"DOCUMENT_URI\":    docURI,\n\t\t\"HTTP_HOST\":       r.Host, // added here, since not always part of headers\n\t\t\"REQUEST_URI\":     origReq.URL.RequestURI(),\n\t\t\"SCRIPT_FILENAME\": scriptFilename,\n\t\t\"SCRIPT_NAME\":     scriptName,\n\t}\n\n\t// compliance with the CGI specification requires that\n\t// PATH_TRANSLATED should only exist if PATH_INFO is defined.\n\t// Info: https://www.ietf.org/rfc/rfc3875 Page 14\n\tif env[\"PATH_INFO\"] != \"\" {\n\t\tenv[\"PATH_TRANSLATED\"] = caddyhttp.SanitizedPathJoin(root, pathInfo) // Info: http://www.oreilly.com/openbook/cgi/ch02_04.html\n\t}\n\n\t// compliance with the CGI specification requires that\n\t// the SERVER_PORT variable MUST be set to the TCP/IP port number on which this request is received from the client\n\t// even if the port is the default port for the scheme and could otherwise be omitted from a URI.\n\t// https://tools.ietf.org/html/rfc3875#section-4.1.15\n\tif reqPort != \"\" {\n\t\tenv[\"SERVER_PORT\"] = reqPort\n\t} else if requestScheme == \"http\" {\n\t\tenv[\"SERVER_PORT\"] = \"80\"\n\t} else if requestScheme == \"https\" {\n\t\tenv[\"SERVER_PORT\"] = \"443\"\n\t}\n\n\t// Some web apps rely on knowing HTTPS or not\n\tif r.TLS != nil {\n\t\tenv[\"HTTPS\"] = \"on\"\n\t\t// and pass the protocol details in a manner compatible with apache's mod_ssl\n\t\t// (which is why these have a SSL_ prefix and not TLS_).\n\t\tv, ok := tlsProtocolStrings[r.TLS.Version]\n\t\tif ok {\n\t\t\tenv[\"SSL_PROTOCOL\"] = v\n\t\t}\n\t\t// and pass the cipher suite in a manner compatible with apache's mod_ssl\n\t\tfor _, cs := range caddytls.SupportedCipherSuites() {\n\t\t\tif cs.ID == r.TLS.CipherSuite {\n\t\t\t\tenv[\"SSL_CIPHER\"] = cs.Name\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\t// Add env variables from config (with support for placeholders in values)\n\tfor key, value := range t.EnvVars {\n\t\tenv[key] = repl.ReplaceAll(value, \"\")\n\t}\n\n\t// Add all HTTP headers to env variables\n\tfor field, val := range r.Header {\n\t\theader := strings.ToUpper(field)\n\t\theader = headerNameReplacer.Replace(header)\n\t\tenv[\"HTTP_\"+header] = strings.Join(val, \", \")\n\t}\n\treturn env, nil\n}\n\n// splitPos returns the index where path should\n// be split based on t.SplitPath.\nfunc (t Transport) splitPos(path string) int {\n\t// TODO: from v1...\n\t// if httpserver.CaseSensitivePath {\n\t// \treturn strings.Index(path, r.SplitPath)\n\t// }\n\tif len(t.SplitPath) == 0 {\n\t\treturn 0\n\t}\n\n\tlowerPath := strings.ToLower(path)\n\tfor _, split := range t.SplitPath {\n\t\tif idx := strings.Index(lowerPath, strings.ToLower(split)); idx > -1 {\n\t\t\treturn idx + len(split)\n\t\t}\n\t}\n\treturn -1\n}\n\ntype envVars map[string]string\n\n// loggableEnv is a simple type to allow for speeding up zap log encoding.\ntype loggableEnv struct {\n\tvars           envVars\n\tlogCredentials bool\n}\n\nfunc (env loggableEnv) MarshalLogObject(enc zapcore.ObjectEncoder) error {\n\tfor k, v := range env.vars {\n\t\tif !env.logCredentials {\n\t\t\tswitch strings.ToLower(k) {\n\t\t\tcase \"http_cookie\", \"http_set_cookie\", \"http_authorization\", \"http_proxy_authorization\":\n\t\t\t\tv = \"\"\n\t\t\t}\n\t\t}\n\t\tenc.AddString(k, v)\n\t}\n\treturn nil\n}\n\n// Map of supported protocols to Apache ssl_mod format\n// Note that these are slightly different from SupportedProtocols in caddytls/config.go\nvar tlsProtocolStrings = map[uint16]string{\n\ttls.VersionTLS10: \"TLSv1\",\n\ttls.VersionTLS11: \"TLSv1.1\",\n\ttls.VersionTLS12: \"TLSv1.2\",\n\ttls.VersionTLS13: \"TLSv1.3\",\n}\n\nvar headerNameReplacer = strings.NewReplacer(\" \", \"_\", \"-\", \"_\")\n\n// Interface guards\nvar (\n\t_ zapcore.ObjectMarshaler = (*loggableEnv)(nil)\n\n\t_ caddy.Provisioner = (*Transport)(nil)\n\t_ http.RoundTripper = (*Transport)(nil)\n)\n",
    "source_file": "modules/caddyhttp/reverseproxy/fastcgi/fastcgi.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fastcgi\n\nimport (\n\t\"bytes\"\n\t\"sync\"\n)\n\nvar bufPool = sync.Pool{\n\tNew: func() any {\n\t\treturn new(bytes.Buffer)\n\t},\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/fastcgi/pool.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage fastcgi\n\nimport (\n\t\"encoding/json\"\n\t\"net/http\"\n\t\"slices\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/httpcaddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/fileserver\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/reverseproxy\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/rewrite\"\n)\n\nfunc init() {\n\thttpcaddyfile.RegisterDirective(\"php_fastcgi\", parsePHPFastCGI)\n}\n\n// UnmarshalCaddyfile deserializes Caddyfile tokens into h.\n//\n//\ttransport fastcgi {\n//\t    root <path>\n//\t    split <at>\n//\t    env <key> <value>\n//\t    resolve_root_symlink\n//\t    dial_timeout <duration>\n//\t    read_timeout <duration>\n//\t    write_timeout <duration>\n//\t    capture_stderr\n//\t}\nfunc (t *Transport) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume transport name\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"root\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tt.Root = d.Val()\n\n\t\tcase \"split\":\n\t\t\tt.SplitPath = d.RemainingArgs()\n\t\t\tif len(t.SplitPath) == 0 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\n\t\tcase \"env\":\n\t\t\targs := d.RemainingArgs()\n\t\t\tif len(args) != 2 {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tif t.EnvVars == nil {\n\t\t\t\tt.EnvVars = make(map[string]string)\n\t\t\t}\n\t\t\tt.EnvVars[args[0]] = args[1]\n\n\t\tcase \"resolve_root_symlink\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tt.ResolveRootSymlink = true\n\n\t\tcase \"dial_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\tt.DialTimeout = caddy.Duration(dur)\n\n\t\tcase \"read_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\tt.ReadTimeout = caddy.Duration(dur)\n\n\t\tcase \"write_timeout\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn d.Errf(\"bad timeout value %s: %v\", d.Val(), err)\n\t\t\t}\n\t\t\tt.WriteTimeout = caddy.Duration(dur)\n\n\t\tcase \"capture_stderr\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn d.ArgErr()\n\t\t\t}\n\t\t\tt.CaptureStderr = true\n\n\t\tdefault:\n\t\t\treturn d.Errf(\"unrecognized subdirective %s\", d.Val())\n\t\t}\n\t}\n\treturn nil\n}\n\n// parsePHPFastCGI parses the php_fastcgi directive, which has the same syntax\n// as the reverse_proxy directive (in fact, the reverse_proxy's directive\n// Unmarshaler is invoked by this function) but the resulting proxy is specially\n// configured for most\u2122\ufe0f PHP apps over FastCGI. A line such as this:\n//\n//\tphp_fastcgi localhost:7777\n//\n// is equivalent to a route consisting of:\n//\n//\t# Add trailing slash for directory requests\n//\t# This redirection is automatically disabled if \"{http.request.uri.path}/index.php\"\n//\t# doesn't appear in the try_files list\n//\t@canonicalPath {\n//\t    file {path}/index.php\n//\t    not path */\n//\t}\n//\tredir @canonicalPath {path}/ 308\n//\n//\t# If the requested file does not exist, try index files and assume index.php always exists\n//\t@indexFiles file {\n//\t    try_files {path} {path}/index.php index.php\n//\t    try_policy first_exist_fallback\n//\t    split_path .php\n//\t}\n//\trewrite @indexFiles {http.matchers.file.relative}\n//\n//\t# Proxy PHP files to the FastCGI responder\n//\t@phpFiles path *.php\n//\treverse_proxy @phpFiles localhost:7777 {\n//\t    transport fastcgi {\n//\t        split .php\n//\t    }\n//\t}\n//\n// Thus, this directive produces multiple handlers, each with a different\n// matcher because multiple consecutive handlers are necessary to support\n// the common PHP use case. If this \"common\" config is not compatible\n// with a user's PHP requirements, they can use a manual approach based\n// on the example above to configure it precisely as they need.\n//\n// If a matcher is specified by the user, for example:\n//\n//\tphp_fastcgi /subpath localhost:7777\n//\n// then the resulting handlers are wrapped in a subroute that uses the\n// user's matcher as a prerequisite to enter the subroute. In other\n// words, the directive's matcher is necessary, but not sufficient.\nfunc parsePHPFastCGI(h httpcaddyfile.Helper) ([]httpcaddyfile.ConfigValue, error) {\n\tif !h.Next() {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\t// set up the transport for FastCGI, and specifically PHP\n\tfcgiTransport := Transport{}\n\n\t// set up the set of file extensions allowed to execute PHP code\n\textensions := []string{\".php\"}\n\n\t// set the default index file for the try_files rewrites\n\tindexFile := \"index.php\"\n\n\t// set up for explicitly overriding try_files\n\tvar tryFiles []string\n\n\t// if the user specified a matcher token, use that\n\t// matcher in a route that wraps both of our routes;\n\t// either way, strip the matcher token and pass\n\t// the remaining tokens to the unmarshaler so that\n\t// we can gain the rest of the reverse_proxy syntax\n\tuserMatcherSet, err := h.ExtractMatcherSet()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// make a new dispenser from the remaining tokens so that we\n\t// can reset the dispenser back to this point for the\n\t// reverse_proxy unmarshaler to read from it as well\n\tdispenser := h.NewFromNextSegment()\n\n\t// read the subdirectives that we allow as overrides to\n\t// the php_fastcgi shortcut\n\t// NOTE: we delete the tokens as we go so that the reverse_proxy\n\t// unmarshal doesn't see these subdirectives which it cannot handle\n\tfor dispenser.Next() {\n\t\tfor dispenser.NextBlock(0) {\n\t\t\t// ignore any sub-subdirectives that might\n\t\t\t// have the same name somewhere within\n\t\t\t// the reverse_proxy passthrough tokens\n\t\t\tif dispenser.Nesting() != 1 {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// parse the php_fastcgi subdirectives\n\t\t\tswitch dispenser.Val() {\n\t\t\tcase \"root\":\n\t\t\t\tif !dispenser.NextArg() {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\t\t\t\tfcgiTransport.Root = dispenser.Val()\n\t\t\t\tdispenser.DeleteN(2)\n\n\t\t\tcase \"split\":\n\t\t\t\textensions = dispenser.RemainingArgs()\n\t\t\t\tdispenser.DeleteN(len(extensions) + 1)\n\t\t\t\tif len(extensions) == 0 {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\n\t\t\tcase \"env\":\n\t\t\t\targs := dispenser.RemainingArgs()\n\t\t\t\tdispenser.DeleteN(len(args) + 1)\n\t\t\t\tif len(args) != 2 {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\t\t\t\tif fcgiTransport.EnvVars == nil {\n\t\t\t\t\tfcgiTransport.EnvVars = make(map[string]string)\n\t\t\t\t}\n\t\t\t\tfcgiTransport.EnvVars[args[0]] = args[1]\n\n\t\t\tcase \"index\":\n\t\t\t\targs := dispenser.RemainingArgs()\n\t\t\t\tdispenser.DeleteN(len(args) + 1)\n\t\t\t\tif len(args) != 1 {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\t\t\t\tindexFile = args[0]\n\n\t\t\tcase \"try_files\":\n\t\t\t\targs := dispenser.RemainingArgs()\n\t\t\t\tdispenser.DeleteN(len(args) + 1)\n\t\t\t\tif len(args) < 1 {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\t\t\t\ttryFiles = args\n\n\t\t\tcase \"resolve_root_symlink\":\n\t\t\t\targs := dispenser.RemainingArgs()\n\t\t\t\tdispenser.DeleteN(len(args) + 1)\n\t\t\t\tfcgiTransport.ResolveRootSymlink = true\n\n\t\t\tcase \"dial_timeout\":\n\t\t\t\tif !dispenser.NextArg() {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\t\t\t\tdur, err := caddy.ParseDuration(dispenser.Val())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, dispenser.Errf(\"bad timeout value %s: %v\", dispenser.Val(), err)\n\t\t\t\t}\n\t\t\t\tfcgiTransport.DialTimeout = caddy.Duration(dur)\n\t\t\t\tdispenser.DeleteN(2)\n\n\t\t\tcase \"read_timeout\":\n\t\t\t\tif !dispenser.NextArg() {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\t\t\t\tdur, err := caddy.ParseDuration(dispenser.Val())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, dispenser.Errf(\"bad timeout value %s: %v\", dispenser.Val(), err)\n\t\t\t\t}\n\t\t\t\tfcgiTransport.ReadTimeout = caddy.Duration(dur)\n\t\t\t\tdispenser.DeleteN(2)\n\n\t\t\tcase \"write_timeout\":\n\t\t\t\tif !dispenser.NextArg() {\n\t\t\t\t\treturn nil, dispenser.ArgErr()\n\t\t\t\t}\n\t\t\t\tdur, err := caddy.ParseDuration(dispenser.Val())\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, dispenser.Errf(\"bad timeout value %s: %v\", dispenser.Val(), err)\n\t\t\t\t}\n\t\t\t\tfcgiTransport.WriteTimeout = caddy.Duration(dur)\n\t\t\t\tdispenser.DeleteN(2)\n\n\t\t\tcase \"capture_stderr\":\n\t\t\t\targs := dispenser.RemainingArgs()\n\t\t\t\tdispenser.DeleteN(len(args) + 1)\n\t\t\t\tfcgiTransport.CaptureStderr = true\n\t\t\t}\n\t\t}\n\t}\n\n\t// reset the dispenser after we're done so that the reverse_proxy\n\t// unmarshaler can read it from the start\n\tdispenser.Reset()\n\n\t// set up a route list that we'll append to\n\troutes := caddyhttp.RouteList{}\n\n\t// set the list of allowed path segments on which to split\n\tfcgiTransport.SplitPath = extensions\n\n\t// if the index is turned off, we skip the redirect and try_files\n\tif indexFile != \"off\" {\n\t\tvar dirRedir bool\n\t\tdirIndex := \"{http.request.uri.path}/\" + indexFile\n\t\ttryPolicy := \"first_exist_fallback\"\n\n\t\t// if tryFiles wasn't overridden, use a reasonable default\n\t\tif len(tryFiles) == 0 {\n\t\t\ttryFiles = []string{\"{http.request.uri.path}\", dirIndex, indexFile}\n\t\t\tdirRedir = true\n\t\t} else {\n\t\t\tif !strings.HasSuffix(tryFiles[len(tryFiles)-1], \".php\") {\n\t\t\t\t// use first_exist strategy if the last file is not a PHP file\n\t\t\t\ttryPolicy = \"\"\n\t\t\t}\n\n\t\t\tdirRedir = slices.Contains(tryFiles, dirIndex)\n\t\t}\n\n\t\tif dirRedir {\n\t\t\t// route to redirect to canonical path if index PHP file\n\t\t\tredirMatcherSet := caddy.ModuleMap{\n\t\t\t\t\"file\": h.JSON(fileserver.MatchFile{\n\t\t\t\t\tTryFiles: []string{dirIndex},\n\t\t\t\t}),\n\t\t\t\t\"not\": h.JSON(caddyhttp.MatchNot{\n\t\t\t\t\tMatcherSetsRaw: []caddy.ModuleMap{\n\t\t\t\t\t\t{\n\t\t\t\t\t\t\t\"path\": h.JSON(caddyhttp.MatchPath{\"*/\"}),\n\t\t\t\t\t\t},\n\t\t\t\t\t},\n\t\t\t\t}),\n\t\t\t}\n\t\t\tredirHandler := caddyhttp.StaticResponse{\n\t\t\t\tStatusCode: caddyhttp.WeakString(strconv.Itoa(http.StatusPermanentRedirect)),\n\t\t\t\tHeaders:    http.Header{\"Location\": []string{\"{http.request.orig_uri.path}/{http.request.orig_uri.prefixed_query}\"}},\n\t\t\t}\n\t\t\tredirRoute := caddyhttp.Route{\n\t\t\t\tMatcherSetsRaw: []caddy.ModuleMap{redirMatcherSet},\n\t\t\t\tHandlersRaw:    []json.RawMessage{caddyconfig.JSONModuleObject(redirHandler, \"handler\", \"static_response\", nil)},\n\t\t\t}\n\n\t\t\troutes = append(routes, redirRoute)\n\t\t}\n\n\t\t// route to rewrite to PHP index file\n\t\trewriteMatcherSet := caddy.ModuleMap{\n\t\t\t\"file\": h.JSON(fileserver.MatchFile{\n\t\t\t\tTryFiles:  tryFiles,\n\t\t\t\tTryPolicy: tryPolicy,\n\t\t\t\tSplitPath: extensions,\n\t\t\t}),\n\t\t}\n\t\trewriteHandler := rewrite.Rewrite{\n\t\t\tURI: \"{http.matchers.file.relative}\",\n\t\t}\n\t\trewriteRoute := caddyhttp.Route{\n\t\t\tMatcherSetsRaw: []caddy.ModuleMap{rewriteMatcherSet},\n\t\t\tHandlersRaw:    []json.RawMessage{caddyconfig.JSONModuleObject(rewriteHandler, \"handler\", \"rewrite\", nil)},\n\t\t}\n\n\t\troutes = append(routes, rewriteRoute)\n\t}\n\n\t// route to actually reverse proxy requests to PHP files;\n\t// match only requests that are for PHP files\n\tpathList := []string{}\n\tfor _, ext := range extensions {\n\t\tpathList = append(pathList, \"*\"+ext)\n\t}\n\trpMatcherSet := caddy.ModuleMap{\n\t\t\"path\": h.JSON(pathList),\n\t}\n\n\t// create the reverse proxy handler which uses our FastCGI transport\n\trpHandler := &reverseproxy.Handler{\n\t\tTransportRaw: caddyconfig.JSONModuleObject(fcgiTransport, \"protocol\", \"fastcgi\", nil),\n\t}\n\n\t// the rest of the config is specified by the user\n\t// using the reverse_proxy directive syntax\n\tdispenser.Next() // consume the directive name\n\terr = rpHandler.UnmarshalCaddyfile(dispenser)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\terr = rpHandler.FinalizeUnmarshalCaddyfile(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\t// create the final reverse proxy route which is\n\t// conditional on matching PHP files\n\trpRoute := caddyhttp.Route{\n\t\tMatcherSetsRaw: []caddy.ModuleMap{rpMatcherSet},\n\t\tHandlersRaw:    []json.RawMessage{caddyconfig.JSONModuleObject(rpHandler, \"handler\", \"reverse_proxy\", nil)},\n\t}\n\n\tsubroute := caddyhttp.Subroute{\n\t\tRoutes: append(routes, rpRoute),\n\t}\n\n\t// the user's matcher is a prerequisite for ours, so\n\t// wrap ours in a subroute and return that\n\tif userMatcherSet != nil {\n\t\treturn []httpcaddyfile.ConfigValue{\n\t\t\t{\n\t\t\t\tClass: \"route\",\n\t\t\t\tValue: caddyhttp.Route{\n\t\t\t\t\tMatcherSetsRaw: []caddy.ModuleMap{userMatcherSet},\n\t\t\t\t\tHandlersRaw:    []json.RawMessage{caddyconfig.JSONModuleObject(subroute, \"handler\", \"subroute\", nil)},\n\t\t\t\t},\n\t\t\t},\n\t\t}, nil\n\t}\n\n\t// otherwise, return the literal subroute instead of\n\t// individual routes, to ensure they stay together and\n\t// are treated as a single unit, without necessarily\n\t// creating an actual subroute in the output\n\treturn []httpcaddyfile.ConfigValue{\n\t\t{\n\t\t\tClass: \"route\",\n\t\t\tValue: subroute,\n\t\t},\n\t}, nil\n}\n",
    "source_file": "modules/caddyhttp/reverseproxy/fastcgi/caddyfile.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddybrotli\n\nimport (\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(BrotliPrecompressed{})\n}\n\n// BrotliPrecompressed provides the file extension for files precompressed with brotli encoding.\ntype BrotliPrecompressed struct{}\n\n// CaddyModule returns the Caddy module information.\nfunc (BrotliPrecompressed) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.precompressed.br\",\n\t\tNew: func() caddy.Module { return new(BrotliPrecompressed) },\n\t}\n}\n\n// AcceptEncoding returns the name of the encoding as\n// used in the Accept-Encoding request headers.\nfunc (BrotliPrecompressed) AcceptEncoding() string { return \"br\" }\n\n// Suffix returns the filename suffix of precompressed files.\nfunc (BrotliPrecompressed) Suffix() string { return \".br\" }\n\n// Interface guards\nvar _ encode.Precompressed = (*BrotliPrecompressed)(nil)\n",
    "source_file": "modules/caddyhttp/encode/brotli/brotli_precompressed.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddygzip\n\nimport (\n\t\"fmt\"\n\t\"strconv\"\n\n\t\"github.com/klauspost/compress/gzip\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Gzip{})\n}\n\n// Gzip can create gzip encoders.\ntype Gzip struct {\n\tLevel int `json:\"level,omitempty\"`\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Gzip) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.encoders.gzip\",\n\t\tNew: func() caddy.Module { return new(Gzip) },\n\t}\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens.\nfunc (g *Gzip) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume option name\n\tif !d.NextArg() {\n\t\treturn nil\n\t}\n\tlevelStr := d.Val()\n\tlevel, err := strconv.Atoi(levelStr)\n\tif err != nil {\n\t\treturn err\n\t}\n\tg.Level = level\n\treturn nil\n}\n\n// Provision provisions g's configuration.\nfunc (g *Gzip) Provision(ctx caddy.Context) error {\n\tif g.Level == 0 {\n\t\tg.Level = defaultGzipLevel\n\t}\n\treturn nil\n}\n\n// Validate validates g's configuration.\nfunc (g Gzip) Validate() error {\n\tif g.Level < gzip.StatelessCompression {\n\t\treturn fmt.Errorf(\"quality too low; must be >= %d\", gzip.StatelessCompression)\n\t}\n\tif g.Level > gzip.BestCompression {\n\t\treturn fmt.Errorf(\"quality too high; must be <= %d\", gzip.BestCompression)\n\t}\n\treturn nil\n}\n\n// AcceptEncoding returns the name of the encoding as\n// used in the Accept-Encoding request headers.\nfunc (Gzip) AcceptEncoding() string { return \"gzip\" }\n\n// NewEncoder returns a new gzip writer.\nfunc (g Gzip) NewEncoder() encode.Encoder {\n\twriter, _ := gzip.NewWriterLevel(nil, g.Level)\n\treturn writer\n}\n\n// Informed from http://blog.klauspost.com/gzip-performance-for-go-webservers/\nvar defaultGzipLevel = 5\n\n// Interface guards\nvar (\n\t_ encode.Encoding       = (*Gzip)(nil)\n\t_ caddy.Provisioner     = (*Gzip)(nil)\n\t_ caddy.Validator       = (*Gzip)(nil)\n\t_ caddyfile.Unmarshaler = (*Gzip)(nil)\n)\n",
    "source_file": "modules/caddyhttp/encode/gzip/gzip.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddygzip\n\nimport (\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(GzipPrecompressed{})\n}\n\n// GzipPrecompressed provides the file extension for files precompressed with gzip encoding.\ntype GzipPrecompressed struct {\n\tGzip\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (GzipPrecompressed) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.precompressed.gzip\",\n\t\tNew: func() caddy.Module { return new(GzipPrecompressed) },\n\t}\n}\n\n// Suffix returns the filename suffix of precompressed files.\nfunc (GzipPrecompressed) Suffix() string { return \".gz\" }\n\nvar _ encode.Precompressed = (*GzipPrecompressed)(nil)\n",
    "source_file": "modules/caddyhttp/encode/gzip/gzip_precompressed.go",
    "chunk_type": "code"
  },
  {
    "content": "package caddyzstd\n\nimport (\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(ZstdPrecompressed{})\n}\n\n// ZstdPrecompressed provides the file extension for files precompressed with zstandard encoding.\ntype ZstdPrecompressed struct {\n\tZstd\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (ZstdPrecompressed) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.precompressed.zstd\",\n\t\tNew: func() caddy.Module { return new(ZstdPrecompressed) },\n\t}\n}\n\n// Suffix returns the filename suffix of precompressed files.\nfunc (ZstdPrecompressed) Suffix() string { return \".zst\" }\n\nvar _ encode.Precompressed = (*ZstdPrecompressed)(nil)\n",
    "source_file": "modules/caddyhttp/encode/zstd/zstd_precompressed.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyzstd\n\nimport (\n\t\"fmt\"\n\n\t\"github.com/klauspost/compress/zstd\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp/encode\"\n)\n\nfunc init() {\n\tcaddy.RegisterModule(Zstd{})\n}\n\n// Zstd can create Zstandard encoders.\ntype Zstd struct {\n\t// The compression level. Accepted values: fastest, better, best, default.\n\tLevel string `json:\"level,omitempty\"`\n\n\t// Compression level refer to type constants value from zstd.SpeedFastest to zstd.SpeedBestCompression\n\tlevel zstd.EncoderLevel\n}\n\n// CaddyModule returns the Caddy module information.\nfunc (Zstd) CaddyModule() caddy.ModuleInfo {\n\treturn caddy.ModuleInfo{\n\t\tID:  \"http.encoders.zstd\",\n\t\tNew: func() caddy.Module { return new(Zstd) },\n\t}\n}\n\n// UnmarshalCaddyfile sets up the handler from Caddyfile tokens.\nfunc (z *Zstd) UnmarshalCaddyfile(d *caddyfile.Dispenser) error {\n\td.Next() // consume option name\n\tif !d.NextArg() {\n\t\treturn nil\n\t}\n\tlevelStr := d.Val()\n\tif ok, _ := zstd.EncoderLevelFromString(levelStr); !ok {\n\t\treturn d.Errf(\"unexpected compression level, use one of '%s', '%s', '%s', '%s'\",\n\t\t\tzstd.SpeedFastest,\n\t\t\tzstd.SpeedBetterCompression,\n\t\t\tzstd.SpeedBestCompression,\n\t\t\tzstd.SpeedDefault,\n\t\t)\n\t}\n\tz.Level = levelStr\n\treturn nil\n}\n\n// Provision provisions z's configuration.\nfunc (z *Zstd) Provision(ctx caddy.Context) error {\n\tif z.Level == \"\" {\n\t\tz.Level = zstd.SpeedDefault.String()\n\t}\n\tvar ok bool\n\tif ok, z.level = zstd.EncoderLevelFromString(z.Level); !ok {\n\t\treturn fmt.Errorf(\"unexpected compression level, use one of '%s', '%s', '%s', '%s'\",\n\t\t\tzstd.SpeedFastest,\n\t\t\tzstd.SpeedDefault,\n\t\t\tzstd.SpeedBetterCompression,\n\t\t\tzstd.SpeedBestCompression,\n\t\t)\n\t}\n\treturn nil\n}\n\n// AcceptEncoding returns the name of the encoding as\n// used in the Accept-Encoding request headers.\nfunc (Zstd) AcceptEncoding() string { return \"zstd\" }\n\n// NewEncoder returns a new Zstandard writer.\nfunc (z Zstd) NewEncoder() encode.Encoder {\n\t// The default of 8MB for the window is\n\t// too large for many clients, so we limit\n\t// it to 128K to lighten their load.\n\twriter, _ := zstd.NewWriter(\n\t\tnil,\n\t\tzstd.WithWindowSize(128<<10),\n\t\tzstd.WithEncoderConcurrency(1),\n\t\tzstd.WithZeroFrames(true),\n\t\tzstd.WithEncoderLevel(z.level),\n\t)\n\treturn writer\n}\n\n// Interface guards\nvar (\n\t_ encode.Encoding       = (*Zstd)(nil)\n\t_ caddyfile.Unmarshaler = (*Zstd)(nil)\n\t_ caddy.Provisioner     = (*Zstd)(nil)\n)\n",
    "source_file": "modules/caddyhttp/encode/zstd/zstd.go",
    "chunk_type": "code"
  },
  {
    "content": "package metrics\n\nimport (\n\t\"net/http\"\n\t\"strconv\"\n)\n\nfunc SanitizeCode(s int) string {\n\tswitch s {\n\tcase 0, 200:\n\t\treturn \"200\"\n\tdefault:\n\t\treturn strconv.Itoa(s)\n\t}\n}\n\n// Only support the list of \"regular\" HTTP methods, see\n// https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods\nvar methodMap = map[string]string{\n\t\"GET\": http.MethodGet, \"get\": http.MethodGet,\n\t\"HEAD\": http.MethodHead, \"head\": http.MethodHead,\n\t\"PUT\": http.MethodPut, \"put\": http.MethodPut,\n\t\"POST\": http.MethodPost, \"post\": http.MethodPost,\n\t\"DELETE\": http.MethodDelete, \"delete\": http.MethodDelete,\n\t\"CONNECT\": http.MethodConnect, \"connect\": http.MethodConnect,\n\t\"OPTIONS\": http.MethodOptions, \"options\": http.MethodOptions,\n\t\"TRACE\": http.MethodTrace, \"trace\": http.MethodTrace,\n\t\"PATCH\": http.MethodPatch, \"patch\": http.MethodPatch,\n}\n\n// SanitizeMethod sanitizes the method for use as a metric label. This helps\n// prevent high cardinality on the method label. The name is always upper case.\nfunc SanitizeMethod(m string) string {\n\tif m, ok := methodMap[m]; ok {\n\t\treturn m\n\t}\n\n\treturn \"OTHER\"\n}\n",
    "source_file": "internal/metrics/metrics.go",
    "chunk_type": "code"
  },
  {
    "content": "package filesystems\n\nimport (\n\t\"io/fs\"\n\t\"os\"\n\t\"path/filepath\"\n)\n\n// OsFS is a simple fs.FS implementation that uses the local\n// file system. (We do not use os.DirFS because we do our own\n// rooting or path prefixing without being constrained to a single\n// root folder. The standard os.DirFS implementation is problematic\n// since roots can be dynamic in our application.)\n//\n// OsFS also implements fs.StatFS, fs.GlobFS, fs.ReadDirFS, and fs.ReadFileFS.\ntype OsFS struct{}\n\nfunc (OsFS) Open(name string) (fs.File, error)          { return os.Open(name) }\nfunc (OsFS) Stat(name string) (fs.FileInfo, error)      { return os.Stat(name) }\nfunc (OsFS) Glob(pattern string) ([]string, error)      { return filepath.Glob(pattern) }\nfunc (OsFS) ReadDir(name string) ([]fs.DirEntry, error) { return os.ReadDir(name) }\nfunc (OsFS) ReadFile(name string) ([]byte, error)       { return os.ReadFile(name) }\n\nvar (\n\t_ fs.StatFS     = (*OsFS)(nil)\n\t_ fs.GlobFS     = (*OsFS)(nil)\n\t_ fs.ReadDirFS  = (*OsFS)(nil)\n\t_ fs.ReadFileFS = (*OsFS)(nil)\n)\n",
    "source_file": "internal/filesystems/os.go",
    "chunk_type": "code"
  },
  {
    "content": "package filesystems\n\nimport (\n\t\"io/fs\"\n\t\"strings\"\n\t\"sync\"\n)\n\nconst (\n\tDefaultFileSystemKey = \"default\"\n)\n\nvar DefaultFileSystem = &wrapperFs{key: DefaultFileSystemKey, FS: OsFS{}}\n\n// wrapperFs exists so can easily add to wrapperFs down the line\ntype wrapperFs struct {\n\tkey string\n\tfs.FS\n}\n\n// FileSystemMap stores a map of filesystems\n// the empty key will be overwritten to be the default key\n// it includes a default filesystem, based off the os fs\ntype FileSystemMap struct {\n\tm sync.Map\n}\n\n// note that the first invocation of key cannot be called in a racy context.\nfunc (f *FileSystemMap) key(k string) string {\n\tif k == \"\" {\n\t\tk = DefaultFileSystemKey\n\t}\n\treturn k\n}\n\n// Register will add the filesystem with key to later be retrieved\n// A call with a nil fs will call unregister, ensuring that a call to Default() will never be nil\nfunc (f *FileSystemMap) Register(k string, v fs.FS) {\n\tk = f.key(k)\n\tif v == nil {\n\t\tf.Unregister(k)\n\t\treturn\n\t}\n\tf.m.Store(k, &wrapperFs{key: k, FS: v})\n}\n\n// Unregister will remove the filesystem with key from the filesystem map\n// if the key is the default key, it will set the default to the osFS instead of deleting it\n// modules should call this on cleanup to be safe\nfunc (f *FileSystemMap) Unregister(k string) {\n\tk = f.key(k)\n\tif k == DefaultFileSystemKey {\n\t\tf.m.Store(k, DefaultFileSystem)\n\t} else {\n\t\tf.m.Delete(k)\n\t}\n}\n\n// Get will get a filesystem with a given key\nfunc (f *FileSystemMap) Get(k string) (v fs.FS, ok bool) {\n\tk = f.key(k)\n\tc, ok := f.m.Load(strings.TrimSpace(k))\n\tif !ok {\n\t\tif k == DefaultFileSystemKey {\n\t\t\tf.m.Store(k, DefaultFileSystem)\n\t\t\treturn DefaultFileSystem, true\n\t\t}\n\t\treturn nil, ok\n\t}\n\treturn c.(fs.FS), true\n}\n\n// Default will get the default filesystem in the filesystem map\nfunc (f *FileSystemMap) Default() fs.FS {\n\tval, _ := f.Get(DefaultFileSystemKey)\n\treturn val\n}\n",
    "source_file": "internal/filesystems/map.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyfile\n\nimport (\n\t\"bytes\"\n\t\"io\"\n\t\"slices\"\n\t\"unicode\"\n)\n\n// Format formats the input Caddyfile to a standard, nice-looking\n// appearance. It works by reading each rune of the input and taking\n// control over all the bracing and whitespace that is written; otherwise,\n// words, comments, placeholders, and escaped characters are all treated\n// literally and written as they appear in the input.\nfunc Format(input []byte) []byte {\n\tinput = bytes.TrimSpace(input)\n\n\tout := new(bytes.Buffer)\n\trdr := bytes.NewReader(input)\n\n\ttype heredocState int\n\n\tconst (\n\t\theredocClosed  heredocState = 0\n\t\theredocOpening heredocState = 1\n\t\theredocOpened  heredocState = 2\n\t)\n\n\tvar (\n\t\tlast rune // the last character that was written to the result\n\n\t\tspace           = true // whether current/previous character was whitespace (beginning of input counts as space)\n\t\tbeginningOfLine = true // whether we are at beginning of line\n\n\t\topenBrace        bool // whether current word/token is or started with open curly brace\n\t\topenBraceWritten bool // if openBrace, whether that brace was written or not\n\t\topenBraceSpace   bool // whether there was a non-newline space before open brace\n\n\t\tnewLines int // count of newlines consumed\n\n\t\tcomment bool // whether we're in a comment\n\t\tquoted  bool // whether we're in a quoted segment\n\t\tescaped bool // whether current char is escaped\n\n\t\theredoc              heredocState // whether we're in a heredoc\n\t\theredocEscaped       bool         // whether heredoc is escaped\n\t\theredocMarker        []rune\n\t\theredocClosingMarker []rune\n\n\t\tnesting         int // indentation level\n\t\twithinBackquote bool\n\t)\n\n\twrite := func(ch rune) {\n\t\tout.WriteRune(ch)\n\t\tlast = ch\n\t}\n\n\tindent := func() {\n\t\tfor tabs := nesting; tabs > 0; tabs-- {\n\t\t\twrite('\\t')\n\t\t}\n\t}\n\n\tnextLine := func() {\n\t\twrite('\\n')\n\t\tbeginningOfLine = true\n\t}\n\n\tfor {\n\t\tch, _, err := rdr.ReadRune()\n\t\tif err != nil {\n\t\t\tif err == io.EOF {\n\t\t\t\tbreak\n\t\t\t}\n\t\t\tpanic(err)\n\t\t}\n\t\tif ch == '`' {\n\t\t\twithinBackquote = !withinBackquote\n\t\t}\n\n\t\t// detect whether we have the start of a heredoc\n\t\tif !quoted && (heredoc == heredocClosed && !heredocEscaped) &&\n\t\t\tspace && last == '<' && ch == '<' {\n\t\t\twrite(ch)\n\t\t\theredoc = heredocOpening\n\t\t\tspace = false\n\t\t\tcontinue\n\t\t}\n\n\t\tif heredoc == heredocOpening {\n\t\t\tif ch == '\\n' {\n\t\t\t\tif len(heredocMarker) > 0 && heredocMarkerRegexp.MatchString(string(heredocMarker)) {\n\t\t\t\t\theredoc = heredocOpened\n\t\t\t\t} else {\n\t\t\t\t\theredocMarker = nil\n\t\t\t\t\theredoc = heredocClosed\n\t\t\t\t\tnextLine()\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t\twrite(ch)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif unicode.IsSpace(ch) {\n\t\t\t\t// a space means it's just a regular token and not a heredoc\n\t\t\t\theredocMarker = nil\n\t\t\t\theredoc = heredocClosed\n\t\t\t} else {\n\t\t\t\theredocMarker = append(heredocMarker, ch)\n\t\t\t\twrite(ch)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\t\t// if we're in a heredoc, all characters are read&write as-is\n\t\tif heredoc == heredocOpened {\n\t\t\theredocClosingMarker = append(heredocClosingMarker, ch)\n\t\t\tif len(heredocClosingMarker) > len(heredocMarker)+1 { // We assert that the heredocClosingMarker is followed by a unicode.Space\n\t\t\t\theredocClosingMarker = heredocClosingMarker[1:]\n\t\t\t}\n\t\t\t// check if we're done\n\t\t\tif unicode.IsSpace(ch) && slices.Equal(heredocClosingMarker[:len(heredocClosingMarker)-1], heredocMarker) {\n\t\t\t\theredocMarker = nil\n\t\t\t\theredocClosingMarker = nil\n\t\t\t\theredoc = heredocClosed\n\t\t\t} else {\n\t\t\t\twrite(ch)\n\t\t\t\tif ch == '\\n' {\n\t\t\t\t\theredocClosingMarker = heredocClosingMarker[:0]\n\t\t\t\t}\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif last == '<' && space {\n\t\t\tspace = false\n\t\t}\n\n\t\tif comment {\n\t\t\tif ch == '\\n' {\n\t\t\t\tcomment = false\n\t\t\t\tspace = true\n\t\t\t\tnextLine()\n\t\t\t\tcontinue\n\t\t\t} else {\n\t\t\t\twrite(ch)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif !escaped && ch == '\\\\' {\n\t\t\tif space {\n\t\t\t\twrite(' ')\n\t\t\t\tspace = false\n\t\t\t}\n\t\t\twrite(ch)\n\t\t\tescaped = true\n\t\t\tcontinue\n\t\t}\n\n\t\tif escaped {\n\t\t\tif ch == '<' {\n\t\t\t\theredocEscaped = true\n\t\t\t}\n\t\t\twrite(ch)\n\t\t\tescaped = false\n\t\t\tcontinue\n\t\t}\n\n\t\tif quoted {\n\t\t\tif ch == '\"' {\n\t\t\t\tquoted = false\n\t\t\t}\n\t\t\twrite(ch)\n\t\t\tcontinue\n\t\t}\n\n\t\tif space && ch == '\"' {\n\t\t\tquoted = true\n\t\t}\n\n\t\tif unicode.IsSpace(ch) {\n\t\t\tspace = true\n\t\t\theredocEscaped = false\n\t\t\tif ch == '\\n' {\n\t\t\t\tnewLines++\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\t\tspacePrior := space\n\t\tspace = false\n\n\t\t//////////////////////////////////////////////////////////\n\t\t// I find it helpful to think of the formatting loop in two\n\t\t// main sections; by the time we reach this point, we\n\t\t// know we are in a \"regular\" part of the file: we know\n\t\t// the character is not a space, not in a literal segment\n\t\t// like a comment or quoted, it's not escaped, etc.\n\t\t//////////////////////////////////////////////////////////\n\n\t\tif ch == '#' {\n\t\t\tcomment = true\n\t\t}\n\n\t\tif openBrace && spacePrior && !openBraceWritten {\n\t\t\tif nesting == 0 && last == '}' {\n\t\t\t\tnextLine()\n\t\t\t\tnextLine()\n\t\t\t}\n\n\t\t\topenBrace = false\n\t\t\tif beginningOfLine {\n\t\t\t\tindent()\n\t\t\t} else if !openBraceSpace {\n\t\t\t\twrite(' ')\n\t\t\t}\n\t\t\twrite('{')\n\t\t\topenBraceWritten = true\n\t\t\tnextLine()\n\t\t\tnewLines = 0\n\t\t\t// prevent infinite nesting from ridiculous inputs (issue #4169)\n\t\t\tif nesting < 10 {\n\t\t\t\tnesting++\n\t\t\t}\n\t\t}\n\n\t\tswitch {\n\t\tcase ch == '{':\n\t\t\topenBrace = true\n\t\t\topenBraceSpace = spacePrior && !beginningOfLine\n\t\t\tif openBraceSpace {\n\t\t\t\twrite(' ')\n\t\t\t}\n\t\t\topenBraceWritten = false\n\t\t\tif withinBackquote {\n\t\t\t\twrite('{')\n\t\t\t\topenBraceWritten = true\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tcontinue\n\n\t\tcase ch == '}' && (spacePrior || !openBrace):\n\t\t\tif withinBackquote {\n\t\t\t\twrite('}')\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif last != '\\n' {\n\t\t\t\tnextLine()\n\t\t\t}\n\t\t\tif nesting > 0 {\n\t\t\t\tnesting--\n\t\t\t}\n\t\t\tindent()\n\t\t\twrite('}')\n\t\t\tnewLines = 0\n\t\t\tcontinue\n\t\t}\n\n\t\tif newLines > 2 {\n\t\t\tnewLines = 2\n\t\t}\n\t\tfor i := 0; i < newLines; i++ {\n\t\t\tnextLine()\n\t\t}\n\t\tnewLines = 0\n\t\tif beginningOfLine {\n\t\t\tindent()\n\t\t}\n\t\tif nesting == 0 && last == '}' && beginningOfLine {\n\t\t\tnextLine()\n\t\t\tnextLine()\n\t\t}\n\n\t\tif !beginningOfLine && spacePrior {\n\t\t\twrite(' ')\n\t\t}\n\n\t\tif openBrace && !openBraceWritten {\n\t\t\twrite('{')\n\t\t\topenBraceWritten = true\n\t\t}\n\n\t\tif spacePrior && ch == '<' {\n\t\t\tspace = true\n\t\t}\n\n\t\twrite(ch)\n\n\t\tbeginningOfLine = false\n\t}\n\n\t// the Caddyfile does not need any leading or trailing spaces, but...\n\ttrimmedResult := bytes.TrimSpace(out.Bytes())\n\n\t// ...Caddyfiles should, however, end with a newline because\n\t// newlines are significant to the syntax of the file\n\treturn append(trimmedResult, '\\n')\n}\n",
    "source_file": "caddyconfig/caddyfile/formatter.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyfile\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"log\"\n\t\"strconv\"\n\t\"strings\"\n)\n\n// Dispenser is a type that dispenses tokens, similarly to a lexer,\n// except that it can do so with some notion of structure. An empty\n// Dispenser is invalid; call NewDispenser to make a proper instance.\ntype Dispenser struct {\n\ttokens  []Token\n\tcursor  int\n\tnesting int\n\n\t// A map of arbitrary context data that can be used\n\t// to pass through some information to unmarshalers.\n\tcontext map[string]any\n}\n\n// NewDispenser returns a Dispenser filled with the given tokens.\nfunc NewDispenser(tokens []Token) *Dispenser {\n\treturn &Dispenser{\n\t\ttokens: tokens,\n\t\tcursor: -1,\n\t}\n}\n\n// NewTestDispenser parses input into tokens and creates a new\n// Dispenser for test purposes only; any errors are fatal.\nfunc NewTestDispenser(input string) *Dispenser {\n\ttokens, err := allTokens(\"Testfile\", []byte(input))\n\tif err != nil && err != io.EOF {\n\t\tlog.Fatalf(\"getting all tokens from input: %v\", err)\n\t}\n\treturn NewDispenser(tokens)\n}\n\n// Next loads the next token. Returns true if a token\n// was loaded; false otherwise. If false, all tokens\n// have been consumed.\nfunc (d *Dispenser) Next() bool {\n\tif d.cursor < len(d.tokens)-1 {\n\t\td.cursor++\n\t\treturn true\n\t}\n\treturn false\n}\n\n// Prev moves to the previous token. It does the inverse\n// of Next(), except this function may decrement the cursor\n// to -1 so that the next call to Next() points to the\n// first token; this allows dispensing to \"start over\". This\n// method returns true if the cursor ends up pointing to a\n// valid token.\nfunc (d *Dispenser) Prev() bool {\n\tif d.cursor > -1 {\n\t\td.cursor--\n\t\treturn d.cursor > -1\n\t}\n\treturn false\n}\n\n// NextArg loads the next token if it is on the same\n// line and if it is not a block opening (open curly\n// brace). Returns true if an argument token was\n// loaded; false otherwise. If false, all tokens on\n// the line have been consumed except for potentially\n// a block opening. It handles imported tokens\n// correctly.\nfunc (d *Dispenser) NextArg() bool {\n\tif !d.nextOnSameLine() {\n\t\treturn false\n\t}\n\tif d.Val() == \"{\" {\n\t\t// roll back; a block opening is not an argument\n\t\td.cursor--\n\t\treturn false\n\t}\n\treturn true\n}\n\n// nextOnSameLine advances the cursor if the next\n// token is on the same line of the same file.\nfunc (d *Dispenser) nextOnSameLine() bool {\n\tif d.cursor < 0 {\n\t\td.cursor++\n\t\treturn true\n\t}\n\tif d.cursor >= len(d.tokens)-1 {\n\t\treturn false\n\t}\n\tcurr := d.tokens[d.cursor]\n\tnext := d.tokens[d.cursor+1]\n\tif !isNextOnNewLine(curr, next) {\n\t\td.cursor++\n\t\treturn true\n\t}\n\treturn false\n}\n\n// NextLine loads the next token only if it is not on the same\n// line as the current token, and returns true if a token was\n// loaded; false otherwise. If false, there is not another token\n// or it is on the same line. It handles imported tokens correctly.\nfunc (d *Dispenser) NextLine() bool {\n\tif d.cursor < 0 {\n\t\td.cursor++\n\t\treturn true\n\t}\n\tif d.cursor >= len(d.tokens)-1 {\n\t\treturn false\n\t}\n\tcurr := d.tokens[d.cursor]\n\tnext := d.tokens[d.cursor+1]\n\tif isNextOnNewLine(curr, next) {\n\t\td.cursor++\n\t\treturn true\n\t}\n\treturn false\n}\n\n// NextBlock can be used as the condition of a for loop\n// to load the next token as long as it opens a block or\n// is already in a block nested more than initialNestingLevel.\n// In other words, a loop over NextBlock() will iterate\n// all tokens in the block assuming the next token is an\n// open curly brace, until the matching closing brace.\n// The open and closing brace tokens for the outer-most\n// block will be consumed internally and omitted from\n// the iteration.\n//\n// Proper use of this method looks like this:\n//\n//\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n//\t}\n//\n// However, in simple cases where it is known that the\n// Dispenser is new and has not already traversed state\n// by a loop over NextBlock(), this will do:\n//\n//\tfor d.NextBlock(0) {\n//\t}\n//\n// As with other token parsing logic, a loop over\n// NextBlock() should be contained within a loop over\n// Next(), as it is usually prudent to skip the initial\n// token.\nfunc (d *Dispenser) NextBlock(initialNestingLevel int) bool {\n\tif d.nesting > initialNestingLevel {\n\t\tif !d.Next() {\n\t\t\treturn false // should be EOF error\n\t\t}\n\t\tif d.Val() == \"}\" && !d.nextOnSameLine() {\n\t\t\td.nesting--\n\t\t} else if d.Val() == \"{\" && !d.nextOnSameLine() {\n\t\t\td.nesting++\n\t\t}\n\t\treturn d.nesting > initialNestingLevel\n\t}\n\tif !d.nextOnSameLine() { // block must open on same line\n\t\treturn false\n\t}\n\tif d.Val() != \"{\" {\n\t\td.cursor-- // roll back if not opening brace\n\t\treturn false\n\t}\n\td.Next() // consume open curly brace\n\tif d.Val() == \"}\" {\n\t\treturn false // open and then closed right away\n\t}\n\td.nesting++\n\treturn true\n}\n\n// Nesting returns the current nesting level. Necessary\n// if using NextBlock()\nfunc (d *Dispenser) Nesting() int {\n\treturn d.nesting\n}\n\n// Val gets the text of the current token. If there is no token\n// loaded, it returns empty string.\nfunc (d *Dispenser) Val() string {\n\tif d.cursor < 0 || d.cursor >= len(d.tokens) {\n\t\treturn \"\"\n\t}\n\treturn d.tokens[d.cursor].Text\n}\n\n// ValRaw gets the raw text of the current token (including quotes).\n// If the token was a heredoc, then the delimiter is not included,\n// because that is not relevant to any unmarshaling logic at this time.\n// If there is no token loaded, it returns empty string.\nfunc (d *Dispenser) ValRaw() string {\n\tif d.cursor < 0 || d.cursor >= len(d.tokens) {\n\t\treturn \"\"\n\t}\n\tquote := d.tokens[d.cursor].wasQuoted\n\tif quote > 0 && quote != '<' {\n\t\t// string literal\n\t\treturn string(quote) + d.tokens[d.cursor].Text + string(quote)\n\t}\n\treturn d.tokens[d.cursor].Text\n}\n\n// ScalarVal gets value of the current token, converted to the closest\n// scalar type. If there is no token loaded, it returns nil.\nfunc (d *Dispenser) ScalarVal() any {\n\tif d.cursor < 0 || d.cursor >= len(d.tokens) {\n\t\treturn nil\n\t}\n\tquote := d.tokens[d.cursor].wasQuoted\n\ttext := d.tokens[d.cursor].Text\n\n\tif quote > 0 {\n\t\treturn text // string literal\n\t}\n\tif num, err := strconv.Atoi(text); err == nil {\n\t\treturn num\n\t}\n\tif num, err := strconv.ParseFloat(text, 64); err == nil {\n\t\treturn num\n\t}\n\tif bool, err := strconv.ParseBool(text); err == nil {\n\t\treturn bool\n\t}\n\treturn text\n}\n\n// Line gets the line number of the current token.\n// If there is no token loaded, it returns 0.\nfunc (d *Dispenser) Line() int {\n\tif d.cursor < 0 || d.cursor >= len(d.tokens) {\n\t\treturn 0\n\t}\n\treturn d.tokens[d.cursor].Line\n}\n\n// File gets the filename where the current token originated.\nfunc (d *Dispenser) File() string {\n\tif d.cursor < 0 || d.cursor >= len(d.tokens) {\n\t\treturn \"\"\n\t}\n\treturn d.tokens[d.cursor].File\n}\n\n// Args is a convenience function that loads the next arguments\n// (tokens on the same line) into an arbitrary number of strings\n// pointed to in targets. If there are not enough argument tokens\n// available to fill targets, false is returned and the remaining\n// targets are left unchanged. If all the targets are filled,\n// then true is returned.\nfunc (d *Dispenser) Args(targets ...*string) bool {\n\tfor i := 0; i < len(targets); i++ {\n\t\tif !d.NextArg() {\n\t\t\treturn false\n\t\t}\n\t\t*targets[i] = d.Val()\n\t}\n\treturn true\n}\n\n// AllArgs is like Args, but if there are more argument tokens\n// available than there are targets, false is returned. The\n// number of available argument tokens must match the number of\n// targets exactly to return true.\nfunc (d *Dispenser) AllArgs(targets ...*string) bool {\n\tif !d.Args(targets...) {\n\t\treturn false\n\t}\n\tif d.NextArg() {\n\t\td.Prev()\n\t\treturn false\n\t}\n\treturn true\n}\n\n// CountRemainingArgs counts the amount of remaining arguments\n// (tokens on the same line) without consuming the tokens.\nfunc (d *Dispenser) CountRemainingArgs() int {\n\tcount := 0\n\tfor d.NextArg() {\n\t\tcount++\n\t}\n\tfor i := 0; i < count; i++ {\n\t\td.Prev()\n\t}\n\treturn count\n}\n\n// RemainingArgs loads any more arguments (tokens on the same line)\n// into a slice and returns them. Open curly brace tokens also indicate\n// the end of arguments, and the curly brace is not included in\n// the return value nor is it loaded.\nfunc (d *Dispenser) RemainingArgs() []string {\n\tvar args []string\n\tfor d.NextArg() {\n\t\targs = append(args, d.Val())\n\t}\n\treturn args\n}\n\n// RemainingArgsRaw loads any more arguments (tokens on the same line,\n// retaining quotes) into a slice and returns them. Open curly brace\n// tokens also indicate the end of arguments, and the curly brace is\n// not included in the return value nor is it loaded.\nfunc (d *Dispenser) RemainingArgsRaw() []string {\n\tvar args []string\n\tfor d.NextArg() {\n\t\targs = append(args, d.ValRaw())\n\t}\n\treturn args\n}\n\n// NewFromNextSegment returns a new dispenser with a copy of\n// the tokens from the current token until the end of the\n// \"directive\" whether that be to the end of the line or\n// the end of a block that starts at the end of the line;\n// in other words, until the end of the segment.\nfunc (d *Dispenser) NewFromNextSegment() *Dispenser {\n\treturn NewDispenser(d.NextSegment())\n}\n\n// NextSegment returns a copy of the tokens from the current\n// token until the end of the line or block that starts at\n// the end of the line.\nfunc (d *Dispenser) NextSegment() Segment {\n\ttkns := Segment{d.Token()}\n\tfor d.NextArg() {\n\t\ttkns = append(tkns, d.Token())\n\t}\n\tvar openedBlock bool\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tif !openedBlock {\n\t\t\t// because NextBlock() consumes the initial open\n\t\t\t// curly brace, we rewind here to append it, since\n\t\t\t// our case is special in that we want the new\n\t\t\t// dispenser to have all the tokens including\n\t\t\t// surrounding curly braces\n\t\t\td.Prev()\n\t\t\ttkns = append(tkns, d.Token())\n\t\t\td.Next()\n\t\t\topenedBlock = true\n\t\t}\n\t\ttkns = append(tkns, d.Token())\n\t}\n\tif openedBlock {\n\t\t// include closing brace\n\t\ttkns = append(tkns, d.Token())\n\n\t\t// do not consume the closing curly brace; the\n\t\t// next iteration of the enclosing loop will\n\t\t// call Next() and consume it\n\t}\n\treturn tkns\n}\n\n// Token returns the current token.\nfunc (d *Dispenser) Token() Token {\n\tif d.cursor < 0 || d.cursor >= len(d.tokens) {\n\t\treturn Token{}\n\t}\n\treturn d.tokens[d.cursor]\n}\n\n// Reset sets d's cursor to the beginning, as\n// if this was a new and unused dispenser.\nfunc (d *Dispenser) Reset() {\n\td.cursor = -1\n\td.nesting = 0\n}\n\n// ArgErr returns an argument error, meaning that another\n// argument was expected but not found. In other words,\n// a line break or open curly brace was encountered instead of\n// an argument.\nfunc (d *Dispenser) ArgErr() error {\n\tif d.Val() == \"{\" {\n\t\treturn d.Err(\"unexpected token '{', expecting argument\")\n\t}\n\treturn d.Errf(\"wrong argument count or unexpected line ending after '%s'\", d.Val())\n}\n\n// SyntaxErr creates a generic syntax error which explains what was\n// found and what was expected.\nfunc (d *Dispenser) SyntaxErr(expected string) error {\n\tmsg := fmt.Sprintf(\"syntax error: unexpected token '%s', expecting '%s', at %s:%d import chain: ['%s']\", d.Val(), expected, d.File(), d.Line(), strings.Join(d.Token().imports, \"','\"))\n\treturn errors.New(msg)\n}\n\n// EOFErr returns an error indicating that the dispenser reached\n// the end of the input when searching for the next token.\nfunc (d *Dispenser) EOFErr() error {\n\treturn d.Errf(\"unexpected EOF\")\n}\n\n// Err generates a custom parse-time error with a message of msg.\nfunc (d *Dispenser) Err(msg string) error {\n\treturn d.WrapErr(errors.New(msg))\n}\n\n// Errf is like Err, but for formatted error messages\nfunc (d *Dispenser) Errf(format string, args ...any) error {\n\treturn d.WrapErr(fmt.Errorf(format, args...))\n}\n\n// WrapErr takes an existing error and adds the Caddyfile file and line number.\nfunc (d *Dispenser) WrapErr(err error) error {\n\tif len(d.Token().imports) > 0 {\n\t\treturn fmt.Errorf(\"%w, at %s:%d import chain ['%s']\", err, d.File(), d.Line(), strings.Join(d.Token().imports, \"','\"))\n\t}\n\treturn fmt.Errorf(\"%w, at %s:%d\", err, d.File(), d.Line())\n}\n\n// Delete deletes the current token and returns the updated slice\n// of tokens. The cursor is not advanced to the next token.\n// Because deletion modifies the underlying slice, this method\n// should only be called if you have access to the original slice\n// of tokens and/or are using the slice of tokens outside this\n// Dispenser instance. If you do not re-assign the slice with the\n// return value of this method, inconsistencies in the token\n// array will become apparent (or worse, hide from you like they\n// did me for 3 and a half freaking hours late one night).\nfunc (d *Dispenser) Delete() []Token {\n\tif d.cursor >= 0 && d.cursor <= len(d.tokens)-1 {\n\t\td.tokens = append(d.tokens[:d.cursor], d.tokens[d.cursor+1:]...)\n\t\td.cursor--\n\t}\n\treturn d.tokens\n}\n\n// DeleteN is the same as Delete, but can delete many tokens at once.\n// If there aren't N tokens available to delete, none are deleted.\nfunc (d *Dispenser) DeleteN(amount int) []Token {\n\tif amount > 0 && d.cursor >= (amount-1) && d.cursor <= len(d.tokens)-1 {\n\t\td.tokens = append(d.tokens[:d.cursor-(amount-1)], d.tokens[d.cursor+1:]...)\n\t\td.cursor -= amount\n\t}\n\treturn d.tokens\n}\n\n// SetContext sets a key-value pair in the context map.\nfunc (d *Dispenser) SetContext(key string, value any) {\n\tif d.context == nil {\n\t\td.context = make(map[string]any)\n\t}\n\td.context[key] = value\n}\n\n// GetContext gets the value of a key in the context map.\nfunc (d *Dispenser) GetContext(key string) any {\n\tif d.context == nil {\n\t\treturn nil\n\t}\n\treturn d.context[key]\n}\n\n// GetContextString gets the value of a key in the context map\n// as a string, or an empty string if the key does not exist.\nfunc (d *Dispenser) GetContextString(key string) string {\n\tif d.context == nil {\n\t\treturn \"\"\n\t}\n\tif val, ok := d.context[key].(string); ok {\n\t\treturn val\n\t}\n\treturn \"\"\n}\n\n// isNewLine determines whether the current token is on a different\n// line (higher line number) than the previous token. It handles imported\n// tokens correctly. If there isn't a previous token, it returns true.\nfunc (d *Dispenser) isNewLine() bool {\n\tif d.cursor < 1 {\n\t\treturn true\n\t}\n\tif d.cursor > len(d.tokens)-1 {\n\t\treturn false\n\t}\n\n\tprev := d.tokens[d.cursor-1]\n\tcurr := d.tokens[d.cursor]\n\treturn isNextOnNewLine(prev, curr)\n}\n\n// isNextOnNewLine determines whether the current token is on a different\n// line (higher line number) than the next token. It handles imported\n// tokens correctly. If there isn't a next token, it returns true.\nfunc (d *Dispenser) isNextOnNewLine() bool {\n\tif d.cursor < 0 {\n\t\treturn false\n\t}\n\tif d.cursor >= len(d.tokens)-1 {\n\t\treturn true\n\t}\n\n\tcurr := d.tokens[d.cursor]\n\tnext := d.tokens[d.cursor+1]\n\treturn isNextOnNewLine(curr, next)\n}\n\nconst MatcherNameCtxKey = \"matcher_name\"\n",
    "source_file": "caddyconfig/caddyfile/dispenser.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyfile\n\nimport (\n\t\"fmt\"\n\t\"slices\"\n)\n\ntype adjacency map[string][]string\n\ntype importGraph struct {\n\tnodes map[string]struct{}\n\tedges adjacency\n}\n\nfunc (i *importGraph) addNode(name string) {\n\tif i.nodes == nil {\n\t\ti.nodes = make(map[string]struct{})\n\t}\n\tif _, exists := i.nodes[name]; exists {\n\t\treturn\n\t}\n\ti.nodes[name] = struct{}{}\n}\n\nfunc (i *importGraph) addNodes(names []string) {\n\tfor _, name := range names {\n\t\ti.addNode(name)\n\t}\n}\n\nfunc (i *importGraph) removeNode(name string) {\n\tdelete(i.nodes, name)\n}\n\nfunc (i *importGraph) removeNodes(names []string) {\n\tfor _, name := range names {\n\t\ti.removeNode(name)\n\t}\n}\n\nfunc (i *importGraph) addEdge(from, to string) error {\n\tif !i.exists(from) || !i.exists(to) {\n\t\treturn fmt.Errorf(\"one of the nodes does not exist\")\n\t}\n\n\tif i.willCycle(to, from) {\n\t\treturn fmt.Errorf(\"a cycle of imports exists between %s and %s\", from, to)\n\t}\n\n\tif i.areConnected(from, to) {\n\t\t// if connected, there's nothing to do\n\t\treturn nil\n\t}\n\n\tif i.nodes == nil {\n\t\ti.nodes = make(map[string]struct{})\n\t}\n\tif i.edges == nil {\n\t\ti.edges = make(adjacency)\n\t}\n\n\ti.edges[from] = append(i.edges[from], to)\n\treturn nil\n}\n\nfunc (i *importGraph) addEdges(from string, tos []string) error {\n\tfor _, to := range tos {\n\t\terr := i.addEdge(from, to)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc (i *importGraph) areConnected(from, to string) bool {\n\tal, ok := i.edges[from]\n\tif !ok {\n\t\treturn false\n\t}\n\treturn slices.Contains(al, to)\n}\n\nfunc (i *importGraph) willCycle(from, to string) bool {\n\tcollector := make(map[string]bool)\n\n\tvar visit func(string)\n\tvisit = func(start string) {\n\t\tif !collector[start] {\n\t\t\tcollector[start] = true\n\t\t\tfor _, v := range i.edges[start] {\n\t\t\t\tvisit(v)\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, v := range i.edges[from] {\n\t\tvisit(v)\n\t}\n\tfor k := range collector {\n\t\tif to == k {\n\t\t\treturn true\n\t\t}\n\t}\n\n\treturn false\n}\n\nfunc (i *importGraph) exists(key string) bool {\n\t_, exists := i.nodes[key]\n\treturn exists\n}\n",
    "source_file": "caddyconfig/caddyfile/importgraph.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyfile\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n)\n\n// Adapter adapts Caddyfile to Caddy JSON.\ntype Adapter struct {\n\tServerType ServerType\n}\n\n// Adapt converts the Caddyfile config in body to Caddy JSON.\nfunc (a Adapter) Adapt(body []byte, options map[string]any) ([]byte, []caddyconfig.Warning, error) {\n\tif a.ServerType == nil {\n\t\treturn nil, nil, fmt.Errorf(\"no server type\")\n\t}\n\tif options == nil {\n\t\toptions = make(map[string]any)\n\t}\n\n\tfilename, _ := options[\"filename\"].(string)\n\tif filename == \"\" {\n\t\tfilename = \"Caddyfile\"\n\t}\n\n\tserverBlocks, err := Parse(filename, body)\n\tif err != nil {\n\t\treturn nil, nil, err\n\t}\n\n\tcfg, warnings, err := a.ServerType.Setup(serverBlocks, options)\n\tif err != nil {\n\t\treturn nil, warnings, err\n\t}\n\n\t// lint check: see if input was properly formatted; sometimes messy files parse\n\t// successfully but result in logical errors (the Caddyfile is a bad format, I'm sorry)\n\tif warning, different := FormattingDifference(filename, body); different {\n\t\twarnings = append(warnings, warning)\n\t}\n\n\tresult, err := json.Marshal(cfg)\n\n\treturn result, warnings, err\n}\n\n// FormattingDifference returns a warning and true if the formatted version\n// is any different from the input; empty warning and false otherwise.\n// TODO: also perform this check on imported files\nfunc FormattingDifference(filename string, body []byte) (caddyconfig.Warning, bool) {\n\t// replace windows-style newlines to normalize comparison\n\tnormalizedBody := bytes.ReplaceAll(body, []byte(\"\\r\\n\"), []byte(\"\\n\"))\n\n\tformatted := Format(normalizedBody)\n\tif bytes.Equal(formatted, normalizedBody) {\n\t\treturn caddyconfig.Warning{}, false\n\t}\n\n\t// find where the difference is\n\tline := 1\n\tfor i, ch := range normalizedBody {\n\t\tif i >= len(formatted) || ch != formatted[i] {\n\t\t\tbreak\n\t\t}\n\t\tif ch == '\\n' {\n\t\t\tline++\n\t\t}\n\t}\n\treturn caddyconfig.Warning{\n\t\tFile:    filename,\n\t\tLine:    line,\n\t\tMessage: \"Caddyfile input is not formatted; run 'caddy fmt --overwrite' to fix inconsistencies\",\n\t}, true\n}\n\n// Unmarshaler is a type that can unmarshal Caddyfile tokens to\n// set itself up for a JSON encoding. The goal of an unmarshaler\n// is not to set itself up for actual use, but to set itself up for\n// being marshaled into JSON. Caddyfile-unmarshaled values will not\n// be used directly; they will be encoded as JSON and then used from\n// that. Implementations _may_ be able to support multiple segments\n// (instances of their directive or batch of tokens); typically this\n// means wrapping parsing logic in a loop: `for d.Next() { ... }`.\n// More commonly, only a single segment is supported, so a simple\n// `d.Next()` at the start should be used to consume the module\n// identifier token (directive name, etc).\ntype Unmarshaler interface {\n\tUnmarshalCaddyfile(d *Dispenser) error\n}\n\n// ServerType is a type that can evaluate a Caddyfile and set up a caddy config.\ntype ServerType interface {\n\t// Setup takes the server blocks which contain tokens,\n\t// as well as options (e.g. CLI flags) and creates a\n\t// Caddy config, along with any warnings or an error.\n\tSetup([]ServerBlock, map[string]any) (*caddy.Config, []caddyconfig.Warning, error)\n}\n\n// UnmarshalModule instantiates a module with the given ID and invokes\n// UnmarshalCaddyfile on the new value using the immediate next segment\n// of d as input. In other words, d's next token should be the first\n// token of the module's Caddyfile input.\n//\n// This function is used when the next segment of Caddyfile tokens\n// belongs to another Caddy module. The returned value is often\n// type-asserted to the module's associated type for practical use\n// when setting up a config.\nfunc UnmarshalModule(d *Dispenser, moduleID string) (Unmarshaler, error) {\n\tmod, err := caddy.GetModule(moduleID)\n\tif err != nil {\n\t\treturn nil, d.Errf(\"getting module named '%s': %v\", moduleID, err)\n\t}\n\tinst := mod.New()\n\tunm, ok := inst.(Unmarshaler)\n\tif !ok {\n\t\treturn nil, d.Errf(\"module %s is not a Caddyfile unmarshaler; is %T\", mod.ID, inst)\n\t}\n\terr = unm.UnmarshalCaddyfile(d.NewFromNextSegment())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn unm, nil\n}\n\n// Interface guard\nvar _ caddyconfig.Adapter = (*Adapter)(nil)\n",
    "source_file": "caddyconfig/caddyfile/adapter.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build gofuzz\n\npackage caddyfile\n\nimport \"bytes\"\n\nfunc FuzzFormat(input []byte) int {\n\tformatted := Format(input)\n\tif bytes.Equal(formatted, Format(formatted)) {\n\t\treturn 1\n\t}\n\treturn 0\n}\n",
    "source_file": "caddyconfig/caddyfile/formatter_fuzz.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyfile\n\nimport (\n\t\"bufio\"\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"regexp\"\n\t\"strings\"\n\t\"unicode\"\n)\n\ntype (\n\t// lexer is a utility which can get values, token by\n\t// token, from a Reader. A token is a word, and tokens\n\t// are separated by whitespace. A word can be enclosed\n\t// in quotes if it contains whitespace.\n\tlexer struct {\n\t\treader       *bufio.Reader\n\t\ttoken        Token\n\t\tline         int\n\t\tskippedLines int\n\t}\n\n\t// Token represents a single parsable unit.\n\tToken struct {\n\t\tFile          string\n\t\timports       []string\n\t\tLine          int\n\t\tText          string\n\t\twasQuoted     rune // enclosing quote character, if any\n\t\theredocMarker string\n\t\tsnippetName   string\n\t}\n)\n\n// Tokenize takes bytes as input and lexes it into\n// a list of tokens that can be parsed as a Caddyfile.\n// Also takes a filename to fill the token's File as\n// the source of the tokens, which is important to\n// determine relative paths for `import` directives.\nfunc Tokenize(input []byte, filename string) ([]Token, error) {\n\tl := lexer{}\n\tif err := l.load(bytes.NewReader(input)); err != nil {\n\t\treturn nil, err\n\t}\n\tvar tokens []Token\n\tfor {\n\t\tfound, err := l.next()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tif !found {\n\t\t\tbreak\n\t\t}\n\t\tl.token.File = filename\n\t\ttokens = append(tokens, l.token)\n\t}\n\treturn tokens, nil\n}\n\n// load prepares the lexer to scan an input for tokens.\n// It discards any leading byte order mark.\nfunc (l *lexer) load(input io.Reader) error {\n\tl.reader = bufio.NewReader(input)\n\tl.line = 1\n\n\t// discard byte order mark, if present\n\tfirstCh, _, err := l.reader.ReadRune()\n\tif err != nil {\n\t\treturn err\n\t}\n\tif firstCh != 0xFEFF {\n\t\terr := l.reader.UnreadRune()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// next loads the next token into the lexer.\n// A token is delimited by whitespace, unless\n// the token starts with a quotes character (\")\n// in which case the token goes until the closing\n// quotes (the enclosing quotes are not included).\n// Inside quoted strings, quotes may be escaped\n// with a preceding \\ character. No other chars\n// may be escaped. The rest of the line is skipped\n// if a \"#\" character is read in. Returns true if\n// a token was loaded; false otherwise.\nfunc (l *lexer) next() (bool, error) {\n\tvar val []rune\n\tvar comment, quoted, btQuoted, inHeredoc, heredocEscaped, escaped bool\n\tvar heredocMarker string\n\n\tmakeToken := func(quoted rune) bool {\n\t\tl.token.Text = string(val)\n\t\tl.token.wasQuoted = quoted\n\t\tl.token.heredocMarker = heredocMarker\n\t\treturn true\n\t}\n\n\tfor {\n\t\t// Read a character in; if err then if we had\n\t\t// read some characters, make a token. If we\n\t\t// reached EOF, then no more tokens to read.\n\t\t// If no EOF, then we had a problem.\n\t\tch, _, err := l.reader.ReadRune()\n\t\tif err != nil {\n\t\t\tif len(val) > 0 {\n\t\t\t\tif inHeredoc {\n\t\t\t\t\treturn false, fmt.Errorf(\"incomplete heredoc <<%s on line #%d, expected ending marker %s\", heredocMarker, l.line+l.skippedLines, heredocMarker)\n\t\t\t\t}\n\n\t\t\t\treturn makeToken(0), nil\n\t\t\t}\n\t\t\tif err == io.EOF {\n\t\t\t\treturn false, nil\n\t\t\t}\n\t\t\treturn false, err\n\t\t}\n\n\t\t// detect whether we have the start of a heredoc\n\t\tif (!quoted && !btQuoted) && (!inHeredoc && !heredocEscaped) &&\n\t\t\tlen(val) > 1 && string(val[:2]) == \"<<\" {\n\t\t\t// a space means it's just a regular token and not a heredoc\n\t\t\tif ch == ' ' {\n\t\t\t\treturn makeToken(0), nil\n\t\t\t}\n\n\t\t\t// skip CR, we only care about LF\n\t\t\tif ch == '\\r' {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// after hitting a newline, we know that the heredoc marker\n\t\t\t// is the characters after the two << and the newline.\n\t\t\t// we reset the val because the heredoc is syntax we don't\n\t\t\t// want to keep.\n\t\t\tif ch == '\\n' {\n\t\t\t\tif len(val) == 2 {\n\t\t\t\t\treturn false, fmt.Errorf(\"missing opening heredoc marker on line #%d; must contain only alpha-numeric characters, dashes and underscores; got empty string\", l.line)\n\t\t\t\t}\n\n\t\t\t\t// check if there's too many <\n\t\t\t\tif string(val[:3]) == \"<<<\" {\n\t\t\t\t\treturn false, fmt.Errorf(\"too many '<' for heredoc on line #%d; only use two, for example <<END\", l.line)\n\t\t\t\t}\n\n\t\t\t\theredocMarker = string(val[2:])\n\t\t\t\tif !heredocMarkerRegexp.Match([]byte(heredocMarker)) {\n\t\t\t\t\treturn false, fmt.Errorf(\"heredoc marker on line #%d must contain only alpha-numeric characters, dashes and underscores; got '%s'\", l.line, heredocMarker)\n\t\t\t\t}\n\n\t\t\t\tinHeredoc = true\n\t\t\t\tl.skippedLines++\n\t\t\t\tval = nil\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tval = append(val, ch)\n\t\t\tcontinue\n\t\t}\n\n\t\t// if we're in a heredoc, all characters are read as-is\n\t\tif inHeredoc {\n\t\t\tval = append(val, ch)\n\n\t\t\tif ch == '\\n' {\n\t\t\t\tl.skippedLines++\n\t\t\t}\n\n\t\t\t// check if we're done, i.e. that the last few characters are the marker\n\t\t\tif len(val) >= len(heredocMarker) && heredocMarker == string(val[len(val)-len(heredocMarker):]) {\n\t\t\t\t// set the final value\n\t\t\t\tval, err = l.finalizeHeredoc(val, heredocMarker)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn false, err\n\t\t\t\t}\n\n\t\t\t\t// set the line counter, and make the token\n\t\t\t\tl.line += l.skippedLines\n\t\t\t\tl.skippedLines = 0\n\t\t\t\treturn makeToken('<'), nil\n\t\t\t}\n\n\t\t\t// stay in the heredoc until we find the ending marker\n\t\t\tcontinue\n\t\t}\n\n\t\t// track whether we found an escape '\\' for the next\n\t\t// iteration to be contextually aware\n\t\tif !escaped && !btQuoted && ch == '\\\\' {\n\t\t\tescaped = true\n\t\t\tcontinue\n\t\t}\n\n\t\tif quoted || btQuoted {\n\t\t\tif quoted && escaped {\n\t\t\t\t// all is literal in quoted area,\n\t\t\t\t// so only escape quotes\n\t\t\t\tif ch != '\"' {\n\t\t\t\t\tval = append(val, '\\\\')\n\t\t\t\t}\n\t\t\t\tescaped = false\n\t\t\t} else {\n\t\t\t\tif (quoted && ch == '\"') || (btQuoted && ch == '`') {\n\t\t\t\t\treturn makeToken(ch), nil\n\t\t\t\t}\n\t\t\t}\n\t\t\t// allow quoted text to wrap continue on multiple lines\n\t\t\tif ch == '\\n' {\n\t\t\t\tl.line += 1 + l.skippedLines\n\t\t\t\tl.skippedLines = 0\n\t\t\t}\n\t\t\t// collect this character as part of the quoted token\n\t\t\tval = append(val, ch)\n\t\t\tcontinue\n\t\t}\n\n\t\tif unicode.IsSpace(ch) {\n\t\t\t// ignore CR altogether, we only actually care about LF (\\n)\n\t\t\tif ch == '\\r' {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t// end of the line\n\t\t\tif ch == '\\n' {\n\t\t\t\t// newlines can be escaped to chain arguments\n\t\t\t\t// onto multiple lines; else, increment the line count\n\t\t\t\tif escaped {\n\t\t\t\t\tl.skippedLines++\n\t\t\t\t\tescaped = false\n\t\t\t\t} else {\n\t\t\t\t\tl.line += 1 + l.skippedLines\n\t\t\t\t\tl.skippedLines = 0\n\t\t\t\t}\n\t\t\t\t// comments (#) are single-line only\n\t\t\t\tcomment = false\n\t\t\t}\n\t\t\t// any kind of space means we're at the end of this token\n\t\t\tif len(val) > 0 {\n\t\t\t\treturn makeToken(0), nil\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// comments must be at the start of a token,\n\t\t// in other words, preceded by space or newline\n\t\tif ch == '#' && len(val) == 0 {\n\t\t\tcomment = true\n\t\t}\n\t\tif comment {\n\t\t\tcontinue\n\t\t}\n\n\t\tif len(val) == 0 {\n\t\t\tl.token = Token{Line: l.line}\n\t\t\tif ch == '\"' {\n\t\t\t\tquoted = true\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif ch == '`' {\n\t\t\t\tbtQuoted = true\n\t\t\t\tcontinue\n\t\t\t}\n\t\t}\n\n\t\tif escaped {\n\t\t\t// allow escaping the first < to skip the heredoc syntax\n\t\t\tif ch == '<' {\n\t\t\t\theredocEscaped = true\n\t\t\t} else {\n\t\t\t\tval = append(val, '\\\\')\n\t\t\t}\n\t\t\tescaped = false\n\t\t}\n\n\t\tval = append(val, ch)\n\t}\n}\n\n// finalizeHeredoc takes the runes read as the heredoc text and the marker,\n// and processes the text to strip leading whitespace, returning the final\n// value without the leading whitespace.\nfunc (l *lexer) finalizeHeredoc(val []rune, marker string) ([]rune, error) {\n\tstringVal := string(val)\n\n\t// find the last newline of the heredoc, which is where the contents end\n\tlastNewline := strings.LastIndex(stringVal, \"\\n\")\n\n\t// collapse the content, then split into separate lines\n\tlines := strings.Split(stringVal[:lastNewline+1], \"\\n\")\n\n\t// figure out how much whitespace we need to strip from the front of every line\n\t// by getting the string that precedes the marker, on the last line\n\tpaddingToStrip := stringVal[lastNewline+1 : len(stringVal)-len(marker)]\n\n\t// iterate over each line and strip the whitespace from the front\n\tvar out string\n\tfor lineNum, lineText := range lines[:len(lines)-1] {\n\t\tif lineText == \"\" || lineText == \"\\r\" {\n\t\t\tout += \"\\n\"\n\t\t\tcontinue\n\t\t}\n\n\t\t// find an exact match for the padding\n\t\tindex := strings.Index(lineText, paddingToStrip)\n\n\t\t// if the padding doesn't match exactly at the start then we can't safely strip\n\t\tif index != 0 {\n\t\t\treturn nil, fmt.Errorf(\"mismatched leading whitespace in heredoc <<%s on line #%d [%s], expected whitespace [%s] to match the closing marker\", marker, l.line+lineNum+1, lineText, paddingToStrip)\n\t\t}\n\n\t\t// strip, then append the line, with the newline, to the output.\n\t\t// also removes all \"\\r\" because Windows.\n\t\tout += strings.ReplaceAll(lineText[len(paddingToStrip):]+\"\\n\", \"\\r\", \"\")\n\t}\n\n\t// Remove the trailing newline from the loop\n\tif len(out) > 0 && out[len(out)-1] == '\\n' {\n\t\tout = out[:len(out)-1]\n\t}\n\n\t// return the final value\n\treturn []rune(out), nil\n}\n\n// Quoted returns true if the token was enclosed in quotes\n// (i.e. double quotes, backticks, or heredoc).\nfunc (t Token) Quoted() bool {\n\treturn t.wasQuoted > 0\n}\n\n// NumLineBreaks counts how many line breaks are in the token text.\nfunc (t Token) NumLineBreaks() int {\n\tlineBreaks := strings.Count(t.Text, \"\\n\")\n\tif t.wasQuoted == '<' {\n\t\t// heredocs have an extra linebreak because the opening\n\t\t// delimiter is on its own line and is not included in the\n\t\t// token Text itself, and the trailing newline is removed.\n\t\tlineBreaks += 2\n\t}\n\treturn lineBreaks\n}\n\n// Clone returns a deep copy of the token.\nfunc (t Token) Clone() Token {\n\treturn Token{\n\t\tFile:          t.File,\n\t\timports:       append([]string{}, t.imports...),\n\t\tLine:          t.Line,\n\t\tText:          t.Text,\n\t\twasQuoted:     t.wasQuoted,\n\t\theredocMarker: t.heredocMarker,\n\t\tsnippetName:   t.snippetName,\n\t}\n}\n\nvar heredocMarkerRegexp = regexp.MustCompile(\"^[A-Za-z0-9_-]+$\")\n\n// isNextOnNewLine tests whether t2 is on a different line from t1\nfunc isNextOnNewLine(t1, t2 Token) bool {\n\t// If the second token is from a different file,\n\t// we can assume it's from a different line\n\tif t1.File != t2.File {\n\t\treturn true\n\t}\n\n\t// If the second token is from a different import chain,\n\t// we can assume it's from a different line\n\tif len(t1.imports) != len(t2.imports) {\n\t\treturn true\n\t}\n\tfor i, im := range t1.imports {\n\t\tif im != t2.imports[i] {\n\t\t\treturn true\n\t\t}\n\t}\n\n\t// If the first token (incl line breaks) ends\n\t// on a line earlier than the next token,\n\t// then the second token is on a new line\n\treturn t1.Line+t1.NumLineBreaks() < t2.Line\n}\n",
    "source_file": "caddyconfig/caddyfile/lexer.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build gofuzz\n\npackage caddyfile\n\nfunc FuzzTokenize(input []byte) int {\n\ttokens, err := Tokenize(input, \"Caddyfile\")\n\tif err != nil {\n\t\treturn 0\n\t}\n\tif len(tokens) == 0 {\n\t\treturn -1\n\t}\n\treturn 1\n}\n",
    "source_file": "caddyconfig/caddyfile/lexer_fuzz.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyfile\n\nimport (\n\t\"regexp\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// parseVariadic determines if the token is a variadic placeholder,\n// and if so, determines the index range (start/end) of args to use.\n// Returns a boolean signaling whether a variadic placeholder was found,\n// and the start and end indices.\nfunc parseVariadic(token Token, argCount int) (bool, int, int) {\n\tif !strings.HasPrefix(token.Text, \"{args[\") {\n\t\treturn false, 0, 0\n\t}\n\tif !strings.HasSuffix(token.Text, \"]}\") {\n\t\treturn false, 0, 0\n\t}\n\n\targRange := strings.TrimSuffix(strings.TrimPrefix(token.Text, \"{args[\"), \"]}\")\n\tif argRange == \"\" {\n\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\"Placeholder \"+token.Text+\" cannot have an empty index\",\n\t\t\tzap.String(\"file\", token.File+\":\"+strconv.Itoa(token.Line)), zap.Strings(\"import_chain\", token.imports))\n\t\treturn false, 0, 0\n\t}\n\n\tstart, end, found := strings.Cut(argRange, \":\")\n\n\t// If no \":\" delimiter is found, this is not a variadic.\n\t// The replacer will pick this up.\n\tif !found {\n\t\treturn false, 0, 0\n\t}\n\n\t// A valid token may contain several placeholders, and\n\t// they may be separated by \":\". It's not variadic.\n\t// https://github.com/caddyserver/caddy/issues/5716\n\tif strings.Contains(start, \"}\") || strings.Contains(end, \"{\") {\n\t\treturn false, 0, 0\n\t}\n\n\tvar (\n\t\tstartIndex = 0\n\t\tendIndex   = argCount\n\t\terr        error\n\t)\n\tif start != \"\" {\n\t\tstartIndex, err = strconv.Atoi(start)\n\t\tif err != nil {\n\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\t\"Variadic placeholder \"+token.Text+\" has an invalid start index\",\n\t\t\t\tzap.String(\"file\", token.File+\":\"+strconv.Itoa(token.Line)), zap.Strings(\"import_chain\", token.imports))\n\t\t\treturn false, 0, 0\n\t\t}\n\t}\n\tif end != \"\" {\n\t\tendIndex, err = strconv.Atoi(end)\n\t\tif err != nil {\n\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\t\"Variadic placeholder \"+token.Text+\" has an invalid end index\",\n\t\t\t\tzap.String(\"file\", token.File+\":\"+strconv.Itoa(token.Line)), zap.Strings(\"import_chain\", token.imports))\n\t\t\treturn false, 0, 0\n\t\t}\n\t}\n\n\t// bound check\n\tif startIndex < 0 || startIndex > endIndex || endIndex > argCount {\n\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\"Variadic placeholder \"+token.Text+\" indices are out of bounds, only \"+strconv.Itoa(argCount)+\" argument(s) exist\",\n\t\t\tzap.String(\"file\", token.File+\":\"+strconv.Itoa(token.Line)), zap.Strings(\"import_chain\", token.imports))\n\t\treturn false, 0, 0\n\t}\n\treturn true, startIndex, endIndex\n}\n\n// makeArgsReplacer prepares a Replacer which can replace\n// non-variadic args placeholders in imported tokens.\nfunc makeArgsReplacer(args []string) *caddy.Replacer {\n\trepl := caddy.NewEmptyReplacer()\n\trepl.Map(func(key string) (any, bool) {\n\t\t// TODO: Remove the deprecated {args.*} placeholder\n\t\t// support at some point in the future\n\t\tif matches := argsRegexpIndexDeprecated.FindStringSubmatch(key); len(matches) > 0 {\n\t\t\t// What's matched may be a substring of the key\n\t\t\tif matches[0] != key {\n\t\t\t\treturn nil, false\n\t\t\t}\n\n\t\t\tvalue, err := strconv.Atoi(matches[1])\n\t\t\tif err != nil {\n\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\t\t\"Placeholder {args.\" + matches[1] + \"} has an invalid index\")\n\t\t\t\treturn nil, false\n\t\t\t}\n\t\t\tif value >= len(args) {\n\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\t\t\"Placeholder {args.\" + matches[1] + \"} index is out of bounds, only \" + strconv.Itoa(len(args)) + \" argument(s) exist\")\n\t\t\t\treturn nil, false\n\t\t\t}\n\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\t\"Placeholder {args.\" + matches[1] + \"} deprecated, use {args[\" + matches[1] + \"]} instead\")\n\t\t\treturn args[value], true\n\t\t}\n\n\t\t// Handle args[*] form\n\t\tif matches := argsRegexpIndex.FindStringSubmatch(key); len(matches) > 0 {\n\t\t\t// What's matched may be a substring of the key\n\t\t\tif matches[0] != key {\n\t\t\t\treturn nil, false\n\t\t\t}\n\n\t\t\tif strings.Contains(matches[1], \":\") {\n\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\t\t\"Variadic placeholder {args[\" + matches[1] + \"]} must be a token on its own\")\n\t\t\t\treturn nil, false\n\t\t\t}\n\t\t\tvalue, err := strconv.Atoi(matches[1])\n\t\t\tif err != nil {\n\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\t\t\"Placeholder {args[\" + matches[1] + \"]} has an invalid index\")\n\t\t\t\treturn nil, false\n\t\t\t}\n\t\t\tif value >= len(args) {\n\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\n\t\t\t\t\t\"Placeholder {args[\" + matches[1] + \"]} index is out of bounds, only \" + strconv.Itoa(len(args)) + \" argument(s) exist\")\n\t\t\t\treturn nil, false\n\t\t\t}\n\t\t\treturn args[value], true\n\t\t}\n\n\t\t// Not an args placeholder, ignore\n\t\treturn nil, false\n\t})\n\treturn repl\n}\n\nvar (\n\targsRegexpIndexDeprecated = regexp.MustCompile(`args\\.(.+)`)\n\targsRegexpIndex           = regexp.MustCompile(`args\\[(.+)]`)\n)\n",
    "source_file": "caddyconfig/caddyfile/importargs.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage caddyfile\n\nimport (\n\t\"bytes\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n)\n\n// Parse parses the input just enough to group tokens, in\n// order, by server block. No further parsing is performed.\n// Server blocks are returned in the order in which they appear.\n// Directives that do not appear in validDirectives will cause\n// an error. If you do not want to check for valid directives,\n// pass in nil instead.\n//\n// Environment variables in {$ENVIRONMENT_VARIABLE} notation\n// will be replaced before parsing begins.\nfunc Parse(filename string, input []byte) ([]ServerBlock, error) {\n\t// unfortunately, we must copy the input because parsing must\n\t// remain a read-only operation, but we have to expand environment\n\t// variables before we parse, which changes the underlying array (#4422)\n\tinputCopy := make([]byte, len(input))\n\tcopy(inputCopy, input)\n\n\ttokens, err := allTokens(filename, inputCopy)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tp := parser{\n\t\tDispenser: NewDispenser(tokens),\n\t\timportGraph: importGraph{\n\t\t\tnodes: make(map[string]struct{}),\n\t\t\tedges: make(adjacency),\n\t\t},\n\t}\n\treturn p.parseAll()\n}\n\n// allTokens lexes the entire input, but does not parse it.\n// It returns all the tokens from the input, unstructured\n// and in order. It may mutate input as it expands env vars.\nfunc allTokens(filename string, input []byte) ([]Token, error) {\n\treturn Tokenize(replaceEnvVars(input), filename)\n}\n\n// replaceEnvVars replaces all occurrences of environment variables.\n// It mutates the underlying array and returns the updated slice.\nfunc replaceEnvVars(input []byte) []byte {\n\tvar offset int\n\tfor {\n\t\tbegin := bytes.Index(input[offset:], spanOpen)\n\t\tif begin < 0 {\n\t\t\tbreak\n\t\t}\n\t\tbegin += offset // make beginning relative to input, not offset\n\t\tend := bytes.Index(input[begin+len(spanOpen):], spanClose)\n\t\tif end < 0 {\n\t\t\tbreak\n\t\t}\n\t\tend += begin + len(spanOpen) // make end relative to input, not begin\n\n\t\t// get the name; if there is no name, skip it\n\t\tenvString := input[begin+len(spanOpen) : end]\n\t\tif len(envString) == 0 {\n\t\t\toffset = end + len(spanClose)\n\t\t\tcontinue\n\t\t}\n\n\t\t// split the string into a key and an optional default\n\t\tenvParts := strings.SplitN(string(envString), envVarDefaultDelimiter, 2)\n\n\t\t// do a lookup for the env var, replace with the default if not found\n\t\tenvVarValue, found := os.LookupEnv(envParts[0])\n\t\tif !found && len(envParts) == 2 {\n\t\t\tenvVarValue = envParts[1]\n\t\t}\n\n\t\t// get the value of the environment variable\n\t\t// note that this causes one-level deep chaining\n\t\tenvVarBytes := []byte(envVarValue)\n\n\t\t// splice in the value\n\t\tinput = append(input[:begin],\n\t\t\tappend(envVarBytes, input[end+len(spanClose):]...)...)\n\n\t\t// continue at the end of the replacement\n\t\toffset = begin + len(envVarBytes)\n\t}\n\treturn input\n}\n\ntype parser struct {\n\t*Dispenser\n\tblock           ServerBlock // current server block being parsed\n\teof             bool        // if we encounter a valid EOF in a hard place\n\tdefinedSnippets map[string][]Token\n\tnesting         int\n\timportGraph     importGraph\n}\n\nfunc (p *parser) parseAll() ([]ServerBlock, error) {\n\tvar blocks []ServerBlock\n\n\tfor p.Next() {\n\t\terr := p.parseOne()\n\t\tif err != nil {\n\t\t\treturn blocks, err\n\t\t}\n\t\tif len(p.block.Keys) > 0 || len(p.block.Segments) > 0 {\n\t\t\tblocks = append(blocks, p.block)\n\t\t}\n\t\tif p.nesting > 0 {\n\t\t\treturn blocks, p.EOFErr()\n\t\t}\n\t}\n\n\treturn blocks, nil\n}\n\nfunc (p *parser) parseOne() error {\n\tp.block = ServerBlock{}\n\treturn p.begin()\n}\n\nfunc (p *parser) begin() error {\n\tif len(p.tokens) == 0 {\n\t\treturn nil\n\t}\n\n\terr := p.addresses()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\tif p.eof {\n\t\t// this happens if the Caddyfile consists of only\n\t\t// a line of addresses and nothing else\n\t\treturn nil\n\t}\n\n\tif ok, name := p.isNamedRoute(); ok {\n\t\t// we just need a dummy leading token to ease parsing later\n\t\tnameToken := p.Token()\n\t\tnameToken.Text = name\n\n\t\t// named routes only have one key, the route name\n\t\tp.block.Keys = []Token{nameToken}\n\t\tp.block.IsNamedRoute = true\n\n\t\t// get all the tokens from the block, including the braces\n\t\ttokens, err := p.blockTokens(true)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\ttokens = append([]Token{nameToken}, tokens...)\n\t\tp.block.Segments = []Segment{tokens}\n\t\treturn nil\n\t}\n\n\tif ok, name := p.isSnippet(); ok {\n\t\tif p.definedSnippets == nil {\n\t\t\tp.definedSnippets = map[string][]Token{}\n\t\t}\n\t\tif _, found := p.definedSnippets[name]; found {\n\t\t\treturn p.Errf(\"redeclaration of previously declared snippet %s\", name)\n\t\t}\n\t\t// consume all tokens til matched close brace\n\t\ttokens, err := p.blockTokens(false)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Just as we need to track which file the token comes from, we need to\n\t\t// keep track of which snippet the token comes from. This is helpful\n\t\t// in tracking import cycles across files/snippets by namespacing them.\n\t\t// Without this, we end up with false-positives in cycle-detection.\n\t\tfor k, v := range tokens {\n\t\t\tv.snippetName = name\n\t\t\ttokens[k] = v\n\t\t}\n\t\tp.definedSnippets[name] = tokens\n\t\t// empty block keys so we don't save this block as a real server.\n\t\tp.block.Keys = nil\n\t\treturn nil\n\t}\n\n\treturn p.blockContents()\n}\n\nfunc (p *parser) addresses() error {\n\tvar expectingAnother bool\n\n\tfor {\n\t\tvalue := p.Val()\n\t\ttoken := p.Token()\n\n\t\t// Reject request matchers if trying to define them globally\n\t\tif strings.HasPrefix(value, \"@\") {\n\t\t\treturn p.Errf(\"request matchers may not be defined globally, they must be in a site block; found %s\", value)\n\t\t}\n\n\t\t// Special case: import directive replaces tokens during parse-time\n\t\tif value == \"import\" && p.isNewLine() {\n\t\t\terr := p.doImport(0)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\t// Open brace definitely indicates end of addresses\n\t\tif value == \"{\" {\n\t\t\tif expectingAnother {\n\t\t\t\treturn p.Errf(\"Expected another address but had '%s' - check for extra comma\", value)\n\t\t\t}\n\t\t\t// Mark this server block as being defined with braces.\n\t\t\t// This is used to provide a better error message when\n\t\t\t// the user may have tried to define two server blocks\n\t\t\t// without having used braces, which are required in\n\t\t\t// that case.\n\t\t\tp.block.HasBraces = true\n\t\t\tbreak\n\t\t}\n\n\t\t// Users commonly forget to place a space between the address and the '{'\n\t\tif strings.HasSuffix(value, \"{\") {\n\t\t\treturn p.Errf(\"Site addresses cannot end with a curly brace: '%s' - put a space between the token and the brace\", value)\n\t\t}\n\n\t\tif value != \"\" { // empty token possible if user typed \"\"\n\t\t\t// Trailing comma indicates another address will follow, which\n\t\t\t// may possibly be on the next line\n\t\t\tif value[len(value)-1] == ',' {\n\t\t\t\tvalue = value[:len(value)-1]\n\t\t\t\texpectingAnother = true\n\t\t\t} else {\n\t\t\t\texpectingAnother = false // but we may still see another one on this line\n\t\t\t}\n\n\t\t\t// If there's a comma here, it's probably because they didn't use a space\n\t\t\t// between their two domains, e.g. \"foo.com,bar.com\", which would not be\n\t\t\t// parsed as two separate site addresses.\n\t\t\tif strings.Contains(value, \",\") {\n\t\t\t\treturn p.Errf(\"Site addresses cannot contain a comma ',': '%s' - put a space after the comma to separate site addresses\", value)\n\t\t\t}\n\n\t\t\t// After the above, a comma surrounded by spaces would result\n\t\t\t// in an empty token which we should ignore\n\t\t\tif value != \"\" {\n\t\t\t\t// Add the token as a site address\n\t\t\t\ttoken.Text = value\n\t\t\t\tp.block.Keys = append(p.block.Keys, token)\n\t\t\t}\n\t\t}\n\n\t\t// Advance token and possibly break out of loop or return error\n\t\thasNext := p.Next()\n\t\tif expectingAnother && !hasNext {\n\t\t\treturn p.EOFErr()\n\t\t}\n\t\tif !hasNext {\n\t\t\tp.eof = true\n\t\t\tbreak // EOF\n\t\t}\n\t\tif !expectingAnother && p.isNewLine() {\n\t\t\tbreak\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc (p *parser) blockContents() error {\n\terrOpenCurlyBrace := p.openCurlyBrace()\n\tif errOpenCurlyBrace != nil {\n\t\t// single-server configs don't need curly braces\n\t\tp.cursor--\n\t}\n\n\terr := p.directives()\n\tif err != nil {\n\t\treturn err\n\t}\n\n\t// only look for close curly brace if there was an opening\n\tif errOpenCurlyBrace == nil {\n\t\terr = p.closeCurlyBrace()\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// directives parses through all the lines for directives\n// and it expects the next token to be the first\n// directive. It goes until EOF or closing curly brace\n// which ends the server block.\nfunc (p *parser) directives() error {\n\tfor p.Next() {\n\t\t// end of server block\n\t\tif p.Val() == \"}\" {\n\t\t\t// p.nesting has already been decremented\n\t\t\tbreak\n\t\t}\n\n\t\t// special case: import directive replaces tokens during parse-time\n\t\tif p.Val() == \"import\" {\n\t\t\terr := p.doImport(1)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tp.cursor-- // cursor is advanced when we continue, so roll back one more\n\t\t\tcontinue\n\t\t}\n\n\t\t// normal case: parse a directive as a new segment\n\t\t// (a \"segment\" is a line which starts with a directive\n\t\t// and which ends at the end of the line or at the end of\n\t\t// the block that is opened at the end of the line)\n\t\tif err := p.directive(); err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// doImport swaps out the import directive and its argument\n// (a total of 2 tokens) with the tokens in the specified file\n// or globbing pattern. When the function returns, the cursor\n// is on the token before where the import directive was. In\n// other words, call Next() to access the first token that was\n// imported.\nfunc (p *parser) doImport(nesting int) error {\n\t// syntax checks\n\tif !p.NextArg() {\n\t\treturn p.ArgErr()\n\t}\n\timportPattern := p.Val()\n\tif importPattern == \"\" {\n\t\treturn p.Err(\"Import requires a non-empty filepath\")\n\t}\n\n\t// grab remaining args as placeholder replacements\n\targs := p.RemainingArgs()\n\n\t// set up a replacer for non-variadic args replacement\n\trepl := makeArgsReplacer(args)\n\n\t// grab all the tokens (if it exists) from within a block that follows the import\n\tvar blockTokens []Token\n\tfor currentNesting := p.Nesting(); p.NextBlock(currentNesting); {\n\t\tblockTokens = append(blockTokens, p.Token())\n\t}\n\t// initialize with size 1\n\tblockMapping := make(map[string][]Token, 1)\n\tif len(blockTokens) > 0 {\n\t\t// use such tokens to create a new dispenser, and then use it to parse each block\n\t\tbd := NewDispenser(blockTokens)\n\t\tfor bd.Next() {\n\t\t\t// see if we can grab a key\n\t\t\tvar currentMappingKey string\n\t\t\tif bd.Val() == \"{\" {\n\t\t\t\treturn p.Err(\"anonymous blocks are not supported\")\n\t\t\t}\n\t\t\tcurrentMappingKey = bd.Val()\n\t\t\tcurrentMappingTokens := []Token{}\n\t\t\t// read all args until end of line / {\n\t\t\tif bd.NextArg() {\n\t\t\t\tcurrentMappingTokens = append(currentMappingTokens, bd.Token())\n\t\t\t\tfor bd.NextArg() {\n\t\t\t\t\tcurrentMappingTokens = append(currentMappingTokens, bd.Token())\n\t\t\t\t}\n\t\t\t\t// TODO(elee1766): we don't enter another mapping here because it's annoying to extract the { and } properly.\n\t\t\t\t// maybe someone can do that in the future\n\t\t\t} else {\n\t\t\t\t// attempt to enter a block and add tokens to the currentMappingTokens\n\t\t\t\tfor mappingNesting := bd.Nesting(); bd.NextBlock(mappingNesting); {\n\t\t\t\t\tcurrentMappingTokens = append(currentMappingTokens, bd.Token())\n\t\t\t\t}\n\t\t\t}\n\t\t\tblockMapping[currentMappingKey] = currentMappingTokens\n\t\t}\n\t}\n\n\t// splice out the import directive and its arguments\n\t// (2 tokens, plus the length of args)\n\ttokensBefore := p.tokens[:p.cursor-1-len(args)-len(blockTokens)]\n\ttokensAfter := p.tokens[p.cursor+1:]\n\tvar importedTokens []Token\n\tvar nodes []string\n\n\t// first check snippets. That is a simple, non-recursive replacement\n\tif p.definedSnippets != nil && p.definedSnippets[importPattern] != nil {\n\t\timportedTokens = p.definedSnippets[importPattern]\n\t\tif len(importedTokens) > 0 {\n\t\t\t// just grab the first one\n\t\t\tnodes = append(nodes, fmt.Sprintf(\"%s:%s\", importedTokens[0].File, importedTokens[0].snippetName))\n\t\t}\n\t} else {\n\t\t// make path relative to the file of the _token_ being processed rather\n\t\t// than current working directory (issue #867) and then use glob to get\n\t\t// list of matching filenames\n\t\tabsFile, err := caddy.FastAbs(p.Dispenser.File())\n\t\tif err != nil {\n\t\t\treturn p.Errf(\"Failed to get absolute path of file: %s: %v\", p.Dispenser.File(), err)\n\t\t}\n\n\t\tvar matches []string\n\t\tvar globPattern string\n\t\tif !filepath.IsAbs(importPattern) {\n\t\t\tglobPattern = filepath.Join(filepath.Dir(absFile), importPattern)\n\t\t} else {\n\t\t\tglobPattern = importPattern\n\t\t}\n\t\tif strings.Count(globPattern, \"*\") > 1 || strings.Count(globPattern, \"?\") > 1 ||\n\t\t\t(strings.Contains(globPattern, \"[\") && strings.Contains(globPattern, \"]\")) {\n\t\t\t// See issue #2096 - a pattern with many glob expansions can hang for too long\n\t\t\treturn p.Errf(\"Glob pattern may only contain one wildcard (*), but has others: %s\", globPattern)\n\t\t}\n\t\tmatches, err = filepath.Glob(globPattern)\n\t\tif err != nil {\n\t\t\treturn p.Errf(\"Failed to use import pattern %s: %v\", importPattern, err)\n\t\t}\n\t\tif len(matches) == 0 {\n\t\t\tif strings.ContainsAny(globPattern, \"*?[]\") {\n\t\t\t\tcaddy.Log().Warn(\"No files matching import glob pattern\", zap.String(\"pattern\", importPattern))\n\t\t\t} else {\n\t\t\t\treturn p.Errf(\"File to import not found: %s\", importPattern)\n\t\t\t}\n\t\t} else {\n\t\t\t// See issue #5295 - should skip any files that start with a . when iterating over them.\n\t\t\tsep := string(filepath.Separator)\n\t\t\tsegGlobPattern := strings.Split(globPattern, sep)\n\t\t\tif strings.HasPrefix(segGlobPattern[len(segGlobPattern)-1], \"*\") {\n\t\t\t\tvar tmpMatches []string\n\t\t\t\tfor _, m := range matches {\n\t\t\t\t\tseg := strings.Split(m, sep)\n\t\t\t\t\tif !strings.HasPrefix(seg[len(seg)-1], \".\") {\n\t\t\t\t\t\ttmpMatches = append(tmpMatches, m)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tmatches = tmpMatches\n\t\t\t}\n\t\t}\n\n\t\t// collect all the imported tokens\n\t\tfor _, importFile := range matches {\n\t\t\tnewTokens, err := p.doSingleImport(importFile)\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\timportedTokens = append(importedTokens, newTokens...)\n\t\t}\n\t\tnodes = matches\n\t}\n\n\tnodeName := p.File()\n\tif p.Token().snippetName != \"\" {\n\t\tnodeName += fmt.Sprintf(\":%s\", p.Token().snippetName)\n\t}\n\tp.importGraph.addNode(nodeName)\n\tp.importGraph.addNodes(nodes)\n\tif err := p.importGraph.addEdges(nodeName, nodes); err != nil {\n\t\tp.importGraph.removeNodes(nodes)\n\t\treturn err\n\t}\n\n\t// copy the tokens so we don't overwrite p.definedSnippets\n\ttokensCopy := make([]Token, 0, len(importedTokens))\n\n\tvar (\n\t\tmaybeSnippet   bool\n\t\tmaybeSnippetId bool\n\t\tindex          int\n\t)\n\n\t// run the argument replacer on the tokens\n\t// golang for range slice return a copy of value\n\t// similarly, append also copy value\n\tfor i, token := range importedTokens {\n\t\t// update the token's imports to refer to import directive filename, line number and snippet name if there is one\n\t\tif token.snippetName != \"\" {\n\t\t\ttoken.imports = append(token.imports, fmt.Sprintf(\"%s:%d (import %s)\", p.File(), p.Line(), token.snippetName))\n\t\t} else {\n\t\t\ttoken.imports = append(token.imports, fmt.Sprintf(\"%s:%d (import)\", p.File(), p.Line()))\n\t\t}\n\n\t\t// naive way of determine snippets, as snippets definition can only follow name + block\n\t\t// format, won't check for nesting correctness or any other error, that's what parser does.\n\t\tif !maybeSnippet && nesting == 0 {\n\t\t\t// first of the line\n\t\t\tif i == 0 || isNextOnNewLine(tokensCopy[i-1], token) {\n\t\t\t\tindex = 0\n\t\t\t} else {\n\t\t\t\tindex++\n\t\t\t}\n\n\t\t\tif index == 0 && len(token.Text) >= 3 && strings.HasPrefix(token.Text, \"(\") && strings.HasSuffix(token.Text, \")\") {\n\t\t\t\tmaybeSnippetId = true\n\t\t\t}\n\t\t}\n\n\t\tswitch token.Text {\n\t\tcase \"{\":\n\t\t\tnesting++\n\t\t\tif index == 1 && maybeSnippetId && nesting == 1 {\n\t\t\t\tmaybeSnippet = true\n\t\t\t\tmaybeSnippetId = false\n\t\t\t}\n\t\tcase \"}\":\n\t\t\tnesting--\n\t\t\tif nesting == 0 && maybeSnippet {\n\t\t\t\tmaybeSnippet = false\n\t\t\t}\n\t\t}\n\t\t// if it is {block}, we substitute with all tokens in the block\n\t\t// if it is {blocks.*}, we substitute with the tokens in the mapping for the *\n\t\tvar skip bool\n\t\tvar tokensToAdd []Token\n\t\tswitch {\n\t\tcase token.Text == \"{block}\":\n\t\t\ttokensToAdd = blockTokens\n\t\tcase strings.HasPrefix(token.Text, \"{blocks.\") && strings.HasSuffix(token.Text, \"}\"):\n\t\t\t// {blocks.foo.bar} will be extracted to key `foo.bar`\n\t\t\tblockKey := strings.TrimPrefix(strings.TrimSuffix(token.Text, \"}\"), \"{blocks.\")\n\t\t\tval, ok := blockMapping[blockKey]\n\t\t\tif ok {\n\t\t\t\ttokensToAdd = val\n\t\t\t}\n\t\tdefault:\n\t\t\tskip = true\n\t\t}\n\t\tif !skip {\n\t\t\tif len(tokensToAdd) == 0 {\n\t\t\t\t// if there is no content in the snippet block, don't do any replacement\n\t\t\t\t// this allows snippets which contained {block}/{block.*} before this change to continue functioning as normal\n\t\t\t\ttokensCopy = append(tokensCopy, token)\n\t\t\t} else {\n\t\t\t\ttokensCopy = append(tokensCopy, tokensToAdd...)\n\t\t\t}\n\t\t\tcontinue\n\t\t}\n\n\t\tif maybeSnippet {\n\t\t\ttokensCopy = append(tokensCopy, token)\n\t\t\tcontinue\n\t\t}\n\n\t\tfoundVariadic, startIndex, endIndex := parseVariadic(token, len(args))\n\t\tif foundVariadic {\n\t\t\tfor _, arg := range args[startIndex:endIndex] {\n\t\t\t\ttoken.Text = arg\n\t\t\t\ttokensCopy = append(tokensCopy, token)\n\t\t\t}\n\t\t} else {\n\t\t\ttoken.Text = repl.ReplaceKnown(token.Text, \"\")\n\t\t\ttokensCopy = append(tokensCopy, token)\n\t\t}\n\t}\n\n\t// splice the imported tokens in the place of the import statement\n\t// and rewind cursor so Next() will land on first imported token\n\tp.tokens = append(tokensBefore, append(tokensCopy, tokensAfter...)...)\n\tp.cursor -= len(args) + len(blockTokens) + 1\n\n\treturn nil\n}\n\n// doSingleImport lexes the individual file at importFile and returns\n// its tokens or an error, if any.\nfunc (p *parser) doSingleImport(importFile string) ([]Token, error) {\n\tfile, err := os.Open(importFile)\n\tif err != nil {\n\t\treturn nil, p.Errf(\"Could not import %s: %v\", importFile, err)\n\t}\n\tdefer file.Close()\n\n\tif info, err := file.Stat(); err != nil {\n\t\treturn nil, p.Errf(\"Could not import %s: %v\", importFile, err)\n\t} else if info.IsDir() {\n\t\treturn nil, p.Errf(\"Could not import %s: is a directory\", importFile)\n\t}\n\n\tinput, err := io.ReadAll(file)\n\tif err != nil {\n\t\treturn nil, p.Errf(\"Could not read imported file %s: %v\", importFile, err)\n\t}\n\n\t// only warning in case of empty files\n\tif len(input) == 0 || len(strings.TrimSpace(string(input))) == 0 {\n\t\tcaddy.Log().Warn(\"Import file is empty\", zap.String(\"file\", importFile))\n\t\treturn []Token{}, nil\n\t}\n\n\timportedTokens, err := allTokens(importFile, input)\n\tif err != nil {\n\t\treturn nil, p.Errf(\"Could not read tokens while importing %s: %v\", importFile, err)\n\t}\n\n\t// Tack the file path onto these tokens so errors show the imported file's name\n\t// (we use full, absolute path to avoid bugs: issue #1892)\n\tfilename, err := caddy.FastAbs(importFile)\n\tif err != nil {\n\t\treturn nil, p.Errf(\"Failed to get absolute path of file: %s: %v\", importFile, err)\n\t}\n\tfor i := 0; i < len(importedTokens); i++ {\n\t\timportedTokens[i].File = filename\n\t}\n\n\treturn importedTokens, nil\n}\n\n// directive collects tokens until the directive's scope\n// closes (either end of line or end of curly brace block).\n// It expects the currently-loaded token to be a directive\n// (or } that ends a server block). The collected tokens\n// are loaded into the current server block for later use\n// by directive setup functions.\nfunc (p *parser) directive() error {\n\t// a segment is a list of tokens associated with this directive\n\tvar segment Segment\n\n\t// the directive itself is appended as a relevant token\n\tsegment = append(segment, p.Token())\n\n\tfor p.Next() {\n\t\tif p.Val() == \"{\" {\n\t\t\tp.nesting++\n\t\t\tif !p.isNextOnNewLine() && p.Token().wasQuoted == 0 {\n\t\t\t\treturn p.Err(\"Unexpected next token after '{' on same line\")\n\t\t\t}\n\t\t\tif p.isNewLine() {\n\t\t\t\treturn p.Err(\"Unexpected '{' on a new line; did you mean to place the '{' on the previous line?\")\n\t\t\t}\n\t\t} else if p.Val() == \"{}\" {\n\t\t\tif p.isNextOnNewLine() && p.Token().wasQuoted == 0 {\n\t\t\t\treturn p.Err(\"Unexpected '{}' at end of line\")\n\t\t\t}\n\t\t} else if p.isNewLine() && p.nesting == 0 {\n\t\t\tp.cursor-- // read too far\n\t\t\tbreak\n\t\t} else if p.Val() == \"}\" && p.nesting > 0 {\n\t\t\tp.nesting--\n\t\t} else if p.Val() == \"}\" && p.nesting == 0 {\n\t\t\treturn p.Err(\"Unexpected '}' because no matching opening brace\")\n\t\t} else if p.Val() == \"import\" && p.isNewLine() {\n\t\t\tif err := p.doImport(1); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\tp.cursor-- // cursor is advanced when we continue, so roll back one more\n\t\t\tcontinue\n\t\t}\n\n\t\tsegment = append(segment, p.Token())\n\t}\n\n\tp.block.Segments = append(p.block.Segments, segment)\n\n\tif p.nesting > 0 {\n\t\treturn p.EOFErr()\n\t}\n\n\treturn nil\n}\n\n// openCurlyBrace expects the current token to be an\n// opening curly brace. This acts like an assertion\n// because it returns an error if the token is not\n// a opening curly brace. It does NOT advance the token.\nfunc (p *parser) openCurlyBrace() error {\n\tif p.Val() != \"{\" {\n\t\treturn p.SyntaxErr(\"{\")\n\t}\n\treturn nil\n}\n\n// closeCurlyBrace expects the current token to be\n// a closing curly brace. This acts like an assertion\n// because it returns an error if the token is not\n// a closing curly brace. It does NOT advance the token.\nfunc (p *parser) closeCurlyBrace() error {\n\tif p.Val() != \"}\" {\n\t\treturn p.SyntaxErr(\"}\")\n\t}\n\treturn nil\n}\n\nfunc (p *parser) isNamedRoute() (bool, string) {\n\tkeys := p.block.Keys\n\t// A named route block is a single key with parens, prefixed with &.\n\tif len(keys) == 1 && strings.HasPrefix(keys[0].Text, \"&(\") && strings.HasSuffix(keys[0].Text, \")\") {\n\t\treturn true, strings.TrimSuffix(keys[0].Text[2:], \")\")\n\t}\n\treturn false, \"\"\n}\n\nfunc (p *parser) isSnippet() (bool, string) {\n\tkeys := p.block.Keys\n\t// A snippet block is a single key with parens. Nothing else qualifies.\n\tif len(keys) == 1 && strings.HasPrefix(keys[0].Text, \"(\") && strings.HasSuffix(keys[0].Text, \")\") {\n\t\treturn true, strings.TrimSuffix(keys[0].Text[1:], \")\")\n\t}\n\treturn false, \"\"\n}\n\n// read and store everything in a block for later replay.\nfunc (p *parser) blockTokens(retainCurlies bool) ([]Token, error) {\n\t// block must have curlies.\n\terr := p.openCurlyBrace()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tnesting := 1 // count our own nesting\n\ttokens := []Token{}\n\tif retainCurlies {\n\t\ttokens = append(tokens, p.Token())\n\t}\n\tfor p.Next() {\n\t\tif p.Val() == \"}\" {\n\t\t\tnesting--\n\t\t\tif nesting == 0 {\n\t\t\t\tif retainCurlies {\n\t\t\t\t\ttokens = append(tokens, p.Token())\n\t\t\t\t}\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif p.Val() == \"{\" {\n\t\t\tnesting++\n\t\t}\n\t\ttokens = append(tokens, p.tokens[p.cursor])\n\t}\n\t// make sure we're matched up\n\tif nesting != 0 {\n\t\treturn nil, p.SyntaxErr(\"}\")\n\t}\n\treturn tokens, nil\n}\n\n// ServerBlock associates any number of keys from the\n// head of the server block with tokens, which are\n// grouped by segments.\ntype ServerBlock struct {\n\tHasBraces    bool\n\tKeys         []Token\n\tSegments     []Segment\n\tIsNamedRoute bool\n}\n\nfunc (sb ServerBlock) GetKeysText() []string {\n\tres := []string{}\n\tfor _, k := range sb.Keys {\n\t\tres = append(res, k.Text)\n\t}\n\treturn res\n}\n\n// DispenseDirective returns a dispenser that contains\n// all the tokens in the server block.\nfunc (sb ServerBlock) DispenseDirective(dir string) *Dispenser {\n\tvar tokens []Token\n\tfor _, seg := range sb.Segments {\n\t\tif len(seg) > 0 && seg[0].Text == dir {\n\t\t\ttokens = append(tokens, seg...)\n\t\t}\n\t}\n\treturn NewDispenser(tokens)\n}\n\n// Segment is a list of tokens which begins with a directive\n// and ends at the end of the directive (either at the end of\n// the line, or at the end of a block it opens).\ntype Segment []Token\n\n// Directive returns the directive name for the segment.\n// The directive name is the text of the first token.\nfunc (s Segment) Directive() string {\n\tif len(s) > 0 {\n\t\treturn s[0].Text\n\t}\n\treturn \"\"\n}\n\n// spanOpen and spanClose are used to bound spans that\n// contain the name of an environment variable.\nvar (\n\tspanOpen, spanClose    = []byte{'{', '$'}, []byte{'}'}\n\tenvVarDefaultDelimiter = \":\"\n)\n",
    "source_file": "caddyconfig/caddyfile/parse.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage httpcaddyfile\n\nimport (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"slices\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/mholt/acmez/v3/acme\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\nfunc (st ServerType) buildTLSApp(\n\tpairings []sbAddrAssociation,\n\toptions map[string]any,\n\twarnings []caddyconfig.Warning,\n) (*caddytls.TLS, []caddyconfig.Warning, error) {\n\ttlsApp := &caddytls.TLS{CertificatesRaw: make(caddy.ModuleMap)}\n\tvar certLoaders []caddytls.CertificateLoader\n\n\thttpPort := strconv.Itoa(caddyhttp.DefaultHTTPPort)\n\tif hp, ok := options[\"http_port\"].(int); ok {\n\t\thttpPort = strconv.Itoa(hp)\n\t}\n\tautoHTTPS := []string{}\n\tif ah, ok := options[\"auto_https\"].([]string); ok {\n\t\tautoHTTPS = ah\n\t}\n\n\t// find all hosts that share a server block with a hostless\n\t// key, so that they don't get forgotten/omitted by auto-HTTPS\n\t// (since they won't appear in route matchers)\n\thttpsHostsSharedWithHostlessKey := make(map[string]struct{})\n\tif !slices.Contains(autoHTTPS, \"off\") {\n\t\tfor _, pair := range pairings {\n\t\t\tfor _, sb := range pair.serverBlocks {\n\t\t\t\tfor _, addr := range sb.parsedKeys {\n\t\t\t\t\tif addr.Host != \"\" {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// this server block has a hostless key, now\n\t\t\t\t\t// go through and add all the hosts to the set\n\t\t\t\t\tfor _, otherAddr := range sb.parsedKeys {\n\t\t\t\t\t\tif otherAddr.Original == addr.Original {\n\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif otherAddr.Host != \"\" && otherAddr.Scheme != \"http\" && otherAddr.Port != httpPort {\n\t\t\t\t\t\t\thttpsHostsSharedWithHostlessKey[otherAddr.Host] = struct{}{}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// a catch-all automation policy is used as a \"default\" for all subjects that\n\t// don't have custom configuration explicitly associated with them; this\n\t// is only to add if the global settings or defaults are non-empty\n\tcatchAllAP, err := newBaseAutomationPolicy(options, warnings, false)\n\tif err != nil {\n\t\treturn nil, warnings, err\n\t}\n\tif catchAllAP != nil {\n\t\tif tlsApp.Automation == nil {\n\t\t\ttlsApp.Automation = new(caddytls.AutomationConfig)\n\t\t}\n\t\ttlsApp.Automation.Policies = append(tlsApp.Automation.Policies, catchAllAP)\n\t}\n\n\tvar wildcardHosts []string                        // collect all hosts that have a wildcard in them, and aren't HTTP\n\tforcedAutomatedNames := make(map[string]struct{}) // explicitly configured to be automated, even if covered by a wildcard\n\n\tfor _, p := range pairings {\n\t\tvar addresses []string\n\t\tfor _, addressWithProtocols := range p.addressesWithProtocols {\n\t\t\taddresses = append(addresses, addressWithProtocols.address)\n\t\t}\n\t\tif !listenersUseAnyPortOtherThan(addresses, httpPort) {\n\t\t\tcontinue\n\t\t}\n\t\tfor _, sblock := range p.serverBlocks {\n\t\t\tfor _, addr := range sblock.parsedKeys {\n\t\t\t\tif strings.HasPrefix(addr.Host, \"*.\") {\n\t\t\t\t\twildcardHosts = append(wildcardHosts, addr.Host[2:])\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tfor _, p := range pairings {\n\t\t// avoid setting up TLS automation policies for a server that is HTTP-only\n\t\tvar addresses []string\n\t\tfor _, addressWithProtocols := range p.addressesWithProtocols {\n\t\t\taddresses = append(addresses, addressWithProtocols.address)\n\t\t}\n\t\tif !listenersUseAnyPortOtherThan(addresses, httpPort) {\n\t\t\tcontinue\n\t\t}\n\n\t\tfor _, sblock := range p.serverBlocks {\n\t\t\t// check the scheme of all the site addresses,\n\t\t\t// skip building AP if they all had http://\n\t\t\tif sblock.isAllHTTP() {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// get values that populate an automation policy for this block\n\t\t\tap, err := newBaseAutomationPolicy(options, warnings, true)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, warnings, err\n\t\t\t}\n\n\t\t\t// make a plain copy so we can compare whether we made any changes\n\t\t\tapCopy, err := newBaseAutomationPolicy(options, warnings, true)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, warnings, err\n\t\t\t}\n\n\t\t\tsblockHosts := sblock.hostsFromKeys(false)\n\t\t\tif len(sblockHosts) == 0 && catchAllAP != nil {\n\t\t\t\tap = catchAllAP\n\t\t\t}\n\n\t\t\t// on-demand tls\n\t\t\tif _, ok := sblock.pile[\"tls.on_demand\"]; ok {\n\t\t\t\tap.OnDemand = true\n\t\t\t}\n\n\t\t\t// collect hosts that are forced to have certs automated for their specific name\n\t\t\tif _, ok := sblock.pile[\"tls.force_automate\"]; ok {\n\t\t\t\tfor _, host := range sblockHosts {\n\t\t\t\t\tforcedAutomatedNames[host] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// reuse private keys tls\n\t\t\tif _, ok := sblock.pile[\"tls.reuse_private_keys\"]; ok {\n\t\t\t\tap.ReusePrivateKeys = true\n\t\t\t}\n\n\t\t\tif keyTypeVals, ok := sblock.pile[\"tls.key_type\"]; ok {\n\t\t\t\tap.KeyType = keyTypeVals[0].Value.(string)\n\t\t\t}\n\n\t\t\t// certificate issuers\n\t\t\tif issuerVals, ok := sblock.pile[\"tls.cert_issuer\"]; ok {\n\t\t\t\tvar issuers []certmagic.Issuer\n\t\t\t\tfor _, issuerVal := range issuerVals {\n\t\t\t\t\tissuers = append(issuers, issuerVal.Value.(certmagic.Issuer))\n\t\t\t\t}\n\t\t\t\tif ap == catchAllAP && !reflect.DeepEqual(ap.Issuers, issuers) {\n\t\t\t\t\t// this more correctly implements an error check that was removed\n\t\t\t\t\t// below; try it with this config:\n\t\t\t\t\t//\n\t\t\t\t\t// :443 {\n\t\t\t\t\t// \tbind 127.0.0.1\n\t\t\t\t\t// }\n\t\t\t\t\t//\n\t\t\t\t\t// :443 {\n\t\t\t\t\t// \tbind ::1\n\t\t\t\t\t// \ttls {\n\t\t\t\t\t// \t\tissuer acme\n\t\t\t\t\t// \t}\n\t\t\t\t\t// }\n\t\t\t\t\treturn nil, warnings, fmt.Errorf(\"automation policy from site block is also default/catch-all policy because of key without hostname, and the two are in conflict: %#v != %#v\", ap.Issuers, issuers)\n\t\t\t\t}\n\t\t\t\tap.Issuers = issuers\n\t\t\t}\n\n\t\t\t// certificate managers\n\t\t\tif certManagerVals, ok := sblock.pile[\"tls.cert_manager\"]; ok {\n\t\t\t\tfor _, certManager := range certManagerVals {\n\t\t\t\t\tcertGetterName := certManager.Value.(caddy.Module).CaddyModule().ID.Name()\n\t\t\t\t\tap.ManagersRaw = append(ap.ManagersRaw, caddyconfig.JSONModuleObject(certManager.Value, \"via\", certGetterName, &warnings))\n\t\t\t\t}\n\t\t\t}\n\t\t\t// custom bind host\n\t\t\tfor _, cfgVal := range sblock.pile[\"bind\"] {\n\t\t\t\tfor _, iss := range ap.Issuers {\n\t\t\t\t\t// if an issuer was already configured and it is NOT an ACME issuer,\n\t\t\t\t\t// skip, since we intend to adjust only ACME issuers; ensure we\n\t\t\t\t\t// include any issuer that embeds/wraps an underlying ACME issuer\n\t\t\t\t\tvar acmeIssuer *caddytls.ACMEIssuer\n\t\t\t\t\tif acmeWrapper, ok := iss.(acmeCapable); ok {\n\t\t\t\t\t\tacmeIssuer = acmeWrapper.GetACMEIssuer()\n\t\t\t\t\t}\n\t\t\t\t\tif acmeIssuer == nil {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\n\t\t\t\t\t// proceed to configure the ACME issuer's bind host, without\n\t\t\t\t\t// overwriting any existing settings\n\t\t\t\t\tif acmeIssuer.Challenges == nil {\n\t\t\t\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t\t\t\t}\n\t\t\t\t\tif acmeIssuer.Challenges.BindHost == \"\" {\n\t\t\t\t\t\t// only binding to one host is supported\n\t\t\t\t\t\tvar bindHost string\n\t\t\t\t\t\tif asserted, ok := cfgVal.Value.(addressesWithProtocols); ok && len(asserted.addresses) > 0 {\n\t\t\t\t\t\t\tbindHost = asserted.addresses[0]\n\t\t\t\t\t\t}\n\t\t\t\t\t\tacmeIssuer.Challenges.BindHost = bindHost\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// we used to ensure this block is allowed to create an automation policy;\n\t\t\t// doing so was forbidden if it has a key with no host (i.e. \":443\")\n\t\t\t// and if there is a different server block that also has a key with no\n\t\t\t// host -- since a key with no host matches any host, we need its\n\t\t\t// associated automation policy to have an empty Subjects list, i.e. no\n\t\t\t// host filter, which is indistinguishable between the two server blocks\n\t\t\t// because automation is not done in the context of a particular server...\n\t\t\t// this is an example of a poor mapping from Caddyfile to JSON but that's\n\t\t\t// the least-leaky abstraction I could figure out -- however, this check\n\t\t\t// was preventing certain listeners, like those provided by plugins, from\n\t\t\t// being used as desired (see the Tailscale listener plugin), so I removed\n\t\t\t// the check: and I think since I originally wrote the check I added a new\n\t\t\t// check above which *properly* detects this ambiguity without breaking the\n\t\t\t// listener plugin; see the check above with a commented example config\n\t\t\tif len(sblockHosts) == 0 && catchAllAP == nil {\n\t\t\t\t// this server block has a key with no hosts, but there is not yet\n\t\t\t\t// a catch-all automation policy (probably because no global options\n\t\t\t\t// were set), so this one becomes it\n\t\t\t\tcatchAllAP = ap\n\t\t\t}\n\n\t\t\thostsNotHTTP := sblock.hostsFromKeysNotHTTP(httpPort)\n\t\t\tsort.Strings(hostsNotHTTP) // solely for deterministic test results\n\n\t\t\t// if the we prefer wildcards and the AP is unchanged,\n\t\t\t// then we can skip this AP because it should be covered\n\t\t\t// by an AP with a wildcard\n\t\t\tif slices.Contains(autoHTTPS, \"prefer_wildcard\") {\n\t\t\t\tif hostsCoveredByWildcard(hostsNotHTTP, wildcardHosts) &&\n\t\t\t\t\treflect.DeepEqual(ap, apCopy) {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// associate our new automation policy with this server block's hosts\n\t\t\tap.SubjectsRaw = hostsNotHTTP\n\n\t\t\t// if a combination of public and internal names were given\n\t\t\t// for this same server block and no issuer was specified, we\n\t\t\t// need to separate them out in the automation policies so\n\t\t\t// that the internal names can use the internal issuer and\n\t\t\t// the other names can use the default/public/ACME issuer\n\t\t\tvar ap2 *caddytls.AutomationPolicy\n\t\t\tif len(ap.Issuers) == 0 {\n\t\t\t\tvar internal, external []string\n\t\t\t\tfor _, s := range ap.SubjectsRaw {\n\t\t\t\t\t// do not create Issuers for Tailscale domains; they will be given a Manager instead\n\t\t\t\t\tif isTailscaleDomain(s) {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif !certmagic.SubjectQualifiesForCert(s) {\n\t\t\t\t\t\treturn nil, warnings, fmt.Errorf(\"subject does not qualify for certificate: '%s'\", s)\n\t\t\t\t\t}\n\t\t\t\t\t// we don't use certmagic.SubjectQualifiesForPublicCert() because of one nuance:\n\t\t\t\t\t// names like *.*.tld that may not qualify for a public certificate are actually\n\t\t\t\t\t// fine when used with OnDemand, since OnDemand (currently) does not obtain\n\t\t\t\t\t// wildcards (if it ever does, there will be a separate config option to enable\n\t\t\t\t\t// it that we would need to check here) since the hostname is known at handshake;\n\t\t\t\t\t// and it is unexpected to switch to internal issuer when the user wants to get\n\t\t\t\t\t// regular certificates on-demand for a class of certs like *.*.tld.\n\t\t\t\t\tif subjectQualifiesForPublicCert(ap, s) {\n\t\t\t\t\t\texternal = append(external, s)\n\t\t\t\t\t} else {\n\t\t\t\t\t\tinternal = append(internal, s)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif len(external) > 0 && len(internal) > 0 {\n\t\t\t\t\tap.SubjectsRaw = external\n\t\t\t\t\tapCopy := *ap\n\t\t\t\t\tap2 = &apCopy\n\t\t\t\t\tap2.SubjectsRaw = internal\n\t\t\t\t\tap2.IssuersRaw = []json.RawMessage{caddyconfig.JSONModuleObject(caddytls.InternalIssuer{}, \"module\", \"internal\", &warnings)}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tif tlsApp.Automation == nil {\n\t\t\t\ttlsApp.Automation = new(caddytls.AutomationConfig)\n\t\t\t}\n\t\t\ttlsApp.Automation.Policies = append(tlsApp.Automation.Policies, ap)\n\t\t\tif ap2 != nil {\n\t\t\t\ttlsApp.Automation.Policies = append(tlsApp.Automation.Policies, ap2)\n\t\t\t}\n\n\t\t\t// certificate loaders\n\t\t\tif clVals, ok := sblock.pile[\"tls.cert_loader\"]; ok {\n\t\t\t\tfor _, clVal := range clVals {\n\t\t\t\t\tcertLoaders = append(certLoaders, clVal.Value.(caddytls.CertificateLoader))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// group certificate loaders by module name, then add to config\n\tif len(certLoaders) > 0 {\n\t\tloadersByName := make(map[string]caddytls.CertificateLoader)\n\t\tfor _, cl := range certLoaders {\n\t\t\tname := caddy.GetModuleName(cl)\n\t\t\t// ugh... technically, we may have multiple FileLoader and FolderLoader\n\t\t\t// modules (because the tls directive returns one per occurrence), but\n\t\t\t// the config structure expects only one instance of each kind of loader\n\t\t\t// module, so we have to combine them... instead of enumerating each\n\t\t\t// possible cert loader module in a type switch, we can use reflection,\n\t\t\t// which works on any cert loaders that are slice types\n\t\t\tif reflect.TypeOf(cl).Kind() == reflect.Slice {\n\t\t\t\tcombined := reflect.ValueOf(loadersByName[name])\n\t\t\t\tif !combined.IsValid() {\n\t\t\t\t\tcombined = reflect.New(reflect.TypeOf(cl)).Elem()\n\t\t\t\t}\n\t\t\t\tclVal := reflect.ValueOf(cl)\n\t\t\t\tfor i := range clVal.Len() {\n\t\t\t\t\tcombined = reflect.Append(combined, clVal.Index(i))\n\t\t\t\t}\n\t\t\t\tloadersByName[name] = combined.Interface().(caddytls.CertificateLoader)\n\t\t\t}\n\t\t}\n\t\tfor certLoaderName, loaders := range loadersByName {\n\t\t\ttlsApp.CertificatesRaw[certLoaderName] = caddyconfig.JSON(loaders, &warnings)\n\t\t}\n\t}\n\n\t// set any of the on-demand options, for if/when on-demand TLS is enabled\n\tif onDemand, ok := options[\"on_demand_tls\"].(*caddytls.OnDemandConfig); ok {\n\t\tif tlsApp.Automation == nil {\n\t\t\ttlsApp.Automation = new(caddytls.AutomationConfig)\n\t\t}\n\t\ttlsApp.Automation.OnDemand = onDemand\n\t}\n\n\t// set up \"global\" (to the TLS app) DNS provider config\n\tif globalDNS, ok := options[\"dns\"]; ok && globalDNS != nil {\n\t\ttlsApp.DNSRaw = caddyconfig.JSONModuleObject(globalDNS, \"name\", globalDNS.(caddy.Module).CaddyModule().ID.Name(), nil)\n\t}\n\n\t// set up ECH from Caddyfile options\n\tif ech, ok := options[\"ech\"].(*caddytls.ECH); ok {\n\t\ttlsApp.EncryptedClientHello = ech\n\n\t\t// outer server names will need certificates, so make sure they're included\n\t\t// in an automation policy for them that applies any global options\n\t\tap, err := newBaseAutomationPolicy(options, warnings, true)\n\t\tif err != nil {\n\t\t\treturn nil, warnings, err\n\t\t}\n\t\tfor _, cfg := range ech.Configs {\n\t\t\tif cfg.PublicName != \"\" {\n\t\t\t\tap.SubjectsRaw = append(ap.SubjectsRaw, cfg.PublicName)\n\t\t\t}\n\t\t}\n\t\tif tlsApp.Automation == nil {\n\t\t\ttlsApp.Automation = new(caddytls.AutomationConfig)\n\t\t}\n\t\ttlsApp.Automation.Policies = append(tlsApp.Automation.Policies, ap)\n\t}\n\n\t// if the storage clean interval is a boolean, then it's \"off\" to disable cleaning\n\tif sc, ok := options[\"storage_check\"].(string); ok && sc == \"off\" {\n\t\ttlsApp.DisableStorageCheck = true\n\t}\n\n\t// if the storage clean interval is a boolean, then it's \"off\" to disable cleaning\n\tif sci, ok := options[\"storage_clean_interval\"].(bool); ok && !sci {\n\t\ttlsApp.DisableStorageClean = true\n\t}\n\n\t// set the storage clean interval if configured\n\tif storageCleanInterval, ok := options[\"storage_clean_interval\"].(caddy.Duration); ok {\n\t\tif tlsApp.Automation == nil {\n\t\t\ttlsApp.Automation = new(caddytls.AutomationConfig)\n\t\t}\n\t\ttlsApp.Automation.StorageCleanInterval = storageCleanInterval\n\t}\n\n\t// set the expired certificates renew interval if configured\n\tif renewCheckInterval, ok := options[\"renew_interval\"].(caddy.Duration); ok {\n\t\tif tlsApp.Automation == nil {\n\t\t\ttlsApp.Automation = new(caddytls.AutomationConfig)\n\t\t}\n\t\ttlsApp.Automation.RenewCheckInterval = renewCheckInterval\n\t}\n\n\t// set the OCSP check interval if configured\n\tif ocspCheckInterval, ok := options[\"ocsp_interval\"].(caddy.Duration); ok {\n\t\tif tlsApp.Automation == nil {\n\t\t\ttlsApp.Automation = new(caddytls.AutomationConfig)\n\t\t}\n\t\ttlsApp.Automation.OCSPCheckInterval = ocspCheckInterval\n\t}\n\n\t// set whether OCSP stapling should be disabled for manually-managed certificates\n\tif ocspConfig, ok := options[\"ocsp_stapling\"].(certmagic.OCSPConfig); ok {\n\t\ttlsApp.DisableOCSPStapling = ocspConfig.DisableStapling\n\t}\n\n\t// if any hostnames appear on the same server block as a key with\n\t// no host, they will not be used with route matchers because the\n\t// hostless key matches all hosts, therefore, it wouldn't be\n\t// considered for auto-HTTPS, so we need to make sure those hosts\n\t// are manually considered for managed certificates; we also need\n\t// to make sure that any of these names which are internal-only\n\t// get internal certificates by default rather than ACME\n\tvar al caddytls.AutomateLoader\n\tinternalAP := &caddytls.AutomationPolicy{\n\t\tIssuersRaw: []json.RawMessage{json.RawMessage(`{\"module\":\"internal\"}`)},\n\t}\n\tif !slices.Contains(autoHTTPS, \"off\") && !slices.Contains(autoHTTPS, \"disable_certs\") {\n\t\tfor h := range httpsHostsSharedWithHostlessKey {\n\t\t\tal = append(al, h)\n\t\t\tif !certmagic.SubjectQualifiesForPublicCert(h) {\n\t\t\t\tinternalAP.SubjectsRaw = append(internalAP.SubjectsRaw, h)\n\t\t\t}\n\t\t}\n\t}\n\tfor name := range forcedAutomatedNames {\n\t\tif slices.Contains(al, name) {\n\t\t\tcontinue\n\t\t}\n\t\tal = append(al, name)\n\t}\n\tslices.Sort(al) // to stabilize the adapt output\n\tif len(al) > 0 {\n\t\ttlsApp.CertificatesRaw[\"automate\"] = caddyconfig.JSON(al, &warnings)\n\t}\n\tif len(internalAP.SubjectsRaw) > 0 {\n\t\tif tlsApp.Automation == nil {\n\t\t\ttlsApp.Automation = new(caddytls.AutomationConfig)\n\t\t}\n\t\ttlsApp.Automation.Policies = append(tlsApp.Automation.Policies, internalAP)\n\t}\n\n\t// if there are any global options set for issuers (ACME ones in particular), make sure they\n\t// take effect in every automation policy that does not have any issuers\n\tif tlsApp.Automation != nil {\n\t\tglobalEmail := options[\"email\"]\n\t\tglobalACMECA := options[\"acme_ca\"]\n\t\tglobalACMECARoot := options[\"acme_ca_root\"]\n\t\tglobalACMEDNS := options[\"acme_dns\"]\n\t\tglobalACMEEAB := options[\"acme_eab\"]\n\t\tglobalPreferredChains := options[\"preferred_chains\"]\n\t\thasGlobalACMEDefaults := globalEmail != nil || globalACMECA != nil || globalACMECARoot != nil || globalACMEDNS != nil || globalACMEEAB != nil || globalPreferredChains != nil\n\t\tif hasGlobalACMEDefaults {\n\t\t\tfor i := range tlsApp.Automation.Policies {\n\t\t\t\tap := tlsApp.Automation.Policies[i]\n\t\t\t\tif len(ap.Issuers) == 0 && automationPolicyHasAllPublicNames(ap) {\n\t\t\t\t\t// for public names, create default issuers which will later be filled in with configured global defaults\n\t\t\t\t\t// (internal names will implicitly use the internal issuer at auto-https time)\n\t\t\t\t\temailStr, _ := globalEmail.(string)\n\t\t\t\t\tap.Issuers = caddytls.DefaultIssuers(emailStr)\n\n\t\t\t\t\t// if a specific endpoint is configured, can't use multiple default issuers\n\t\t\t\t\tif globalACMECA != nil {\n\t\t\t\t\t\tap.Issuers = []certmagic.Issuer{new(caddytls.ACMEIssuer)}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// finalize and verify policies; do cleanup\n\tif tlsApp.Automation != nil {\n\t\tfor i, ap := range tlsApp.Automation.Policies {\n\t\t\t// ensure all issuers have global defaults filled in\n\t\t\tfor j, issuer := range ap.Issuers {\n\t\t\t\terr := fillInGlobalACMEDefaults(issuer, options)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, warnings, fmt.Errorf(\"filling in global issuer defaults for AP %d, issuer %d: %v\", i, j, err)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// encode all issuer values we created, so they will be rendered in the output\n\t\t\tif len(ap.Issuers) > 0 && ap.IssuersRaw == nil {\n\t\t\t\tfor _, iss := range ap.Issuers {\n\t\t\t\t\tissuerName := iss.(caddy.Module).CaddyModule().ID.Name()\n\t\t\t\t\tap.IssuersRaw = append(ap.IssuersRaw, caddyconfig.JSONModuleObject(iss, \"module\", issuerName, &warnings))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// consolidate automation policies that are the exact same\n\t\ttlsApp.Automation.Policies = consolidateAutomationPolicies(tlsApp.Automation.Policies)\n\n\t\t// ensure automation policies don't overlap subjects (this should be\n\t\t// an error at provision-time as well, but catch it in the adapt phase\n\t\t// for convenience)\n\t\tautomationHostSet := make(map[string]struct{})\n\t\tfor _, ap := range tlsApp.Automation.Policies {\n\t\t\tfor _, s := range ap.SubjectsRaw {\n\t\t\t\tif _, ok := automationHostSet[s]; ok {\n\t\t\t\t\treturn nil, warnings, fmt.Errorf(\"hostname appears in more than one automation policy, making certificate management ambiguous: %s\", s)\n\t\t\t\t}\n\t\t\t\tautomationHostSet[s] = struct{}{}\n\t\t\t}\n\t\t}\n\n\t\t// if nothing remains, remove any excess values to clean up the resulting config\n\t\tif len(tlsApp.Automation.Policies) == 0 {\n\t\t\ttlsApp.Automation.Policies = nil\n\t\t}\n\t\tif reflect.DeepEqual(tlsApp.Automation, new(caddytls.AutomationConfig)) {\n\t\t\ttlsApp.Automation = nil\n\t\t}\n\t}\n\n\treturn tlsApp, warnings, nil\n}\n\ntype acmeCapable interface{ GetACMEIssuer() *caddytls.ACMEIssuer }\n\nfunc fillInGlobalACMEDefaults(issuer certmagic.Issuer, options map[string]any) error {\n\tacmeWrapper, ok := issuer.(acmeCapable)\n\tif !ok {\n\t\treturn nil\n\t}\n\tacmeIssuer := acmeWrapper.GetACMEIssuer()\n\tif acmeIssuer == nil {\n\t\treturn nil\n\t}\n\n\tglobalEmail := options[\"email\"]\n\tglobalACMECA := options[\"acme_ca\"]\n\tglobalACMECARoot := options[\"acme_ca_root\"]\n\tglobalACMEDNS := options[\"acme_dns\"]\n\tglobalACMEEAB := options[\"acme_eab\"]\n\tglobalPreferredChains := options[\"preferred_chains\"]\n\tglobalCertLifetime := options[\"cert_lifetime\"]\n\tglobalHTTPPort, globalHTTPSPort := options[\"http_port\"], options[\"https_port\"]\n\n\tif globalEmail != nil && acmeIssuer.Email == \"\" {\n\t\tacmeIssuer.Email = globalEmail.(string)\n\t}\n\tif globalACMECA != nil && acmeIssuer.CA == \"\" {\n\t\tacmeIssuer.CA = globalACMECA.(string)\n\t}\n\tif globalACMECARoot != nil && !slices.Contains(acmeIssuer.TrustedRootsPEMFiles, globalACMECARoot.(string)) {\n\t\tacmeIssuer.TrustedRootsPEMFiles = append(acmeIssuer.TrustedRootsPEMFiles, globalACMECARoot.(string))\n\t}\n\tif globalACMEDNS != nil && (acmeIssuer.Challenges == nil || acmeIssuer.Challenges.DNS == nil) {\n\t\tacmeIssuer.Challenges = &caddytls.ChallengesConfig{\n\t\t\tDNS: &caddytls.DNSChallengeConfig{\n\t\t\t\tProviderRaw: caddyconfig.JSONModuleObject(globalACMEDNS, \"name\", globalACMEDNS.(caddy.Module).CaddyModule().ID.Name(), nil),\n\t\t\t},\n\t\t}\n\t}\n\tif globalACMEEAB != nil && acmeIssuer.ExternalAccount == nil {\n\t\tacmeIssuer.ExternalAccount = globalACMEEAB.(*acme.EAB)\n\t}\n\tif globalPreferredChains != nil && acmeIssuer.PreferredChains == nil {\n\t\tacmeIssuer.PreferredChains = globalPreferredChains.(*caddytls.ChainPreference)\n\t}\n\t// only configure alt HTTP and TLS-ALPN ports if the DNS challenge is not enabled (wouldn't hurt, but isn't necessary since the DNS challenge is exclusive of others)\n\tif globalHTTPPort != nil && (acmeIssuer.Challenges == nil || acmeIssuer.Challenges.DNS == nil) && (acmeIssuer.Challenges == nil || acmeIssuer.Challenges.HTTP == nil || acmeIssuer.Challenges.HTTP.AlternatePort == 0) {\n\t\tif acmeIssuer.Challenges == nil {\n\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t}\n\t\tif acmeIssuer.Challenges.HTTP == nil {\n\t\t\tacmeIssuer.Challenges.HTTP = new(caddytls.HTTPChallengeConfig)\n\t\t}\n\t\tacmeIssuer.Challenges.HTTP.AlternatePort = globalHTTPPort.(int)\n\t}\n\tif globalHTTPSPort != nil && (acmeIssuer.Challenges == nil || acmeIssuer.Challenges.DNS == nil) && (acmeIssuer.Challenges == nil || acmeIssuer.Challenges.TLSALPN == nil || acmeIssuer.Challenges.TLSALPN.AlternatePort == 0) {\n\t\tif acmeIssuer.Challenges == nil {\n\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t}\n\t\tif acmeIssuer.Challenges.TLSALPN == nil {\n\t\t\tacmeIssuer.Challenges.TLSALPN = new(caddytls.TLSALPNChallengeConfig)\n\t\t}\n\t\tacmeIssuer.Challenges.TLSALPN.AlternatePort = globalHTTPSPort.(int)\n\t}\n\tif globalCertLifetime != nil && acmeIssuer.CertificateLifetime == 0 {\n\t\tacmeIssuer.CertificateLifetime = globalCertLifetime.(caddy.Duration)\n\t}\n\treturn nil\n}\n\n// newBaseAutomationPolicy returns a new TLS automation policy that gets\n// its values from the global options map. It should be used as the base\n// for any other automation policies. A nil policy (and no error) will be\n// returned if there are no default/global options. However, if always is\n// true, a non-nil value will always be returned (unless there is an error).\nfunc newBaseAutomationPolicy(\n\toptions map[string]any,\n\t_ []caddyconfig.Warning,\n\talways bool,\n) (*caddytls.AutomationPolicy, error) {\n\tissuers, hasIssuers := options[\"cert_issuer\"]\n\t_, hasLocalCerts := options[\"local_certs\"]\n\tkeyType, hasKeyType := options[\"key_type\"]\n\tocspStapling, hasOCSPStapling := options[\"ocsp_stapling\"]\n\n\thasGlobalAutomationOpts := hasIssuers || hasLocalCerts || hasKeyType || hasOCSPStapling\n\n\t// if there are no global options related to automation policies\n\t// set, then we can just return right away\n\tif !hasGlobalAutomationOpts {\n\t\tif always {\n\t\t\treturn new(caddytls.AutomationPolicy), nil\n\t\t}\n\t\treturn nil, nil\n\t}\n\n\tap := new(caddytls.AutomationPolicy)\n\tif hasKeyType {\n\t\tap.KeyType = keyType.(string)\n\t}\n\n\tif hasIssuers && hasLocalCerts {\n\t\treturn nil, fmt.Errorf(\"global options are ambiguous: local_certs is confusing when combined with cert_issuer, because local_certs is also a specific kind of issuer\")\n\t}\n\n\tif hasIssuers {\n\t\tap.Issuers = issuers.([]certmagic.Issuer)\n\t} else if hasLocalCerts {\n\t\tap.Issuers = []certmagic.Issuer{new(caddytls.InternalIssuer)}\n\t}\n\n\tif hasOCSPStapling {\n\t\tocspConfig := ocspStapling.(certmagic.OCSPConfig)\n\t\tap.DisableOCSPStapling = ocspConfig.DisableStapling\n\t\tap.OCSPOverrides = ocspConfig.ResponderOverrides\n\t}\n\n\treturn ap, nil\n}\n\n// consolidateAutomationPolicies combines automation policies that are the same,\n// for a cleaner overall output.\nfunc consolidateAutomationPolicies(aps []*caddytls.AutomationPolicy) []*caddytls.AutomationPolicy {\n\t// sort from most specific to least specific; we depend on this ordering\n\tsort.SliceStable(aps, func(i, j int) bool {\n\t\tif automationPolicyIsSubset(aps[i], aps[j]) {\n\t\t\treturn true\n\t\t}\n\t\tif automationPolicyIsSubset(aps[j], aps[i]) {\n\t\t\treturn false\n\t\t}\n\t\treturn len(aps[i].SubjectsRaw) > len(aps[j].SubjectsRaw)\n\t})\n\n\temptyAPCount := 0\n\torigLenAPs := len(aps)\n\t// compute the number of empty policies (disregarding subjects) - see #4128\n\temptyAP := new(caddytls.AutomationPolicy)\n\tfor i := 0; i < len(aps); i++ {\n\t\temptyAP.SubjectsRaw = aps[i].SubjectsRaw\n\t\tif reflect.DeepEqual(aps[i], emptyAP) {\n\t\t\temptyAPCount++\n\t\t\tif !automationPolicyHasAllPublicNames(aps[i]) {\n\t\t\t\t// if this automation policy has internal names, we might as well remove it\n\t\t\t\t// so auto-https can implicitly use the internal issuer\n\t\t\t\taps = slices.Delete(aps, i, i+1)\n\t\t\t\ti--\n\t\t\t}\n\t\t}\n\t}\n\t// If all policies are empty, we can return nil, as there is no need to set any policy\n\tif emptyAPCount == origLenAPs {\n\t\treturn nil\n\t}\n\n\t// remove or combine duplicate policies\nouter:\n\tfor i := 0; i < len(aps); i++ {\n\t\t// compare only with next policies; we sorted by specificity so we must not delete earlier policies\n\t\tfor j := i + 1; j < len(aps); j++ {\n\t\t\t// if they're exactly equal in every way, just keep one of them\n\t\t\tif reflect.DeepEqual(aps[i], aps[j]) {\n\t\t\t\taps = slices.Delete(aps, j, j+1)\n\t\t\t\t// must re-evaluate current i against next j; can't skip it!\n\t\t\t\t// even if i decrements to -1, will be incremented to 0 immediately\n\t\t\t\ti--\n\t\t\t\tcontinue outer\n\t\t\t}\n\n\t\t\t// if the policy is the same, we can keep just one, but we have\n\t\t\t// to be careful which one we keep; if only one has any hostnames\n\t\t\t// defined, then we need to keep the one without any hostnames,\n\t\t\t// otherwise the one without any subjects (a catch-all) would be\n\t\t\t// eaten up by the one with subjects; and if both have subjects, we\n\t\t\t// need to combine their lists\n\t\t\tif reflect.DeepEqual(aps[i].IssuersRaw, aps[j].IssuersRaw) &&\n\t\t\t\treflect.DeepEqual(aps[i].ManagersRaw, aps[j].ManagersRaw) &&\n\t\t\t\tbytes.Equal(aps[i].StorageRaw, aps[j].StorageRaw) &&\n\t\t\t\taps[i].MustStaple == aps[j].MustStaple &&\n\t\t\t\taps[i].KeyType == aps[j].KeyType &&\n\t\t\t\taps[i].OnDemand == aps[j].OnDemand &&\n\t\t\t\taps[i].ReusePrivateKeys == aps[j].ReusePrivateKeys &&\n\t\t\t\taps[i].RenewalWindowRatio == aps[j].RenewalWindowRatio {\n\t\t\t\tif len(aps[i].SubjectsRaw) > 0 && len(aps[j].SubjectsRaw) == 0 {\n\t\t\t\t\t// later policy (at j) has no subjects (\"catch-all\"), so we can\n\t\t\t\t\t// remove the identical-but-more-specific policy that comes first\n\t\t\t\t\t// AS LONG AS it is not shadowed by another policy before it; e.g.\n\t\t\t\t\t// if policy i is for example.com, policy i+1 is '*.com', and policy\n\t\t\t\t\t// j is catch-all, we cannot remove policy i because that would\n\t\t\t\t\t// cause example.com to be served by the less specific policy for\n\t\t\t\t\t// '*.com', which might be different (yes we've seen this happen)\n\t\t\t\t\tif automationPolicyShadows(i, aps) >= j {\n\t\t\t\t\t\taps = slices.Delete(aps, i, i+1)\n\t\t\t\t\t\ti--\n\t\t\t\t\t\tcontinue outer\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t// avoid repeated subjects\n\t\t\t\t\tfor _, subj := range aps[j].SubjectsRaw {\n\t\t\t\t\t\tif !slices.Contains(aps[i].SubjectsRaw, subj) {\n\t\t\t\t\t\t\taps[i].SubjectsRaw = append(aps[i].SubjectsRaw, subj)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t\taps = slices.Delete(aps, j, j+1)\n\t\t\t\t\tj--\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn aps\n}\n\n// automationPolicyIsSubset returns true if a's subjects are a subset\n// of b's subjects.\nfunc automationPolicyIsSubset(a, b *caddytls.AutomationPolicy) bool {\n\tif len(b.SubjectsRaw) == 0 {\n\t\treturn true\n\t}\n\tif len(a.SubjectsRaw) == 0 {\n\t\treturn false\n\t}\n\tfor _, aSubj := range a.SubjectsRaw {\n\t\tinSuperset := slices.ContainsFunc(b.SubjectsRaw, func(bSubj string) bool {\n\t\t\treturn certmagic.MatchWildcard(aSubj, bSubj)\n\t\t})\n\t\tif !inSuperset {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\n// automationPolicyShadows returns the index of a policy that aps[i] shadows;\n// in other words, for all policies after position i, if that policy covers\n// the same subjects but is less specific, that policy's position is returned,\n// or -1 if no shadowing is found. For example, if policy i is for\n// \"foo.example.com\" and policy i+2 is for \"*.example.com\", then i+2 will be\n// returned, since that policy is shadowed by i, which is in front.\nfunc automationPolicyShadows(i int, aps []*caddytls.AutomationPolicy) int {\n\tfor j := i + 1; j < len(aps); j++ {\n\t\tif automationPolicyIsSubset(aps[i], aps[j]) {\n\t\t\treturn j\n\t\t}\n\t}\n\treturn -1\n}\n\n// subjectQualifiesForPublicCert is like certmagic.SubjectQualifiesForPublicCert() except\n// that this allows domains with multiple wildcard levels like '*.*.example.com' to qualify\n// if the automation policy has OnDemand enabled (i.e. this function is more lenient).\n//\n// IP subjects are considered as non-qualifying for public certs. Technically, there are\n// now public ACME CAs as well as non-ACME CAs that issue IP certificates. But this function\n// is used solely for implicit automation (defaults), where it gets really complicated to\n// keep track of which issuers support IP certificates in which circumstances. Currently,\n// issuers that support IP certificates are very few, and all require some sort of config\n// from the user anyway (such as an account credential). Since we cannot implicitly and\n// automatically get public IP certs without configuration from the user, we treat IPs as\n// not qualifying for public certificates. Users should expressly configure an issuer\n// that supports IP certs for that purpose.\nfunc subjectQualifiesForPublicCert(ap *caddytls.AutomationPolicy, subj string) bool {\n\treturn !certmagic.SubjectIsIP(subj) &&\n\t\t!certmagic.SubjectIsInternal(subj) &&\n\t\t(strings.Count(subj, \"*.\") < 2 || ap.OnDemand)\n}\n\n// automationPolicyHasAllPublicNames returns true if all the names on the policy\n// do NOT qualify for public certs OR are tailscale domains.\nfunc automationPolicyHasAllPublicNames(ap *caddytls.AutomationPolicy) bool {\n\treturn !slices.ContainsFunc(ap.SubjectsRaw, func(i string) bool {\n\t\treturn !subjectQualifiesForPublicCert(ap, i) || isTailscaleDomain(i)\n\t})\n}\n\nfunc isTailscaleDomain(name string) bool {\n\treturn strings.HasSuffix(strings.ToLower(name), \".ts.net\")\n}\n\nfunc hostsCoveredByWildcard(hosts []string, wildcards []string) bool {\n\tif len(hosts) == 0 || len(wildcards) == 0 {\n\t\treturn false\n\t}\n\tfor _, host := range hosts {\n\t\tfor _, wildcard := range wildcards {\n\t\t\tif strings.HasPrefix(host, \"*.\") {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif certmagic.MatchWildcard(host, \"*.\"+wildcard) {\n\t\t\t\treturn true\n\t\t\t}\n\t\t}\n\t}\n\treturn false\n}\n",
    "source_file": "caddyconfig/httpcaddyfile/tlsapp.go",
    "chunk_type": "code"
  },
  {
    "content": "package httpcaddyfile\n\nimport (\n\t\"regexp\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n)\n\ntype ComplexShorthandReplacer struct {\n\tsearch  *regexp.Regexp\n\treplace string\n}\n\ntype ShorthandReplacer struct {\n\tcomplex []ComplexShorthandReplacer\n\tsimple  *strings.Replacer\n}\n\nfunc NewShorthandReplacer() ShorthandReplacer {\n\t// replace shorthand placeholders (which are convenient\n\t// when writing a Caddyfile) with their actual placeholder\n\t// identifiers or variable names\n\treplacer := strings.NewReplacer(placeholderShorthands()...)\n\n\t// these are placeholders that allow a user-defined final\n\t// parameters, but we still want to provide a shorthand\n\t// for those, so we use a regexp to replace\n\tregexpReplacements := []ComplexShorthandReplacer{\n\t\t{regexp.MustCompile(`{header\\.([\\w-]*)}`), \"{http.request.header.$1}\"},\n\t\t{regexp.MustCompile(`{cookie\\.([\\w-]*)}`), \"{http.request.cookie.$1}\"},\n\t\t{regexp.MustCompile(`{labels\\.([\\w-]*)}`), \"{http.request.host.labels.$1}\"},\n\t\t{regexp.MustCompile(`{path\\.([\\w-]*)}`), \"{http.request.uri.path.$1}\"},\n\t\t{regexp.MustCompile(`{file\\.([\\w-]*)}`), \"{http.request.uri.path.file.$1}\"},\n\t\t{regexp.MustCompile(`{query\\.([\\w-]*)}`), \"{http.request.uri.query.$1}\"},\n\t\t{regexp.MustCompile(`{re\\.([\\w-\\.]*)}`), \"{http.regexp.$1}\"},\n\t\t{regexp.MustCompile(`{vars\\.([\\w-]*)}`), \"{http.vars.$1}\"},\n\t\t{regexp.MustCompile(`{rp\\.([\\w-\\.]*)}`), \"{http.reverse_proxy.$1}\"},\n\t\t{regexp.MustCompile(`{resp\\.([\\w-\\.]*)}`), \"{http.intercept.$1}\"},\n\t\t{regexp.MustCompile(`{err\\.([\\w-\\.]*)}`), \"{http.error.$1}\"},\n\t\t{regexp.MustCompile(`{file_match\\.([\\w-]*)}`), \"{http.matchers.file.$1}\"},\n\t}\n\n\treturn ShorthandReplacer{\n\t\tcomplex: regexpReplacements,\n\t\tsimple:  replacer,\n\t}\n}\n\n// placeholderShorthands returns a slice of old-new string pairs,\n// where the left of the pair is a placeholder shorthand that may\n// be used in the Caddyfile, and the right is the replacement.\nfunc placeholderShorthands() []string {\n\treturn []string{\n\t\t\"{host}\", \"{http.request.host}\",\n\t\t\"{hostport}\", \"{http.request.hostport}\",\n\t\t\"{port}\", \"{http.request.port}\",\n\t\t\"{orig_method}\", \"{http.request.orig_method}\",\n\t\t\"{orig_uri}\", \"{http.request.orig_uri}\",\n\t\t\"{orig_path}\", \"{http.request.orig_uri.path}\",\n\t\t\"{orig_dir}\", \"{http.request.orig_uri.path.dir}\",\n\t\t\"{orig_file}\", \"{http.request.orig_uri.path.file}\",\n\t\t\"{orig_query}\", \"{http.request.orig_uri.query}\",\n\t\t\"{orig_?query}\", \"{http.request.orig_uri.prefixed_query}\",\n\t\t\"{method}\", \"{http.request.method}\",\n\t\t\"{uri}\", \"{http.request.uri}\",\n\t\t\"{path}\", \"{http.request.uri.path}\",\n\t\t\"{dir}\", \"{http.request.uri.path.dir}\",\n\t\t\"{file}\", \"{http.request.uri.path.file}\",\n\t\t\"{query}\", \"{http.request.uri.query}\",\n\t\t\"{?query}\", \"{http.request.uri.prefixed_query}\",\n\t\t\"{remote}\", \"{http.request.remote}\",\n\t\t\"{remote_host}\", \"{http.request.remote.host}\",\n\t\t\"{remote_port}\", \"{http.request.remote.port}\",\n\t\t\"{scheme}\", \"{http.request.scheme}\",\n\t\t\"{uuid}\", \"{http.request.uuid}\",\n\t\t\"{tls_cipher}\", \"{http.request.tls.cipher_suite}\",\n\t\t\"{tls_version}\", \"{http.request.tls.version}\",\n\t\t\"{tls_client_fingerprint}\", \"{http.request.tls.client.fingerprint}\",\n\t\t\"{tls_client_issuer}\", \"{http.request.tls.client.issuer}\",\n\t\t\"{tls_client_serial}\", \"{http.request.tls.client.serial}\",\n\t\t\"{tls_client_subject}\", \"{http.request.tls.client.subject}\",\n\t\t\"{tls_client_certificate_pem}\", \"{http.request.tls.client.certificate_pem}\",\n\t\t\"{tls_client_certificate_der_base64}\", \"{http.request.tls.client.certificate_der_base64}\",\n\t\t\"{upstream_hostport}\", \"{http.reverse_proxy.upstream.hostport}\",\n\t\t\"{client_ip}\", \"{http.vars.client_ip}\",\n\t}\n}\n\n// ApplyToSegment replaces shorthand placeholder to its full placeholder, understandable by Caddy.\nfunc (s ShorthandReplacer) ApplyToSegment(segment *caddyfile.Segment) {\n\tif segment != nil {\n\t\tfor i := 0; i < len(*segment); i++ {\n\t\t\t// simple string replacements\n\t\t\t(*segment)[i].Text = s.simple.Replace((*segment)[i].Text)\n\t\t\t// complex regexp replacements\n\t\t\tfor _, r := range s.complex {\n\t\t\t\t(*segment)[i].Text = r.search.ReplaceAllString((*segment)[i].Text, r.replace)\n\t\t\t}\n\t\t}\n\t}\n}\n",
    "source_file": "caddyconfig/httpcaddyfile/shorthands.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage httpcaddyfile\n\nimport (\n\t\"slices\"\n\t\"strconv\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/libdns/libdns\"\n\t\"github.com/mholt/acmez/v3/acme\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\nfunc init() {\n\tRegisterGlobalOption(\"debug\", parseOptTrue)\n\tRegisterGlobalOption(\"http_port\", parseOptHTTPPort)\n\tRegisterGlobalOption(\"https_port\", parseOptHTTPSPort)\n\tRegisterGlobalOption(\"default_bind\", parseOptDefaultBind)\n\tRegisterGlobalOption(\"grace_period\", parseOptDuration)\n\tRegisterGlobalOption(\"shutdown_delay\", parseOptDuration)\n\tRegisterGlobalOption(\"default_sni\", parseOptSingleString)\n\tRegisterGlobalOption(\"fallback_sni\", parseOptSingleString)\n\tRegisterGlobalOption(\"order\", parseOptOrder)\n\tRegisterGlobalOption(\"storage\", parseOptStorage)\n\tRegisterGlobalOption(\"storage_check\", parseStorageCheck)\n\tRegisterGlobalOption(\"storage_clean_interval\", parseStorageCleanInterval)\n\tRegisterGlobalOption(\"renew_interval\", parseOptDuration)\n\tRegisterGlobalOption(\"ocsp_interval\", parseOptDuration)\n\tRegisterGlobalOption(\"acme_ca\", parseOptSingleString)\n\tRegisterGlobalOption(\"acme_ca_root\", parseOptSingleString)\n\tRegisterGlobalOption(\"acme_dns\", parseOptDNS)\n\tRegisterGlobalOption(\"acme_eab\", parseOptACMEEAB)\n\tRegisterGlobalOption(\"cert_issuer\", parseOptCertIssuer)\n\tRegisterGlobalOption(\"skip_install_trust\", parseOptTrue)\n\tRegisterGlobalOption(\"email\", parseOptSingleString)\n\tRegisterGlobalOption(\"admin\", parseOptAdmin)\n\tRegisterGlobalOption(\"on_demand_tls\", parseOptOnDemand)\n\tRegisterGlobalOption(\"local_certs\", parseOptTrue)\n\tRegisterGlobalOption(\"key_type\", parseOptSingleString)\n\tRegisterGlobalOption(\"auto_https\", parseOptAutoHTTPS)\n\tRegisterGlobalOption(\"metrics\", parseMetricsOptions)\n\tRegisterGlobalOption(\"servers\", parseServerOptions)\n\tRegisterGlobalOption(\"ocsp_stapling\", parseOCSPStaplingOptions)\n\tRegisterGlobalOption(\"cert_lifetime\", parseOptDuration)\n\tRegisterGlobalOption(\"log\", parseLogOptions)\n\tRegisterGlobalOption(\"preferred_chains\", parseOptPreferredChains)\n\tRegisterGlobalOption(\"persist_config\", parseOptPersistConfig)\n\tRegisterGlobalOption(\"dns\", parseOptDNS)\n\tRegisterGlobalOption(\"ech\", parseOptECH)\n}\n\nfunc parseOptTrue(d *caddyfile.Dispenser, _ any) (any, error) { return true, nil }\n\nfunc parseOptHTTPPort(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tvar httpPort int\n\tvar httpPortStr string\n\tif !d.AllArgs(&httpPortStr) {\n\t\treturn 0, d.ArgErr()\n\t}\n\tvar err error\n\thttpPort, err = strconv.Atoi(httpPortStr)\n\tif err != nil {\n\t\treturn 0, d.Errf(\"converting port '%s' to integer value: %v\", httpPortStr, err)\n\t}\n\treturn httpPort, nil\n}\n\nfunc parseOptHTTPSPort(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tvar httpsPort int\n\tvar httpsPortStr string\n\tif !d.AllArgs(&httpsPortStr) {\n\t\treturn 0, d.ArgErr()\n\t}\n\tvar err error\n\thttpsPort, err = strconv.Atoi(httpsPortStr)\n\tif err != nil {\n\t\treturn 0, d.Errf(\"converting port '%s' to integer value: %v\", httpsPortStr, err)\n\t}\n\treturn httpsPort, nil\n}\n\nfunc parseOptOrder(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\n\t// get directive name\n\tif !d.Next() {\n\t\treturn nil, d.ArgErr()\n\t}\n\tdirName := d.Val()\n\tif _, ok := registeredDirectives[dirName]; !ok {\n\t\treturn nil, d.Errf(\"%s is not a registered directive\", dirName)\n\t}\n\n\t// get positional token\n\tif !d.Next() {\n\t\treturn nil, d.ArgErr()\n\t}\n\tpos := Positional(d.Val())\n\n\t// if directive already had an order, drop it\n\tnewOrder := slices.DeleteFunc(directiveOrder, func(d string) bool {\n\t\treturn d == dirName\n\t})\n\n\t// act on the positional; if it's First or Last, we're done right away\n\tswitch pos {\n\tcase First:\n\t\tnewOrder = append([]string{dirName}, newOrder...)\n\t\tif d.NextArg() {\n\t\t\treturn nil, d.ArgErr()\n\t\t}\n\t\tdirectiveOrder = newOrder\n\t\treturn newOrder, nil\n\n\tcase Last:\n\t\tnewOrder = append(newOrder, dirName)\n\t\tif d.NextArg() {\n\t\t\treturn nil, d.ArgErr()\n\t\t}\n\t\tdirectiveOrder = newOrder\n\t\treturn newOrder, nil\n\n\t// if it's Before or After, continue\n\tcase Before:\n\tcase After:\n\n\tdefault:\n\t\treturn nil, d.Errf(\"unknown positional '%s'\", pos)\n\t}\n\n\t// get name of other directive\n\tif !d.NextArg() {\n\t\treturn nil, d.ArgErr()\n\t}\n\totherDir := d.Val()\n\tif d.NextArg() {\n\t\treturn nil, d.ArgErr()\n\t}\n\n\t// get the position of the target directive\n\ttargetIndex := slices.Index(newOrder, otherDir)\n\tif targetIndex == -1 {\n\t\treturn nil, d.Errf(\"directive '%s' not found\", otherDir)\n\t}\n\t// if we're inserting after, we need to increment the index to go after\n\tif pos == After {\n\t\ttargetIndex++\n\t}\n\t// insert the directive into the new order\n\tnewOrder = slices.Insert(newOrder, targetIndex, dirName)\n\n\tdirectiveOrder = newOrder\n\n\treturn newOrder, nil\n}\n\nfunc parseOptStorage(d *caddyfile.Dispenser, _ any) (any, error) {\n\tif !d.Next() { // consume option name\n\t\treturn nil, d.ArgErr()\n\t}\n\tif !d.Next() { // get storage module name\n\t\treturn nil, d.ArgErr()\n\t}\n\tmodID := \"caddy.storage.\" + d.Val()\n\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tstorage, ok := unm.(caddy.StorageConverter)\n\tif !ok {\n\t\treturn nil, d.Errf(\"module %s is not a caddy.StorageConverter\", modID)\n\t}\n\treturn storage, nil\n}\n\nfunc parseStorageCheck(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tif !d.Next() {\n\t\treturn \"\", d.ArgErr()\n\t}\n\tval := d.Val()\n\tif d.Next() {\n\t\treturn \"\", d.ArgErr()\n\t}\n\tif val != \"off\" {\n\t\treturn \"\", d.Errf(\"storage_check must be 'off'\")\n\t}\n\treturn val, nil\n}\n\nfunc parseStorageCleanInterval(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tif !d.Next() {\n\t\treturn \"\", d.ArgErr()\n\t}\n\tval := d.Val()\n\tif d.Next() {\n\t\treturn \"\", d.ArgErr()\n\t}\n\tif val == \"off\" {\n\t\treturn false, nil\n\t}\n\tdur, err := caddy.ParseDuration(d.Val())\n\tif err != nil {\n\t\treturn nil, d.Errf(\"failed to parse storage_clean_interval, must be a duration or 'off' %w\", err)\n\t}\n\treturn caddy.Duration(dur), nil\n}\n\nfunc parseOptDuration(d *caddyfile.Dispenser, _ any) (any, error) {\n\tif !d.Next() { // consume option name\n\t\treturn nil, d.ArgErr()\n\t}\n\tif !d.Next() { // get duration value\n\t\treturn nil, d.ArgErr()\n\t}\n\tdur, err := caddy.ParseDuration(d.Val())\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn caddy.Duration(dur), nil\n}\n\nfunc parseOptACMEEAB(d *caddyfile.Dispenser, _ any) (any, error) {\n\teab := new(acme.EAB)\n\td.Next() // consume option name\n\tif d.NextArg() {\n\t\treturn nil, d.ArgErr()\n\t}\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"key_id\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\teab.KeyID = d.Val()\n\n\t\tcase \"mac_key\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\teab.MACKey = d.Val()\n\n\t\tdefault:\n\t\t\treturn nil, d.Errf(\"unrecognized parameter '%s'\", d.Val())\n\t\t}\n\t}\n\treturn eab, nil\n}\n\nfunc parseOptCertIssuer(d *caddyfile.Dispenser, existing any) (any, error) {\n\td.Next() // consume option name\n\n\tvar issuers []certmagic.Issuer\n\tif existing != nil {\n\t\tissuers = existing.([]certmagic.Issuer)\n\t}\n\n\t// get issuer module name\n\tif !d.Next() {\n\t\treturn nil, d.ArgErr()\n\t}\n\tmodID := \"tls.issuance.\" + d.Val()\n\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tiss, ok := unm.(certmagic.Issuer)\n\tif !ok {\n\t\treturn nil, d.Errf(\"module %s (%T) is not a certmagic.Issuer\", modID, unm)\n\t}\n\tissuers = append(issuers, iss)\n\treturn issuers, nil\n}\n\nfunc parseOptSingleString(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tif !d.Next() {\n\t\treturn \"\", d.ArgErr()\n\t}\n\tval := d.Val()\n\tif d.Next() {\n\t\treturn \"\", d.ArgErr()\n\t}\n\treturn val, nil\n}\n\nfunc parseOptDefaultBind(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\n\tvar addresses, protocols []string\n\taddresses = d.RemainingArgs()\n\n\tif len(addresses) == 0 {\n\t\taddresses = append(addresses, \"\")\n\t}\n\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"protocols\":\n\t\t\tprotocols = d.RemainingArgs()\n\t\t\tif len(protocols) == 0 {\n\t\t\t\treturn nil, d.Errf(\"protocols requires one or more arguments\")\n\t\t\t}\n\t\tdefault:\n\t\t\treturn nil, d.Errf(\"unknown subdirective: %s\", d.Val())\n\t\t}\n\t}\n\n\treturn []ConfigValue{{Class: \"bind\", Value: addressesWithProtocols{\n\t\taddresses: addresses,\n\t\tprotocols: protocols,\n\t}}}, nil\n}\n\nfunc parseOptAdmin(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\n\tadminCfg := new(caddy.AdminConfig)\n\tif d.NextArg() {\n\t\tlistenAddress := d.Val()\n\t\tif listenAddress == \"off\" {\n\t\t\tadminCfg.Disabled = true\n\t\t\tif d.Next() { // Do not accept any remaining options including block\n\t\t\t\treturn nil, d.Err(\"No more option is allowed after turning off admin config\")\n\t\t\t}\n\t\t} else {\n\t\t\tadminCfg.Listen = listenAddress\n\t\t\tif d.NextArg() { // At most 1 arg is allowed\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t}\n\t}\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"enforce_origin\":\n\t\t\tadminCfg.EnforceOrigin = true\n\n\t\tcase \"origins\":\n\t\t\tadminCfg.Origins = d.RemainingArgs()\n\n\t\tdefault:\n\t\t\treturn nil, d.Errf(\"unrecognized parameter '%s'\", d.Val())\n\t\t}\n\t}\n\tif adminCfg.Listen == \"\" && !adminCfg.Disabled {\n\t\tadminCfg.Listen = caddy.DefaultAdminListen\n\t}\n\treturn adminCfg, nil\n}\n\nfunc parseOptOnDemand(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tif d.NextArg() {\n\t\treturn nil, d.ArgErr()\n\t}\n\n\tvar ond *caddytls.OnDemandConfig\n\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"ask\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tif ond == nil {\n\t\t\t\tond = new(caddytls.OnDemandConfig)\n\t\t\t}\n\t\t\tif ond.PermissionRaw != nil {\n\t\t\t\treturn nil, d.Err(\"on-demand TLS permission module (or 'ask') already specified\")\n\t\t\t}\n\t\t\tperm := caddytls.PermissionByHTTP{Endpoint: d.Val()}\n\t\t\tond.PermissionRaw = caddyconfig.JSONModuleObject(perm, \"module\", \"http\", nil)\n\n\t\tcase \"permission\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tif ond == nil {\n\t\t\t\tond = new(caddytls.OnDemandConfig)\n\t\t\t}\n\t\t\tif ond.PermissionRaw != nil {\n\t\t\t\treturn nil, d.Err(\"on-demand TLS permission module (or 'ask') already specified\")\n\t\t\t}\n\t\t\tmodName := d.Val()\n\t\t\tmodID := \"tls.permission.\" + modName\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tperm, ok := unm.(caddytls.OnDemandPermission)\n\t\t\tif !ok {\n\t\t\t\treturn nil, d.Errf(\"module %s (%T) is not an on-demand TLS permission module\", modID, unm)\n\t\t\t}\n\t\t\tond.PermissionRaw = caddyconfig.JSONModuleObject(perm, \"module\", modName, nil)\n\n\t\tcase \"interval\":\n\t\t\treturn nil, d.Errf(\"the on_demand_tls 'interval' option is no longer supported, remove it from your config\")\n\n\t\tcase \"burst\":\n\t\t\treturn nil, d.Errf(\"the on_demand_tls 'burst' option is no longer supported, remove it from your config\")\n\n\t\tdefault:\n\t\t\treturn nil, d.Errf(\"unrecognized parameter '%s'\", d.Val())\n\t\t}\n\t}\n\tif ond == nil {\n\t\treturn nil, d.Err(\"expected at least one config parameter for on_demand_tls\")\n\t}\n\treturn ond, nil\n}\n\nfunc parseOptPersistConfig(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tif !d.Next() {\n\t\treturn \"\", d.ArgErr()\n\t}\n\tval := d.Val()\n\tif d.Next() {\n\t\treturn \"\", d.ArgErr()\n\t}\n\tif val != \"off\" {\n\t\treturn \"\", d.Errf(\"persist_config must be 'off'\")\n\t}\n\treturn val, nil\n}\n\nfunc parseOptAutoHTTPS(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tval := d.RemainingArgs()\n\tif len(val) == 0 {\n\t\treturn \"\", d.ArgErr()\n\t}\n\tfor _, v := range val {\n\t\tswitch v {\n\t\tcase \"off\":\n\t\tcase \"disable_redirects\":\n\t\tcase \"disable_certs\":\n\t\tcase \"ignore_loaded_certs\":\n\t\tcase \"prefer_wildcard\":\n\t\t\tbreak\n\n\t\tdefault:\n\t\t\treturn \"\", d.Errf(\"auto_https must be one of 'off', 'disable_redirects', 'disable_certs', 'ignore_loaded_certs', or 'prefer_wildcard'\")\n\t\t}\n\t}\n\treturn val, nil\n}\n\nfunc unmarshalCaddyfileMetricsOptions(d *caddyfile.Dispenser) (any, error) {\n\td.Next() // consume option name\n\tmetrics := new(caddyhttp.Metrics)\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"per_host\":\n\t\t\tmetrics.PerHost = true\n\t\tdefault:\n\t\t\treturn nil, d.Errf(\"unrecognized servers option '%s'\", d.Val())\n\t\t}\n\t}\n\treturn metrics, nil\n}\n\nfunc parseMetricsOptions(d *caddyfile.Dispenser, _ any) (any, error) {\n\treturn unmarshalCaddyfileMetricsOptions(d)\n}\n\nfunc parseServerOptions(d *caddyfile.Dispenser, _ any) (any, error) {\n\treturn unmarshalCaddyfileServerOptions(d)\n}\n\nfunc parseOCSPStaplingOptions(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\tvar val string\n\tif !d.AllArgs(&val) {\n\t\treturn nil, d.ArgErr()\n\t}\n\tif val != \"off\" {\n\t\treturn nil, d.Errf(\"invalid argument '%s'\", val)\n\t}\n\treturn certmagic.OCSPConfig{\n\t\tDisableStapling: val == \"off\",\n\t}, nil\n}\n\n// parseLogOptions parses the global log option. Syntax:\n//\n//\tlog [name] {\n//\t    output  <writer_module> ...\n//\t    format  <encoder_module> ...\n//\t    level   <level>\n//\t    include <namespaces...>\n//\t    exclude <namespaces...>\n//\t}\n//\n// When the name argument is unspecified, this directive modifies the default\n// logger.\nfunc parseLogOptions(d *caddyfile.Dispenser, existingVal any) (any, error) {\n\tcurrentNames := make(map[string]struct{})\n\tif existingVal != nil {\n\t\tinnerVals, ok := existingVal.([]ConfigValue)\n\t\tif !ok {\n\t\t\treturn nil, d.Errf(\"existing log values of unexpected type: %T\", existingVal)\n\t\t}\n\t\tfor _, rawVal := range innerVals {\n\t\t\tval, ok := rawVal.Value.(namedCustomLog)\n\t\t\tif !ok {\n\t\t\t\treturn nil, d.Errf(\"existing log value of unexpected type: %T\", existingVal)\n\t\t\t}\n\t\t\tcurrentNames[val.name] = struct{}{}\n\t\t}\n\t}\n\n\tvar warnings []caddyconfig.Warning\n\t// Call out the same parser that handles server-specific log configuration.\n\tconfigValues, err := parseLogHelper(\n\t\tHelper{\n\t\t\tDispenser: d,\n\t\t\twarnings:  &warnings,\n\t\t},\n\t\tcurrentNames,\n\t)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif len(warnings) > 0 {\n\t\treturn nil, d.Errf(\"warnings found in parsing global log options: %+v\", warnings)\n\t}\n\n\treturn configValues, nil\n}\n\nfunc parseOptPreferredChains(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next()\n\treturn caddytls.ParseCaddyfilePreferredChainsOptions(d)\n}\n\nfunc parseOptDNS(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\n\tif !d.Next() { // get DNS module name\n\t\treturn nil, d.ArgErr()\n\t}\n\tmodID := \"dns.providers.\" + d.Val()\n\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tswitch unm.(type) {\n\tcase libdns.RecordGetter,\n\t\tlibdns.RecordSetter,\n\t\tlibdns.RecordAppender,\n\t\tlibdns.RecordDeleter:\n\tdefault:\n\t\treturn nil, d.Errf(\"module %s (%T) is not a libdns provider\", modID, unm)\n\t}\n\treturn unm, nil\n}\n\nfunc parseOptECH(d *caddyfile.Dispenser, _ any) (any, error) {\n\td.Next() // consume option name\n\n\tech := new(caddytls.ECH)\n\n\tpublicNames := d.RemainingArgs()\n\tfor _, publicName := range publicNames {\n\t\tech.Configs = append(ech.Configs, caddytls.ECHConfiguration{\n\t\t\tPublicName: publicName,\n\t\t})\n\t}\n\tif len(ech.Configs) == 0 {\n\t\treturn nil, d.ArgErr()\n\t}\n\n\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\tswitch d.Val() {\n\t\tcase \"dns\":\n\t\t\tif !d.Next() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tproviderName := d.Val()\n\t\t\tmodID := \"dns.providers.\" + providerName\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tech.Publication = append(ech.Publication, &caddytls.ECHPublication{\n\t\t\t\tConfigs: publicNames,\n\t\t\t\tPublishersRaw: caddy.ModuleMap{\n\t\t\t\t\t\"dns\": caddyconfig.JSON(caddytls.ECHDNSPublisher{\n\t\t\t\t\t\tProviderRaw: caddyconfig.JSONModuleObject(unm, \"name\", providerName, nil),\n\t\t\t\t\t}, nil),\n\t\t\t\t},\n\t\t\t})\n\t\tdefault:\n\t\t\treturn nil, d.Errf(\"ech: unrecognized subdirective '%s'\", d.Val())\n\t\t}\n\t}\n\n\treturn ech, nil\n}\n",
    "source_file": "caddyconfig/httpcaddyfile/options.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage httpcaddyfile\n\nimport (\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddypki\"\n)\n\nfunc init() {\n\tRegisterGlobalOption(\"pki\", parsePKIApp)\n}\n\n// parsePKIApp parses the global log option. Syntax:\n//\n//\tpki {\n//\t    ca [<id>] {\n//\t        name                  <name>\n//\t        root_cn               <name>\n//\t        intermediate_cn       <name>\n//\t        intermediate_lifetime <duration>\n//\t        root {\n//\t            cert   <path>\n//\t            key    <path>\n//\t            format <format>\n//\t        }\n//\t        intermediate {\n//\t            cert   <path>\n//\t            key    <path>\n//\t            format <format>\n//\t        }\n//\t    }\n//\t}\n//\n// When the CA ID is unspecified, 'local' is assumed.\nfunc parsePKIApp(d *caddyfile.Dispenser, existingVal any) (any, error) {\n\td.Next() // consume app name\n\n\tpki := &caddypki.PKI{\n\t\tCAs: make(map[string]*caddypki.CA),\n\t}\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"ca\":\n\t\t\tpkiCa := new(caddypki.CA)\n\t\t\tif d.NextArg() {\n\t\t\t\tpkiCa.ID = d.Val()\n\t\t\t\tif d.NextArg() {\n\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t}\n\t\t\t}\n\t\t\tif pkiCa.ID == \"\" {\n\t\t\t\tpkiCa.ID = caddypki.DefaultCAID\n\t\t\t}\n\n\t\t\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\t\t\tswitch d.Val() {\n\t\t\t\tcase \"name\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tpkiCa.Name = d.Val()\n\n\t\t\t\tcase \"root_cn\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tpkiCa.RootCommonName = d.Val()\n\n\t\t\t\tcase \"intermediate_cn\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tpkiCa.IntermediateCommonName = d.Val()\n\n\t\t\t\tcase \"intermediate_lifetime\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, err\n\t\t\t\t\t}\n\t\t\t\t\tpkiCa.IntermediateLifetime = caddy.Duration(dur)\n\n\t\t\t\tcase \"root\":\n\t\t\t\t\tif pkiCa.Root == nil {\n\t\t\t\t\t\tpkiCa.Root = new(caddypki.KeyPair)\n\t\t\t\t\t}\n\t\t\t\t\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\t\t\t\t\tswitch d.Val() {\n\t\t\t\t\t\tcase \"cert\":\n\t\t\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpkiCa.Root.Certificate = d.Val()\n\n\t\t\t\t\t\tcase \"key\":\n\t\t\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpkiCa.Root.PrivateKey = d.Val()\n\n\t\t\t\t\t\tcase \"format\":\n\t\t\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpkiCa.Root.Format = d.Val()\n\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\treturn nil, d.Errf(\"unrecognized pki ca root option '%s'\", d.Val())\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\tcase \"intermediate\":\n\t\t\t\t\tif pkiCa.Intermediate == nil {\n\t\t\t\t\t\tpkiCa.Intermediate = new(caddypki.KeyPair)\n\t\t\t\t\t}\n\t\t\t\t\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\t\t\t\t\tswitch d.Val() {\n\t\t\t\t\t\tcase \"cert\":\n\t\t\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpkiCa.Intermediate.Certificate = d.Val()\n\n\t\t\t\t\t\tcase \"key\":\n\t\t\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpkiCa.Intermediate.PrivateKey = d.Val()\n\n\t\t\t\t\t\tcase \"format\":\n\t\t\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tpkiCa.Intermediate.Format = d.Val()\n\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\treturn nil, d.Errf(\"unrecognized pki ca intermediate option '%s'\", d.Val())\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\tdefault:\n\t\t\t\t\treturn nil, d.Errf(\"unrecognized pki ca option '%s'\", d.Val())\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tpki.CAs[pkiCa.ID] = pkiCa\n\n\t\tdefault:\n\t\t\treturn nil, d.Errf(\"unrecognized pki option '%s'\", d.Val())\n\t\t}\n\t}\n\treturn pki, nil\n}\n\nfunc (st ServerType) buildPKIApp(\n\tpairings []sbAddrAssociation,\n\toptions map[string]any,\n\twarnings []caddyconfig.Warning,\n) (*caddypki.PKI, []caddyconfig.Warning, error) {\n\tskipInstallTrust := false\n\tif _, ok := options[\"skip_install_trust\"]; ok {\n\t\tskipInstallTrust = true\n\t}\n\tfalseBool := false\n\n\t// Load the PKI app configured via global options\n\tvar pkiApp *caddypki.PKI\n\tunwrappedPki, ok := options[\"pki\"].(*caddypki.PKI)\n\tif ok {\n\t\tpkiApp = unwrappedPki\n\t} else {\n\t\tpkiApp = &caddypki.PKI{CAs: make(map[string]*caddypki.CA)}\n\t}\n\tfor _, ca := range pkiApp.CAs {\n\t\tif skipInstallTrust {\n\t\t\tca.InstallTrust = &falseBool\n\t\t}\n\t\tpkiApp.CAs[ca.ID] = ca\n\t}\n\n\t// Add in the CAs configured via directives\n\tfor _, p := range pairings {\n\t\tfor _, sblock := range p.serverBlocks {\n\t\t\t// find all the CAs that were defined and add them to the app config\n\t\t\t// i.e. from any \"acme_server\" directives\n\t\t\tfor _, caCfgValue := range sblock.pile[\"pki.ca\"] {\n\t\t\t\tca := caCfgValue.Value.(*caddypki.CA)\n\t\t\t\tif skipInstallTrust {\n\t\t\t\t\tca.InstallTrust = &falseBool\n\t\t\t\t}\n\n\t\t\t\t// the CA might already exist from global options, so\n\t\t\t\t// don't overwrite it in that case\n\t\t\t\tif _, ok := pkiApp.CAs[ca.ID]; !ok {\n\t\t\t\t\tpkiApp.CAs[ca.ID] = ca\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// if there was no CAs defined in any of the servers,\n\t// and we were requested to not install trust, then\n\t// add one for the default/local CA to do so\n\tif len(pkiApp.CAs) == 0 && skipInstallTrust {\n\t\tca := new(caddypki.CA)\n\t\tca.ID = caddypki.DefaultCAID\n\t\tca.InstallTrust = &falseBool\n\t\tpkiApp.CAs[ca.ID] = ca\n\t}\n\n\treturn pkiApp, warnings, nil\n}\n",
    "source_file": "caddyconfig/httpcaddyfile/pkiapp.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage httpcaddyfile\n\nimport (\n\t\"cmp\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"net\"\n\t\"reflect\"\n\t\"slices\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"go.uber.org/zap\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddypki\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\nfunc init() {\n\tcaddyconfig.RegisterAdapter(\"caddyfile\", caddyfile.Adapter{ServerType: ServerType{}})\n}\n\n// App represents the configuration for a non-standard\n// Caddy app module (e.g. third-party plugin) which was\n// parsed from a global options block.\ntype App struct {\n\t// The JSON key for the app being configured\n\tName string\n\n\t// The raw app config as JSON\n\tValue json.RawMessage\n}\n\n// ServerType can set up a config from an HTTP Caddyfile.\ntype ServerType struct{}\n\n// Setup makes a config from the tokens.\nfunc (st ServerType) Setup(\n\tinputServerBlocks []caddyfile.ServerBlock,\n\toptions map[string]any,\n) (*caddy.Config, []caddyconfig.Warning, error) {\n\tvar warnings []caddyconfig.Warning\n\tgc := counter{new(int)}\n\tstate := make(map[string]any)\n\n\t// load all the server blocks and associate them with a \"pile\" of config values\n\toriginalServerBlocks := make([]serverBlock, 0, len(inputServerBlocks))\n\tfor _, sblock := range inputServerBlocks {\n\t\tfor j, k := range sblock.Keys {\n\t\t\tif j == 0 && strings.HasPrefix(k.Text, \"@\") {\n\t\t\t\treturn nil, warnings, fmt.Errorf(\"%s:%d: cannot define a matcher outside of a site block: '%s'\", k.File, k.Line, k.Text)\n\t\t\t}\n\t\t\tif _, ok := registeredDirectives[k.Text]; ok {\n\t\t\t\treturn nil, warnings, fmt.Errorf(\"%s:%d: parsed '%s' as a site address, but it is a known directive; directives must appear in a site block\", k.File, k.Line, k.Text)\n\t\t\t}\n\t\t}\n\t\toriginalServerBlocks = append(originalServerBlocks, serverBlock{\n\t\t\tblock: sblock,\n\t\t\tpile:  make(map[string][]ConfigValue),\n\t\t})\n\t}\n\n\t// apply any global options\n\tvar err error\n\toriginalServerBlocks, err = st.evaluateGlobalOptionsBlock(originalServerBlocks, options)\n\tif err != nil {\n\t\treturn nil, warnings, err\n\t}\n\n\t// this will replace both static and user-defined placeholder shorthands\n\t// with actual identifiers used by Caddy\n\treplacer := NewShorthandReplacer()\n\n\toriginalServerBlocks, err = st.extractNamedRoutes(originalServerBlocks, options, &warnings, replacer)\n\tif err != nil {\n\t\treturn nil, warnings, err\n\t}\n\n\tfor _, sb := range originalServerBlocks {\n\t\tfor i := range sb.block.Segments {\n\t\t\treplacer.ApplyToSegment(&sb.block.Segments[i])\n\t\t}\n\n\t\tif len(sb.block.Keys) == 0 {\n\t\t\treturn nil, warnings, fmt.Errorf(\"server block without any key is global configuration, and if used, it must be first\")\n\t\t}\n\n\t\t// extract matcher definitions\n\t\tmatcherDefs := make(map[string]caddy.ModuleMap)\n\t\tfor _, segment := range sb.block.Segments {\n\t\t\tif dir := segment.Directive(); strings.HasPrefix(dir, matcherPrefix) {\n\t\t\t\td := sb.block.DispenseDirective(dir)\n\t\t\t\terr := parseMatcherDefinitions(d, matcherDefs)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, warnings, err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// evaluate each directive (\"segment\") in this block\n\t\tfor _, segment := range sb.block.Segments {\n\t\t\tdir := segment.Directive()\n\n\t\t\tif strings.HasPrefix(dir, matcherPrefix) {\n\t\t\t\t// matcher definitions were pre-processed\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tdirFunc, ok := registeredDirectives[dir]\n\t\t\tif !ok {\n\t\t\t\ttkn := segment[0]\n\t\t\t\tmessage := \"%s:%d: unrecognized directive: %s\"\n\t\t\t\tif !sb.block.HasBraces {\n\t\t\t\t\tmessage += \"\\nDid you mean to define a second site? If so, you must use curly braces around each site to separate their configurations.\"\n\t\t\t\t}\n\t\t\t\treturn nil, warnings, fmt.Errorf(message, tkn.File, tkn.Line, dir)\n\t\t\t}\n\n\t\t\th := Helper{\n\t\t\t\tDispenser:    caddyfile.NewDispenser(segment),\n\t\t\t\toptions:      options,\n\t\t\t\twarnings:     &warnings,\n\t\t\t\tmatcherDefs:  matcherDefs,\n\t\t\t\tparentBlock:  sb.block,\n\t\t\t\tgroupCounter: gc,\n\t\t\t\tState:        state,\n\t\t\t}\n\n\t\t\tresults, err := dirFunc(h)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, warnings, fmt.Errorf(\"parsing caddyfile tokens for '%s': %v\", dir, err)\n\t\t\t}\n\n\t\t\tdir = normalizeDirectiveName(dir)\n\n\t\t\tfor _, result := range results {\n\t\t\t\tresult.directive = dir\n\t\t\t\tsb.pile[result.Class] = append(sb.pile[result.Class], result)\n\t\t\t}\n\n\t\t\t// specially handle named routes that were pulled out from\n\t\t\t// the invoke directive, which could be nested anywhere within\n\t\t\t// some subroutes in this directive; we add them to the pile\n\t\t\t// for this server block\n\t\t\tif state[namedRouteKey] != nil {\n\t\t\t\tfor name := range state[namedRouteKey].(map[string]struct{}) {\n\t\t\t\t\tresult := ConfigValue{Class: namedRouteKey, Value: name}\n\t\t\t\t\tsb.pile[result.Class] = append(sb.pile[result.Class], result)\n\t\t\t\t}\n\t\t\t\tstate[namedRouteKey] = nil\n\t\t\t}\n\t\t}\n\t}\n\n\t// map\n\tsbmap, err := st.mapAddressToProtocolToServerBlocks(originalServerBlocks, options)\n\tif err != nil {\n\t\treturn nil, warnings, err\n\t}\n\n\t// reduce\n\tpairings := st.consolidateAddrMappings(sbmap)\n\n\t// each pairing of listener addresses to list of server\n\t// blocks is basically a server definition\n\tservers, err := st.serversFromPairings(pairings, options, &warnings, gc)\n\tif err != nil {\n\t\treturn nil, warnings, err\n\t}\n\n\t// hoist the metrics config from per-server to global\n\tmetrics, _ := options[\"metrics\"].(*caddyhttp.Metrics)\n\tfor _, s := range servers {\n\t\tif s.Metrics != nil {\n\t\t\tmetrics = cmp.Or(metrics, &caddyhttp.Metrics{})\n\t\t\tmetrics = &caddyhttp.Metrics{\n\t\t\t\tPerHost: metrics.PerHost || s.Metrics.PerHost,\n\t\t\t}\n\t\t\ts.Metrics = nil // we don't need it anymore\n\t\t}\n\t}\n\n\t// now that each server is configured, make the HTTP app\n\thttpApp := caddyhttp.App{\n\t\tHTTPPort:      tryInt(options[\"http_port\"], &warnings),\n\t\tHTTPSPort:     tryInt(options[\"https_port\"], &warnings),\n\t\tGracePeriod:   tryDuration(options[\"grace_period\"], &warnings),\n\t\tShutdownDelay: tryDuration(options[\"shutdown_delay\"], &warnings),\n\t\tMetrics:       metrics,\n\t\tServers:       servers,\n\t}\n\n\t// then make the TLS app\n\ttlsApp, warnings, err := st.buildTLSApp(pairings, options, warnings)\n\tif err != nil {\n\t\treturn nil, warnings, err\n\t}\n\n\t// then make the PKI app\n\tpkiApp, warnings, err := st.buildPKIApp(pairings, options, warnings)\n\tif err != nil {\n\t\treturn nil, warnings, err\n\t}\n\n\t// extract any custom logs, and enforce configured levels\n\tvar customLogs []namedCustomLog\n\tvar hasDefaultLog bool\n\taddCustomLog := func(ncl namedCustomLog) {\n\t\tif ncl.name == \"\" {\n\t\t\treturn\n\t\t}\n\t\tif ncl.name == caddy.DefaultLoggerName {\n\t\t\thasDefaultLog = true\n\t\t}\n\t\tif _, ok := options[\"debug\"]; ok && ncl.log != nil && ncl.log.Level == \"\" {\n\t\t\tncl.log.Level = zap.DebugLevel.CapitalString()\n\t\t}\n\t\tcustomLogs = append(customLogs, ncl)\n\t}\n\n\t// Apply global log options, when set\n\tif options[\"log\"] != nil {\n\t\tfor _, logValue := range options[\"log\"].([]ConfigValue) {\n\t\t\taddCustomLog(logValue.Value.(namedCustomLog))\n\t\t}\n\t}\n\n\tif !hasDefaultLog {\n\t\t// if the default log was not customized, ensure we\n\t\t// configure it with any applicable options\n\t\tif _, ok := options[\"debug\"]; ok {\n\t\t\tcustomLogs = append(customLogs, namedCustomLog{\n\t\t\t\tname: caddy.DefaultLoggerName,\n\t\t\t\tlog: &caddy.CustomLog{\n\t\t\t\t\tBaseLog: caddy.BaseLog{Level: zap.DebugLevel.CapitalString()},\n\t\t\t\t},\n\t\t\t})\n\t\t}\n\t}\n\n\t// Apply server-specific log options\n\tfor _, p := range pairings {\n\t\tfor _, sb := range p.serverBlocks {\n\t\t\tfor _, clVal := range sb.pile[\"custom_log\"] {\n\t\t\t\taddCustomLog(clVal.Value.(namedCustomLog))\n\t\t\t}\n\t\t}\n\t}\n\n\t// annnd the top-level config, then we're done!\n\tcfg := &caddy.Config{AppsRaw: make(caddy.ModuleMap)}\n\n\t// loop through the configured options, and if any of\n\t// them are an httpcaddyfile App, then we insert them\n\t// into the config as raw Caddy apps\n\tfor _, opt := range options {\n\t\tif app, ok := opt.(App); ok {\n\t\t\tcfg.AppsRaw[app.Name] = app.Value\n\t\t}\n\t}\n\n\t// insert the standard Caddy apps into the config\n\tif len(httpApp.Servers) > 0 {\n\t\tcfg.AppsRaw[\"http\"] = caddyconfig.JSON(httpApp, &warnings)\n\t}\n\tif !reflect.DeepEqual(tlsApp, &caddytls.TLS{CertificatesRaw: make(caddy.ModuleMap)}) {\n\t\tcfg.AppsRaw[\"tls\"] = caddyconfig.JSON(tlsApp, &warnings)\n\t}\n\tif !reflect.DeepEqual(pkiApp, &caddypki.PKI{CAs: make(map[string]*caddypki.CA)}) {\n\t\tcfg.AppsRaw[\"pki\"] = caddyconfig.JSON(pkiApp, &warnings)\n\t}\n\tif filesystems, ok := options[\"filesystem\"].(caddy.Module); ok {\n\t\tcfg.AppsRaw[\"caddy.filesystems\"] = caddyconfig.JSON(\n\t\t\tfilesystems,\n\t\t\t&warnings)\n\t}\n\n\tif storageCvtr, ok := options[\"storage\"].(caddy.StorageConverter); ok {\n\t\tcfg.StorageRaw = caddyconfig.JSONModuleObject(storageCvtr,\n\t\t\t\"module\",\n\t\t\tstorageCvtr.(caddy.Module).CaddyModule().ID.Name(),\n\t\t\t&warnings)\n\t}\n\tif adminConfig, ok := options[\"admin\"].(*caddy.AdminConfig); ok && adminConfig != nil {\n\t\tcfg.Admin = adminConfig\n\t}\n\tif pc, ok := options[\"persist_config\"].(string); ok && pc == \"off\" {\n\t\tif cfg.Admin == nil {\n\t\t\tcfg.Admin = new(caddy.AdminConfig)\n\t\t}\n\t\tif cfg.Admin.Config == nil {\n\t\t\tcfg.Admin.Config = new(caddy.ConfigSettings)\n\t\t}\n\t\tcfg.Admin.Config.Persist = new(bool)\n\t}\n\n\tif len(customLogs) > 0 {\n\t\tif cfg.Logging == nil {\n\t\t\tcfg.Logging = &caddy.Logging{\n\t\t\t\tLogs: make(map[string]*caddy.CustomLog),\n\t\t\t}\n\t\t}\n\n\t\t// Add the default log first if defined, so that it doesn't\n\t\t// accidentally get re-created below due to the Exclude logic\n\t\tfor _, ncl := range customLogs {\n\t\t\tif ncl.name == caddy.DefaultLoggerName && ncl.log != nil {\n\t\t\t\tcfg.Logging.Logs[caddy.DefaultLoggerName] = ncl.log\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\t// Add the rest of the custom logs\n\t\tfor _, ncl := range customLogs {\n\t\t\tif ncl.log == nil || ncl.name == caddy.DefaultLoggerName {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tif ncl.name != \"\" {\n\t\t\t\tcfg.Logging.Logs[ncl.name] = ncl.log\n\t\t\t}\n\t\t\t// most users seem to prefer not writing access logs\n\t\t\t// to the default log when they are directed to a\n\t\t\t// file or have any other special customization\n\t\t\tif ncl.name != caddy.DefaultLoggerName && len(ncl.log.Include) > 0 {\n\t\t\t\tdefaultLog, ok := cfg.Logging.Logs[caddy.DefaultLoggerName]\n\t\t\t\tif !ok {\n\t\t\t\t\tdefaultLog = new(caddy.CustomLog)\n\t\t\t\t\tcfg.Logging.Logs[caddy.DefaultLoggerName] = defaultLog\n\t\t\t\t}\n\t\t\t\tdefaultLog.Exclude = append(defaultLog.Exclude, ncl.log.Include...)\n\n\t\t\t\t// avoid duplicates by sorting + compacting\n\t\t\t\tsort.Strings(defaultLog.Exclude)\n\t\t\t\tdefaultLog.Exclude = slices.Compact(defaultLog.Exclude)\n\t\t\t}\n\t\t}\n\t\t// we may have not actually added anything, so remove if empty\n\t\tif len(cfg.Logging.Logs) == 0 {\n\t\t\tcfg.Logging = nil\n\t\t}\n\t}\n\n\treturn cfg, warnings, nil\n}\n\n// evaluateGlobalOptionsBlock evaluates the global options block,\n// which is expected to be the first server block if it has zero\n// keys. It returns the updated list of server blocks with the\n// global options block removed, and updates options accordingly.\nfunc (ServerType) evaluateGlobalOptionsBlock(serverBlocks []serverBlock, options map[string]any) ([]serverBlock, error) {\n\tif len(serverBlocks) == 0 || len(serverBlocks[0].block.Keys) > 0 {\n\t\treturn serverBlocks, nil\n\t}\n\n\tfor _, segment := range serverBlocks[0].block.Segments {\n\t\topt := segment.Directive()\n\t\tvar val any\n\t\tvar err error\n\t\tdisp := caddyfile.NewDispenser(segment)\n\n\t\toptFunc, ok := registeredGlobalOptions[opt]\n\t\tif !ok {\n\t\t\ttkn := segment[0]\n\t\t\treturn nil, fmt.Errorf(\"%s:%d: unrecognized global option: %s\", tkn.File, tkn.Line, opt)\n\t\t}\n\n\t\tval, err = optFunc(disp, options[opt])\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"parsing caddyfile tokens for '%s': %v\", opt, err)\n\t\t}\n\n\t\t// As a special case, fold multiple \"servers\" options together\n\t\t// in an array instead of overwriting a possible existing value\n\t\tif opt == \"servers\" {\n\t\t\texistingOpts, ok := options[opt].([]serverOptions)\n\t\t\tif !ok {\n\t\t\t\texistingOpts = []serverOptions{}\n\t\t\t}\n\t\t\tserverOpts, ok := val.(serverOptions)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected type from 'servers' global options: %T\", val)\n\t\t\t}\n\t\t\toptions[opt] = append(existingOpts, serverOpts)\n\t\t\tcontinue\n\t\t}\n\t\t// Additionally, fold multiple \"log\" options together into an\n\t\t// array so that multiple loggers can be configured.\n\t\tif opt == \"log\" {\n\t\t\texistingOpts, ok := options[opt].([]ConfigValue)\n\t\t\tif !ok {\n\t\t\t\texistingOpts = []ConfigValue{}\n\t\t\t}\n\t\t\tlogOpts, ok := val.([]ConfigValue)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected type from 'log' global options: %T\", val)\n\t\t\t}\n\t\t\toptions[opt] = append(existingOpts, logOpts...)\n\t\t\tcontinue\n\t\t}\n\t\t// Also fold multiple \"default_bind\" options together into an\n\t\t// array so that server blocks can have multiple binds by default.\n\t\tif opt == \"default_bind\" {\n\t\t\texistingOpts, ok := options[opt].([]ConfigValue)\n\t\t\tif !ok {\n\t\t\t\texistingOpts = []ConfigValue{}\n\t\t\t}\n\t\t\tdefaultBindOpts, ok := val.([]ConfigValue)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"unexpected type from 'default_bind' global options: %T\", val)\n\t\t\t}\n\t\t\toptions[opt] = append(existingOpts, defaultBindOpts...)\n\t\t\tcontinue\n\t\t}\n\n\t\toptions[opt] = val\n\t}\n\n\t// If we got \"servers\" options, we'll sort them by their listener address\n\tif serverOpts, ok := options[\"servers\"].([]serverOptions); ok {\n\t\tsort.Slice(serverOpts, func(i, j int) bool {\n\t\t\treturn len(serverOpts[i].ListenerAddress) > len(serverOpts[j].ListenerAddress)\n\t\t})\n\n\t\t// Reject the config if there are duplicate listener address\n\t\tseen := make(map[string]bool)\n\t\tfor _, entry := range serverOpts {\n\t\t\tif _, alreadySeen := seen[entry.ListenerAddress]; alreadySeen {\n\t\t\t\treturn nil, fmt.Errorf(\"cannot have 'servers' global options with duplicate listener addresses: %s\", entry.ListenerAddress)\n\t\t\t}\n\t\t\tseen[entry.ListenerAddress] = true\n\t\t}\n\t}\n\n\treturn serverBlocks[1:], nil\n}\n\n// extractNamedRoutes pulls out any named route server blocks\n// so they don't get parsed as sites, and stores them in options\n// for later.\nfunc (ServerType) extractNamedRoutes(\n\tserverBlocks []serverBlock,\n\toptions map[string]any,\n\twarnings *[]caddyconfig.Warning,\n\treplacer ShorthandReplacer,\n) ([]serverBlock, error) {\n\tnamedRoutes := map[string]*caddyhttp.Route{}\n\n\tgc := counter{new(int)}\n\tstate := make(map[string]any)\n\n\t// copy the server blocks so we can\n\t// splice out the named route ones\n\tfiltered := append([]serverBlock{}, serverBlocks...)\n\tindex := -1\n\n\tfor _, sb := range serverBlocks {\n\t\tindex++\n\t\tif !sb.block.IsNamedRoute {\n\t\t\tcontinue\n\t\t}\n\n\t\t// splice out this block, because we know it's not a real server\n\t\tfiltered = append(filtered[:index], filtered[index+1:]...)\n\t\tindex--\n\n\t\tif len(sb.block.Segments) == 0 {\n\t\t\tcontinue\n\t\t}\n\n\t\twholeSegment := caddyfile.Segment{}\n\t\tfor i := range sb.block.Segments {\n\t\t\t// replace user-defined placeholder shorthands in extracted named routes\n\t\t\treplacer.ApplyToSegment(&sb.block.Segments[i])\n\n\t\t\t// zip up all the segments since ParseSegmentAsSubroute\n\t\t\t// was designed to take a directive+\n\t\t\twholeSegment = append(wholeSegment, sb.block.Segments[i]...)\n\t\t}\n\n\t\th := Helper{\n\t\t\tDispenser:    caddyfile.NewDispenser(wholeSegment),\n\t\t\toptions:      options,\n\t\t\twarnings:     warnings,\n\t\t\tmatcherDefs:  nil,\n\t\t\tparentBlock:  sb.block,\n\t\t\tgroupCounter: gc,\n\t\t\tState:        state,\n\t\t}\n\n\t\thandler, err := ParseSegmentAsSubroute(h)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\t\tsubroute := handler.(*caddyhttp.Subroute)\n\t\troute := caddyhttp.Route{}\n\n\t\tif len(subroute.Routes) == 1 && len(subroute.Routes[0].MatcherSetsRaw) == 0 {\n\t\t\t// if there's only one route with no matcher, then we can simplify\n\t\t\troute.HandlersRaw = append(route.HandlersRaw, subroute.Routes[0].HandlersRaw[0])\n\t\t} else {\n\t\t\t// otherwise we need the whole subroute\n\t\t\troute.HandlersRaw = []json.RawMessage{caddyconfig.JSONModuleObject(handler, \"handler\", subroute.CaddyModule().ID.Name(), h.warnings)}\n\t\t}\n\n\t\tnamedRoutes[sb.block.GetKeysText()[0]] = &route\n\t}\n\toptions[\"named_routes\"] = namedRoutes\n\n\treturn filtered, nil\n}\n\n// serversFromPairings creates the servers for each pairing of addresses\n// to server blocks. Each pairing is essentially a server definition.\nfunc (st *ServerType) serversFromPairings(\n\tpairings []sbAddrAssociation,\n\toptions map[string]any,\n\twarnings *[]caddyconfig.Warning,\n\tgroupCounter counter,\n) (map[string]*caddyhttp.Server, error) {\n\tservers := make(map[string]*caddyhttp.Server)\n\tdefaultSNI := tryString(options[\"default_sni\"], warnings)\n\tfallbackSNI := tryString(options[\"fallback_sni\"], warnings)\n\n\thttpPort := strconv.Itoa(caddyhttp.DefaultHTTPPort)\n\tif hp, ok := options[\"http_port\"].(int); ok {\n\t\thttpPort = strconv.Itoa(hp)\n\t}\n\thttpsPort := strconv.Itoa(caddyhttp.DefaultHTTPSPort)\n\tif hsp, ok := options[\"https_port\"].(int); ok {\n\t\thttpsPort = strconv.Itoa(hsp)\n\t}\n\tautoHTTPS := []string{}\n\tif ah, ok := options[\"auto_https\"].([]string); ok {\n\t\tautoHTTPS = ah\n\t}\n\n\tfor i, p := range pairings {\n\t\t// detect ambiguous site definitions: server blocks which\n\t\t// have the same host bound to the same interface (listener\n\t\t// address), otherwise their routes will improperly be added\n\t\t// to the same server (see issue #4635)\n\t\tfor j, sblock1 := range p.serverBlocks {\n\t\t\tfor _, key := range sblock1.block.GetKeysText() {\n\t\t\t\tfor k, sblock2 := range p.serverBlocks {\n\t\t\t\t\tif k == j {\n\t\t\t\t\t\tcontinue\n\t\t\t\t\t}\n\t\t\t\t\tif slices.Contains(sblock2.block.GetKeysText(), key) {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"ambiguous site definition: %s\", key)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tvar (\n\t\t\taddresses []string\n\t\t\tprotocols [][]string\n\t\t)\n\n\t\tfor _, addressWithProtocols := range p.addressesWithProtocols {\n\t\t\taddresses = append(addresses, addressWithProtocols.address)\n\t\t\tprotocols = append(protocols, addressWithProtocols.protocols)\n\t\t}\n\n\t\tsrv := &caddyhttp.Server{\n\t\t\tListen:          addresses,\n\t\t\tListenProtocols: protocols,\n\t\t}\n\n\t\t// remove srv.ListenProtocols[j] if it only contains the default protocols\n\t\tfor j, lnProtocols := range srv.ListenProtocols {\n\t\t\tsrv.ListenProtocols[j] = nil\n\t\t\tfor _, lnProtocol := range lnProtocols {\n\t\t\t\tif lnProtocol != \"\" {\n\t\t\t\t\tsrv.ListenProtocols[j] = lnProtocols\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// remove srv.ListenProtocols if it only contains the default protocols for all listen addresses\n\t\tlistenProtocols := srv.ListenProtocols\n\t\tsrv.ListenProtocols = nil\n\t\tfor _, lnProtocols := range listenProtocols {\n\t\t\tif lnProtocols != nil {\n\t\t\t\tsrv.ListenProtocols = listenProtocols\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\t// handle the auto_https global option\n\t\tfor _, val := range autoHTTPS {\n\t\t\tswitch val {\n\t\t\tcase \"off\":\n\t\t\t\tif srv.AutoHTTPS == nil {\n\t\t\t\t\tsrv.AutoHTTPS = new(caddyhttp.AutoHTTPSConfig)\n\t\t\t\t}\n\t\t\t\tsrv.AutoHTTPS.Disabled = true\n\n\t\t\tcase \"disable_redirects\":\n\t\t\t\tif srv.AutoHTTPS == nil {\n\t\t\t\t\tsrv.AutoHTTPS = new(caddyhttp.AutoHTTPSConfig)\n\t\t\t\t}\n\t\t\t\tsrv.AutoHTTPS.DisableRedir = true\n\n\t\t\tcase \"disable_certs\":\n\t\t\t\tif srv.AutoHTTPS == nil {\n\t\t\t\t\tsrv.AutoHTTPS = new(caddyhttp.AutoHTTPSConfig)\n\t\t\t\t}\n\t\t\t\tsrv.AutoHTTPS.DisableCerts = true\n\n\t\t\tcase \"ignore_loaded_certs\":\n\t\t\t\tif srv.AutoHTTPS == nil {\n\t\t\t\t\tsrv.AutoHTTPS = new(caddyhttp.AutoHTTPSConfig)\n\t\t\t\t}\n\t\t\t\tsrv.AutoHTTPS.IgnoreLoadedCerts = true\n\t\t\t}\n\t\t}\n\n\t\t// Using paths in site addresses is deprecated\n\t\t// See ParseAddress() where parsing should later reject paths\n\t\t// See https://github.com/caddyserver/caddy/pull/4728 for a full explanation\n\t\tfor _, sblock := range p.serverBlocks {\n\t\t\tfor _, addr := range sblock.parsedKeys {\n\t\t\t\tif addr.Path != \"\" {\n\t\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\"Using a path in a site address is deprecated; please use the 'handle' directive instead\", zap.String(\"address\", addr.String()))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// sort server blocks by their keys; this is important because\n\t\t// only the first matching site should be evaluated, and we should\n\t\t// attempt to match most specific site first (host and path), in\n\t\t// case their matchers overlap; we do this somewhat naively by\n\t\t// descending sort by length of host then path\n\t\tsort.SliceStable(p.serverBlocks, func(i, j int) bool {\n\t\t\t// TODO: we could pre-process the specificities for efficiency,\n\t\t\t// but I don't expect many blocks will have THAT many keys...\n\t\t\tvar iLongestPath, jLongestPath string\n\t\t\tvar iLongestHost, jLongestHost string\n\t\t\tvar iWildcardHost, jWildcardHost bool\n\t\t\tfor _, addr := range p.serverBlocks[i].parsedKeys {\n\t\t\t\tif strings.Contains(addr.Host, \"*\") || addr.Host == \"\" {\n\t\t\t\t\tiWildcardHost = true\n\t\t\t\t}\n\t\t\t\tif specificity(addr.Host) > specificity(iLongestHost) {\n\t\t\t\t\tiLongestHost = addr.Host\n\t\t\t\t}\n\t\t\t\tif specificity(addr.Path) > specificity(iLongestPath) {\n\t\t\t\t\tiLongestPath = addr.Path\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor _, addr := range p.serverBlocks[j].parsedKeys {\n\t\t\t\tif strings.Contains(addr.Host, \"*\") || addr.Host == \"\" {\n\t\t\t\t\tjWildcardHost = true\n\t\t\t\t}\n\t\t\t\tif specificity(addr.Host) > specificity(jLongestHost) {\n\t\t\t\t\tjLongestHost = addr.Host\n\t\t\t\t}\n\t\t\t\tif specificity(addr.Path) > specificity(jLongestPath) {\n\t\t\t\t\tjLongestPath = addr.Path\n\t\t\t\t}\n\t\t\t}\n\t\t\t// catch-all blocks (blocks with no hostname) should always go\n\t\t\t// last, even after blocks with wildcard hosts\n\t\t\tif specificity(iLongestHost) == 0 {\n\t\t\t\treturn false\n\t\t\t}\n\t\t\tif specificity(jLongestHost) == 0 {\n\t\t\t\treturn true\n\t\t\t}\n\t\t\tif iWildcardHost != jWildcardHost {\n\t\t\t\t// site blocks that have a key with a wildcard in the hostname\n\t\t\t\t// must always be less specific than blocks without one; see\n\t\t\t\t// https://github.com/caddyserver/caddy/issues/3410\n\t\t\t\treturn jWildcardHost && !iWildcardHost\n\t\t\t}\n\t\t\tif specificity(iLongestHost) == specificity(jLongestHost) {\n\t\t\t\treturn len(iLongestPath) > len(jLongestPath)\n\t\t\t}\n\t\t\treturn specificity(iLongestHost) > specificity(jLongestHost)\n\t\t})\n\n\t\tvar hasCatchAllTLSConnPolicy, addressQualifiesForTLS bool\n\t\tautoHTTPSWillAddConnPolicy := srv.AutoHTTPS == nil || !srv.AutoHTTPS.Disabled\n\n\t\t// if needed, the ServerLogConfig is initialized beforehand so\n\t\t// that all server blocks can populate it with data, even when not\n\t\t// coming with a log directive\n\t\tfor _, sblock := range p.serverBlocks {\n\t\t\tif len(sblock.pile[\"custom_log\"]) != 0 {\n\t\t\t\tsrv.Logs = new(caddyhttp.ServerLogConfig)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\n\t\t// add named routes to the server if 'invoke' was used inside of it\n\t\tconfiguredNamedRoutes := options[\"named_routes\"].(map[string]*caddyhttp.Route)\n\t\tfor _, sblock := range p.serverBlocks {\n\t\t\tif len(sblock.pile[namedRouteKey]) == 0 {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tfor _, value := range sblock.pile[namedRouteKey] {\n\t\t\t\tif srv.NamedRoutes == nil {\n\t\t\t\t\tsrv.NamedRoutes = map[string]*caddyhttp.Route{}\n\t\t\t\t}\n\t\t\t\tname := value.Value.(string)\n\t\t\t\tif configuredNamedRoutes[name] == nil {\n\t\t\t\t\treturn nil, fmt.Errorf(\"cannot invoke named route '%s', which was not defined\", name)\n\t\t\t\t}\n\t\t\t\tsrv.NamedRoutes[name] = configuredNamedRoutes[name]\n\t\t\t}\n\t\t}\n\n\t\t// create a subroute for each site in the server block\n\t\tfor _, sblock := range p.serverBlocks {\n\t\t\tmatcherSetsEnc, err := st.compileEncodedMatcherSets(sblock)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"server block %v: compiling matcher sets: %v\", sblock.block.Keys, err)\n\t\t\t}\n\n\t\t\thosts := sblock.hostsFromKeys(false)\n\n\t\t\t// emit warnings if user put unspecified IP addresses; they probably want the bind directive\n\t\t\tfor _, h := range hosts {\n\t\t\t\tif h == \"0.0.0.0\" || h == \"::\" {\n\t\t\t\t\tcaddy.Log().Named(\"caddyfile\").Warn(\"Site block has an unspecified IP address which only matches requests having that Host header; you probably want the 'bind' directive to configure the socket\", zap.String(\"address\", h))\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// collect hosts that are forced to be automated\n\t\t\tforceAutomatedNames := make(map[string]struct{})\n\t\t\tif _, ok := sblock.pile[\"tls.force_automate\"]; ok {\n\t\t\t\tfor _, host := range hosts {\n\t\t\t\t\tforceAutomatedNames[host] = struct{}{}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// tls: connection policies\n\t\t\tif cpVals, ok := sblock.pile[\"tls.connection_policy\"]; ok {\n\t\t\t\t// tls connection policies\n\t\t\t\tfor _, cpVal := range cpVals {\n\t\t\t\t\tcp := cpVal.Value.(*caddytls.ConnectionPolicy)\n\n\t\t\t\t\t// make sure the policy covers all hostnames from the block\n\t\t\t\t\tfor _, h := range hosts {\n\t\t\t\t\t\tif h == defaultSNI {\n\t\t\t\t\t\t\thosts = append(hosts, \"\")\n\t\t\t\t\t\t\tcp.DefaultSNI = defaultSNI\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif h == fallbackSNI {\n\t\t\t\t\t\t\thosts = append(hosts, \"\")\n\t\t\t\t\t\t\tcp.FallbackSNI = fallbackSNI\n\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif len(hosts) > 0 {\n\t\t\t\t\t\tslices.Sort(hosts) // for deterministic JSON output\n\t\t\t\t\t\tcp.MatchersRaw = caddy.ModuleMap{\n\t\t\t\t\t\t\t\"sni\": caddyconfig.JSON(hosts, warnings), // make sure to match all hosts, not just auto-HTTPS-qualified ones\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tcp.DefaultSNI = defaultSNI\n\t\t\t\t\t\tcp.FallbackSNI = fallbackSNI\n\t\t\t\t\t}\n\n\t\t\t\t\t// only append this policy if it actually changes something,\n\t\t\t\t\t// or if the configuration explicitly automates certs for\n\t\t\t\t\t// these names (this is necessary to hoist a connection policy\n\t\t\t\t\t// above one that may manually load a wildcard cert that would\n\t\t\t\t\t// otherwise clobber the automated one; the code that appends\n\t\t\t\t\t// policies that manually load certs comes later, so they're\n\t\t\t\t\t// lower in the list)\n\t\t\t\t\tif !cp.SettingsEmpty() || mapContains(forceAutomatedNames, hosts) {\n\t\t\t\t\t\tsrv.TLSConnPolicies = append(srv.TLSConnPolicies, cp)\n\t\t\t\t\t\thasCatchAllTLSConnPolicy = len(hosts) == 0\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tfor _, addr := range sblock.parsedKeys {\n\t\t\t\t// if server only uses HTTP port, auto-HTTPS will not apply\n\t\t\t\tif listenersUseAnyPortOtherThan(srv.Listen, httpPort) {\n\t\t\t\t\t// exclude any hosts that were defined explicitly with \"http://\"\n\t\t\t\t\t// in the key from automated cert management (issue #2998)\n\t\t\t\t\tif addr.Scheme == \"http\" && addr.Host != \"\" {\n\t\t\t\t\t\tif srv.AutoHTTPS == nil {\n\t\t\t\t\t\t\tsrv.AutoHTTPS = new(caddyhttp.AutoHTTPSConfig)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif !slices.Contains(srv.AutoHTTPS.Skip, addr.Host) {\n\t\t\t\t\t\t\tsrv.AutoHTTPS.Skip = append(srv.AutoHTTPS.Skip, addr.Host)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// If TLS is specified as directive, it will also result in 1 or more connection policy being created\n\t\t\t\t// Thus, catch-all address with non-standard port, e.g. :8443, can have TLS enabled without\n\t\t\t\t// specifying prefix \"https://\"\n\t\t\t\t// Second part of the condition is to allow creating TLS conn policy even though `auto_https` has been disabled\n\t\t\t\t// ensuring compatibility with behavior described in below link\n\t\t\t\t// https://caddy.community/t/making-sense-of-auto-https-and-why-disabling-it-still-serves-https-instead-of-http/9761\n\t\t\t\tcreatedTLSConnPolicies, ok := sblock.pile[\"tls.connection_policy\"]\n\t\t\t\thasTLSEnabled := (ok && len(createdTLSConnPolicies) > 0) ||\n\t\t\t\t\t(addr.Host != \"\" && srv.AutoHTTPS != nil && !slices.Contains(srv.AutoHTTPS.Skip, addr.Host))\n\n\t\t\t\t// we'll need to remember if the address qualifies for auto-HTTPS, so we\n\t\t\t\t// can add a TLS conn policy if necessary\n\t\t\t\tif addr.Scheme == \"https\" ||\n\t\t\t\t\t(addr.Scheme != \"http\" && addr.Port != httpPort && hasTLSEnabled) {\n\t\t\t\t\taddressQualifiesForTLS = true\n\t\t\t\t}\n\n\t\t\t\t// predict whether auto-HTTPS will add the conn policy for us; if so, we\n\t\t\t\t// may not need to add one for this server\n\t\t\t\tautoHTTPSWillAddConnPolicy = autoHTTPSWillAddConnPolicy &&\n\t\t\t\t\t(addr.Port == httpsPort || (addr.Port != httpPort && addr.Host != \"\"))\n\t\t\t}\n\n\t\t\t// Look for any config values that provide listener wrappers on the server block\n\t\t\tfor _, listenerConfig := range sblock.pile[\"listener_wrapper\"] {\n\t\t\t\tlistenerWrapper, ok := listenerConfig.Value.(caddy.ListenerWrapper)\n\t\t\t\tif !ok {\n\t\t\t\t\treturn nil, fmt.Errorf(\"config for a listener wrapper did not provide a value that implements caddy.ListenerWrapper\")\n\t\t\t\t}\n\t\t\t\tjsonListenerWrapper := caddyconfig.JSONModuleObject(\n\t\t\t\t\tlistenerWrapper,\n\t\t\t\t\t\"wrapper\",\n\t\t\t\t\tlistenerWrapper.(caddy.Module).CaddyModule().ID.Name(),\n\t\t\t\t\twarnings)\n\t\t\t\tsrv.ListenerWrappersRaw = append(srv.ListenerWrappersRaw, jsonListenerWrapper)\n\t\t\t}\n\n\t\t\t// set up each handler directive, making sure to honor directive order\n\t\t\tdirRoutes := sblock.pile[\"route\"]\n\t\t\tsiteSubroute, err := buildSubroute(dirRoutes, groupCounter, true)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\n\t\t\t// add the site block's route(s) to the server\n\t\t\tsrv.Routes = appendSubrouteToRouteList(srv.Routes, siteSubroute, matcherSetsEnc, p, warnings)\n\n\t\t\t// if error routes are defined, add those too\n\t\t\tif errorSubrouteVals, ok := sblock.pile[\"error_route\"]; ok {\n\t\t\t\tif srv.Errors == nil {\n\t\t\t\t\tsrv.Errors = new(caddyhttp.HTTPErrorConfig)\n\t\t\t\t}\n\t\t\t\tsort.SliceStable(errorSubrouteVals, func(i, j int) bool {\n\t\t\t\t\tsri, srj := errorSubrouteVals[i].Value.(*caddyhttp.Subroute), errorSubrouteVals[j].Value.(*caddyhttp.Subroute)\n\t\t\t\t\tif len(sri.Routes[0].MatcherSetsRaw) == 0 && len(srj.Routes[0].MatcherSetsRaw) != 0 {\n\t\t\t\t\t\treturn false\n\t\t\t\t\t}\n\t\t\t\t\treturn true\n\t\t\t\t})\n\t\t\t\terrorsSubroute := &caddyhttp.Subroute{}\n\t\t\t\tfor _, val := range errorSubrouteVals {\n\t\t\t\t\tsr := val.Value.(*caddyhttp.Subroute)\n\t\t\t\t\terrorsSubroute.Routes = append(errorsSubroute.Routes, sr.Routes...)\n\t\t\t\t}\n\t\t\t\tsrv.Errors.Routes = appendSubrouteToRouteList(srv.Errors.Routes, errorsSubroute, matcherSetsEnc, p, warnings)\n\t\t\t}\n\n\t\t\t// add log associations\n\t\t\t// see https://github.com/caddyserver/caddy/issues/3310\n\t\t\tsblockLogHosts := sblock.hostsFromKeys(true)\n\t\t\tfor _, cval := range sblock.pile[\"custom_log\"] {\n\t\t\t\tncl := cval.Value.(namedCustomLog)\n\n\t\t\t\t// if `no_hostname` is set, then this logger will not\n\t\t\t\t// be associated with any of the site block's hostnames,\n\t\t\t\t// and only be usable via the `log_name` directive\n\t\t\t\t// or the `access_logger_names` variable\n\t\t\t\tif ncl.noHostname {\n\t\t\t\t\tcontinue\n\t\t\t\t}\n\n\t\t\t\tif sblock.hasHostCatchAllKey() && len(ncl.hostnames) == 0 {\n\t\t\t\t\t// all requests for hosts not able to be listed should use\n\t\t\t\t\t// this log because it's a catch-all-hosts server block\n\t\t\t\t\tsrv.Logs.DefaultLoggerName = ncl.name\n\t\t\t\t} else if len(ncl.hostnames) > 0 {\n\t\t\t\t\t// if the logger overrides the hostnames, map that to the logger name\n\t\t\t\t\tfor _, h := range ncl.hostnames {\n\t\t\t\t\t\tif srv.Logs.LoggerNames == nil {\n\t\t\t\t\t\t\tsrv.Logs.LoggerNames = make(map[string]caddyhttp.StringArray)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsrv.Logs.LoggerNames[h] = append(srv.Logs.LoggerNames[h], ncl.name)\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t// otherwise, map each host to the logger name\n\t\t\t\t\tfor _, h := range sblockLogHosts {\n\t\t\t\t\t\t// strip the port from the host, if any\n\t\t\t\t\t\thost, _, err := net.SplitHostPort(h)\n\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\thost = h\n\t\t\t\t\t\t}\n\t\t\t\t\t\tif srv.Logs.LoggerNames == nil {\n\t\t\t\t\t\t\tsrv.Logs.LoggerNames = make(map[string]caddyhttp.StringArray)\n\t\t\t\t\t\t}\n\t\t\t\t\t\tsrv.Logs.LoggerNames[host] = append(srv.Logs.LoggerNames[host], ncl.name)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\tif srv.Logs != nil && len(sblock.pile[\"custom_log\"]) == 0 {\n\t\t\t\t// server has access logs enabled, but this server block does not\n\t\t\t\t// enable access logs; therefore, all hosts of this server block\n\t\t\t\t// should not be access-logged\n\t\t\t\tif len(hosts) == 0 {\n\t\t\t\t\t// if the server block has a catch-all-hosts key, then we should\n\t\t\t\t\t// not log reqs to any host unless it appears in the map\n\t\t\t\t\tsrv.Logs.SkipUnmappedHosts = true\n\t\t\t\t}\n\t\t\t\tsrv.Logs.SkipHosts = append(srv.Logs.SkipHosts, sblockLogHosts...)\n\t\t\t}\n\t\t}\n\n\t\t// sort for deterministic JSON output\n\t\tif srv.Logs != nil {\n\t\t\tslices.Sort(srv.Logs.SkipHosts)\n\t\t}\n\n\t\t// a server cannot (natively) serve both HTTP and HTTPS at the\n\t\t// same time, so make sure the configuration isn't in conflict\n\t\terr := detectConflictingSchemes(srv, p.serverBlocks, options)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\t// a catch-all TLS conn policy is necessary to ensure TLS can\n\t\t// be offered to all hostnames of the server; even though only\n\t\t// one policy is needed to enable TLS for the server, that\n\t\t// policy might apply to only certain TLS handshakes; but when\n\t\t// using the Caddyfile, user would expect all handshakes to at\n\t\t// least have a matching connection policy, so here we append a\n\t\t// catch-all/default policy if there isn't one already (it's\n\t\t// important that it goes at the end) - see issue #3004:\n\t\t// https://github.com/caddyserver/caddy/issues/3004\n\t\t// TODO: maybe a smarter way to handle this might be to just make the\n\t\t// auto-HTTPS logic at provision-time detect if there is any connection\n\t\t// policy missing for any HTTPS-enabled hosts, if so, add it... maybe?\n\t\tif addressQualifiesForTLS &&\n\t\t\t!hasCatchAllTLSConnPolicy &&\n\t\t\t(len(srv.TLSConnPolicies) > 0 || !autoHTTPSWillAddConnPolicy || defaultSNI != \"\" || fallbackSNI != \"\") {\n\t\t\tsrv.TLSConnPolicies = append(srv.TLSConnPolicies, &caddytls.ConnectionPolicy{\n\t\t\t\tDefaultSNI:  defaultSNI,\n\t\t\t\tFallbackSNI: fallbackSNI,\n\t\t\t})\n\t\t}\n\n\t\t// tidy things up a bit\n\t\tsrv.TLSConnPolicies, err = consolidateConnPolicies(srv.TLSConnPolicies)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"consolidating TLS connection policies for server %d: %v\", i, err)\n\t\t}\n\t\tsrv.Routes = consolidateRoutes(srv.Routes)\n\n\t\tservers[fmt.Sprintf(\"srv%d\", i)] = srv\n\t}\n\n\tif err := applyServerOptions(servers, options, warnings); err != nil {\n\t\treturn nil, fmt.Errorf(\"applying global server options: %v\", err)\n\t}\n\n\treturn servers, nil\n}\n\nfunc detectConflictingSchemes(srv *caddyhttp.Server, serverBlocks []serverBlock, options map[string]any) error {\n\thttpPort := strconv.Itoa(caddyhttp.DefaultHTTPPort)\n\tif hp, ok := options[\"http_port\"].(int); ok {\n\t\thttpPort = strconv.Itoa(hp)\n\t}\n\thttpsPort := strconv.Itoa(caddyhttp.DefaultHTTPSPort)\n\tif hsp, ok := options[\"https_port\"].(int); ok {\n\t\thttpsPort = strconv.Itoa(hsp)\n\t}\n\n\tvar httpOrHTTPS string\n\tcheckAndSetHTTP := func(addr Address) error {\n\t\tif httpOrHTTPS == \"HTTPS\" {\n\t\t\terrMsg := fmt.Errorf(\"server listening on %v is configured for HTTPS and cannot natively multiplex HTTP and HTTPS: %s\",\n\t\t\t\tsrv.Listen, addr.Original)\n\t\t\tif addr.Scheme == \"\" && addr.Host == \"\" {\n\t\t\t\terrMsg = fmt.Errorf(\"%s (try specifying https:// in the address)\", errMsg)\n\t\t\t}\n\t\t\treturn errMsg\n\t\t}\n\t\tif len(srv.TLSConnPolicies) > 0 {\n\t\t\t// any connection policies created for an HTTP server\n\t\t\t// is a logical conflict, as it would enable HTTPS\n\t\t\treturn fmt.Errorf(\"server listening on %v is HTTP, but attempts to configure TLS connection policies\", srv.Listen)\n\t\t}\n\t\thttpOrHTTPS = \"HTTP\"\n\t\treturn nil\n\t}\n\tcheckAndSetHTTPS := func(addr Address) error {\n\t\tif httpOrHTTPS == \"HTTP\" {\n\t\t\treturn fmt.Errorf(\"server listening on %v is configured for HTTP and cannot natively multiplex HTTP and HTTPS: %s\",\n\t\t\t\tsrv.Listen, addr.Original)\n\t\t}\n\t\thttpOrHTTPS = \"HTTPS\"\n\t\treturn nil\n\t}\n\n\tfor _, sblock := range serverBlocks {\n\t\tfor _, addr := range sblock.parsedKeys {\n\t\t\tif addr.Scheme == \"http\" || addr.Port == httpPort {\n\t\t\t\tif err := checkAndSetHTTP(addr); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t} else if addr.Scheme == \"https\" || addr.Port == httpsPort || len(srv.TLSConnPolicies) > 0 {\n\t\t\t\tif err := checkAndSetHTTPS(addr); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t} else if addr.Host == \"\" {\n\t\t\t\tif err := checkAndSetHTTP(addr); err != nil {\n\t\t\t\t\treturn err\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn nil\n}\n\n// consolidateConnPolicies sorts any catch-all policy to the end, removes empty TLS connection\n// policies, and combines equivalent ones for a cleaner overall output.\nfunc consolidateConnPolicies(cps caddytls.ConnectionPolicies) (caddytls.ConnectionPolicies, error) {\n\t// catch-all policies (those without any matcher) should be at the\n\t// end, otherwise it nullifies any more specific policies\n\tsort.SliceStable(cps, func(i, j int) bool {\n\t\treturn cps[j].MatchersRaw == nil && cps[i].MatchersRaw != nil\n\t})\n\n\tfor i := 0; i < len(cps); i++ {\n\t\t// compare it to the others\n\t\tfor j := 0; j < len(cps); j++ {\n\t\t\tif j == i {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t// if they're exactly equal in every way, just keep one of them\n\t\t\tif reflect.DeepEqual(cps[i], cps[j]) {\n\t\t\t\tcps = slices.Delete(cps, j, j+1)\n\t\t\t\ti--\n\t\t\t\tbreak\n\t\t\t}\n\n\t\t\t// as a special case, if there are adjacent TLS conn policies that are identical except\n\t\t\t// by their matchers, and the matchers are specifically just ServerName (\"sni\") matchers\n\t\t\t// (by far the most common), we can combine them into a single policy\n\t\t\tif i == j-1 && len(cps[i].MatchersRaw) == 1 && len(cps[j].MatchersRaw) == 1 {\n\t\t\t\tif iSNIMatcherJSON, ok := cps[i].MatchersRaw[\"sni\"]; ok {\n\t\t\t\t\tif jSNIMatcherJSON, ok := cps[j].MatchersRaw[\"sni\"]; ok {\n\t\t\t\t\t\t// position of policies and the matcher criteria check out; if settings are\n\t\t\t\t\t\t// the same, then we can combine the policies; we have to unmarshal and\n\t\t\t\t\t\t// remarshal the matchers though\n\t\t\t\t\t\tif cps[i].SettingsEqual(*cps[j]) {\n\t\t\t\t\t\t\tvar iSNIMatcher caddytls.MatchServerName\n\t\t\t\t\t\t\tif err := json.Unmarshal(iSNIMatcherJSON, &iSNIMatcher); err == nil {\n\t\t\t\t\t\t\t\tvar jSNIMatcher caddytls.MatchServerName\n\t\t\t\t\t\t\t\tif err := json.Unmarshal(jSNIMatcherJSON, &jSNIMatcher); err == nil {\n\t\t\t\t\t\t\t\t\tiSNIMatcher = append(iSNIMatcher, jSNIMatcher...)\n\t\t\t\t\t\t\t\t\tcps[i].MatchersRaw[\"sni\"], err = json.Marshal(iSNIMatcher)\n\t\t\t\t\t\t\t\t\tif err != nil {\n\t\t\t\t\t\t\t\t\t\treturn nil, fmt.Errorf(\"recombining SNI matchers: %v\", err)\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tcps = slices.Delete(cps, j, j+1)\n\t\t\t\t\t\t\t\t\ti--\n\t\t\t\t\t\t\t\t\tbreak\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// if they have the same matcher, try to reconcile each field: either they must\n\t\t\t// be identical, or we have to be able to combine them safely\n\t\t\tif reflect.DeepEqual(cps[i].MatchersRaw, cps[j].MatchersRaw) {\n\t\t\t\tif len(cps[i].ALPN) > 0 &&\n\t\t\t\t\tlen(cps[j].ALPN) > 0 &&\n\t\t\t\t\t!reflect.DeepEqual(cps[i].ALPN, cps[j].ALPN) {\n\t\t\t\t\treturn nil, fmt.Errorf(\"two policies with same match criteria have conflicting ALPN: %v vs. %v\",\n\t\t\t\t\t\tcps[i].ALPN, cps[j].ALPN)\n\t\t\t\t}\n\t\t\t\tif len(cps[i].CipherSuites) > 0 &&\n\t\t\t\t\tlen(cps[j].CipherSuites) > 0 &&\n\t\t\t\t\t!reflect.DeepEqual(cps[i].CipherSuites, cps[j].CipherSuites) {\n\t\t\t\t\treturn nil, fmt.Errorf(\"two policies with same match criteria have conflicting cipher suites: %v vs. %v\",\n\t\t\t\t\t\tcps[i].CipherSuites, cps[j].CipherSuites)\n\t\t\t\t}\n\t\t\t\tif cps[i].ClientAuthentication == nil &&\n\t\t\t\t\tcps[j].ClientAuthentication != nil &&\n\t\t\t\t\t!reflect.DeepEqual(cps[i].ClientAuthentication, cps[j].ClientAuthentication) {\n\t\t\t\t\treturn nil, fmt.Errorf(\"two policies with same match criteria have conflicting client auth configuration: %+v vs. %+v\",\n\t\t\t\t\t\tcps[i].ClientAuthentication, cps[j].ClientAuthentication)\n\t\t\t\t}\n\t\t\t\tif len(cps[i].Curves) > 0 &&\n\t\t\t\t\tlen(cps[j].Curves) > 0 &&\n\t\t\t\t\t!reflect.DeepEqual(cps[i].Curves, cps[j].Curves) {\n\t\t\t\t\treturn nil, fmt.Errorf(\"two policies with same match criteria have conflicting curves: %v vs. %v\",\n\t\t\t\t\t\tcps[i].Curves, cps[j].Curves)\n\t\t\t\t}\n\t\t\t\tif cps[i].DefaultSNI != \"\" &&\n\t\t\t\t\tcps[j].DefaultSNI != \"\" &&\n\t\t\t\t\tcps[i].DefaultSNI != cps[j].DefaultSNI {\n\t\t\t\t\treturn nil, fmt.Errorf(\"two policies with same match criteria have conflicting default SNI: %s vs. %s\",\n\t\t\t\t\t\tcps[i].DefaultSNI, cps[j].DefaultSNI)\n\t\t\t\t}\n\t\t\t\tif cps[i].FallbackSNI != \"\" &&\n\t\t\t\t\tcps[j].FallbackSNI != \"\" &&\n\t\t\t\t\tcps[i].FallbackSNI != cps[j].FallbackSNI {\n\t\t\t\t\treturn nil, fmt.Errorf(\"two policies with same match criteria have conflicting fallback SNI: %s vs. %s\",\n\t\t\t\t\t\tcps[i].FallbackSNI, cps[j].FallbackSNI)\n\t\t\t\t}\n\t\t\t\tif cps[i].ProtocolMin != \"\" &&\n\t\t\t\t\tcps[j].ProtocolMin != \"\" &&\n\t\t\t\t\tcps[i].ProtocolMin != cps[j].ProtocolMin {\n\t\t\t\t\treturn nil, fmt.Errorf(\"two policies with same match criteria have conflicting min protocol: %s vs. %s\",\n\t\t\t\t\t\tcps[i].ProtocolMin, cps[j].ProtocolMin)\n\t\t\t\t}\n\t\t\t\tif cps[i].ProtocolMax != \"\" &&\n\t\t\t\t\tcps[j].ProtocolMax != \"\" &&\n\t\t\t\t\tcps[i].ProtocolMax != cps[j].ProtocolMax {\n\t\t\t\t\treturn nil, fmt.Errorf(\"two policies with same match criteria have conflicting max protocol: %s vs. %s\",\n\t\t\t\t\t\tcps[i].ProtocolMax, cps[j].ProtocolMax)\n\t\t\t\t}\n\t\t\t\tif cps[i].CertSelection != nil && cps[j].CertSelection != nil {\n\t\t\t\t\t// merging fields other than AnyTag is not implemented\n\t\t\t\t\tif !reflect.DeepEqual(cps[i].CertSelection.SerialNumber, cps[j].CertSelection.SerialNumber) ||\n\t\t\t\t\t\t!reflect.DeepEqual(cps[i].CertSelection.SubjectOrganization, cps[j].CertSelection.SubjectOrganization) ||\n\t\t\t\t\t\tcps[i].CertSelection.PublicKeyAlgorithm != cps[j].CertSelection.PublicKeyAlgorithm ||\n\t\t\t\t\t\t!reflect.DeepEqual(cps[i].CertSelection.AllTags, cps[j].CertSelection.AllTags) {\n\t\t\t\t\t\treturn nil, fmt.Errorf(\"two policies with same match criteria have conflicting cert selections: %+v vs. %+v\",\n\t\t\t\t\t\t\tcps[i].CertSelection, cps[j].CertSelection)\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t// by now we've decided that we can merge the two -- we'll keep i and drop j\n\n\t\t\t\tif len(cps[i].ALPN) == 0 && len(cps[j].ALPN) > 0 {\n\t\t\t\t\tcps[i].ALPN = cps[j].ALPN\n\t\t\t\t}\n\t\t\t\tif len(cps[i].CipherSuites) == 0 && len(cps[j].CipherSuites) > 0 {\n\t\t\t\t\tcps[i].CipherSuites = cps[j].CipherSuites\n\t\t\t\t}\n\t\t\t\tif cps[i].ClientAuthentication == nil && cps[j].ClientAuthentication != nil {\n\t\t\t\t\tcps[i].ClientAuthentication = cps[j].ClientAuthentication\n\t\t\t\t}\n\t\t\t\tif len(cps[i].Curves) == 0 && len(cps[j].Curves) > 0 {\n\t\t\t\t\tcps[i].Curves = cps[j].Curves\n\t\t\t\t}\n\t\t\t\tif cps[i].DefaultSNI == \"\" && cps[j].DefaultSNI != \"\" {\n\t\t\t\t\tcps[i].DefaultSNI = cps[j].DefaultSNI\n\t\t\t\t}\n\t\t\t\tif cps[i].FallbackSNI == \"\" && cps[j].FallbackSNI != \"\" {\n\t\t\t\t\tcps[i].FallbackSNI = cps[j].FallbackSNI\n\t\t\t\t}\n\t\t\t\tif cps[i].ProtocolMin == \"\" && cps[j].ProtocolMin != \"\" {\n\t\t\t\t\tcps[i].ProtocolMin = cps[j].ProtocolMin\n\t\t\t\t}\n\t\t\t\tif cps[i].ProtocolMax == \"\" && cps[j].ProtocolMax != \"\" {\n\t\t\t\t\tcps[i].ProtocolMax = cps[j].ProtocolMax\n\t\t\t\t}\n\n\t\t\t\tif cps[i].CertSelection == nil && cps[j].CertSelection != nil {\n\t\t\t\t\t// if j is the only one with a policy, move it over to i\n\t\t\t\t\tcps[i].CertSelection = cps[j].CertSelection\n\t\t\t\t} else if cps[i].CertSelection != nil && cps[j].CertSelection != nil {\n\t\t\t\t\t// if both have one, then combine AnyTag\n\t\t\t\t\tfor _, tag := range cps[j].CertSelection.AnyTag {\n\t\t\t\t\t\tif !slices.Contains(cps[i].CertSelection.AnyTag, tag) {\n\t\t\t\t\t\t\tcps[i].CertSelection.AnyTag = append(cps[i].CertSelection.AnyTag, tag)\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tcps = slices.Delete(cps, j, j+1)\n\t\t\t\ti--\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\treturn cps, nil\n}\n\n// appendSubrouteToRouteList appends the routes in subroute\n// to the routeList, optionally qualified by matchers.\nfunc appendSubrouteToRouteList(routeList caddyhttp.RouteList,\n\tsubroute *caddyhttp.Subroute,\n\tmatcherSetsEnc []caddy.ModuleMap,\n\tp sbAddrAssociation,\n\twarnings *[]caddyconfig.Warning,\n) caddyhttp.RouteList {\n\t// nothing to do if... there's nothing to do\n\tif len(matcherSetsEnc) == 0 && len(subroute.Routes) == 0 && subroute.Errors == nil {\n\t\treturn routeList\n\t}\n\n\t// No need to wrap the handlers in a subroute if this is the only server block\n\t// and there is no matcher for it (doing so would produce unnecessarily nested\n\t// JSON), *unless* there is a host matcher within this site block; if so, then\n\t// we still need to wrap in a subroute because otherwise the host matcher from\n\t// the inside of the site block would be a top-level host matcher, which is\n\t// subject to auto-HTTPS (cert management), and using a host matcher within\n\t// a site block is a valid, common pattern for excluding domains from cert\n\t// management, leading to unexpected behavior; see issue #5124.\n\twrapInSubroute := true\n\tif len(matcherSetsEnc) == 0 && len(p.serverBlocks) == 1 {\n\t\tvar hasHostMatcher bool\n\touter:\n\t\tfor _, route := range subroute.Routes {\n\t\t\tfor _, ms := range route.MatcherSetsRaw {\n\t\t\t\tfor matcherName := range ms {\n\t\t\t\t\tif matcherName == \"host\" {\n\t\t\t\t\t\thasHostMatcher = true\n\t\t\t\t\t\tbreak outer\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\twrapInSubroute = hasHostMatcher\n\t}\n\n\tif wrapInSubroute {\n\t\troute := caddyhttp.Route{\n\t\t\t// the semantics of a site block in the Caddyfile dictate\n\t\t\t// that only the first matching one is evaluated, since\n\t\t\t// site blocks do not cascade nor inherit\n\t\t\tTerminal: true,\n\t\t}\n\t\tif len(matcherSetsEnc) > 0 {\n\t\t\troute.MatcherSetsRaw = matcherSetsEnc\n\t\t}\n\t\tif len(subroute.Routes) > 0 || subroute.Errors != nil {\n\t\t\troute.HandlersRaw = []json.RawMessage{\n\t\t\t\tcaddyconfig.JSONModuleObject(subroute, \"handler\", \"subroute\", warnings),\n\t\t\t}\n\t\t}\n\t\tif len(route.MatcherSetsRaw) > 0 || len(route.HandlersRaw) > 0 {\n\t\t\trouteList = append(routeList, route)\n\t\t}\n\t} else {\n\t\trouteList = append(routeList, subroute.Routes...)\n\t}\n\n\treturn routeList\n}\n\n// buildSubroute turns the config values, which are expected to be routes\n// into a clean and orderly subroute that has all the routes within it.\nfunc buildSubroute(routes []ConfigValue, groupCounter counter, needsSorting bool) (*caddyhttp.Subroute, error) {\n\tif needsSorting {\n\t\tfor _, val := range routes {\n\t\t\tif !slices.Contains(directiveOrder, val.directive) {\n\t\t\t\treturn nil, fmt.Errorf(\"directive '%s' is not an ordered HTTP handler, so it cannot be used here - try placing within a route block or using the order global option\", val.directive)\n\t\t\t}\n\t\t}\n\n\t\tsortRoutes(routes)\n\t}\n\n\tsubroute := new(caddyhttp.Subroute)\n\n\t// some directives are mutually exclusive (only first matching\n\t// instance should be evaluated); this is done by putting their\n\t// routes in the same group\n\tmutuallyExclusiveDirs := map[string]*struct {\n\t\tcount     int\n\t\tgroupName string\n\t}{\n\t\t// as a special case, group rewrite directives so that they are mutually exclusive;\n\t\t// this means that only the first matching rewrite will be evaluated, and that's\n\t\t// probably a good thing, since there should never be a need to do more than one\n\t\t// rewrite (I think?), and cascading rewrites smell bad... imagine these rewrites:\n\t\t//     rewrite /docs/json/* /docs/json/index.html\n\t\t//     rewrite /docs/*      /docs/index.html\n\t\t// (We use this on the Caddy website, or at least we did once.) The first rewrite's\n\t\t// result is also matched by the second rewrite, making the first rewrite pointless.\n\t\t// See issue #2959.\n\t\t\"rewrite\": {},\n\n\t\t// handle blocks are also mutually exclusive by definition\n\t\t\"handle\": {},\n\n\t\t// root just sets a variable, so if it was not mutually exclusive, intersecting\n\t\t// root directives would overwrite previously-matched ones; they should not cascade\n\t\t\"root\": {},\n\t}\n\n\t// we need to deterministically loop over each of these directives\n\t// in order to keep the group numbers consistent\n\tkeys := make([]string, 0, len(mutuallyExclusiveDirs))\n\tfor k := range mutuallyExclusiveDirs {\n\t\tkeys = append(keys, k)\n\t}\n\tsort.Strings(keys)\n\n\tfor _, meDir := range keys {\n\t\tinfo := mutuallyExclusiveDirs[meDir]\n\n\t\t// see how many instances of the directive there are\n\t\tfor _, r := range routes {\n\t\t\tif r.directive == meDir {\n\t\t\t\tinfo.count++\n\t\t\t\tif info.count > 1 {\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t// if there is more than one, put them in a group\n\t\t// (special case: \"rewrite\" directive must always be in\n\t\t// its own group--even if there is only one--because we\n\t\t// do not want a rewrite to be consolidated into other\n\t\t// adjacent routes that happen to have the same matcher,\n\t\t// see caddyserver/caddy#3108 - because the implied\n\t\t// intent of rewrite is to do an internal redirect,\n\t\t// we can't assume that the request will continue to\n\t\t// match the same matcher; anyway, giving a route a\n\t\t// unique group name should keep it from consolidating)\n\t\tif info.count > 1 || meDir == \"rewrite\" {\n\t\t\tinfo.groupName = groupCounter.nextGroup()\n\t\t}\n\t}\n\n\t// add all the routes piled in from directives\n\tfor _, r := range routes {\n\t\t// put this route into a group if it is mutually exclusive\n\t\tif info, ok := mutuallyExclusiveDirs[r.directive]; ok {\n\t\t\troute := r.Value.(caddyhttp.Route)\n\t\t\troute.Group = info.groupName\n\t\t\tr.Value = route\n\t\t}\n\n\t\tswitch route := r.Value.(type) {\n\t\tcase caddyhttp.Subroute:\n\t\t\t// if a route-class config value is actually a Subroute handler\n\t\t\t// with nothing but a list of routes, then it is the intention\n\t\t\t// of the directive to keep these handlers together and in this\n\t\t\t// same order, but not necessarily in a subroute (if it wanted\n\t\t\t// to keep them in a subroute, the directive would have returned\n\t\t\t// a route with a Subroute as its handler); this is useful to\n\t\t\t// keep multiple handlers/routes together and in the same order\n\t\t\t// so that the sorting procedure we did above doesn't reorder them\n\t\t\tif route.Errors != nil {\n\t\t\t\t// if error handlers are also set, this is confusing; it's\n\t\t\t\t// probably supposed to be wrapped in a Route and encoded\n\t\t\t\t// as a regular handler route... programmer error.\n\t\t\t\tpanic(\"found subroute with more than just routes; perhaps it should have been wrapped in a route?\")\n\t\t\t}\n\t\t\tsubroute.Routes = append(subroute.Routes, route.Routes...)\n\t\tcase caddyhttp.Route:\n\t\t\tsubroute.Routes = append(subroute.Routes, route)\n\t\t}\n\t}\n\n\tsubroute.Routes = consolidateRoutes(subroute.Routes)\n\n\treturn subroute, nil\n}\n\n// normalizeDirectiveName ensures directives that should be sorted\n// at the same level are named the same before sorting happens.\nfunc normalizeDirectiveName(directive string) string {\n\t// As a special case, we want \"handle_path\" to be sorted\n\t// at the same level as \"handle\", so we force them to use\n\t// the same directive name after their parsing is complete.\n\t// See https://github.com/caddyserver/caddy/issues/3675#issuecomment-678042377\n\tif directive == \"handle_path\" {\n\t\tdirective = \"handle\"\n\t}\n\treturn directive\n}\n\n// consolidateRoutes combines routes with the same properties\n// (same matchers, same Terminal and Group settings) for a\n// cleaner overall output.\nfunc consolidateRoutes(routes caddyhttp.RouteList) caddyhttp.RouteList {\n\tfor i := 0; i < len(routes)-1; i++ {\n\t\tif reflect.DeepEqual(routes[i].MatcherSetsRaw, routes[i+1].MatcherSetsRaw) &&\n\t\t\troutes[i].Terminal == routes[i+1].Terminal &&\n\t\t\troutes[i].Group == routes[i+1].Group {\n\t\t\t// keep the handlers in the same order, then splice out repetitive route\n\t\t\troutes[i].HandlersRaw = append(routes[i].HandlersRaw, routes[i+1].HandlersRaw...)\n\t\t\troutes = append(routes[:i+1], routes[i+2:]...)\n\t\t\ti--\n\t\t}\n\t}\n\treturn routes\n}\n\nfunc matcherSetFromMatcherToken(\n\ttkn caddyfile.Token,\n\tmatcherDefs map[string]caddy.ModuleMap,\n\twarnings *[]caddyconfig.Warning,\n) (caddy.ModuleMap, bool, error) {\n\t// matcher tokens can be wildcards, simple path matchers,\n\t// or refer to a pre-defined matcher by some name\n\tif tkn.Text == \"*\" {\n\t\t// match all requests == no matchers, so nothing to do\n\t\treturn nil, true, nil\n\t}\n\n\t// convenient way to specify a single path match\n\tif strings.HasPrefix(tkn.Text, \"/\") {\n\t\treturn caddy.ModuleMap{\n\t\t\t\"path\": caddyconfig.JSON(caddyhttp.MatchPath{tkn.Text}, warnings),\n\t\t}, true, nil\n\t}\n\n\t// pre-defined matcher\n\tif strings.HasPrefix(tkn.Text, matcherPrefix) {\n\t\tm, ok := matcherDefs[tkn.Text]\n\t\tif !ok {\n\t\t\treturn nil, false, fmt.Errorf(\"unrecognized matcher name: %+v\", tkn.Text)\n\t\t}\n\t\treturn m, true, nil\n\t}\n\n\treturn nil, false, nil\n}\n\nfunc (st *ServerType) compileEncodedMatcherSets(sblock serverBlock) ([]caddy.ModuleMap, error) {\n\ttype hostPathPair struct {\n\t\thostm caddyhttp.MatchHost\n\t\tpathm caddyhttp.MatchPath\n\t}\n\n\t// keep routes with common host and path matchers together\n\tvar matcherPairs []*hostPathPair\n\n\tvar catchAllHosts bool\n\tfor _, addr := range sblock.parsedKeys {\n\t\t// choose a matcher pair that should be shared by this\n\t\t// server block; if none exists yet, create one\n\t\tvar chosenMatcherPair *hostPathPair\n\t\tfor _, mp := range matcherPairs {\n\t\t\tif (len(mp.pathm) == 0 && addr.Path == \"\") ||\n\t\t\t\t(len(mp.pathm) == 1 && mp.pathm[0] == addr.Path) {\n\t\t\t\tchosenMatcherPair = mp\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t\tif chosenMatcherPair == nil {\n\t\t\tchosenMatcherPair = new(hostPathPair)\n\t\t\tif addr.Path != \"\" {\n\t\t\t\tchosenMatcherPair.pathm = []string{addr.Path}\n\t\t\t}\n\t\t\tmatcherPairs = append(matcherPairs, chosenMatcherPair)\n\t\t}\n\n\t\t// if one of the keys has no host (i.e. is a catch-all for\n\t\t// any hostname), then we need to null out the host matcher\n\t\t// entirely so that it matches all hosts\n\t\tif addr.Host == \"\" && !catchAllHosts {\n\t\t\tchosenMatcherPair.hostm = nil\n\t\t\tcatchAllHosts = true\n\t\t}\n\t\tif catchAllHosts {\n\t\t\tcontinue\n\t\t}\n\n\t\t// add this server block's keys to the matcher\n\t\t// pair if it doesn't already exist\n\t\tif addr.Host != \"\" && !slices.Contains(chosenMatcherPair.hostm, addr.Host) {\n\t\t\tchosenMatcherPair.hostm = append(chosenMatcherPair.hostm, addr.Host)\n\t\t}\n\t}\n\n\t// iterate each pairing of host and path matchers and\n\t// put them into a map for JSON encoding\n\tvar matcherSets []map[string]caddyhttp.RequestMatcherWithError\n\tfor _, mp := range matcherPairs {\n\t\tmatcherSet := make(map[string]caddyhttp.RequestMatcherWithError)\n\t\tif len(mp.hostm) > 0 {\n\t\t\tmatcherSet[\"host\"] = mp.hostm\n\t\t}\n\t\tif len(mp.pathm) > 0 {\n\t\t\tmatcherSet[\"path\"] = mp.pathm\n\t\t}\n\t\tif len(matcherSet) > 0 {\n\t\t\tmatcherSets = append(matcherSets, matcherSet)\n\t\t}\n\t}\n\n\t// finally, encode each of the matcher sets\n\tmatcherSetsEnc := make([]caddy.ModuleMap, 0, len(matcherSets))\n\tfor _, ms := range matcherSets {\n\t\tmsEncoded, err := encodeMatcherSet(ms)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"server block %v: %v\", sblock.block.Keys, err)\n\t\t}\n\t\tmatcherSetsEnc = append(matcherSetsEnc, msEncoded)\n\t}\n\n\treturn matcherSetsEnc, nil\n}\n\nfunc parseMatcherDefinitions(d *caddyfile.Dispenser, matchers map[string]caddy.ModuleMap) error {\n\td.Next() // advance to the first token\n\n\t// this is the \"name\" for \"named matchers\"\n\tdefinitionName := d.Val()\n\n\tif _, ok := matchers[definitionName]; ok {\n\t\treturn fmt.Errorf(\"matcher is defined more than once: %s\", definitionName)\n\t}\n\tmatchers[definitionName] = make(caddy.ModuleMap)\n\n\t// given a matcher name and the tokens following it, parse\n\t// the tokens as a matcher module and record it\n\tmakeMatcher := func(matcherName string, tokens []caddyfile.Token) error {\n\t\t// create a new dispenser from the tokens\n\t\tdispenser := caddyfile.NewDispenser(tokens)\n\n\t\t// set the matcher name (without @) in the dispenser context so\n\t\t// that matcher modules can access it to use it as their name\n\t\t// (e.g. regexp matchers which use the name for capture groups)\n\t\tdispenser.SetContext(caddyfile.MatcherNameCtxKey, definitionName[1:])\n\n\t\tmod, err := caddy.GetModule(\"http.matchers.\" + matcherName)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"getting matcher module '%s': %v\", matcherName, err)\n\t\t}\n\t\tunm, ok := mod.New().(caddyfile.Unmarshaler)\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"matcher module '%s' is not a Caddyfile unmarshaler\", matcherName)\n\t\t}\n\t\terr = unm.UnmarshalCaddyfile(dispenser)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif rm, ok := unm.(caddyhttp.RequestMatcherWithError); ok {\n\t\t\tmatchers[definitionName][matcherName] = caddyconfig.JSON(rm, nil)\n\t\t\treturn nil\n\t\t}\n\t\t// nolint:staticcheck\n\t\tif rm, ok := unm.(caddyhttp.RequestMatcher); ok {\n\t\t\tmatchers[definitionName][matcherName] = caddyconfig.JSON(rm, nil)\n\t\t\treturn nil\n\t\t}\n\t\treturn fmt.Errorf(\"matcher module '%s' is not a request matcher\", matcherName)\n\t}\n\n\t// if the next token is quoted, we can assume it's not a matcher name\n\t// and that it's probably an 'expression' matcher\n\tif d.NextArg() {\n\t\tif d.Token().Quoted() {\n\t\t\t// since it was missing the matcher name, we insert a token\n\t\t\t// in front of the expression token itself; we use Clone() to\n\t\t\t// make the new token to keep the same the import location as\n\t\t\t// the next token, if this is within a snippet or imported file.\n\t\t\t// see https://github.com/caddyserver/caddy/issues/6287\n\t\t\texpressionToken := d.Token().Clone()\n\t\t\texpressionToken.Text = \"expression\"\n\t\t\terr := makeMatcher(\"expression\", []caddyfile.Token{expressionToken, d.Token()})\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\treturn nil\n\t\t}\n\n\t\t// if it wasn't quoted, then we need to rewind after calling\n\t\t// d.NextArg() so the below properly grabs the matcher name\n\t\td.Prev()\n\t}\n\n\t// in case there are multiple instances of the same matcher, concatenate\n\t// their tokens (we expect that UnmarshalCaddyfile should be able to\n\t// handle more than one segment); otherwise, we'd overwrite other\n\t// instances of the matcher in this set\n\ttokensByMatcherName := make(map[string][]caddyfile.Token)\n\tfor nesting := d.Nesting(); d.NextArg() || d.NextBlock(nesting); {\n\t\tmatcherName := d.Val()\n\t\ttokensByMatcherName[matcherName] = append(tokensByMatcherName[matcherName], d.NextSegment()...)\n\t}\n\tfor matcherName, tokens := range tokensByMatcherName {\n\t\terr := makeMatcher(matcherName, tokens)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t}\n\treturn nil\n}\n\nfunc encodeMatcherSet(matchers map[string]caddyhttp.RequestMatcherWithError) (caddy.ModuleMap, error) {\n\tmsEncoded := make(caddy.ModuleMap)\n\tfor matcherName, val := range matchers {\n\t\tjsonBytes, err := json.Marshal(val)\n\t\tif err != nil {\n\t\t\treturn nil, fmt.Errorf(\"marshaling matcher set %#v: %v\", matchers, err)\n\t\t}\n\t\tmsEncoded[matcherName] = jsonBytes\n\t}\n\treturn msEncoded, nil\n}\n\n// WasReplacedPlaceholderShorthand checks if a token string was\n// likely a replaced shorthand of the known Caddyfile placeholder\n// replacement outputs. Useful to prevent some user-defined map\n// output destinations from overlapping with one of the\n// predefined shorthands.\nfunc WasReplacedPlaceholderShorthand(token string) string {\n\tprev := \"\"\n\tfor i, item := range placeholderShorthands() {\n\t\t// only look at every 2nd item, which is the replacement\n\t\tif i%2 == 0 {\n\t\t\tprev = item\n\t\t\tcontinue\n\t\t}\n\t\tif strings.Trim(token, \"{}\") == strings.Trim(item, \"{}\") {\n\t\t\t// we return the original shorthand so it\n\t\t\t// can be used for an error message\n\t\t\treturn prev\n\t\t}\n\t}\n\treturn \"\"\n}\n\n// tryInt tries to convert val to an integer. If it fails,\n// it downgrades the error to a warning and returns 0.\nfunc tryInt(val any, warnings *[]caddyconfig.Warning) int {\n\tintVal, ok := val.(int)\n\tif val != nil && !ok && warnings != nil {\n\t\t*warnings = append(*warnings, caddyconfig.Warning{Message: \"not an integer type\"})\n\t}\n\treturn intVal\n}\n\nfunc tryString(val any, warnings *[]caddyconfig.Warning) string {\n\tstringVal, ok := val.(string)\n\tif val != nil && !ok && warnings != nil {\n\t\t*warnings = append(*warnings, caddyconfig.Warning{Message: \"not a string type\"})\n\t}\n\treturn stringVal\n}\n\nfunc tryDuration(val any, warnings *[]caddyconfig.Warning) caddy.Duration {\n\tdurationVal, ok := val.(caddy.Duration)\n\tif val != nil && !ok && warnings != nil {\n\t\t*warnings = append(*warnings, caddyconfig.Warning{Message: \"not a duration type\"})\n\t}\n\treturn durationVal\n}\n\n// listenersUseAnyPortOtherThan returns true if there are any\n// listeners in addresses that use a port which is not otherPort.\n// Mostly borrowed from unexported method in caddyhttp package.\nfunc listenersUseAnyPortOtherThan(addresses []string, otherPort string) bool {\n\totherPortInt, err := strconv.Atoi(otherPort)\n\tif err != nil {\n\t\treturn false\n\t}\n\tfor _, lnAddr := range addresses {\n\t\tladdrs, err := caddy.ParseNetworkAddress(lnAddr)\n\t\tif err != nil {\n\t\t\tcontinue\n\t\t}\n\t\tif uint(otherPortInt) > laddrs.EndPort || uint(otherPortInt) < laddrs.StartPort {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\nfunc mapContains[K comparable, V any](m map[K]V, keys []K) bool {\n\tif len(m) == 0 || len(keys) == 0 {\n\t\treturn false\n\t}\n\tfor _, key := range keys {\n\t\tif _, ok := m[key]; ok {\n\t\t\treturn true\n\t\t}\n\t}\n\treturn false\n}\n\n// specificity returns len(s) minus any wildcards (*) and\n// placeholders ({...}). Basically, it's a length count\n// that penalizes the use of wildcards and placeholders.\n// This is useful for comparing hostnames and paths.\n// However, wildcards in paths are not a sure answer to\n// the question of specificity. For example,\n// '*.example.com' is clearly less specific than\n// 'a.example.com', but is '/a' more or less specific\n// than '/a*'?\nfunc specificity(s string) int {\n\tl := len(s) - strings.Count(s, \"*\")\n\tfor len(s) > 0 {\n\t\tstart := strings.Index(s, \"{\")\n\t\tif start < 0 {\n\t\t\treturn l\n\t\t}\n\t\tend := strings.Index(s[start:], \"}\") + start + 1\n\t\tif end <= start {\n\t\t\treturn l\n\t\t}\n\t\tl -= end - start\n\t\ts = s[end:]\n\t}\n\treturn l\n}\n\ntype counter struct {\n\tn *int\n}\n\nfunc (c counter) nextGroup() string {\n\tname := fmt.Sprintf(\"group%d\", *c.n)\n\t*c.n++\n\treturn name\n}\n\ntype namedCustomLog struct {\n\tname       string\n\thostnames  []string\n\tlog        *caddy.CustomLog\n\tnoHostname bool\n}\n\n// addressWithProtocols associates a listen address with\n// the protocols to serve it with\ntype addressWithProtocols struct {\n\taddress   string\n\tprotocols []string\n}\n\n// sbAddrAssociation is a mapping from a list of\n// addresses with protocols, and a list of server\n// blocks that are served on those addresses.\ntype sbAddrAssociation struct {\n\taddressesWithProtocols []addressWithProtocols\n\tserverBlocks           []serverBlock\n}\n\nconst (\n\tmatcherPrefix = \"@\"\n\tnamedRouteKey = \"named_route\"\n)\n\n// Interface guard\nvar _ caddyfile.ServerType = (*ServerType)(nil)\n",
    "source_file": "caddyconfig/httpcaddyfile/httptype.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage httpcaddyfile\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"html\"\n\t\"net/http\"\n\t\"reflect\"\n\t\"strconv\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/caddyserver/certmagic\"\n\t\"github.com/mholt/acmez/v3/acme\"\n\t\"go.uber.org/zap/zapcore\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddytls\"\n)\n\nfunc init() {\n\tRegisterDirective(\"bind\", parseBind)\n\tRegisterDirective(\"tls\", parseTLS)\n\tRegisterHandlerDirective(\"fs\", parseFilesystem)\n\tRegisterDirective(\"root\", parseRoot)\n\tRegisterHandlerDirective(\"vars\", parseVars)\n\tRegisterHandlerDirective(\"redir\", parseRedir)\n\tRegisterHandlerDirective(\"respond\", parseRespond)\n\tRegisterHandlerDirective(\"abort\", parseAbort)\n\tRegisterHandlerDirective(\"error\", parseError)\n\tRegisterHandlerDirective(\"route\", parseRoute)\n\tRegisterHandlerDirective(\"handle\", parseHandle)\n\tRegisterDirective(\"handle_errors\", parseHandleErrors)\n\tRegisterHandlerDirective(\"invoke\", parseInvoke)\n\tRegisterDirective(\"log\", parseLog)\n\tRegisterHandlerDirective(\"skip_log\", parseLogSkip)\n\tRegisterHandlerDirective(\"log_skip\", parseLogSkip)\n\tRegisterHandlerDirective(\"log_name\", parseLogName)\n}\n\n// parseBind parses the bind directive. Syntax:\n//\n//\t\tbind <addresses...> [{\n//\t   protocols [h1|h2|h2c|h3] [...]\n//\t }]\nfunc parseBind(h Helper) ([]ConfigValue, error) {\n\th.Next() // consume directive name\n\tvar addresses, protocols []string\n\taddresses = h.RemainingArgs()\n\n\tfor h.NextBlock(0) {\n\t\tswitch h.Val() {\n\t\tcase \"protocols\":\n\t\t\tprotocols = h.RemainingArgs()\n\t\t\tif len(protocols) == 0 {\n\t\t\t\treturn nil, h.Errf(\"protocols requires one or more arguments\")\n\t\t\t}\n\t\tdefault:\n\t\t\treturn nil, h.Errf(\"unknown subdirective: %s\", h.Val())\n\t\t}\n\t}\n\n\treturn []ConfigValue{{Class: \"bind\", Value: addressesWithProtocols{\n\t\taddresses: addresses,\n\t\tprotocols: protocols,\n\t}}}, nil\n}\n\n// parseTLS parses the tls directive. Syntax:\n//\n//\ttls [<email>|internal|force_automate]|[<cert_file> <key_file>] {\n//\t    protocols <min> [<max>]\n//\t    ciphers   <cipher_suites...>\n//\t    curves    <curves...>\n//\t    client_auth {\n//\t        mode                   [request|require|verify_if_given|require_and_verify]\n//\t        trust_pool\t\t\t   <module_name> [...]\n//\t        trusted_leaf_cert      <base64_der>\n//\t        trusted_leaf_cert_file <filename>\n//\t    }\n//\t    alpn                          <values...>\n//\t    load                          <paths...>\n//\t    ca                            <acme_ca_endpoint>\n//\t    ca_root                       <pem_file>\n//\t    key_type                      [ed25519|p256|p384|rsa2048|rsa4096]\n//\t    dns                           [<provider_name> [...]]    (required, though, if DNS is not configured as global option)\n//\t    propagation_delay             <duration>\n//\t    propagation_timeout           <duration>\n//\t    resolvers                     <dns_servers...>\n//\t    dns_ttl                       <duration>\n//\t    dns_challenge_override_domain <domain>\n//\t    on_demand\n//\t    reuse_private_keys\n//\t    force_automate\n//\t    eab                           <key_id> <mac_key>\n//\t    issuer                        <module_name> [...]\n//\t    get_certificate               <module_name> [...]\n//\t    insecure_secrets_log          <log_file>\n//\t}\nfunc parseTLS(h Helper) ([]ConfigValue, error) {\n\th.Next() // consume directive name\n\n\tcp := new(caddytls.ConnectionPolicy)\n\tvar fileLoader caddytls.FileLoader\n\tvar folderLoader caddytls.FolderLoader\n\tvar certSelector caddytls.CustomCertSelectionPolicy\n\tvar acmeIssuer *caddytls.ACMEIssuer\n\tvar keyType string\n\tvar internalIssuer *caddytls.InternalIssuer\n\tvar issuers []certmagic.Issuer\n\tvar certManagers []certmagic.Manager\n\tvar onDemand bool\n\tvar reusePrivateKeys bool\n\tvar forceAutomate bool\n\n\tfirstLine := h.RemainingArgs()\n\tswitch len(firstLine) {\n\tcase 0:\n\tcase 1:\n\t\tif firstLine[0] == \"internal\" {\n\t\t\tinternalIssuer = new(caddytls.InternalIssuer)\n\t\t} else if firstLine[0] == \"force_automate\" {\n\t\t\tforceAutomate = true\n\t\t} else if !strings.Contains(firstLine[0], \"@\") {\n\t\t\treturn nil, h.Err(\"single argument must either be 'internal', 'force_automate', or an email address\")\n\t\t} else {\n\t\t\tacmeIssuer = &caddytls.ACMEIssuer{\n\t\t\t\tEmail: firstLine[0],\n\t\t\t}\n\t\t}\n\n\tcase 2:\n\t\t// file certificate loader\n\t\tcertFilename := firstLine[0]\n\t\tkeyFilename := firstLine[1]\n\n\t\t// tag this certificate so if multiple certs match, specifically\n\t\t// this one that the user has provided will be used, see #2588:\n\t\t// https://github.com/caddyserver/caddy/issues/2588 ... but we\n\t\t// must be careful about how we do this; being careless will\n\t\t// lead to failed handshakes\n\t\t//\n\t\t// we need to remember which cert files we've seen, since we\n\t\t// must load each cert only once; otherwise, they each get a\n\t\t// different tag... since a cert loaded twice has the same\n\t\t// bytes, it will overwrite the first one in the cache, and\n\t\t// only the last cert (and its tag) will survive, so any conn\n\t\t// policy that is looking for any tag other than the last one\n\t\t// to be loaded won't find it, and TLS handshakes will fail\n\t\t// (see end of issue #3004)\n\t\t//\n\t\t// tlsCertTags maps certificate filenames to their tag.\n\t\t// This is used to remember which tag is used for each\n\t\t// certificate files, since we need to avoid loading\n\t\t// the same certificate files more than once, overwriting\n\t\t// previous tags\n\t\ttlsCertTags, ok := h.State[\"tlsCertTags\"].(map[string]string)\n\t\tif !ok {\n\t\t\ttlsCertTags = make(map[string]string)\n\t\t\th.State[\"tlsCertTags\"] = tlsCertTags\n\t\t}\n\n\t\ttag, ok := tlsCertTags[certFilename]\n\t\tif !ok {\n\t\t\t// haven't seen this cert file yet, let's give it a tag\n\t\t\t// and add a loader for it\n\t\t\ttag = fmt.Sprintf(\"cert%d\", len(tlsCertTags))\n\t\t\tfileLoader = append(fileLoader, caddytls.CertKeyFilePair{\n\t\t\t\tCertificate: certFilename,\n\t\t\t\tKey:         keyFilename,\n\t\t\t\tTags:        []string{tag},\n\t\t\t})\n\t\t\t// remember this for next time we see this cert file\n\t\t\ttlsCertTags[certFilename] = tag\n\t\t}\n\t\tcertSelector.AnyTag = append(certSelector.AnyTag, tag)\n\n\tdefault:\n\t\treturn nil, h.ArgErr()\n\t}\n\n\tvar hasBlock bool\n\tfor h.NextBlock(0) {\n\t\thasBlock = true\n\n\t\tswitch h.Val() {\n\t\tcase \"protocols\":\n\t\t\targs := h.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn nil, h.Errf(\"protocols requires one or two arguments\")\n\t\t\t}\n\t\t\tif len(args) > 0 {\n\t\t\t\tif _, ok := caddytls.SupportedProtocols[args[0]]; !ok {\n\t\t\t\t\treturn nil, h.Errf(\"wrong protocol name or protocol not supported: '%s'\", args[0])\n\t\t\t\t}\n\t\t\t\tcp.ProtocolMin = args[0]\n\t\t\t}\n\t\t\tif len(args) > 1 {\n\t\t\t\tif _, ok := caddytls.SupportedProtocols[args[1]]; !ok {\n\t\t\t\t\treturn nil, h.Errf(\"wrong protocol name or protocol not supported: '%s'\", args[1])\n\t\t\t\t}\n\t\t\t\tcp.ProtocolMax = args[1]\n\t\t\t}\n\n\t\tcase \"ciphers\":\n\t\t\tfor h.NextArg() {\n\t\t\t\tif !caddytls.CipherSuiteNameSupported(h.Val()) {\n\t\t\t\t\treturn nil, h.Errf(\"wrong cipher suite name or cipher suite not supported: '%s'\", h.Val())\n\t\t\t\t}\n\t\t\t\tcp.CipherSuites = append(cp.CipherSuites, h.Val())\n\t\t\t}\n\n\t\tcase \"curves\":\n\t\t\tfor h.NextArg() {\n\t\t\t\tif _, ok := caddytls.SupportedCurves[h.Val()]; !ok {\n\t\t\t\t\treturn nil, h.Errf(\"Wrong curve name or curve not supported: '%s'\", h.Val())\n\t\t\t\t}\n\t\t\t\tcp.Curves = append(cp.Curves, h.Val())\n\t\t\t}\n\n\t\tcase \"client_auth\":\n\t\t\tcp.ClientAuthentication = &caddytls.ClientAuthentication{}\n\t\t\tif err := cp.ClientAuthentication.UnmarshalCaddyfile(h.NewFromNextSegment()); err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\tcase \"alpn\":\n\t\t\targs := h.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tcp.ALPN = args\n\n\t\tcase \"load\":\n\t\t\tfolderLoader = append(folderLoader, h.RemainingArgs()...)\n\n\t\tcase \"ca\":\n\t\t\targ := h.RemainingArgs()\n\t\t\tif len(arg) != 1 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tif acmeIssuer == nil {\n\t\t\t\tacmeIssuer = new(caddytls.ACMEIssuer)\n\t\t\t}\n\t\t\tacmeIssuer.CA = arg[0]\n\n\t\tcase \"key_type\":\n\t\t\targ := h.RemainingArgs()\n\t\t\tif len(arg) != 1 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tkeyType = arg[0]\n\n\t\tcase \"eab\":\n\t\t\targ := h.RemainingArgs()\n\t\t\tif len(arg) != 2 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tif acmeIssuer == nil {\n\t\t\t\tacmeIssuer = new(caddytls.ACMEIssuer)\n\t\t\t}\n\t\t\tacmeIssuer.ExternalAccount = &acme.EAB{\n\t\t\t\tKeyID:  arg[0],\n\t\t\t\tMACKey: arg[1],\n\t\t\t}\n\n\t\tcase \"issuer\":\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tmodName := h.Val()\n\t\t\tmodID := \"tls.issuance.\" + modName\n\t\t\tunm, err := caddyfile.UnmarshalModule(h.Dispenser, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tissuer, ok := unm.(certmagic.Issuer)\n\t\t\tif !ok {\n\t\t\t\treturn nil, h.Errf(\"module %s (%T) is not a certmagic.Issuer\", modID, unm)\n\t\t\t}\n\t\t\tissuers = append(issuers, issuer)\n\n\t\tcase \"get_certificate\":\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tmodName := h.Val()\n\t\t\tmodID := \"tls.get_certificate.\" + modName\n\t\t\tunm, err := caddyfile.UnmarshalModule(h.Dispenser, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tcertManager, ok := unm.(certmagic.Manager)\n\t\t\tif !ok {\n\t\t\t\treturn nil, h.Errf(\"module %s (%T) is not a certmagic.CertificateManager\", modID, unm)\n\t\t\t}\n\t\t\tcertManagers = append(certManagers, certManager)\n\n\t\tcase \"dns\":\n\t\t\tif acmeIssuer == nil {\n\t\t\t\tacmeIssuer = new(caddytls.ACMEIssuer)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges == nil {\n\t\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges.DNS == nil {\n\t\t\t\tacmeIssuer.Challenges.DNS = new(caddytls.DNSChallengeConfig)\n\t\t\t}\n\t\t\t// DNS provider configuration optional, since it may be configured globally via the TLS app with global options\n\t\t\tif h.NextArg() {\n\t\t\t\tprovName := h.Val()\n\t\t\t\tmodID := \"dns.providers.\" + provName\n\t\t\t\tunm, err := caddyfile.UnmarshalModule(h.Dispenser, modID)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tacmeIssuer.Challenges.DNS.ProviderRaw = caddyconfig.JSONModuleObject(unm, \"name\", provName, h.warnings)\n\t\t\t} else if h.Option(\"dns\") == nil {\n\t\t\t\t// if DNS is omitted locally, it needs to be configured globally\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\n\t\tcase \"resolvers\":\n\t\t\targs := h.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tif acmeIssuer == nil {\n\t\t\t\tacmeIssuer = new(caddytls.ACMEIssuer)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges == nil {\n\t\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges.DNS == nil {\n\t\t\t\tacmeIssuer.Challenges.DNS = new(caddytls.DNSChallengeConfig)\n\t\t\t}\n\t\t\tacmeIssuer.Challenges.DNS.Resolvers = args\n\n\t\tcase \"propagation_delay\":\n\t\t\targ := h.RemainingArgs()\n\t\t\tif len(arg) != 1 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tdelayStr := arg[0]\n\t\t\tdelay, err := caddy.ParseDuration(delayStr)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, h.Errf(\"invalid propagation_delay duration %s: %v\", delayStr, err)\n\t\t\t}\n\t\t\tif acmeIssuer == nil {\n\t\t\t\tacmeIssuer = new(caddytls.ACMEIssuer)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges == nil {\n\t\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges.DNS == nil {\n\t\t\t\tacmeIssuer.Challenges.DNS = new(caddytls.DNSChallengeConfig)\n\t\t\t}\n\t\t\tacmeIssuer.Challenges.DNS.PropagationDelay = caddy.Duration(delay)\n\n\t\tcase \"propagation_timeout\":\n\t\t\targ := h.RemainingArgs()\n\t\t\tif len(arg) != 1 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\ttimeoutStr := arg[0]\n\t\t\tvar timeout time.Duration\n\t\t\tif timeoutStr == \"-1\" {\n\t\t\t\ttimeout = time.Duration(-1)\n\t\t\t} else {\n\t\t\t\tvar err error\n\t\t\t\ttimeout, err = caddy.ParseDuration(timeoutStr)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, h.Errf(\"invalid propagation_timeout duration %s: %v\", timeoutStr, err)\n\t\t\t\t}\n\t\t\t}\n\t\t\tif acmeIssuer == nil {\n\t\t\t\tacmeIssuer = new(caddytls.ACMEIssuer)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges == nil {\n\t\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges.DNS == nil {\n\t\t\t\tacmeIssuer.Challenges.DNS = new(caddytls.DNSChallengeConfig)\n\t\t\t}\n\t\t\tacmeIssuer.Challenges.DNS.PropagationTimeout = caddy.Duration(timeout)\n\n\t\tcase \"dns_ttl\":\n\t\t\targ := h.RemainingArgs()\n\t\t\tif len(arg) != 1 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tttlStr := arg[0]\n\t\t\tttl, err := caddy.ParseDuration(ttlStr)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, h.Errf(\"invalid dns_ttl duration %s: %v\", ttlStr, err)\n\t\t\t}\n\t\t\tif acmeIssuer == nil {\n\t\t\t\tacmeIssuer = new(caddytls.ACMEIssuer)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges == nil {\n\t\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges.DNS == nil {\n\t\t\t\tacmeIssuer.Challenges.DNS = new(caddytls.DNSChallengeConfig)\n\t\t\t}\n\t\t\tacmeIssuer.Challenges.DNS.TTL = caddy.Duration(ttl)\n\n\t\tcase \"dns_challenge_override_domain\":\n\t\t\targ := h.RemainingArgs()\n\t\t\tif len(arg) != 1 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tif acmeIssuer == nil {\n\t\t\t\tacmeIssuer = new(caddytls.ACMEIssuer)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges == nil {\n\t\t\t\tacmeIssuer.Challenges = new(caddytls.ChallengesConfig)\n\t\t\t}\n\t\t\tif acmeIssuer.Challenges.DNS == nil {\n\t\t\t\tacmeIssuer.Challenges.DNS = new(caddytls.DNSChallengeConfig)\n\t\t\t}\n\t\t\tacmeIssuer.Challenges.DNS.OverrideDomain = arg[0]\n\n\t\tcase \"ca_root\":\n\t\t\targ := h.RemainingArgs()\n\t\t\tif len(arg) != 1 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tif acmeIssuer == nil {\n\t\t\t\tacmeIssuer = new(caddytls.ACMEIssuer)\n\t\t\t}\n\t\t\tacmeIssuer.TrustedRootsPEMFiles = append(acmeIssuer.TrustedRootsPEMFiles, arg[0])\n\n\t\tcase \"on_demand\":\n\t\t\tif h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tonDemand = true\n\n\t\tcase \"reuse_private_keys\":\n\t\t\tif h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\treusePrivateKeys = true\n\n\t\tcase \"insecure_secrets_log\":\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tcp.InsecureSecretsLog = h.Val()\n\n\t\tdefault:\n\t\t\treturn nil, h.Errf(\"unknown subdirective: %s\", h.Val())\n\t\t}\n\t}\n\n\t// a naked tls directive is not allowed\n\tif len(firstLine) == 0 && !hasBlock {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\t// begin building the final config values\n\tconfigVals := []ConfigValue{}\n\n\t// certificate loaders\n\tif len(fileLoader) > 0 {\n\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\tClass: \"tls.cert_loader\",\n\t\t\tValue: fileLoader,\n\t\t})\n\t}\n\tif len(folderLoader) > 0 {\n\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\tClass: \"tls.cert_loader\",\n\t\t\tValue: folderLoader,\n\t\t})\n\t}\n\n\t// some tls subdirectives are shortcuts that implicitly configure issuers, and the\n\t// user can also configure issuers explicitly using the issuer subdirective; the\n\t// logic to support both would likely be complex, or at least unintuitive\n\tif len(issuers) > 0 && (acmeIssuer != nil || internalIssuer != nil) {\n\t\treturn nil, h.Err(\"cannot mix issuer subdirective (explicit issuers) with other issuer-specific subdirectives (implicit issuers)\")\n\t}\n\tif acmeIssuer != nil && internalIssuer != nil {\n\t\treturn nil, h.Err(\"cannot create both ACME and internal certificate issuers\")\n\t}\n\n\t// now we should either have: explicitly-created issuers, or an implicitly-created\n\t// ACME or internal issuer, or no issuers at all\n\tswitch {\n\tcase len(issuers) > 0:\n\t\tfor _, issuer := range issuers {\n\t\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\t\tClass: \"tls.cert_issuer\",\n\t\t\t\tValue: issuer,\n\t\t\t})\n\t\t}\n\n\tcase acmeIssuer != nil:\n\t\t// implicit ACME issuers (from various subdirectives) - use defaults; there might be more than one\n\t\tdefaultIssuers := caddytls.DefaultIssuers(acmeIssuer.Email)\n\n\t\t// if an ACME CA endpoint was set, the user expects to use that specific one,\n\t\t// not any others that may be defaults, so replace all defaults with that ACME CA\n\t\tif acmeIssuer.CA != \"\" {\n\t\t\tdefaultIssuers = []certmagic.Issuer{acmeIssuer}\n\t\t}\n\n\t\tfor _, issuer := range defaultIssuers {\n\t\t\t// apply settings from the implicitly-configured ACMEIssuer to any\n\t\t\t// default ACMEIssuers, but preserve each default issuer's CA endpoint,\n\t\t\t// because, for example, if you configure the DNS challenge, it should\n\t\t\t// apply to any of the default ACMEIssuers, but you don't want to trample\n\t\t\t// out their unique CA endpoints\n\t\t\tif iss, ok := issuer.(*caddytls.ACMEIssuer); ok && iss != nil {\n\t\t\t\tacmeCopy := *acmeIssuer\n\t\t\t\tacmeCopy.CA = iss.CA\n\t\t\t\tissuer = &acmeCopy\n\t\t\t}\n\t\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\t\tClass: \"tls.cert_issuer\",\n\t\t\t\tValue: issuer,\n\t\t\t})\n\t\t}\n\n\tcase internalIssuer != nil:\n\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\tClass: \"tls.cert_issuer\",\n\t\t\tValue: internalIssuer,\n\t\t})\n\t}\n\n\t// certificate key type\n\tif keyType != \"\" {\n\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\tClass: \"tls.key_type\",\n\t\t\tValue: keyType,\n\t\t})\n\t}\n\n\t// on-demand TLS\n\tif onDemand {\n\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\tClass: \"tls.on_demand\",\n\t\t\tValue: true,\n\t\t})\n\t}\n\tfor _, certManager := range certManagers {\n\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\tClass: \"tls.cert_manager\",\n\t\t\tValue: certManager,\n\t\t})\n\t}\n\n\t// reuse private keys TLS\n\tif reusePrivateKeys {\n\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\tClass: \"tls.reuse_private_keys\",\n\t\t\tValue: true,\n\t\t})\n\t}\n\n\t// if enabled, the names in the site addresses will be\n\t// added to the automation policies\n\tif forceAutomate {\n\t\tconfigVals = append(configVals, ConfigValue{\n\t\t\tClass: \"tls.force_automate\",\n\t\t\tValue: true,\n\t\t})\n\t}\n\n\t// custom certificate selection\n\tif len(certSelector.AnyTag) > 0 {\n\t\tcp.CertSelection = &certSelector\n\t}\n\n\t// connection policy -- always add one, to ensure that TLS\n\t// is enabled, because this directive was used (this is\n\t// needed, for instance, when a site block has a key of\n\t// just \":5000\" - i.e. no hostname, and only on-demand TLS\n\t// is enabled)\n\tconfigVals = append(configVals, ConfigValue{\n\t\tClass: \"tls.connection_policy\",\n\t\tValue: cp,\n\t})\n\n\treturn configVals, nil\n}\n\n// parseRoot parses the root directive. Syntax:\n//\n//\troot [<matcher>] <path>\nfunc parseRoot(h Helper) ([]ConfigValue, error) {\n\th.Next() // consume directive name\n\n\t// count the tokens to determine what to do\n\targsCount := h.CountRemainingArgs()\n\tif argsCount == 0 {\n\t\treturn nil, h.Errf(\"too few arguments; must have at least a root path\")\n\t}\n\tif argsCount > 2 {\n\t\treturn nil, h.Errf(\"too many arguments; should only be a matcher and a path\")\n\t}\n\n\t// with only one arg, assume it's a root path with no matcher token\n\tif argsCount == 1 {\n\t\tif !h.NextArg() {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\t\treturn h.NewRoute(nil, caddyhttp.VarsMiddleware{\"root\": h.Val()}), nil\n\t}\n\n\t// parse the matcher token into a matcher set\n\tuserMatcherSet, err := h.ExtractMatcherSet()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\th.Next() // consume directive name again, matcher parsing does a reset\n\n\t// advance to the root path\n\tif !h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\t// make the route with the matcher\n\treturn h.NewRoute(userMatcherSet, caddyhttp.VarsMiddleware{\"root\": h.Val()}), nil\n}\n\n// parseFilesystem parses the fs directive. Syntax:\n//\n//\tfs <filesystem>\nfunc parseFilesystem(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\tif !h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\tif h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\treturn caddyhttp.VarsMiddleware{\"fs\": h.Val()}, nil\n}\n\n// parseVars parses the vars directive. See its UnmarshalCaddyfile method for syntax.\nfunc parseVars(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\tv := new(caddyhttp.VarsMiddleware)\n\terr := v.UnmarshalCaddyfile(h.Dispenser)\n\treturn v, err\n}\n\n// parseRedir parses the redir directive. Syntax:\n//\n//\tredir [<matcher>] <to> [<code>]\n//\n// <code> can be \"permanent\" for 301, \"temporary\" for 302 (default),\n// a placeholder, or any number in the 3xx range or 401. The special\n// code \"html\" can be used to redirect only browser clients (will\n// respond with HTTP 200 and no Location header; redirect is performed\n// with JS and a meta tag).\nfunc parseRedir(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\tif !h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\tto := h.Val()\n\n\tvar code string\n\tif h.NextArg() {\n\t\tcode = h.Val()\n\t}\n\n\tvar body string\n\tvar hdr http.Header\n\tswitch code {\n\tcase \"permanent\":\n\t\tcode = \"301\"\n\n\tcase \"temporary\", \"\":\n\t\tcode = \"302\"\n\n\tcase \"html\":\n\t\t// Script tag comes first since that will better imitate a redirect in the browser's\n\t\t// history, but the meta tag is a fallback for most non-JS clients.\n\t\tconst metaRedir = `<!DOCTYPE html>\n<html>\n\t<head>\n\t\t<title>Redirecting...</title>\n\t\t<script>window.location.replace(\"%s\");</script>\n\t\t<meta http-equiv=\"refresh\" content=\"0; URL='%s'\">\n\t</head>\n\t<body>Redirecting to <a href=\"%s\">%s</a>...</body>\n</html>\n`\n\t\tsafeTo := html.EscapeString(to)\n\t\tbody = fmt.Sprintf(metaRedir, safeTo, safeTo, safeTo, safeTo)\n\t\thdr = http.Header{\"Content-Type\": []string{\"text/html; charset=utf-8\"}}\n\t\tcode = \"200\" // don't redirect non-browser clients\n\n\tdefault:\n\t\t// Allow placeholders for the code\n\t\tif strings.HasPrefix(code, \"{\") {\n\t\t\tbreak\n\t\t}\n\t\t// Try to validate as an integer otherwise\n\t\tcodeInt, err := strconv.Atoi(code)\n\t\tif err != nil {\n\t\t\treturn nil, h.Errf(\"Not a supported redir code type or not valid integer: '%s'\", code)\n\t\t}\n\t\t// Sometimes, a 401 with Location header is desirable because\n\t\t// requests made with XHR will \"eat\" the 3xx redirect; so if\n\t\t// the intent was to redirect to an auth page, a 3xx won't\n\t\t// work. Responding with 401 allows JS code to read the\n\t\t// Location header and do a window.location redirect manually.\n\t\t// see https://stackoverflow.com/a/2573589/846934\n\t\t// see https://github.com/oauth2-proxy/oauth2-proxy/issues/1522\n\t\tif codeInt < 300 || (codeInt > 399 && codeInt != 401) {\n\t\t\treturn nil, h.Errf(\"Redir code not in the 3xx range or 401: '%v'\", codeInt)\n\t\t}\n\t}\n\n\t// don't redirect non-browser clients\n\tif code != \"200\" {\n\t\thdr = http.Header{\"Location\": []string{to}}\n\t}\n\n\treturn caddyhttp.StaticResponse{\n\t\tStatusCode: caddyhttp.WeakString(code),\n\t\tHeaders:    hdr,\n\t\tBody:       body,\n\t}, nil\n}\n\n// parseRespond parses the respond directive.\nfunc parseRespond(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\tsr := new(caddyhttp.StaticResponse)\n\terr := sr.UnmarshalCaddyfile(h.Dispenser)\n\treturn sr, err\n}\n\n// parseAbort parses the abort directive.\nfunc parseAbort(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive\n\tfor h.Next() || h.NextBlock(0) {\n\t\treturn nil, h.ArgErr()\n\t}\n\treturn &caddyhttp.StaticResponse{Abort: true}, nil\n}\n\n// parseError parses the error directive.\nfunc parseError(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\tse := new(caddyhttp.StaticError)\n\terr := se.UnmarshalCaddyfile(h.Dispenser)\n\treturn se, err\n}\n\n// parseRoute parses the route directive.\nfunc parseRoute(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\tallResults, err := parseSegmentAsConfig(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tfor _, result := range allResults {\n\t\tswitch result.Value.(type) {\n\t\tcase caddyhttp.Route, caddyhttp.Subroute:\n\t\tdefault:\n\t\t\treturn nil, h.Errf(\"%s directive returned something other than an HTTP route or subroute: %#v (only handler directives can be used in routes)\", result.directive, result.Value)\n\t\t}\n\t}\n\n\treturn buildSubroute(allResults, h.groupCounter, false)\n}\n\nfunc parseHandle(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\treturn ParseSegmentAsSubroute(h)\n}\n\nfunc parseHandleErrors(h Helper) ([]ConfigValue, error) {\n\th.Next() // consume directive name\n\n\texpression := \"\"\n\targs := h.RemainingArgs()\n\tif len(args) > 0 {\n\t\tcodes := []string{}\n\t\tfor _, val := range args {\n\t\t\tif len(val) != 3 {\n\t\t\t\treturn nil, h.Errf(\"bad status value '%s'\", val)\n\t\t\t}\n\t\t\tif strings.HasSuffix(val, \"xx\") {\n\t\t\t\tval = val[:1]\n\t\t\t\t_, err := strconv.Atoi(val)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, h.Errf(\"bad status value '%s': %v\", val, err)\n\t\t\t\t}\n\t\t\t\tif expression != \"\" {\n\t\t\t\t\texpression += \" || \"\n\t\t\t\t}\n\t\t\t\texpression += fmt.Sprintf(\"{http.error.status_code} >= %s00 && {http.error.status_code} <= %s99\", val, val)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\t_, err := strconv.Atoi(val)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, h.Errf(\"bad status value '%s': %v\", val, err)\n\t\t\t}\n\t\t\tcodes = append(codes, val)\n\t\t}\n\t\tif len(codes) > 0 {\n\t\t\tif expression != \"\" {\n\t\t\t\texpression += \" || \"\n\t\t\t}\n\t\t\texpression += \"{http.error.status_code} in [\" + strings.Join(codes, \", \") + \"]\"\n\t\t}\n\t\t// Reset cursor position to get ready for ParseSegmentAsSubroute\n\t\th.Reset()\n\t\th.Next()\n\t\th.RemainingArgs()\n\t\th.Prev()\n\t} else {\n\t\t// If no arguments present reset the cursor position to get ready for ParseSegmentAsSubroute\n\t\th.Prev()\n\t}\n\n\thandler, err := ParseSegmentAsSubroute(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tsubroute, ok := handler.(*caddyhttp.Subroute)\n\tif !ok {\n\t\treturn nil, h.Errf(\"segment was not parsed as a subroute\")\n\t}\n\n\t// wrap the subroutes\n\twrappingRoute := caddyhttp.Route{\n\t\tHandlersRaw: []json.RawMessage{caddyconfig.JSONModuleObject(subroute, \"handler\", \"subroute\", nil)},\n\t}\n\tsubroute = &caddyhttp.Subroute{\n\t\tRoutes: []caddyhttp.Route{wrappingRoute},\n\t}\n\tif expression != \"\" {\n\t\tstatusMatcher := caddy.ModuleMap{\n\t\t\t\"expression\": h.JSON(caddyhttp.MatchExpression{Expr: expression}),\n\t\t}\n\t\tsubroute.Routes[0].MatcherSetsRaw = []caddy.ModuleMap{statusMatcher}\n\t}\n\treturn []ConfigValue{\n\t\t{\n\t\t\tClass: \"error_route\",\n\t\t\tValue: subroute,\n\t\t},\n\t}, nil\n}\n\n// parseInvoke parses the invoke directive.\nfunc parseInvoke(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive\n\tif !h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\tfor h.Next() || h.NextBlock(0) {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\t// remember that we're invoking this name\n\t// to populate the server with these named routes\n\tif h.State[namedRouteKey] == nil {\n\t\th.State[namedRouteKey] = map[string]struct{}{}\n\t}\n\th.State[namedRouteKey].(map[string]struct{})[h.Val()] = struct{}{}\n\n\t// return the handler\n\treturn &caddyhttp.Invoke{Name: h.Val()}, nil\n}\n\n// parseLog parses the log directive. Syntax:\n//\n//\tlog <logger_name> {\n//\t    hostnames <hostnames...>\n//\t    output <writer_module> ...\n//\t    core   <core_module> ...\n//\t    format <encoder_module> ...\n//\t    level  <level>\n//\t}\nfunc parseLog(h Helper) ([]ConfigValue, error) {\n\treturn parseLogHelper(h, nil)\n}\n\n// parseLogHelper is used both for the parseLog directive within Server Blocks,\n// as well as the global \"log\" option for configuring loggers at the global\n// level. The parseAsGlobalOption parameter is used to distinguish any differing logic\n// between the two.\nfunc parseLogHelper(h Helper, globalLogNames map[string]struct{}) ([]ConfigValue, error) {\n\th.Next() // consume option name\n\n\t// When the globalLogNames parameter is passed in, we make\n\t// modifications to the parsing behavior.\n\tparseAsGlobalOption := globalLogNames != nil\n\n\tvar configValues []ConfigValue\n\n\t// Logic below expects that a name is always present when a\n\t// global option is being parsed; or an optional override\n\t// is supported for access logs.\n\tvar logName string\n\n\tif parseAsGlobalOption {\n\t\tif h.NextArg() {\n\t\t\tlogName = h.Val()\n\n\t\t\t// Only a single argument is supported.\n\t\t\tif h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t} else {\n\t\t\t// If there is no log name specified, we\n\t\t\t// reference the default logger. See the\n\t\t\t// setupNewDefault function in the logging\n\t\t\t// package for where this is configured.\n\t\t\tlogName = caddy.DefaultLoggerName\n\t\t}\n\n\t\t// Verify this name is unused.\n\t\t_, used := globalLogNames[logName]\n\t\tif used {\n\t\t\treturn nil, h.Err(\"duplicate global log option for: \" + logName)\n\t\t}\n\t\tglobalLogNames[logName] = struct{}{}\n\t} else {\n\t\t// An optional override of the logger name can be provided;\n\t\t// otherwise a default will be used, like \"log0\", \"log1\", etc.\n\t\tif h.NextArg() {\n\t\t\tlogName = h.Val()\n\n\t\t\t// Only a single argument is supported.\n\t\t\tif h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t}\n\t}\n\n\tcl := new(caddy.CustomLog)\n\n\t// allow overriding the current site block's hostnames for this logger;\n\t// this is useful for setting up loggers per subdomain in a site block\n\t// with a wildcard domain\n\tcustomHostnames := []string{}\n\tnoHostname := false\n\tfor h.NextBlock(0) {\n\t\tswitch h.Val() {\n\t\tcase \"hostnames\":\n\t\t\tif parseAsGlobalOption {\n\t\t\t\treturn nil, h.Err(\"hostnames is not allowed in the log global options\")\n\t\t\t}\n\t\t\targs := h.RemainingArgs()\n\t\t\tif len(args) == 0 {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tcustomHostnames = append(customHostnames, args...)\n\n\t\tcase \"output\":\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tmoduleName := h.Val()\n\n\t\t\t// can't use the usual caddyfile.Unmarshaler flow with the\n\t\t\t// standard writers because they are in the caddy package\n\t\t\t// (because they are the default) and implementing that\n\t\t\t// interface there would unfortunately create circular import\n\t\t\tvar wo caddy.WriterOpener\n\t\t\tswitch moduleName {\n\t\t\tcase \"stdout\":\n\t\t\t\two = caddy.StdoutWriter{}\n\t\t\tcase \"stderr\":\n\t\t\t\two = caddy.StderrWriter{}\n\t\t\tcase \"discard\":\n\t\t\t\two = caddy.DiscardWriter{}\n\t\t\tdefault:\n\t\t\t\tmodID := \"caddy.logging.writers.\" + moduleName\n\t\t\t\tunm, err := caddyfile.UnmarshalModule(h.Dispenser, modID)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tvar ok bool\n\t\t\t\two, ok = unm.(caddy.WriterOpener)\n\t\t\t\tif !ok {\n\t\t\t\t\treturn nil, h.Errf(\"module %s (%T) is not a WriterOpener\", modID, unm)\n\t\t\t\t}\n\t\t\t}\n\t\t\tcl.WriterRaw = caddyconfig.JSONModuleObject(wo, \"output\", moduleName, h.warnings)\n\n\t\tcase \"sampling\":\n\t\t\td := h.Dispenser.NewFromNextSegment()\n\t\t\tfor d.NextArg() {\n\t\t\t\t// consume any tokens on the same line, if any.\n\t\t\t}\n\n\t\t\tsampling := &caddy.LogSampling{}\n\t\t\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\t\t\tsubdir := d.Val()\n\t\t\t\tswitch subdir {\n\t\t\t\tcase \"interval\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tinterval, err := time.ParseDuration(d.Val() + \"ns\")\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, d.Errf(\"failed to parse interval: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t\tsampling.Interval = interval\n\t\t\t\tcase \"first\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tfirst, err := strconv.Atoi(d.Val())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, d.Errf(\"failed to parse first: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t\tsampling.First = first\n\t\t\t\tcase \"thereafter\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tthereafter, err := strconv.Atoi(d.Val())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, d.Errf(\"failed to parse thereafter: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t\tsampling.Thereafter = thereafter\n\t\t\t\tdefault:\n\t\t\t\t\treturn nil, d.Errf(\"unrecognized subdirective: %s\", subdir)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tcl.Sampling = sampling\n\n\t\tcase \"core\":\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tmoduleName := h.Val()\n\t\t\tmoduleID := \"caddy.logging.cores.\" + moduleName\n\t\t\tunm, err := caddyfile.UnmarshalModule(h.Dispenser, moduleID)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tcore, ok := unm.(zapcore.Core)\n\t\t\tif !ok {\n\t\t\t\treturn nil, h.Errf(\"module %s (%T) is not a zapcore.Core\", moduleID, unm)\n\t\t\t}\n\t\t\tcl.CoreRaw = caddyconfig.JSONModuleObject(core, \"module\", moduleName, h.warnings)\n\n\t\tcase \"format\":\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tmoduleName := h.Val()\n\t\t\tmoduleID := \"caddy.logging.encoders.\" + moduleName\n\t\t\tunm, err := caddyfile.UnmarshalModule(h.Dispenser, moduleID)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tenc, ok := unm.(zapcore.Encoder)\n\t\t\tif !ok {\n\t\t\t\treturn nil, h.Errf(\"module %s (%T) is not a zapcore.Encoder\", moduleID, unm)\n\t\t\t}\n\t\t\tcl.EncoderRaw = caddyconfig.JSONModuleObject(enc, \"format\", moduleName, h.warnings)\n\n\t\tcase \"level\":\n\t\t\tif !h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tcl.Level = h.Val()\n\t\t\tif h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\n\t\tcase \"include\":\n\t\t\tif !parseAsGlobalOption {\n\t\t\t\treturn nil, h.Err(\"include is not allowed in the log directive\")\n\t\t\t}\n\t\t\tfor h.NextArg() {\n\t\t\t\tcl.Include = append(cl.Include, h.Val())\n\t\t\t}\n\n\t\tcase \"exclude\":\n\t\t\tif !parseAsGlobalOption {\n\t\t\t\treturn nil, h.Err(\"exclude is not allowed in the log directive\")\n\t\t\t}\n\t\t\tfor h.NextArg() {\n\t\t\t\tcl.Exclude = append(cl.Exclude, h.Val())\n\t\t\t}\n\n\t\tcase \"no_hostname\":\n\t\t\tif h.NextArg() {\n\t\t\t\treturn nil, h.ArgErr()\n\t\t\t}\n\t\t\tnoHostname = true\n\n\t\tdefault:\n\t\t\treturn nil, h.Errf(\"unrecognized subdirective: %s\", h.Val())\n\t\t}\n\t}\n\n\tvar val namedCustomLog\n\tval.hostnames = customHostnames\n\tval.noHostname = noHostname\n\tisEmptyConfig := reflect.DeepEqual(cl, new(caddy.CustomLog))\n\n\t// Skip handling of empty logging configs\n\n\tif parseAsGlobalOption {\n\t\t// Use indicated name for global log options\n\t\tval.name = logName\n\t} else {\n\t\tif logName != \"\" {\n\t\t\tval.name = logName\n\t\t} else if !isEmptyConfig {\n\t\t\t// Construct a log name for server log streams\n\t\t\tlogCounter, ok := h.State[\"logCounter\"].(int)\n\t\t\tif !ok {\n\t\t\t\tlogCounter = 0\n\t\t\t}\n\t\t\tval.name = fmt.Sprintf(\"log%d\", logCounter)\n\t\t\tlogCounter++\n\t\t\th.State[\"logCounter\"] = logCounter\n\t\t}\n\t\tif val.name != \"\" {\n\t\t\tcl.Include = []string{\"http.log.access.\" + val.name}\n\t\t}\n\t}\n\tif !isEmptyConfig {\n\t\tval.log = cl\n\t}\n\tconfigValues = append(configValues, ConfigValue{\n\t\tClass: \"custom_log\",\n\t\tValue: val,\n\t})\n\treturn configValues, nil\n}\n\n// parseLogSkip parses the log_skip directive. Syntax:\n//\n//\tlog_skip [<matcher>]\nfunc parseLogSkip(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\n\t// \"skip_log\" is deprecated, replaced by \"log_skip\"\n\tif h.Val() == \"skip_log\" {\n\t\tcaddy.Log().Named(\"config.adapter.caddyfile\").Warn(\"the 'skip_log' directive is deprecated, please use 'log_skip' instead!\")\n\t}\n\n\tif h.NextArg() {\n\t\treturn nil, h.ArgErr()\n\t}\n\n\tif h.NextBlock(0) {\n\t\treturn nil, h.Err(\"log_skip directive does not accept blocks\")\n\t}\n\n\treturn caddyhttp.VarsMiddleware{\"log_skip\": true}, nil\n}\n\n// parseLogName parses the log_name directive. Syntax:\n//\n//\tlog_name <names...>\nfunc parseLogName(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\th.Next() // consume directive name\n\treturn caddyhttp.VarsMiddleware{\n\t\tcaddyhttp.AccessLoggerNameVarKey: h.RemainingArgs(),\n\t}, nil\n}\n",
    "source_file": "caddyconfig/httpcaddyfile/builtins.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage httpcaddyfile\n\nimport (\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"slices\"\n\n\t\"github.com/dustin/go-humanize\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\n// serverOptions collects server config overrides parsed from Caddyfile global options\ntype serverOptions struct {\n\t// If set, will only apply these options to servers that contain a\n\t// listener address that matches exactly. If empty, will apply to all\n\t// servers that were not already matched by another serverOptions.\n\tListenerAddress string\n\n\t// These will all map 1:1 to the caddyhttp.Server struct\n\tName                 string\n\tListenerWrappersRaw  []json.RawMessage\n\tReadTimeout          caddy.Duration\n\tReadHeaderTimeout    caddy.Duration\n\tWriteTimeout         caddy.Duration\n\tIdleTimeout          caddy.Duration\n\tKeepAliveInterval    caddy.Duration\n\tMaxHeaderBytes       int\n\tEnableFullDuplex     bool\n\tProtocols            []string\n\tStrictSNIHost        *bool\n\tTrustedProxiesRaw    json.RawMessage\n\tTrustedProxiesStrict int\n\tClientIPHeaders      []string\n\tShouldLogCredentials bool\n\tMetrics              *caddyhttp.Metrics\n\tTrace                bool // TODO: EXPERIMENTAL\n}\n\nfunc unmarshalCaddyfileServerOptions(d *caddyfile.Dispenser) (any, error) {\n\td.Next() // consume option name\n\n\tserverOpts := serverOptions{}\n\tif d.NextArg() {\n\t\tserverOpts.ListenerAddress = d.Val()\n\t\tif d.NextArg() {\n\t\t\treturn nil, d.ArgErr()\n\t\t}\n\t}\n\tfor d.NextBlock(0) {\n\t\tswitch d.Val() {\n\t\tcase \"name\":\n\t\t\tif serverOpts.ListenerAddress == \"\" {\n\t\t\t\treturn nil, d.Errf(\"cannot set a name for a server without a listener address\")\n\t\t\t}\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tserverOpts.Name = d.Val()\n\n\t\tcase \"listener_wrappers\":\n\t\t\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\t\t\tmodID := \"caddy.listeners.\" + d.Val()\n\t\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\tlistenerWrapper, ok := unm.(caddy.ListenerWrapper)\n\t\t\t\tif !ok {\n\t\t\t\t\treturn nil, fmt.Errorf(\"module %s (%T) is not a listener wrapper\", modID, unm)\n\t\t\t\t}\n\t\t\t\tjsonListenerWrapper := caddyconfig.JSONModuleObject(\n\t\t\t\t\tlistenerWrapper,\n\t\t\t\t\t\"wrapper\",\n\t\t\t\t\tlistenerWrapper.(caddy.Module).CaddyModule().ID.Name(),\n\t\t\t\t\tnil,\n\t\t\t\t)\n\t\t\t\tserverOpts.ListenerWrappersRaw = append(serverOpts.ListenerWrappersRaw, jsonListenerWrapper)\n\t\t\t}\n\n\t\tcase \"timeouts\":\n\t\t\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\t\t\tswitch d.Val() {\n\t\t\t\tcase \"read_body\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, d.Errf(\"parsing read_body timeout duration: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t\tserverOpts.ReadTimeout = caddy.Duration(dur)\n\n\t\t\t\tcase \"read_header\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, d.Errf(\"parsing read_header timeout duration: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t\tserverOpts.ReadHeaderTimeout = caddy.Duration(dur)\n\n\t\t\t\tcase \"write\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, d.Errf(\"parsing write timeout duration: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t\tserverOpts.WriteTimeout = caddy.Duration(dur)\n\n\t\t\t\tcase \"idle\":\n\t\t\t\t\tif !d.NextArg() {\n\t\t\t\t\t\treturn nil, d.ArgErr()\n\t\t\t\t\t}\n\t\t\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\t\t\tif err != nil {\n\t\t\t\t\t\treturn nil, d.Errf(\"parsing idle timeout duration: %v\", err)\n\t\t\t\t\t}\n\t\t\t\t\tserverOpts.IdleTimeout = caddy.Duration(dur)\n\n\t\t\t\tdefault:\n\t\t\t\t\treturn nil, d.Errf(\"unrecognized timeouts option '%s'\", d.Val())\n\t\t\t\t}\n\t\t\t}\n\t\tcase \"keepalive_interval\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tdur, err := caddy.ParseDuration(d.Val())\n\t\t\tif err != nil {\n\t\t\t\treturn nil, d.Errf(\"parsing keepalive interval duration: %v\", err)\n\t\t\t}\n\t\t\tserverOpts.KeepAliveInterval = caddy.Duration(dur)\n\n\t\tcase \"max_header_size\":\n\t\t\tvar sizeStr string\n\t\t\tif !d.AllArgs(&sizeStr) {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tsize, err := humanize.ParseBytes(sizeStr)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, d.Errf(\"parsing max_header_size: %v\", err)\n\t\t\t}\n\t\t\tserverOpts.MaxHeaderBytes = int(size)\n\n\t\tcase \"enable_full_duplex\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tserverOpts.EnableFullDuplex = true\n\n\t\tcase \"log_credentials\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tserverOpts.ShouldLogCredentials = true\n\n\t\tcase \"protocols\":\n\t\t\tprotos := d.RemainingArgs()\n\t\t\tfor _, proto := range protos {\n\t\t\t\tif proto != \"h1\" && proto != \"h2\" && proto != \"h2c\" && proto != \"h3\" {\n\t\t\t\t\treturn nil, d.Errf(\"unknown protocol '%s': expected h1, h2, h2c, or h3\", proto)\n\t\t\t\t}\n\t\t\t\tif slices.Contains(serverOpts.Protocols, proto) {\n\t\t\t\t\treturn nil, d.Errf(\"protocol %s specified more than once\", proto)\n\t\t\t\t}\n\t\t\t\tserverOpts.Protocols = append(serverOpts.Protocols, proto)\n\t\t\t}\n\t\t\tif nesting := d.Nesting(); d.NextBlock(nesting) {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\n\t\tcase \"strict_sni_host\":\n\t\t\tif d.NextArg() && d.Val() != \"insecure_off\" && d.Val() != \"on\" {\n\t\t\t\treturn nil, d.Errf(\"strict_sni_host only supports 'on' or 'insecure_off', got '%s'\", d.Val())\n\t\t\t}\n\t\t\tboolVal := true\n\t\t\tif d.Val() == \"insecure_off\" {\n\t\t\t\tboolVal = false\n\t\t\t}\n\t\t\tserverOpts.StrictSNIHost = &boolVal\n\n\t\tcase \"trusted_proxies\":\n\t\t\tif !d.NextArg() {\n\t\t\t\treturn nil, d.Err(\"trusted_proxies expects an IP range source module name as its first argument\")\n\t\t\t}\n\t\t\tmodID := \"http.ip_sources.\" + d.Val()\n\t\t\tunm, err := caddyfile.UnmarshalModule(d, modID)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\tsource, ok := unm.(caddyhttp.IPRangeSource)\n\t\t\tif !ok {\n\t\t\t\treturn nil, fmt.Errorf(\"module %s (%T) is not an IP range source\", modID, unm)\n\t\t\t}\n\t\t\tjsonSource := caddyconfig.JSONModuleObject(\n\t\t\t\tsource,\n\t\t\t\t\"source\",\n\t\t\t\tsource.(caddy.Module).CaddyModule().ID.Name(),\n\t\t\t\tnil,\n\t\t\t)\n\t\t\tserverOpts.TrustedProxiesRaw = jsonSource\n\n\t\tcase \"trusted_proxies_strict\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tserverOpts.TrustedProxiesStrict = 1\n\n\t\tcase \"client_ip_headers\":\n\t\t\theaders := d.RemainingArgs()\n\t\t\tfor _, header := range headers {\n\t\t\t\tif slices.Contains(serverOpts.ClientIPHeaders, header) {\n\t\t\t\t\treturn nil, d.Errf(\"client IP header %s specified more than once\", header)\n\t\t\t\t}\n\t\t\t\tserverOpts.ClientIPHeaders = append(serverOpts.ClientIPHeaders, header)\n\t\t\t}\n\t\t\tif nesting := d.Nesting(); d.NextBlock(nesting) {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\n\t\tcase \"metrics\":\n\t\t\tcaddy.Log().Warn(\"The nested 'metrics' option inside `servers` is deprecated and will be removed in the next major version. Use the global 'metrics' option instead.\")\n\t\t\tserverOpts.Metrics = new(caddyhttp.Metrics)\n\t\t\tfor nesting := d.Nesting(); d.NextBlock(nesting); {\n\t\t\t\tswitch d.Val() {\n\t\t\t\tcase \"per_host\":\n\t\t\t\t\tserverOpts.Metrics.PerHost = true\n\t\t\t\tdefault:\n\t\t\t\t\treturn nil, d.Errf(\"unrecognized metrics option '%s'\", d.Val())\n\t\t\t\t}\n\t\t\t}\n\n\t\tcase \"trace\":\n\t\t\tif d.NextArg() {\n\t\t\t\treturn nil, d.ArgErr()\n\t\t\t}\n\t\t\tserverOpts.Trace = true\n\n\t\tdefault:\n\t\t\treturn nil, d.Errf(\"unrecognized servers option '%s'\", d.Val())\n\t\t}\n\t}\n\treturn serverOpts, nil\n}\n\n// applyServerOptions sets the server options on the appropriate servers\nfunc applyServerOptions(\n\tservers map[string]*caddyhttp.Server,\n\toptions map[string]any,\n\t_ *[]caddyconfig.Warning,\n) error {\n\tserverOpts, ok := options[\"servers\"].([]serverOptions)\n\tif !ok {\n\t\treturn nil\n\t}\n\n\t// check for duplicate names, which would clobber the config\n\texistingNames := map[string]bool{}\n\tfor _, opts := range serverOpts {\n\t\tif opts.Name == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tif existingNames[opts.Name] {\n\t\t\treturn fmt.Errorf(\"cannot use duplicate server name '%s'\", opts.Name)\n\t\t}\n\t\texistingNames[opts.Name] = true\n\t}\n\n\t// collect the server name overrides\n\tnameReplacements := map[string]string{}\n\n\tfor key, server := range servers {\n\t\t// find the options that apply to this server\n\t\toptsIndex := slices.IndexFunc(serverOpts, func(s serverOptions) bool {\n\t\t\treturn s.ListenerAddress == \"\" || slices.Contains(server.Listen, s.ListenerAddress)\n\t\t})\n\n\t\t// if none apply, then move to the next server\n\t\tif optsIndex == -1 {\n\t\t\tcontinue\n\t\t}\n\t\topts := serverOpts[optsIndex]\n\n\t\t// set all the options\n\t\tserver.ListenerWrappersRaw = opts.ListenerWrappersRaw\n\t\tserver.ReadTimeout = opts.ReadTimeout\n\t\tserver.ReadHeaderTimeout = opts.ReadHeaderTimeout\n\t\tserver.WriteTimeout = opts.WriteTimeout\n\t\tserver.IdleTimeout = opts.IdleTimeout\n\t\tserver.KeepAliveInterval = opts.KeepAliveInterval\n\t\tserver.MaxHeaderBytes = opts.MaxHeaderBytes\n\t\tserver.EnableFullDuplex = opts.EnableFullDuplex\n\t\tserver.Protocols = opts.Protocols\n\t\tserver.StrictSNIHost = opts.StrictSNIHost\n\t\tserver.TrustedProxiesRaw = opts.TrustedProxiesRaw\n\t\tserver.ClientIPHeaders = opts.ClientIPHeaders\n\t\tserver.TrustedProxiesStrict = opts.TrustedProxiesStrict\n\t\tserver.Metrics = opts.Metrics\n\t\tif opts.ShouldLogCredentials {\n\t\t\tif server.Logs == nil {\n\t\t\t\tserver.Logs = new(caddyhttp.ServerLogConfig)\n\t\t\t}\n\t\t\tserver.Logs.ShouldLogCredentials = opts.ShouldLogCredentials\n\t\t}\n\t\tif opts.Trace {\n\t\t\t// TODO: THIS IS EXPERIMENTAL (MAY 2024)\n\t\t\tif server.Logs == nil {\n\t\t\t\tserver.Logs = new(caddyhttp.ServerLogConfig)\n\t\t\t}\n\t\t\tserver.Logs.Trace = opts.Trace\n\t\t}\n\n\t\tif opts.Name != \"\" {\n\t\t\tnameReplacements[key] = opts.Name\n\t\t}\n\t}\n\n\t// rename the servers if marked to do so\n\tfor old, new := range nameReplacements {\n\t\tservers[new] = servers[old]\n\t\tdelete(servers, old)\n\t}\n\n\treturn nil\n}\n",
    "source_file": "caddyconfig/httpcaddyfile/serveroptions.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n//go:build gofuzz\n\npackage httpcaddyfile\n\nfunc FuzzParseAddress(data []byte) int {\n\taddr, err := ParseAddress(string(data))\n\tif err != nil {\n\t\tif addr == (Address{}) {\n\t\t\treturn 1\n\t\t}\n\t\treturn 0\n\t}\n\treturn 1\n}\n",
    "source_file": "caddyconfig/httpcaddyfile/addresses_fuzz.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage httpcaddyfile\n\nimport (\n\t\"encoding/json\"\n\t\"maps\"\n\t\"net\"\n\t\"slices\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\n// defaultDirectiveOrder specifies the default order\n// to apply directives in HTTP routes. This must only\n// consist of directives that are included in Caddy's\n// standard distribution.\n//\n// e.g. The 'root' directive goes near the start in\n// case rewrites or redirects depend on existence of\n// files, i.e. the file matcher, which must know the\n// root first.\n//\n// e.g. The 'header' directive goes before 'redir' so\n// that headers can be manipulated before doing redirects.\n//\n// e.g. The 'respond' directive is near the end because it\n// writes a response and terminates the middleware chain.\nvar defaultDirectiveOrder = []string{\n\t\"tracing\",\n\n\t// set variables that may be used by other directives\n\t\"map\",\n\t\"vars\",\n\t\"fs\",\n\t\"root\",\n\t\"log_append\",\n\t\"skip_log\", // TODO: deprecated, renamed to log_skip\n\t\"log_skip\",\n\t\"log_name\",\n\n\t\"header\",\n\t\"copy_response_headers\", // only in reverse_proxy's handle_response\n\t\"request_body\",\n\n\t\"redir\",\n\n\t// incoming request manipulation\n\t\"method\",\n\t\"rewrite\",\n\t\"uri\",\n\t\"try_files\",\n\n\t// middleware handlers; some wrap responses\n\t\"basicauth\", // TODO: deprecated, renamed to basic_auth\n\t\"basic_auth\",\n\t\"forward_auth\",\n\t\"request_header\",\n\t\"encode\",\n\t\"push\",\n\t\"intercept\",\n\t\"templates\",\n\n\t// special routing & dispatching directives\n\t\"invoke\",\n\t\"handle\",\n\t\"handle_path\",\n\t\"route\",\n\n\t// handlers that typically respond to requests\n\t\"abort\",\n\t\"error\",\n\t\"copy_response\", // only in reverse_proxy's handle_response\n\t\"respond\",\n\t\"metrics\",\n\t\"reverse_proxy\",\n\t\"php_fastcgi\",\n\t\"file_server\",\n\t\"acme_server\",\n}\n\n// directiveOrder specifies the order to apply directives\n// in HTTP routes, after being modified by either the\n// plugins or by the user via the \"order\" global option.\nvar directiveOrder = defaultDirectiveOrder\n\n// RegisterDirective registers a unique directive dir with an\n// associated unmarshaling (setup) function. When directive dir\n// is encountered in a Caddyfile, setupFunc will be called to\n// unmarshal its tokens.\nfunc RegisterDirective(dir string, setupFunc UnmarshalFunc) {\n\tif _, ok := registeredDirectives[dir]; ok {\n\t\tpanic(\"directive \" + dir + \" already registered\")\n\t}\n\tregisteredDirectives[dir] = setupFunc\n}\n\n// RegisterHandlerDirective is like RegisterDirective, but for\n// directives which specifically output only an HTTP handler.\n// Directives registered with this function will always have\n// an optional matcher token as the first argument.\nfunc RegisterHandlerDirective(dir string, setupFunc UnmarshalHandlerFunc) {\n\tRegisterDirective(dir, func(h Helper) ([]ConfigValue, error) {\n\t\tif !h.Next() {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\n\t\tmatcherSet, err := h.ExtractMatcherSet()\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\tval, err := setupFunc(h)\n\t\tif err != nil {\n\t\t\treturn nil, err\n\t\t}\n\n\t\treturn h.NewRoute(matcherSet, val), nil\n\t})\n}\n\n// RegisterDirectiveOrder registers the default order for a\n// directive from a plugin.\n//\n// This is useful when a plugin has a well-understood place\n// it should run in the middleware pipeline, and it allows\n// users to avoid having to define the order themselves.\n//\n// The directive dir may be placed in the position relative\n// to ('before' or 'after') a directive included in Caddy's\n// standard distribution. It cannot be relative to another\n// plugin's directive.\n//\n// EXPERIMENTAL: This API may change or be removed.\nfunc RegisterDirectiveOrder(dir string, position Positional, standardDir string) {\n\t// check if directive was already ordered\n\tif slices.Contains(directiveOrder, dir) {\n\t\tpanic(\"directive '\" + dir + \"' already ordered\")\n\t}\n\n\tif position != Before && position != After {\n\t\tpanic(\"the 2nd argument must be either 'before' or 'after', got '\" + position + \"'\")\n\t}\n\n\t// check if directive exists in standard distribution, since\n\t// we can't allow plugins to depend on one another; we can't\n\t// guarantee the order that plugins are loaded in.\n\tfoundStandardDir := slices.Contains(defaultDirectiveOrder, standardDir)\n\tif !foundStandardDir {\n\t\tpanic(\"the 3rd argument '\" + standardDir + \"' must be a directive that exists in the standard distribution of Caddy\")\n\t}\n\n\t// insert directive into proper position\n\tnewOrder := directiveOrder\n\tfor i, d := range newOrder {\n\t\tif d != standardDir {\n\t\t\tcontinue\n\t\t}\n\t\tswitch position {\n\t\tcase Before:\n\t\t\tnewOrder = append(newOrder[:i], append([]string{dir}, newOrder[i:]...)...)\n\t\tcase After:\n\t\t\tnewOrder = append(newOrder[:i+1], append([]string{dir}, newOrder[i+1:]...)...)\n\t\tcase First, Last:\n\t\t}\n\t\tbreak\n\t}\n\tdirectiveOrder = newOrder\n}\n\n// RegisterGlobalOption registers a unique global option opt with\n// an associated unmarshaling (setup) function. When the global\n// option opt is encountered in a Caddyfile, setupFunc will be\n// called to unmarshal its tokens.\nfunc RegisterGlobalOption(opt string, setupFunc UnmarshalGlobalFunc) {\n\tif _, ok := registeredGlobalOptions[opt]; ok {\n\t\tpanic(\"global option \" + opt + \" already registered\")\n\t}\n\tregisteredGlobalOptions[opt] = setupFunc\n}\n\n// Helper is a type which helps setup a value from\n// Caddyfile tokens.\ntype Helper struct {\n\t*caddyfile.Dispenser\n\t// State stores intermediate variables during caddyfile adaptation.\n\tState        map[string]any\n\toptions      map[string]any\n\twarnings     *[]caddyconfig.Warning\n\tmatcherDefs  map[string]caddy.ModuleMap\n\tparentBlock  caddyfile.ServerBlock\n\tgroupCounter counter\n}\n\n// Option gets the option keyed by name.\nfunc (h Helper) Option(name string) any {\n\treturn h.options[name]\n}\n\n// Caddyfiles returns the list of config files from\n// which tokens in the current server block were loaded.\nfunc (h Helper) Caddyfiles() []string {\n\t// first obtain set of names of files involved\n\t// in this server block, without duplicates\n\tfiles := make(map[string]struct{})\n\tfor _, segment := range h.parentBlock.Segments {\n\t\tfor _, token := range segment {\n\t\t\tfiles[token.File] = struct{}{}\n\t\t}\n\t}\n\t// then convert the set into a slice\n\tfilesSlice := make([]string, 0, len(files))\n\tfor file := range files {\n\t\tfilesSlice = append(filesSlice, file)\n\t}\n\tsort.Strings(filesSlice)\n\treturn filesSlice\n}\n\n// JSON converts val into JSON. Any errors are added to warnings.\nfunc (h Helper) JSON(val any) json.RawMessage {\n\treturn caddyconfig.JSON(val, h.warnings)\n}\n\n// MatcherToken assumes the next argument token is (possibly) a matcher,\n// and if so, returns the matcher set along with a true value. If the next\n// token is not a matcher, nil and false is returned. Note that a true\n// value may be returned with a nil matcher set if it is a catch-all.\nfunc (h Helper) MatcherToken() (caddy.ModuleMap, bool, error) {\n\tif !h.NextArg() {\n\t\treturn nil, false, nil\n\t}\n\treturn matcherSetFromMatcherToken(h.Dispenser.Token(), h.matcherDefs, h.warnings)\n}\n\n// ExtractMatcherSet is like MatcherToken, except this is a higher-level\n// method that returns the matcher set described by the matcher token,\n// or nil if there is none, and deletes the matcher token from the\n// dispenser and resets it as if this look-ahead never happened. Useful\n// when wrapping a route (one or more handlers) in a user-defined matcher.\nfunc (h Helper) ExtractMatcherSet() (caddy.ModuleMap, error) {\n\tmatcherSet, hasMatcher, err := h.MatcherToken()\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\tif hasMatcher {\n\t\t// strip matcher token; we don't need to\n\t\t// use the return value here because a\n\t\t// new dispenser should have been made\n\t\t// solely for this directive's tokens,\n\t\t// with no other uses of same slice\n\t\th.Dispenser.Delete()\n\t}\n\th.Dispenser.Reset() // pretend this lookahead never happened\n\treturn matcherSet, nil\n}\n\n// NewRoute returns config values relevant to creating a new HTTP route.\nfunc (h Helper) NewRoute(matcherSet caddy.ModuleMap,\n\thandler caddyhttp.MiddlewareHandler,\n) []ConfigValue {\n\tmod, err := caddy.GetModule(caddy.GetModuleID(handler))\n\tif err != nil {\n\t\t*h.warnings = append(*h.warnings, caddyconfig.Warning{\n\t\t\tFile:    h.File(),\n\t\t\tLine:    h.Line(),\n\t\t\tMessage: err.Error(),\n\t\t})\n\t\treturn nil\n\t}\n\tvar matcherSetsRaw []caddy.ModuleMap\n\tif matcherSet != nil {\n\t\tmatcherSetsRaw = append(matcherSetsRaw, matcherSet)\n\t}\n\treturn []ConfigValue{\n\t\t{\n\t\t\tClass: \"route\",\n\t\t\tValue: caddyhttp.Route{\n\t\t\t\tMatcherSetsRaw: matcherSetsRaw,\n\t\t\t\tHandlersRaw:    []json.RawMessage{caddyconfig.JSONModuleObject(handler, \"handler\", mod.ID.Name(), h.warnings)},\n\t\t\t},\n\t\t},\n\t}\n}\n\n// GroupRoutes adds the routes (caddyhttp.Route type) in vals to the\n// same group, if there is more than one route in vals.\nfunc (h Helper) GroupRoutes(vals []ConfigValue) {\n\t// ensure there's at least two routes; group of one is pointless\n\tvar count int\n\tfor _, v := range vals {\n\t\tif _, ok := v.Value.(caddyhttp.Route); ok {\n\t\t\tcount++\n\t\t\tif count > 1 {\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\tif count < 2 {\n\t\treturn\n\t}\n\n\t// now that we know the group will have some effect, do it\n\tgroupName := h.groupCounter.nextGroup()\n\tfor i := range vals {\n\t\tif route, ok := vals[i].Value.(caddyhttp.Route); ok {\n\t\t\troute.Group = groupName\n\t\t\tvals[i].Value = route\n\t\t}\n\t}\n}\n\n// WithDispenser returns a new instance based on d. All others Helper\n// fields are copied, so typically maps are shared with this new instance.\nfunc (h Helper) WithDispenser(d *caddyfile.Dispenser) Helper {\n\th.Dispenser = d\n\treturn h\n}\n\n// ParseSegmentAsSubroute parses the segment such that its subdirectives\n// are themselves treated as directives, from which a subroute is built\n// and returned.\nfunc ParseSegmentAsSubroute(h Helper) (caddyhttp.MiddlewareHandler, error) {\n\tallResults, err := parseSegmentAsConfig(h)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\treturn buildSubroute(allResults, h.groupCounter, true)\n}\n\n// parseSegmentAsConfig parses the segment such that its subdirectives\n// are themselves treated as directives, including named matcher definitions,\n// and the raw Config structs are returned.\nfunc parseSegmentAsConfig(h Helper) ([]ConfigValue, error) {\n\tvar allResults []ConfigValue\n\n\tfor h.Next() {\n\t\t// don't allow non-matcher args on the first line\n\t\tif h.NextArg() {\n\t\t\treturn nil, h.ArgErr()\n\t\t}\n\n\t\t// slice the linear list of tokens into top-level segments\n\t\tvar segments []caddyfile.Segment\n\t\tfor nesting := h.Nesting(); h.NextBlock(nesting); {\n\t\t\tsegments = append(segments, h.NextSegment())\n\t\t}\n\n\t\t// copy existing matcher definitions so we can augment\n\t\t// new ones that are defined only in this scope\n\t\tmatcherDefs := make(map[string]caddy.ModuleMap, len(h.matcherDefs))\n\t\tmaps.Copy(matcherDefs, h.matcherDefs)\n\n\t\t// find and extract any embedded matcher definitions in this scope\n\t\tfor i := 0; i < len(segments); i++ {\n\t\t\tseg := segments[i]\n\t\t\tif strings.HasPrefix(seg.Directive(), matcherPrefix) {\n\t\t\t\t// parse, then add the matcher to matcherDefs\n\t\t\t\terr := parseMatcherDefinitions(caddyfile.NewDispenser(seg), matcherDefs)\n\t\t\t\tif err != nil {\n\t\t\t\t\treturn nil, err\n\t\t\t\t}\n\t\t\t\t// remove the matcher segment (consumed), then step back the loop\n\t\t\t\tsegments = append(segments[:i], segments[i+1:]...)\n\t\t\t\ti--\n\t\t\t}\n\t\t}\n\n\t\t// with matchers ready to go, evaluate each directive's segment\n\t\tfor _, seg := range segments {\n\t\t\tdir := seg.Directive()\n\t\t\tdirFunc, ok := registeredDirectives[dir]\n\t\t\tif !ok {\n\t\t\t\treturn nil, h.Errf(\"unrecognized directive: %s - are you sure your Caddyfile structure (nesting and braces) is correct?\", dir)\n\t\t\t}\n\n\t\t\tsubHelper := h\n\t\t\tsubHelper.Dispenser = caddyfile.NewDispenser(seg)\n\t\t\tsubHelper.matcherDefs = matcherDefs\n\n\t\t\tresults, err := dirFunc(subHelper)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, h.Errf(\"parsing caddyfile tokens for '%s': %v\", dir, err)\n\t\t\t}\n\n\t\t\tdir = normalizeDirectiveName(dir)\n\n\t\t\tfor _, result := range results {\n\t\t\t\tresult.directive = dir\n\t\t\t\tallResults = append(allResults, result)\n\t\t\t}\n\t\t}\n\t}\n\n\treturn allResults, nil\n}\n\n// ConfigValue represents a value to be added to the final\n// configuration, or a value to be consulted when building\n// the final configuration.\ntype ConfigValue struct {\n\t// The kind of value this is. As the config is\n\t// being built, the adapter will look in the\n\t// \"pile\" for values belonging to a certain\n\t// class when it is setting up a certain part\n\t// of the config. The associated value will be\n\t// type-asserted and placed accordingly.\n\tClass string\n\n\t// The value to be used when building the config.\n\t// Generally its type is associated with the\n\t// name of the Class.\n\tValue any\n\n\tdirective string\n}\n\nfunc sortRoutes(routes []ConfigValue) {\n\tdirPositions := make(map[string]int)\n\tfor i, dir := range directiveOrder {\n\t\tdirPositions[dir] = i\n\t}\n\n\tsort.SliceStable(routes, func(i, j int) bool {\n\t\t// if the directives are different, just use the established directive order\n\t\tiDir, jDir := routes[i].directive, routes[j].directive\n\t\tif iDir != jDir {\n\t\t\treturn dirPositions[iDir] < dirPositions[jDir]\n\t\t}\n\n\t\t// directives are the same; sub-sort by path matcher length if there's\n\t\t// only one matcher set and one path (this is a very common case and\n\t\t// usually -- but not always -- helpful/expected, oh well; user can\n\t\t// always take manual control of order using handler or route blocks)\n\t\tiRoute, ok := routes[i].Value.(caddyhttp.Route)\n\t\tif !ok {\n\t\t\treturn false\n\t\t}\n\t\tjRoute, ok := routes[j].Value.(caddyhttp.Route)\n\t\tif !ok {\n\t\t\treturn false\n\t\t}\n\n\t\t// decode the path matchers if there is just one matcher set\n\t\tvar iPM, jPM caddyhttp.MatchPath\n\t\tif len(iRoute.MatcherSetsRaw) == 1 {\n\t\t\t_ = json.Unmarshal(iRoute.MatcherSetsRaw[0][\"path\"], &iPM)\n\t\t}\n\t\tif len(jRoute.MatcherSetsRaw) == 1 {\n\t\t\t_ = json.Unmarshal(jRoute.MatcherSetsRaw[0][\"path\"], &jPM)\n\t\t}\n\n\t\t// if there is only one path in the path matcher, sort by longer path\n\t\t// (more specific) first; missing path matchers or multi-matchers are\n\t\t// treated as zero-length paths\n\t\tvar iPathLen, jPathLen int\n\t\tif len(iPM) == 1 {\n\t\t\tiPathLen = len(iPM[0])\n\t\t}\n\t\tif len(jPM) == 1 {\n\t\t\tjPathLen = len(jPM[0])\n\t\t}\n\n\t\tsortByPath := func() bool {\n\t\t\t// we can only confidently compare path lengths if both\n\t\t\t// directives have a single path to match (issue #5037)\n\t\t\tif iPathLen > 0 && jPathLen > 0 {\n\t\t\t\t// trim the trailing wildcard if there is one\n\t\t\t\tiPathTrimmed := strings.TrimSuffix(iPM[0], \"*\")\n\t\t\t\tjPathTrimmed := strings.TrimSuffix(jPM[0], \"*\")\n\n\t\t\t\t// if both paths are the same except for a trailing wildcard,\n\t\t\t\t// sort by the shorter path first (which is more specific)\n\t\t\t\tif iPathTrimmed == jPathTrimmed {\n\t\t\t\t\treturn iPathLen < jPathLen\n\t\t\t\t}\n\n\t\t\t\t// we use the trimmed length to compare the paths\n\t\t\t\t// https://github.com/caddyserver/caddy/issues/7012#issuecomment-2870142195\n\t\t\t\t// credit to https://github.com/Hellio404\n\t\t\t\t// for sorts with many items, mixing matchers w/ and w/o wildcards will confuse the sort and result in incorrect orders\n\t\t\t\tiPathLen = len(iPathTrimmed)\n\t\t\t\tjPathLen = len(jPathTrimmed)\n\n\t\t\t\t// if both paths have the same length, sort lexically\n\t\t\t\t// https://github.com/caddyserver/caddy/pull/7015#issuecomment-2871993588\n\t\t\t\tif iPathLen == jPathLen {\n\t\t\t\t\treturn iPathTrimmed < jPathTrimmed\n\t\t\t\t}\n\n\t\t\t\t// sort most-specific (longest) path first\n\t\t\t\treturn iPathLen > jPathLen\n\t\t\t}\n\n\t\t\t// if both directives don't have a single path to compare,\n\t\t\t// sort whichever one has a matcher first; if both have\n\t\t\t// a matcher, sort equally (stable sort preserves order)\n\t\t\treturn len(iRoute.MatcherSetsRaw) > 0 && len(jRoute.MatcherSetsRaw) == 0\n\t\t}()\n\n\t\t// some directives involve setting values which can overwrite\n\t\t// each other, so it makes most sense to reverse the order so\n\t\t// that the least-specific matcher is first, allowing the last\n\t\t// matching one to win\n\t\tif iDir == \"vars\" {\n\t\t\treturn !sortByPath\n\t\t}\n\n\t\t// everything else is most-specific matcher first\n\t\treturn sortByPath\n\t})\n}\n\n// serverBlock pairs a Caddyfile server block with\n// a \"pile\" of config values, keyed by class name,\n// as well as its parsed keys for convenience.\ntype serverBlock struct {\n\tblock      caddyfile.ServerBlock\n\tpile       map[string][]ConfigValue // config values obtained from directives\n\tparsedKeys []Address\n}\n\n// hostsFromKeys returns a list of all the non-empty hostnames found in\n// the keys of the server block sb. If logger mode is false, a key with\n// an empty hostname portion will return an empty slice, since that\n// server block is interpreted to effectively match all hosts. An empty\n// string is never added to the slice.\n//\n// If loggerMode is true, then the non-standard ports of keys will be\n// joined to the hostnames. This is to effectively match the Host\n// header of requests that come in for that key.\n//\n// The resulting slice is not sorted but will never have duplicates.\nfunc (sb serverBlock) hostsFromKeys(loggerMode bool) []string {\n\t// ensure each entry in our list is unique\n\thostMap := make(map[string]struct{})\n\tfor _, addr := range sb.parsedKeys {\n\t\tif addr.Host == \"\" {\n\t\t\tif !loggerMode {\n\t\t\t\t// server block contains a key like \":443\", i.e. the host portion\n\t\t\t\t// is empty / catch-all, which means to match all hosts\n\t\t\t\treturn []string{}\n\t\t\t}\n\t\t\t// never append an empty string\n\t\t\tcontinue\n\t\t}\n\t\tif loggerMode &&\n\t\t\taddr.Port != \"\" &&\n\t\t\taddr.Port != strconv.Itoa(caddyhttp.DefaultHTTPPort) &&\n\t\t\taddr.Port != strconv.Itoa(caddyhttp.DefaultHTTPSPort) {\n\t\t\thostMap[net.JoinHostPort(addr.Host, addr.Port)] = struct{}{}\n\t\t} else {\n\t\t\thostMap[addr.Host] = struct{}{}\n\t\t}\n\t}\n\n\t// convert map to slice\n\tsblockHosts := make([]string, 0, len(hostMap))\n\tfor host := range hostMap {\n\t\tsblockHosts = append(sblockHosts, host)\n\t}\n\n\treturn sblockHosts\n}\n\nfunc (sb serverBlock) hostsFromKeysNotHTTP(httpPort string) []string {\n\t// ensure each entry in our list is unique\n\thostMap := make(map[string]struct{})\n\tfor _, addr := range sb.parsedKeys {\n\t\tif addr.Host == \"\" {\n\t\t\tcontinue\n\t\t}\n\t\tif addr.Scheme != \"http\" && addr.Port != httpPort {\n\t\t\thostMap[addr.Host] = struct{}{}\n\t\t}\n\t}\n\n\t// convert map to slice\n\tsblockHosts := make([]string, 0, len(hostMap))\n\tfor host := range hostMap {\n\t\tsblockHosts = append(sblockHosts, host)\n\t}\n\n\treturn sblockHosts\n}\n\n// hasHostCatchAllKey returns true if sb has a key that\n// omits a host portion, i.e. it \"catches all\" hosts.\nfunc (sb serverBlock) hasHostCatchAllKey() bool {\n\treturn slices.ContainsFunc(sb.parsedKeys, func(addr Address) bool {\n\t\treturn addr.Host == \"\"\n\t})\n}\n\n// isAllHTTP returns true if all sb keys explicitly specify\n// the http:// scheme\nfunc (sb serverBlock) isAllHTTP() bool {\n\treturn !slices.ContainsFunc(sb.parsedKeys, func(addr Address) bool {\n\t\treturn addr.Scheme != \"http\"\n\t})\n}\n\n// Positional are the supported modes for ordering directives.\ntype Positional string\n\nconst (\n\tBefore Positional = \"before\"\n\tAfter  Positional = \"after\"\n\tFirst  Positional = \"first\"\n\tLast   Positional = \"last\"\n)\n\ntype (\n\t// UnmarshalFunc is a function which can unmarshal Caddyfile\n\t// tokens into zero or more config values using a Helper type.\n\t// These are passed in a call to RegisterDirective.\n\tUnmarshalFunc func(h Helper) ([]ConfigValue, error)\n\n\t// UnmarshalHandlerFunc is like UnmarshalFunc, except the\n\t// output of the unmarshaling is an HTTP handler. This\n\t// function does not need to deal with HTTP request matching\n\t// which is abstracted away. Since writing HTTP handlers\n\t// with Caddyfile support is very common, this is a more\n\t// convenient way to add a handler to the chain since a lot\n\t// of the details common to HTTP handlers are taken care of\n\t// for you. These are passed to a call to\n\t// RegisterHandlerDirective.\n\tUnmarshalHandlerFunc func(h Helper) (caddyhttp.MiddlewareHandler, error)\n\n\t// UnmarshalGlobalFunc is a function which can unmarshal Caddyfile\n\t// tokens from a global option. It is passed the tokens to parse and\n\t// existing value from the previous instance of this global option\n\t// (if any). It returns the value to associate with this global option.\n\tUnmarshalGlobalFunc func(d *caddyfile.Dispenser, existingVal any) (any, error)\n)\n\nvar registeredDirectives = make(map[string]UnmarshalFunc)\n\nvar registeredGlobalOptions = make(map[string]UnmarshalGlobalFunc)\n",
    "source_file": "caddyconfig/httpcaddyfile/directives.go",
    "chunk_type": "code"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\npackage httpcaddyfile\n\nimport (\n\t\"fmt\"\n\t\"net\"\n\t\"net/netip\"\n\t\"reflect\"\n\t\"sort\"\n\t\"strconv\"\n\t\"strings\"\n\t\"unicode\"\n\n\t\"github.com/caddyserver/certmagic\"\n\n\t\"github.com/caddyserver/caddy/v2\"\n\t\"github.com/caddyserver/caddy/v2/caddyconfig/caddyfile\"\n\t\"github.com/caddyserver/caddy/v2/modules/caddyhttp\"\n)\n\n// mapAddressToProtocolToServerBlocks returns a map of listener address to list of server\n// blocks that will be served on that address. To do this, each server block is\n// expanded so that each one is considered individually, although keys of a\n// server block that share the same address stay grouped together so the config\n// isn't repeated unnecessarily. For example, this Caddyfile:\n//\n//\texample.com {\n//\t\tbind 127.0.0.1\n//\t}\n//\twww.example.com, example.net/path, localhost:9999 {\n//\t\tbind 127.0.0.1 1.2.3.4\n//\t}\n//\n// has two server blocks to start with. But expressed in this Caddyfile are\n// actually 4 listener addresses: 127.0.0.1:443, 1.2.3.4:443, 127.0.0.1:9999,\n// and 127.0.0.1:9999. This is because the bind directive is applied to each\n// key of its server block (specifying the host part), and each key may have\n// a different port. And we definitely need to be sure that a site which is\n// bound to be served on a specific interface is not served on others just\n// because that is more convenient: it would be a potential security risk\n// if the difference between interfaces means private vs. public.\n//\n// So what this function does for the example above is iterate each server\n// block, and for each server block, iterate its keys. For the first, it\n// finds one key (example.com) and determines its listener address\n// (127.0.0.1:443 - because of 'bind' and automatic HTTPS). It then adds\n// the listener address to the map value returned by this function, with\n// the first server block as one of its associations.\n//\n// It then iterates each key on the second server block and associates them\n// with one or more listener addresses. Indeed, each key in this block has\n// two listener addresses because of the 'bind' directive. Once we know\n// which addresses serve which keys, we can create a new server block for\n// each address containing the contents of the server block and only those\n// specific keys of the server block which use that address.\n//\n// It is possible and even likely that some keys in the returned map have\n// the exact same list of server blocks (i.e. they are identical). This\n// happens when multiple hosts are declared with a 'bind' directive and\n// the resulting listener addresses are not shared by any other server\n// block (or the other server blocks are exactly identical in their token\n// contents). This happens with our example above because 1.2.3.4:443\n// and 1.2.3.4:9999 are used exclusively with the second server block. This\n// repetition may be undesirable, so call consolidateAddrMappings() to map\n// multiple addresses to the same lists of server blocks (a many:many mapping).\n// (Doing this is essentially a map-reduce technique.)\nfunc (st *ServerType) mapAddressToProtocolToServerBlocks(originalServerBlocks []serverBlock,\n\toptions map[string]any,\n) (map[string]map[string][]serverBlock, error) {\n\taddrToProtocolToServerBlocks := map[string]map[string][]serverBlock{}\n\n\ttype keyWithParsedKey struct {\n\t\tkey       caddyfile.Token\n\t\tparsedKey Address\n\t}\n\n\tfor i, sblock := range originalServerBlocks {\n\t\t// within a server block, we need to map all the listener addresses\n\t\t// implied by the server block to the keys of the server block which\n\t\t// will be served by them; this has the effect of treating each\n\t\t// key of a server block as its own, but without having to repeat its\n\t\t// contents in cases where multiple keys really can be served together\n\t\taddrToProtocolToKeyWithParsedKeys := map[string]map[string][]keyWithParsedKey{}\n\t\tfor j, key := range sblock.block.Keys {\n\t\t\tparsedKey, err := ParseAddress(key.Text)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"parsing key: %v\", err)\n\t\t\t}\n\t\t\tparsedKey = parsedKey.Normalize()\n\n\t\t\t// a key can have multiple listener addresses if there are multiple\n\t\t\t// arguments to the 'bind' directive (although they will all have\n\t\t\t// the same port, since the port is defined by the key or is implicit\n\t\t\t// through automatic HTTPS)\n\t\t\tlisteners, err := st.listenersForServerBlockAddress(sblock, parsedKey, options)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"server block %d, key %d (%s): determining listener address: %v\", i, j, key.Text, err)\n\t\t\t}\n\n\t\t\t// associate this key with its protocols and each listener address served with them\n\t\t\tkwpk := keyWithParsedKey{key, parsedKey}\n\t\t\tfor addr, protocols := range listeners {\n\t\t\t\tprotocolToKeyWithParsedKeys, ok := addrToProtocolToKeyWithParsedKeys[addr]\n\t\t\t\tif !ok {\n\t\t\t\t\tprotocolToKeyWithParsedKeys = map[string][]keyWithParsedKey{}\n\t\t\t\t\taddrToProtocolToKeyWithParsedKeys[addr] = protocolToKeyWithParsedKeys\n\t\t\t\t}\n\n\t\t\t\t// an empty protocol indicates the default, a nil or empty value in the ListenProtocols array\n\t\t\t\tif len(protocols) == 0 {\n\t\t\t\t\tprotocols[\"\"] = struct{}{}\n\t\t\t\t}\n\t\t\t\tfor prot := range protocols {\n\t\t\t\t\tprotocolToKeyWithParsedKeys[prot] = append(\n\t\t\t\t\t\tprotocolToKeyWithParsedKeys[prot],\n\t\t\t\t\t\tkwpk)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// make a slice of the map keys so we can iterate in sorted order\n\t\taddrs := make([]string, 0, len(addrToProtocolToKeyWithParsedKeys))\n\t\tfor addr := range addrToProtocolToKeyWithParsedKeys {\n\t\t\taddrs = append(addrs, addr)\n\t\t}\n\t\tsort.Strings(addrs)\n\n\t\t// now that we know which addresses serve which keys of this\n\t\t// server block, we iterate that mapping and create a list of\n\t\t// new server blocks for each address where the keys of the\n\t\t// server block are only the ones which use the address; but\n\t\t// the contents (tokens) are of course the same\n\t\tfor _, addr := range addrs {\n\t\t\tprotocolToKeyWithParsedKeys := addrToProtocolToKeyWithParsedKeys[addr]\n\n\t\t\tprots := make([]string, 0, len(protocolToKeyWithParsedKeys))\n\t\t\tfor prot := range protocolToKeyWithParsedKeys {\n\t\t\t\tprots = append(prots, prot)\n\t\t\t}\n\t\t\tsort.Strings(prots)\n\n\t\t\tprotocolToServerBlocks, ok := addrToProtocolToServerBlocks[addr]\n\t\t\tif !ok {\n\t\t\t\tprotocolToServerBlocks = map[string][]serverBlock{}\n\t\t\t\taddrToProtocolToServerBlocks[addr] = protocolToServerBlocks\n\t\t\t}\n\n\t\t\tfor _, prot := range prots {\n\t\t\t\tkeyWithParsedKeys := protocolToKeyWithParsedKeys[prot]\n\n\t\t\t\tkeys := make([]caddyfile.Token, len(keyWithParsedKeys))\n\t\t\t\tparsedKeys := make([]Address, len(keyWithParsedKeys))\n\n\t\t\t\tfor k, keyWithParsedKey := range keyWithParsedKeys {\n\t\t\t\t\tkeys[k] = keyWithParsedKey.key\n\t\t\t\t\tparsedKeys[k] = keyWithParsedKey.parsedKey\n\t\t\t\t}\n\n\t\t\t\tprotocolToServerBlocks[prot] = append(protocolToServerBlocks[prot], serverBlock{\n\t\t\t\t\tblock: caddyfile.ServerBlock{\n\t\t\t\t\t\tKeys:     keys,\n\t\t\t\t\t\tSegments: sblock.block.Segments,\n\t\t\t\t\t},\n\t\t\t\t\tpile:       sblock.pile,\n\t\t\t\t\tparsedKeys: parsedKeys,\n\t\t\t\t})\n\t\t\t}\n\t\t}\n\t}\n\n\treturn addrToProtocolToServerBlocks, nil\n}\n\n// consolidateAddrMappings eliminates repetition of identical server blocks in a mapping of\n// single listener addresses to protocols to lists of server blocks. Since multiple addresses\n// may serve multiple protocols to identical sites (server block contents), this function turns\n// a 1:many mapping into a many:many mapping. Server block contents (tokens) must be\n// exactly identical so that reflect.DeepEqual returns true in order for the addresses to be combined.\n// Identical entries are deleted from the addrToServerBlocks map. Essentially, each pairing (each\n// association from multiple addresses to multiple server blocks; i.e. each element of\n// the returned slice) becomes a server definition in the output JSON.\nfunc (st *ServerType) consolidateAddrMappings(addrToProtocolToServerBlocks map[string]map[string][]serverBlock) []sbAddrAssociation {\n\tsbaddrs := make([]sbAddrAssociation, 0, len(addrToProtocolToServerBlocks))\n\n\taddrs := make([]string, 0, len(addrToProtocolToServerBlocks))\n\tfor addr := range addrToProtocolToServerBlocks {\n\t\taddrs = append(addrs, addr)\n\t}\n\tsort.Strings(addrs)\n\n\tfor _, addr := range addrs {\n\t\tprotocolToServerBlocks := addrToProtocolToServerBlocks[addr]\n\n\t\tprots := make([]string, 0, len(protocolToServerBlocks))\n\t\tfor prot := range protocolToServerBlocks {\n\t\t\tprots = append(prots, prot)\n\t\t}\n\t\tsort.Strings(prots)\n\n\t\tfor _, prot := range prots {\n\t\t\tserverBlocks := protocolToServerBlocks[prot]\n\n\t\t\t// now find other addresses that map to identical\n\t\t\t// server blocks and add them to our map of listener\n\t\t\t// addresses and protocols, while removing them from\n\t\t\t// the original map\n\t\t\tlisteners := map[string]map[string]struct{}{}\n\n\t\t\tfor otherAddr, otherProtocolToServerBlocks := range addrToProtocolToServerBlocks {\n\t\t\t\tfor otherProt, otherServerBlocks := range otherProtocolToServerBlocks {\n\t\t\t\t\tif addr == otherAddr && prot == otherProt || reflect.DeepEqual(serverBlocks, otherServerBlocks) {\n\t\t\t\t\t\tlistener, ok := listeners[otherAddr]\n\t\t\t\t\t\tif !ok {\n\t\t\t\t\t\t\tlistener = map[string]struct{}{}\n\t\t\t\t\t\t\tlisteners[otherAddr] = listener\n\t\t\t\t\t\t}\n\t\t\t\t\t\tlistener[otherProt] = struct{}{}\n\t\t\t\t\t\tdelete(otherProtocolToServerBlocks, otherProt)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\taddresses := make([]string, 0, len(listeners))\n\t\t\tfor lnAddr := range listeners {\n\t\t\t\taddresses = append(addresses, lnAddr)\n\t\t\t}\n\t\t\tsort.Strings(addresses)\n\n\t\t\taddressesWithProtocols := make([]addressWithProtocols, 0, len(listeners))\n\n\t\t\tfor _, lnAddr := range addresses {\n\t\t\t\tlnProts := listeners[lnAddr]\n\t\t\t\tprots := make([]string, 0, len(lnProts))\n\t\t\t\tfor prot := range lnProts {\n\t\t\t\t\tprots = append(prots, prot)\n\t\t\t\t}\n\t\t\t\tsort.Strings(prots)\n\n\t\t\t\taddressesWithProtocols = append(addressesWithProtocols, addressWithProtocols{\n\t\t\t\t\taddress:   lnAddr,\n\t\t\t\t\tprotocols: prots,\n\t\t\t\t})\n\t\t\t}\n\n\t\t\tsbaddrs = append(sbaddrs, sbAddrAssociation{\n\t\t\t\taddressesWithProtocols: addressesWithProtocols,\n\t\t\t\tserverBlocks:           serverBlocks,\n\t\t\t})\n\t\t}\n\t}\n\n\treturn sbaddrs\n}\n\n// listenersForServerBlockAddress essentially converts the Caddyfile site addresses to a map from\n// Caddy listener addresses and the protocols to serve them with to the parsed address for each server block.\nfunc (st *ServerType) listenersForServerBlockAddress(sblock serverBlock, addr Address,\n\toptions map[string]any,\n) (map[string]map[string]struct{}, error) {\n\tswitch addr.Scheme {\n\tcase \"wss\":\n\t\treturn nil, fmt.Errorf(\"the scheme wss:// is only supported in browsers; use https:// instead\")\n\tcase \"ws\":\n\t\treturn nil, fmt.Errorf(\"the scheme ws:// is only supported in browsers; use http:// instead\")\n\tcase \"https\", \"http\", \"\":\n\t\t// Do nothing or handle the valid schemes\n\tdefault:\n\t\treturn nil, fmt.Errorf(\"unsupported URL scheme %s://\", addr.Scheme)\n\t}\n\n\t// figure out the HTTP and HTTPS ports; either\n\t// use defaults, or override with user config\n\thttpPort, httpsPort := strconv.Itoa(caddyhttp.DefaultHTTPPort), strconv.Itoa(caddyhttp.DefaultHTTPSPort)\n\tif hport, ok := options[\"http_port\"]; ok {\n\t\thttpPort = strconv.Itoa(hport.(int))\n\t}\n\tif hsport, ok := options[\"https_port\"]; ok {\n\t\thttpsPort = strconv.Itoa(hsport.(int))\n\t}\n\n\t// default port is the HTTPS port\n\tlnPort := httpsPort\n\tif addr.Port != \"\" {\n\t\t// port explicitly defined\n\t\tlnPort = addr.Port\n\t} else if addr.Scheme == \"http\" {\n\t\t// port inferred from scheme\n\t\tlnPort = httpPort\n\t}\n\n\t// error if scheme and port combination violate convention\n\tif (addr.Scheme == \"http\" && lnPort == httpsPort) || (addr.Scheme == \"https\" && lnPort == httpPort) {\n\t\treturn nil, fmt.Errorf(\"[%s] scheme and port violate convention\", addr.String())\n\t}\n\n\t// the bind directive specifies hosts (and potentially network), and the protocols to serve them with, but is optional\n\tlnCfgVals := make([]addressesWithProtocols, 0, len(sblock.pile[\"bind\"]))\n\tfor _, cfgVal := range sblock.pile[\"bind\"] {\n\t\tif val, ok := cfgVal.Value.(addressesWithProtocols); ok {\n\t\t\tlnCfgVals = append(lnCfgVals, val)\n\t\t}\n\t}\n\tif len(lnCfgVals) == 0 {\n\t\tif defaultBindValues, ok := options[\"default_bind\"].([]ConfigValue); ok {\n\t\t\tfor _, defaultBindValue := range defaultBindValues {\n\t\t\t\tlnCfgVals = append(lnCfgVals, defaultBindValue.Value.(addressesWithProtocols))\n\t\t\t}\n\t\t} else {\n\t\t\tlnCfgVals = []addressesWithProtocols{{\n\t\t\t\taddresses: []string{\"\"},\n\t\t\t\tprotocols: nil,\n\t\t\t}}\n\t\t}\n\t}\n\n\t// use a map to prevent duplication\n\tlisteners := map[string]map[string]struct{}{}\n\tfor _, lnCfgVal := range lnCfgVals {\n\t\tfor _, lnAddr := range lnCfgVal.addresses {\n\t\t\tlnNetw, lnHost, _, err := caddy.SplitNetworkAddress(lnAddr)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"splitting listener address: %v\", err)\n\t\t\t}\n\t\t\tnetworkAddr, err := caddy.ParseNetworkAddress(caddy.JoinNetworkAddress(lnNetw, lnHost, lnPort))\n\t\t\tif err != nil {\n\t\t\t\treturn nil, fmt.Errorf(\"parsing network address: %v\", err)\n\t\t\t}\n\t\t\tif _, ok := listeners[addr.String()]; !ok {\n\t\t\t\tlisteners[networkAddr.String()] = map[string]struct{}{}\n\t\t\t}\n\t\t\tfor _, protocol := range lnCfgVal.protocols {\n\t\t\t\tlisteners[networkAddr.String()][protocol] = struct{}{}\n\t\t\t}\n\t\t}\n\t}\n\n\treturn listeners, nil\n}\n\n// addressesWithProtocols associates a list of listen addresses\n// with a list of protocols to serve them with\ntype addressesWithProtocols struct {\n\taddresses []string\n\tprotocols []string\n}\n\n// Address represents a site address. It contains\n// the original input value, and the component\n// parts of an address. The component parts may be\n// updated to the correct values as setup proceeds,\n// but the original value should never be changed.\n//\n// The Host field must be in a normalized form.\ntype Address struct {\n\tOriginal, Scheme, Host, Port, Path string\n}\n\n// ParseAddress parses an address string into a structured format with separate\n// scheme, host, port, and path portions, as well as the original input string.\nfunc ParseAddress(str string) (Address, error) {\n\tconst maxLen = 4096\n\tif len(str) > maxLen {\n\t\tstr = str[:maxLen]\n\t}\n\tremaining := strings.TrimSpace(str)\n\ta := Address{Original: remaining}\n\n\t// extract scheme\n\tsplitScheme := strings.SplitN(remaining, \"://\", 2)\n\tswitch len(splitScheme) {\n\tcase 0:\n\t\treturn a, nil\n\tcase 1:\n\t\tremaining = splitScheme[0]\n\tcase 2:\n\t\ta.Scheme = splitScheme[0]\n\t\tremaining = splitScheme[1]\n\t}\n\n\t// extract host and port\n\thostSplit := strings.SplitN(remaining, \"/\", 2)\n\tif len(hostSplit) > 0 {\n\t\thost, port, err := net.SplitHostPort(hostSplit[0])\n\t\tif err != nil {\n\t\t\thost, port, err = net.SplitHostPort(hostSplit[0] + \":\")\n\t\t\tif err != nil {\n\t\t\t\thost = hostSplit[0]\n\t\t\t}\n\t\t}\n\t\ta.Host = host\n\t\ta.Port = port\n\t}\n\tif len(hostSplit) == 2 {\n\t\t// all that remains is the path\n\t\ta.Path = \"/\" + hostSplit[1]\n\t}\n\n\t// make sure port is valid\n\tif a.Port != \"\" {\n\t\tif portNum, err := strconv.Atoi(a.Port); err != nil {\n\t\t\treturn Address{}, fmt.Errorf(\"invalid port '%s': %v\", a.Port, err)\n\t\t} else if portNum < 0 || portNum > 65535 {\n\t\t\treturn Address{}, fmt.Errorf(\"port %d is out of range\", portNum)\n\t\t}\n\t}\n\n\treturn a, nil\n}\n\n// String returns a human-readable form of a. It will\n// be a cleaned-up and filled-out URL string.\nfunc (a Address) String() string {\n\tif a.Host == \"\" && a.Port == \"\" {\n\t\treturn \"\"\n\t}\n\tscheme := a.Scheme\n\tif scheme == \"\" {\n\t\tif a.Port == strconv.Itoa(certmagic.HTTPSPort) {\n\t\t\tscheme = \"https\"\n\t\t} else {\n\t\t\tscheme = \"http\"\n\t\t}\n\t}\n\ts := scheme\n\tif s != \"\" {\n\t\ts += \"://\"\n\t}\n\tif a.Port != \"\" &&\n\t\t((scheme == \"https\" && a.Port != strconv.Itoa(caddyhttp.DefaultHTTPSPort)) ||\n\t\t\t(scheme == \"http\" && a.Port != strconv.Itoa(caddyhttp.DefaultHTTPPort))) {\n\t\ts += net.JoinHostPort(a.Host, a.Port)\n\t} else {\n\t\ts += a.Host\n\t}\n\tif a.Path != \"\" {\n\t\ts += a.Path\n\t}\n\treturn s\n}\n\n// Normalize returns a normalized version of a.\nfunc (a Address) Normalize() Address {\n\tpath := a.Path\n\n\t// ensure host is normalized if it's an IP address\n\thost := strings.TrimSpace(a.Host)\n\tif ip, err := netip.ParseAddr(host); err == nil {\n\t\tif ip.Is6() && !ip.Is4() && !ip.Is4In6() {\n\t\t\thost = ip.String()\n\t\t}\n\t}\n\n\treturn Address{\n\t\tOriginal: a.Original,\n\t\tScheme:   lowerExceptPlaceholders(a.Scheme),\n\t\tHost:     lowerExceptPlaceholders(host),\n\t\tPort:     a.Port,\n\t\tPath:     path,\n\t}\n}\n\n// lowerExceptPlaceholders lowercases s except within\n// placeholders (substrings in non-escaped '{ }' spans).\n// See https://github.com/caddyserver/caddy/issues/3264\nfunc lowerExceptPlaceholders(s string) string {\n\tvar sb strings.Builder\n\tvar escaped, inPlaceholder bool\n\tfor _, ch := range s {\n\t\tif ch == '\\\\' && !escaped {\n\t\t\tescaped = true\n\t\t\tsb.WriteRune(ch)\n\t\t\tcontinue\n\t\t}\n\t\tif ch == '{' && !escaped {\n\t\t\tinPlaceholder = true\n\t\t}\n\t\tif ch == '}' && inPlaceholder && !escaped {\n\t\t\tinPlaceholder = false\n\t\t}\n\t\tif inPlaceholder {\n\t\t\tsb.WriteRune(ch)\n\t\t} else {\n\t\t\tsb.WriteRune(unicode.ToLower(ch))\n\t\t}\n\t\tescaped = false\n\t}\n\treturn sb.String()\n}\n",
    "source_file": "caddyconfig/httpcaddyfile/addresses.go",
    "chunk_type": "code"
  },
  {
    "content": "#!/bin/sh\n\n# USAGE:\n# \tgo run -exec ./setcap.sh main.go <args...>\n#\n# (Example: `go run -exec ./setcap.sh main.go run --config caddy.json`)\n#\n# For some reason this does not work on my Arch system, so if you find that's\n# the case, you can instead do:\n#\n# \tgo build && ./setcap.sh ./caddy <args...>\n#\n# but this will leave the ./caddy binary laying around.\n#\n\nsudo setcap cap_net_bind_service=+ep \"$1\"\n\"$@\"\n",
    "source_file": "cmd/caddy/setcap.sh",
    "chunk_type": "unknown"
  },
  {
    "content": "// Copyright 2015 Matthew Holt and The Caddy Authors\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//     http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n// Package main is the entry point of the Caddy application.\n// Most of Caddy's functionality is provided through modules,\n// which can be plugged in by adding their import below.\n//\n// There is no need to modify the Caddy source code to customize your\n// builds. You can easily build a custom Caddy with these simple steps:\n//\n//  1. Copy this file (main.go) into a new folder\n//  2. Edit the imports below to include the modules you want plugged in\n//  3. Run `go mod init caddy`\n//  4. Run `go install` or `go build` - you now have a custom binary!\n//\n// Or you can use xcaddy which does it all for you as a command:\n// https://github.com/caddyserver/xcaddy\npackage main\n\nimport (\n\tcaddycmd \"github.com/caddyserver/caddy/v2/cmd\"\n\n\t// plug in Caddy modules here\n\t_ \"github.com/caddyserver/caddy/v2/modules/standard\"\n)\n\nfunc main() {\n\tcaddycmd.Main()\n}\n",
    "source_file": "cmd/caddy/main.go",
    "chunk_type": "code"
  }
]